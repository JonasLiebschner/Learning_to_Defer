{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c923862-4c78-46d2-87e8-a617e07c32d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 06:48:57.593669: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import sklearn\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "#import Verma.experts as vexp\n",
    "import Verma.losses as vlos\n",
    "from Verma.utils import AverageMeter, accuracy\n",
    "import Verma.resnet50 as vres\n",
    "from AL.utils import *\n",
    "from AL.metrics import *\n",
    "\n",
    "import Dataset.Dataset as ds\n",
    "\n",
    "import ssl_functions as ssl\n",
    "import active_learning as al\n",
    "from active_learning import NIHExpertDatasetMemory\n",
    "\n",
    "import expert as expert_module\n",
    "import verma as verm\n",
    "import hemmer as hm\n",
    "\n",
    "import neptune\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9104208e-aaa1-40e2-b3c6-1058f92fd31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed, fold=None, text=None):\n",
    "    if fold is not None and text is not None:\n",
    "        s = text + f\" + {seed} + {fold}\"\n",
    "        seed = int(hashlib.sha256(s.encode('utf-8')).hexdigest(), 16) % 10**8\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e071303-6599-454d-a430-c2b39165f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "import json\n",
    "\n",
    "with open('neptune_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config_neptune = config[\"neptune\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc80118e-ff9d-491c-b393-94569d4e4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def cleanTrainDir(path):\n",
    "    shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6272b79-d261-46c6-bc8e-d5b6fa8dc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertModelSSL_AL(dataManager, expert, labelerId, param=None, seed=None, fold=None, learning_mod=\"ssl\", prediction_type=\"target\"):\n",
    "\n",
    "    if param[\"SETTING\"] == \"SSL_AL_SSL\":\n",
    "        learning_type = \"ssl\"\n",
    "    elif param[\"SETTING\"] == \"SSL_AL\":\n",
    "        learning_type = \"sl\"\n",
    "\n",
    "    assert learning_type != \"\", \"Need to define how experts should be trained with new AL data (sl or ssl)\"\n",
    "    \n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "    train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "    usedFilenames = sslDataset.getLabeledFilenames(labelerId, fold)\n",
    "    \n",
    "    # initialize data, Erhält alle Indizes der Daten\n",
    "    all_indices = list(range(len(train_dataset.getAllIndices())))\n",
    "    all_data_filenames = np.array(train_dataset.getAllFilenames())[all_indices]\n",
    "    all_data_y = np.array(train_dataset.getAllTargets())[all_indices]\n",
    "\n",
    "    used_indices = [index for index in all_indices if all_data_filenames[index] in usedFilenames]\n",
    "    indices = used_indices\n",
    "\n",
    "    print(\"Len overlapping used indices: \" + str(len(used_indices)))\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "    metrics[\"Val\"] = {\n",
    "        \"Start\": met,\n",
    "    }\n",
    "\n",
    "    met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "    metrics[\"Test\"] = {\n",
    "        \"Start\": met,\n",
    "    }\n",
    "\n",
    "    metrics[\"Train\"] = {}\n",
    "\n",
    "    set_seed(seed, fold, text=\"\")\n",
    "    \n",
    "    Intial_random_set = indices\n",
    "    indices_labeled  = Intial_random_set\n",
    "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "    # Lädt die Datasets für die beschrifteten und unbeschrifteten Daten\n",
    "    dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], None , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataset_val_unlabeled = NIHExpertDatasetMemory(None, val_dataset.getAllFilenames(), np.array(val_dataset.getAllTargets()), expert.predict , [1]*len(val_dataset.getAllIndices()), val_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    \n",
    "    # Lädt die Dataloaders\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    dataLoaderValUnlabeled = DataLoader(dataset=dataset_val_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    \n",
    "    for round in range(param[\"AL\"][\"ROUNDS\"]):\n",
    "\n",
    "        print(f'\\n \\n Round {round} \\n \\n')\n",
    "\n",
    "        # get points where expert model is least confident on\n",
    "        indices_confidence = al.get_least_confident_points(expert, dataLoaderTrainUnlabeled, param[\"AL\"][\"LABELS_PER_ROUND\"], mod=\"ssl\")\n",
    "        indices_labeled  = indices_labeled + list(indices_confidence) \n",
    "        indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "        dataset_train_labeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_labeled], all_data_y[indices_labeled], expert.predict , [1]*len(indices_labeled), indices_labeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "        dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "\n",
    "        dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "\n",
    "        if learning_type == \"ssl\": #If the experts should be trained with ssl\n",
    "            sslDataset = dataManager.getSSLDataset(seed)\n",
    "            sslDataset.addNewLabels(all_data_filenames[list(indices_confidence)], fold, expert.labelerId)\n",
    "            emb_model, model = ssl.getExpertModelSSL(labelerId=expert.labelerId, sslDataset=sslDataset, seed=seed, fold_idx=fold, n_labeled=None, embedded_model=None, param=param, neptune_param=param[\"NEPTUNE\"], added_epochs=(round+1)*param[\"AL\"][\"SSL_EPOCHS\"])\n",
    "            expert.setModel(expert_module.SSLModel(emb_model, model), mod=\"SSL\")\n",
    "\n",
    "\n",
    "            #TODO: Test experts and get metrics\n",
    "            n_images = param[\"AL\"][\"INITIAL_SIZE\"] + (round+1)*param[\"AL\"][\"LABELS_PER_ROUND\"]\n",
    "\n",
    "            train_metrics = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderTrainLabeled, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, step=\"Train\", param=param, mod=\"ssl\", prediction_type=\"target\", print_result=False)\n",
    "            val_metrics = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderValUnlabeled, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, step=\"Val\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "\n",
    "            metrics[\"Train\"][n_images] = {\n",
    "                \"train_metrics\": train_metrics,\n",
    "                \"val_metrics\": val_metrics,\n",
    "            }\n",
    "\n",
    "        elif learning_type == \"sl\": #supervised learning\n",
    "        \n",
    "            # train model on labeled data\n",
    "            dataloaders = (dataLoaderTrainLabeled, dataLoaderValUnlabeled)\n",
    "            n_images = param[\"AL\"][\"INITIAL_SIZE\"] + (round+1)*param[\"AL\"][\"LABELS_PER_ROUND\"]\n",
    "            train_metrics, val_metrics = al.run_expert(model=None, expert=expert, epochs=param[\"AL\"][\"EPOCH_TRAIN\"], dataloaders=dataloaders, param=param, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, mod=\"ssl\", prediction_type=\"target\")\n",
    "        \n",
    "            metrics[\"Train\"][n_images] = {\n",
    "                \"train_metrics\": train_metrics,\n",
    "                \"val_metrics\": val_metrics,\n",
    "            }\n",
    "    \n",
    "    dataset_test_unlabeled = NIHExpertDatasetMemory(None, test_dataset.getAllFilenames(), np.array(test_dataset.getAllTargets()), expert.predict , [1]*len(test_dataset.getAllIndices()), test_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataLoaderVal = DataLoader(dataset=dataset_test_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    met_test = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderVal, id=expert.labelerId, seed=seed, fold=fold, n_images=param[\"AL\"][\"INITIAL_SIZE\"] + param[\"AL\"][\"ROUNDS\"]*param[\"AL\"][\"LABELS_PER_ROUND\"], step=\"Test\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "\n",
    "    met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "    metrics[\"Val\"][\"End\"] = met\n",
    "\n",
    "    met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "    metrics[\"Test\"][\"End\"] = met\n",
    "    \n",
    "    #metrics[\"Test\"] = met\n",
    "    print(\"AL finished\")\n",
    "    return met_test, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc438de-b6b0-463c-95ae-c62afdbbc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertModelsSSL_AL(dataManager, experts, param, seed, fold, learning_mod=\"ssl\", prediction_type=\"target\"):\n",
    "\n",
    "    if param[\"SETTING\"] == \"SSL_AL_SSL\":\n",
    "        learning_type = \"ssl\"\n",
    "    elif param[\"SETTING\"] == \"SSL_AL\":\n",
    "        learning_type = \"sl\"\n",
    "\n",
    "    assert learning_type != \"\", \"Need to define how experts should be trained with new AL data (sl or ssl)\"\n",
    "\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "    train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "    usedFilenames = []\n",
    "    for labelerId in param[\"LABELER_IDS\"]:\n",
    "        temp = usedFilenames + sslDataset.getLabeledFilenames(labelerId, fold)\n",
    "    usedFilenames = temp\n",
    "    \n",
    "    \n",
    "    # initialize data, Erhält alle Indizes der Daten\n",
    "    all_indices = list(range(len(train_dataset.getAllIndices())))\n",
    "    all_data_filenames = np.array(train_dataset.getAllFilenames())[all_indices]\n",
    "    all_data_y = np.array(train_dataset.getAllTargets())[all_indices]\n",
    "\n",
    "    unused_indices = [index for index in all_indices if all_data_filenames[index] not in usedFilenames]\n",
    "    \n",
    "    metrics = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        metrics[labelerId] = {}\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"] = {\n",
    "            \"Start\": met,\n",
    "        }\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"] = {\n",
    "            \"Start\": met,\n",
    "        }\n",
    "\n",
    "        metrics[labelerId][\"Train\"] = {}\n",
    "\n",
    "    set_seed(seed, fold, text=\"\")\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    indices_unlabeled = unused_indices\n",
    "    indices_labeled = list(set(all_indices) - set(indices_unlabeled))\n",
    "\n",
    "    dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], experts[param[\"LABELER_IDS\"][0]].predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    \n",
    "    for round in range(param[\"AL\"][\"ROUNDS\"]):\n",
    "\n",
    "        print(f'\\n \\n Round {round} \\n \\n')\n",
    "\n",
    "        #Try to get better Points\n",
    "        if param[\"MOD\"] == \"disagreement\":\n",
    "            indices_qbq = al.getQbQPoints(experts, dataLoaderTrainUnlabeled, param[\"AL\"][\"LABELS_PER_ROUND\"], mod=\"ssl\", param=param)\n",
    "        if param[\"MOD\"] == \"disagreement_diff\":\n",
    "            indices_qbq = al.getQbQPointsDifference(experts, dataLoaderTrainUnlabeled, param[\"AL\"][\"LABELS_PER_ROUND\"], mod=\"ssl\", param=param)\n",
    "        \n",
    "        #indices_labeled  = indices_labeled + list(indices_confidence) \n",
    "        indices_labeled  = indices_labeled + list(indices_qbq) \n",
    "        indices_unlabeled= list(set(all_indices) - set(indices_labeled))     \n",
    "        \n",
    "        # train model on labeled data\n",
    "        for labelerId, expert in experts.items():\n",
    "\n",
    "            #Val Dataset, needed for SSL and AL\n",
    "            dataset_val_unlabeled = NIHExpertDatasetMemory(None, val_dataset.getAllFilenames(), np.array(val_dataset.getAllTargets()), expert.predict , [1]*len(val_dataset.getAllIndices()), val_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "            dataLoaderValUnlabeled = DataLoader(dataset=dataset_val_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "\n",
    "            #Create train dataset\n",
    "            dataset_train_labeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_labeled], all_data_y[indices_labeled], expert.predict , [1]*len(indices_labeled), indices_labeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "            dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "\n",
    "            if learning_type == \"ssl\": #If the experts should be trained with ssl\n",
    "                sslDataset = dataManager.getSSLDataset(seed)\n",
    "                sslDataset.addNewLabels(all_data_filenames[list(indices_qbq)], fold, labelerId)\n",
    "                emb_model, model = ssl.getExpertModelSSL(labelerId=labelerId, sslDataset=sslDataset, seed=seed, fold_idx=fold, n_labeled=None, embedded_model=None, param=param, neptune_param=param[\"NEPTUNE\"], added_epochs=(round+1)*param[\"AL\"][\"SSL_EPOCHS\"])\n",
    "                experts[labelerId].setModel(expert_module.SSLModel(emb_model, model), mod=\"SSL\")\n",
    "\n",
    "\n",
    "                #TODO: Test experts and get metrics\n",
    "                n_images = param[\"AL\"][\"INITIAL_SIZE\"] + (round+1)*param[\"AL\"][\"LABELS_PER_ROUND\"]\n",
    "\n",
    "                train_metrics = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderTrainLabeled, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, step=\"Train\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "                val_metrics = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderValUnlabeled, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, step=\"Val\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "\n",
    "                metrics[labelerId][\"Train\"][n_images] = {\n",
    "                    \"train_metrics\": train_metrics,\n",
    "                    \"val_metrics\": val_metrics,\n",
    "                }\n",
    "\n",
    "                \n",
    "            elif learning_type == \"sl\": # If the experts sould be trained with supervised learning\n",
    "\n",
    "                dataloaders = (dataLoaderTrainLabeled, dataLoaderValUnlabeled)\n",
    "                n_images = param[\"AL\"][\"INITIAL_SIZE\"] + (round+1)*param[\"AL\"][\"LABELS_PER_ROUND\"]\n",
    "                train_metrics, val_metrics = al.run_expert(model=None, expert=expert, epochs=param[\"AL\"][\"EPOCH_TRAIN\"], dataloaders=dataloaders, param=param, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, mod=\"ssl\", prediction_type=\"target\")\n",
    "\n",
    "                metrics[labelerId][\"Train\"][n_images] = {\n",
    "                    \"train_metrics\": train_metrics,\n",
    "                    \"val_metrics\": val_metrics\n",
    "                }\n",
    "        \n",
    "        dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    \n",
    "    dataset_test_unlabeled = NIHExpertDatasetMemory(None, test_dataset.getAllFilenames(), np.array(test_dataset.getAllTargets()), expert.predict , [1]*len(test_dataset.getAllIndices()), test_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataLoaderVal = DataLoader(dataset=dataset_test_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    met_test = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        temp = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderVal, id=expert.labelerId, seed=seed, fold=fold, n_images=param[\"AL\"][\"INITIAL_SIZE\"] + param[\"AL\"][\"ROUNDS\"]*param[\"AL\"][\"LABELS_PER_ROUND\"], step=\"Test\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "        met_test[expert.labelerId] = temp\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"][\"End\"] = met\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"][\"End\"] = met\n",
    "        \n",
    "    return met_test, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be36f3a5-859c-4d0a-956c-8ec5b8f57383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsSSL_AL(dataManager, param, fold, seed):\n",
    "\n",
    "    mod = \"ssl\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    sslDataset.createLabeledIndices(labelerIds=param[\"LABELER_IDS\"], n_L=param[\"AL\"][\"INITIAL_SIZE\"], k=round(param[\"AL\"][\"INITIAL_SIZE\"]*param[\"OVERLAP\"]/100), seed=seed, sample_equal=param[\"SAMPLE_EQUAL\"])\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = sslDataset.get_data_loader_for_fold(fold)\n",
    "    dataloaders = (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "    embedded_model = ssl.create_embedded_model(dataloaders, param, param[\"NEPTUNE\"], fold=fold, seed=seed)\n",
    "\n",
    "    experts = {}\n",
    "    for labelerId in param[\"LABELER_IDS\"]:\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId)\n",
    "        emb_model, model = ssl.getExpertModelSSL(labelerId=labelerId, sslDataset=sslDataset, seed=seed, fold_idx=fold, n_labeled=None, embedded_model=embedded_model, param=param, neptune_param=param[\"NEPTUNE\"])\n",
    "        nih_expert.setModel(expert_module.SSLModel(emb_model, model), mod=\"SSL\")\n",
    "        experts[labelerId] = nih_expert\n",
    "    metrics = {}\n",
    "    if param[\"MOD\"] == \"confidence\":\n",
    "        for i, labelerId in enumerate(param[\"LABELER_IDS\"]):\n",
    "            met, metrics_return = getExpertModelSSL_AL(dataManager=dataManager, expert=experts[labelerId], labelerId=labelerId, param=param, seed=seed, fold=fold, learning_mod=\"ssl\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "            metrics[labelerId] = metrics_return\n",
    "    elif param[\"MOD\"] == \"disagreement\" or param[\"MOD\"] == \"disagreement_diff\":\n",
    "        met, metrics = getExpertModelsSSL_AL(dataManager, experts, param, seed, fold, learning_mod=\"ssl\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "        \n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff5079e-b28c-42c8-a5e0-379f31fdd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsSSL(dataManager, param, fold, seed):\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    mod = \"ssl\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    sslDataset.createLabeledIndices(labelerIds=param[\"LABELER_IDS\"], n_L=param[\"LABELED\"], k=round(param[\"LABELED\"]*param[\"OVERLAP\"]/100), seed=seed, sample_equal=param[\"SAMPLE_EQUAL\"])\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = sslDataset.get_data_loader_for_fold(fold)\n",
    "    dataloaders = (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "    ssl.create_embedded_model(dataloaders, param, param[\"NEPTUNE\"], fold=fold, seed=seed)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    experts = {}\n",
    "    for labelerId in param[\"LABELER_IDS\"]:\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId)\n",
    "        emb_model, model = ssl.getExpertModelSSL(labelerId=labelerId, sslDataset=sslDataset, seed=seed, fold_idx=fold, n_labeled=None, embedded_model=None, param=param, neptune_param=param[\"NEPTUNE\"])\n",
    "        nih_expert.setModel(expert_module.SSLModel(emb_model, model), mod=\"SSL\")\n",
    "        experts[labelerId] = nih_expert\n",
    "\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "\n",
    "    val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    metrics = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        metrics[labelerId] = {}\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"] = {\n",
    "            \"End\": met,\n",
    "        }\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"] = {\n",
    "            \"End\": met\n",
    "        }\n",
    "        \n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f339e5-b0be-466d-b520-ac2f9680c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupEmbeddedModel(dataManager, param, fold, seed):\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    mod = \"ssl\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = sslDataset.get_data_loader_for_fold(fold)\n",
    "    dataloaders = (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "    ssl.create_embedded_model(dataloaders, param, param[\"NEPTUNE\"], fold=fold, seed=seed)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f63a5829-4507-4ce4-bb06-c99ea126c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsAL(dataManager, param, fold_idx, seed):\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold_idx)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "    expert_train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    expert_val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    expert_test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    setupEmbeddedModel(dataManager, param, fold_idx, seed)\n",
    "    #Get init labeled indices with k same images and n-k different images\n",
    "    #k=None means random indieces\n",
    "    k = param[\"OVERLAP\"]\n",
    "    all_indices = list(range(len(expert_train_dataset.getAllIndices())))\n",
    "    #If no k is set than it selects one randomly\n",
    "    k = round(param[\"AL\"][\"INITIAL_SIZE\"]*k/100)\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[\"param/overlap_k\"] = k\n",
    "    indices = al.sampleIndices(n = param[\"AL\"][\"INITIAL_SIZE\"], k = k, all_indices = all_indices, experten = list(param[\"LABELER_IDS\"]), seed = seed, fold=fold_idx)\n",
    "\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[f\"Seed_{seed}/Fold_{fold_idx}/Experts/Indices\"] = indices\n",
    "\n",
    "    print(\"Random indices:\")\n",
    "    print(indices)\n",
    "\n",
    "    experts = {}\n",
    "    metrics = {}\n",
    "    for i, labelerId in enumerate(list(param[\"LABELER_IDS\"])):\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId)\n",
    "        experts[labelerId] = nih_expert\n",
    "        if param[\"MOD\"] == \"confidence\":\n",
    "            expert_model, met_test, metric = al.getExpertModel(indices[labelerId], expert_train_dataset, expert_val_dataset, expert_test_dataset, nih_expert, param, seed, fold_idx, image_container=image_container, learning_mod=\"al\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "            nih_expert.setModel(expert_model, mod=\"AL\")\n",
    "            metrics[labelerId] = metric\n",
    "    if param[\"MOD\"] == \"disagreement\" or param[\"MOD\"]==\"disagreement_diff\":\n",
    "        expert_models, met, metrics = al.getExpertModels(indices, experts, expert_train_dataset, expert_val_dataset, expert_test_dataset, param, seed, fold_idx, mod=param[\"MOD\"], image_container=image_container, learning_mod=\"al\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "        for labelerId, expert in experts.items():\n",
    "            expert.setModel(expert_models[labelerId], mod=\"AL\")\n",
    "\n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d265f97f-07f8-493d-8de5-aa0d60b99eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsNormal(dataManager, param, fold_idx, seed):\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold_idx)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "    expert_train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    expert_val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    expert_test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    setupEmbeddedModel(dataManager, param, fold_idx, seed)\n",
    "    \n",
    "    #Get init labeled indices with k same images and n-k different images\n",
    "    #k=None means random indieces\n",
    "    k = param[\"OVERLAP\"]\n",
    "    all_indices = list(range(len(expert_train_dataset.getAllIndices())))\n",
    "    #If no k is set than it selects one randomly\n",
    "    k = round(param[\"LABELED\"]*k/100)\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[\"param/overlap_k\"] = k\n",
    "    indices = al.sampleIndices(n = param[\"LABELED\"], k = k, all_indices = all_indices, experten = list(param[\"LABELER_IDS\"]), seed = seed, fold=fold_idx)\n",
    "\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[f\"Seed_{seed}/Fold_{fold_idx}/Experts/Indices\"] = indices\n",
    "\n",
    "    print(\"Random indices:\")\n",
    "    print(indices)\n",
    "\n",
    "    experts = {}\n",
    "    #Create the experts\n",
    "    metrics = {}\n",
    "    for i, labelerId in enumerate(list(param[\"LABELER_IDS\"])):\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId)\n",
    "        experts[labelerId] = nih_expert\n",
    "\n",
    "        model, met, metric = al.getExpertModelNormal(indices[labelerId], expert_train_dataset, expert_val_dataset, expert_test_dataset, nih_expert, param, seed, fold_idx, image_container=image_container, learning_mod=\"al\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "        nih_expert.setModel(model, mod=\"AL\")\n",
    "        metrics[labelerId] = metric\n",
    "\n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39124366-b8e9-4c8d-89d2-f06a5b698ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsPerfect(dataManager, param, fold, seed):\n",
    "\n",
    "    experts = {}\n",
    "    for i, labelerId in enumerate(list(param[\"LABELER_IDS\"])):\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId)\n",
    "        experts[labelerId] = nih_expert\n",
    "\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    mod = \"perfect\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "\n",
    "    val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    metrics = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        metrics[labelerId] = {}\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"] = {\n",
    "            \"End\": met,\n",
    "        }\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"] = {\n",
    "            \"End\": met\n",
    "        }\n",
    "\n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1de88e94-d4cf-475b-bd7b-8c3f0c2eb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExperts(dataManager, param, seed, fold):\n",
    "      \n",
    "    #Creates expert models for the choosen method\n",
    "    if param[\"SETTING\"] == \"PERFECT\":\n",
    "        experts, metrics = getExpertsPerfect(dataManager, param, fold, seed)\n",
    "    if param[\"SETTING\"] == \"AL\":\n",
    "        experts, metrics = getExpertsAL(dataManager, param, fold, seed)\n",
    "    elif param[\"SETTING\"] == \"SSL\":\n",
    "        experts, metrics = getExpertsSSL(dataManager, param, fold, seed)\n",
    "    elif param[\"SETTING\"] == \"SSL_AL\" or param[\"SETTING\"] == \"SSL_AL_SSL\":\n",
    "        experts, metrics = getExpertsSSL_AL(dataManager, param, fold, seed)\n",
    "    elif param[\"SETTING\"] == \"NORMAL\":\n",
    "        experts, metrics = getExpertsNormal(dataManager, param, fold, seed)\n",
    "\n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36779aaf-d0a9-4116-8888-d629701db78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2D_Verma(train_loader, val_loader, test_loader, full_dataloader, expert_fns, param, seed, fold_idx, experts):\n",
    "    num_experts = len(expert_fns)\n",
    "            \n",
    "    model = model = vres.ResNet50_defer(int(param[\"n_classes\"]) + num_experts)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Use \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    metrics_train_all, metrics_val_all, metrics_test, metrics_full, metrics_pretrain_all = verm.train(model, train_loader, val_loader, test_loader, expert_fns, param, seed=seed, experts=experts, \n",
    "                                                                                fold=fold_idx, full_dataloader=full_dataloader, param=param)\n",
    "\n",
    "    return metrics_train_all, metrics_val_all, metrics_test, metrics_full, metrics_pretrain_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39c730b2-f947-44cf-95f5-aaf92081a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_run(dataManager, run_param, all_metrics, print_text, run_metrics, count, current_index=None):\n",
    "    \"\"\"\n",
    "    Computes all seed-fold combinations for one parameter combination and saves the metrics into a file\n",
    "    \n",
    "    Param:\n",
    "        dataManager: DataManager for all data\n",
    "        run_param: dict of all relevant parameters for this run\n",
    "        all_metrics: list which contains all already computed results\n",
    "        print_text: output text to print the current paramater combination\n",
    "        run_metrics: core parameters for this run (which vary over different runs)\n",
    "        count: integer to identify the save file (and number of runs)\n",
    "        current_index: index of the current run in all_metrics, if it exists\n",
    "    \"\"\"\n",
    "\n",
    "    #Get device for cuda training\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #To ensure to only print the run text only one time\n",
    "    printed = False\n",
    "\n",
    "    #Metrics for this run\n",
    "    expert_metrics = {}\n",
    "    verma_metrics = {}\n",
    "    hemmer_metrics = {}\n",
    "\n",
    "    #Checks if there is data for this run in the save files\n",
    "    if current_index is not None:\n",
    "        #Load the current metrics\n",
    "        print(f\"Current index: {current_index}\")\n",
    "        current_metric = all_metrics[current_index]\n",
    "\n",
    "        #Save the already computed metrics in the working directories\n",
    "        expert_metrics = current_metric[\"expert metrics\"]\n",
    "        verma_metrics = current_metric[\"verma\"]\n",
    "        hemmer_metrics = current_metric[\"hemmer\"]\n",
    "    #If not, create new element in list of all metrics\n",
    "    else:\n",
    "        all_metrics.append(run_metrics)\n",
    "        \n",
    "\n",
    "    #Iterate over all seeds\n",
    "    for seed in run_param[\"SEEDS\"]:\n",
    "\n",
    "        #If this seed is not already in the save file\n",
    "        if seed not in expert_metrics.keys():\n",
    "            print(f\"New seed: {seed}\")\n",
    "            expert_metrics[seed] = {}\n",
    "            verma_metrics[seed] = {}\n",
    "            hemmer_metrics[seed] = {}\n",
    "\n",
    "        #Iterate over the folds\n",
    "        #for fold_idx in range(run_param[\"K\"]):\n",
    "        for fold_idx in range(2):\n",
    "\n",
    "            #Check if the seed-fold combination is already in the save files\n",
    "            if fold_idx in expert_metrics[seed].keys():\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Keys: {expert_metrics[seed].keys()}\")\n",
    "                print(f\"New fold: {fold_idx}\")\n",
    "\n",
    "            #Print run text if at least one computation is made for this parameter combination (run)\n",
    "            if not printed:\n",
    "                print(print_text)\n",
    "                printed = True\n",
    "\n",
    "            \n",
    "            if run_param[\"cluster\"]: #Keep the embedded model in cluster training\n",
    "                if os.path.isdir(f'{run_param[\"Parent_PATH\"]}/SSL_Working/SSL'):\n",
    "                    cleanTrainDir(f'{run_param[\"Parent_PATH\"]}/SSL_Working/SSL')\n",
    "            else: #delete everything if space is limited\n",
    "                if os.path.isdir(f'{run_param[\"Parent_PATH\"]}/SSL_Working'):\n",
    "                    cleanTrainDir(f'{run_param[\"Parent_PATH\"]}/SSL_Working')\n",
    "\n",
    "            if seed != \"\":\n",
    "                set_seed(seed, fold_idx, text=\"\")\n",
    "\n",
    "            print(\"/n\")\n",
    "            print(f\"Seed: {seed} - Fold: {fold_idx} \\n\")\n",
    "\n",
    "            #if os.path.isdir(f'{run_param[\"Parent_PATH\"]}/SSL_Working/NIH/EmbeddingCM_bin'):\n",
    "            #    cleanTrainDir(f'{run_param[\"Parent_PATH\"]}SSL_Working/NIH/EmbeddingCM_bin')\n",
    "\n",
    "            neptune = {\n",
    "                \"SEED\": seed,\n",
    "                \"FOLD\": fold_idx,\n",
    "            }\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            experts, expert_metric = getExperts(dataManager, run_param, seed, fold_idx)\n",
    "            expert_metrics[seed][fold_idx] = expert_metric\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            #print(f\"Got {len(experts)} experts\")\n",
    "\n",
    "            nih_dataloader = dataManager.getKFoldDataloader(seed=seed)\n",
    "\n",
    "            train_loader, val_loader, test_loader = nih_dataloader.get_data_loader_for_fold(fold_idx)\n",
    "            full_dataloader = nih_dataloader.getFullDataloader()\n",
    "\n",
    "            expert_fns = []\n",
    "            print(run_param[\"SETTING\"])\n",
    "            for labelerId, expert in experts.items():\n",
    "                if run_param[\"SETTING\"] == \"AL\":\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"AL\")\n",
    "                    expert_fns.append(expert.predict_model_predefined_al)\n",
    "                elif run_param[\"SETTING\"] == \"SSL\":\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"SSL\")\n",
    "                    expert_fns.append(expert.predict_model_predefined_ssl)\n",
    "                elif (run_param[\"SETTING\"] == \"SSL_AL\" or run_param[\"SETTING\"] == \"SSL_AL_SSL\"):\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"SSL\")\n",
    "                    expert_fns.append(expert.predict_model_predefined_ssl)\n",
    "                elif run_param[\"SETTING\"] == \"NORMAL\":\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"AL\")\n",
    "                    expert_fns.append(expert.predict_model_predefined_al)\n",
    "                elif run_param[\"SETTING\"] == \"PERFECT\":\n",
    "                    expert_fns.append(expert.predict)\n",
    "\n",
    "            metrics_train_all, metrics_val_all, metrics_test_all, metrics_full_all, metrics_pretrain_all = L2D_Verma(train_loader, val_loader, test_loader, full_dataloader, expert_fns, run_param, seed, fold_idx, experts=experts)\n",
    "\n",
    "            verma_metrics[seed][fold_idx] = {\n",
    "                \"train\": metrics_train_all,\n",
    "                \"val\": metrics_val_all,\n",
    "                \"test\": metrics_test_all,\n",
    "                \"full\": metrics_full_all,\n",
    "                \"pretrain\": metrics_pretrain_all,\n",
    "            }\n",
    "            \n",
    "            system_accuracy, classifier_coverage, all_train_metrics, all_val_metrics, all_test_metrics, all_full_metrics = hm.L2D_Hemmer(train_loader, val_loader, test_loader, full_dataloader, expert_fns, run_param, seed, fold_idx, experts)\n",
    "\n",
    "            hemmer_metrics[seed][fold_idx] = {\n",
    "                \"train\": all_train_metrics,\n",
    "                \"val\": all_val_metrics,\n",
    "                \"test\": all_test_metrics,\n",
    "                \"full\": all_full_metrics,\n",
    "            }\n",
    "\n",
    "            run_metrics[\"expert metrics\"] = expert_metrics\n",
    "            run_metrics[\"verma\"] = verma_metrics\n",
    "            run_metrics[\"hemmer\"] = hemmer_metrics\n",
    "\n",
    "            #Write only into new file if a new run was computed\n",
    "            temp_count = count\n",
    "            if current_index is not None:\n",
    "                all_metrics[current_index] = run_metrics\n",
    "                temp_count = count - 1\n",
    "            else:\n",
    "                all_metrics[-1] = run_metrics\n",
    "            with open(f'{run_param[\"Parent_PATH\"]}/Metrics_Folder/Metrics_{temp_count}.pickle', 'wb') as handle:\n",
    "                pickle.dump(all_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return expert_metrics, verma_metrics, hemmer_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20baf936-e327-4025-94e4-9a06d2cbacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(param):\n",
    "    run_param = copy.deepcopy(param)\n",
    "\n",
    "    runs = None\n",
    "\n",
    "    expert_metrics_all = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    list_of_files = glob.glob(f'{param[\"Parent_PATH\"]}/Metrics_Folder/*') # * means all if need specific format then *.csv\n",
    "    \n",
    "    if len(list_of_files) >= 1:\n",
    "        latest_file = max(list_of_files, key=os.path.getctime)\n",
    "      \n",
    "        print(f\"Open metrics file: {latest_file}\")\n",
    "\n",
    "        with open(latest_file, 'rb') as handle:\n",
    "            expert_metrics_all = pickle.load(handle)\n",
    "\n",
    "        runs = [{i:run[i] for i in run if i not in [\"expert metrics\", \"verma\", \"hemmer\"]} for run in expert_metrics_all]\n",
    "\n",
    "        if \"pickle\" in latest_file:\n",
    "\n",
    "            count = int(latest_file.split(\"/\")[-1][8:-7]) + 1\n",
    "\n",
    "    #Every pair of labeler ids\n",
    "    for labeler_ids in param[\"LABELER_IDS\"]:\n",
    "        run_param[\"LABELER_IDS\"] = labeler_ids\n",
    "        run_param[\"labeler_ids\"] = convert_ids_to_string(labeler_ids)\n",
    "        \n",
    "\n",
    "        dataManager = ds.DataManager(path=param[\"PATH\"], target=param[\"TARGET\"], param=run_param, seeds=param[\"SEEDS\"])\n",
    "        dataManager.createData()\n",
    "\n",
    "        for init_size in param[\"AL\"][\"INITIAL_SIZE\"]:\n",
    "            run_param[\"AL\"][\"INITIAL_SIZE\"] = init_size\n",
    "\n",
    "            for labels_per_round in param[\"AL\"][\"LABELS_PER_ROUND\"]:\n",
    "                run_param[\"AL\"][\"LABELS_PER_ROUND\"] = labels_per_round\n",
    "\n",
    "                for rounds in param[\"AL\"][\"ROUNDS\"]:\n",
    "                    run_param[\"AL\"][\"ROUNDS\"] = rounds\n",
    "\n",
    "                    labeled = init_size + rounds * labels_per_round\n",
    "\n",
    "                    run_param[\"LABELED\"] = labeled\n",
    "\n",
    "                    if (labeled >= 128): #Prevents from large amount of data\n",
    "                        continue\n",
    "\n",
    "                    for cost in param[\"AL\"][\"COST\"]:\n",
    "                        run_param[\"AL\"][\"COST\"] = cost\n",
    "                        run_param[\"AL\"][\"cost\"] = convert_cost_to_string(cost)\n",
    "\n",
    "                        for overlap in param[\"OVERLAP\"]:\n",
    "                            run_param[\"OVERLAP\"] = overlap\n",
    "\n",
    "                            for setting in param[\"SETTING\"]:\n",
    "                                run_param[\"SETTING\"] = setting\n",
    "                        \n",
    "                                for mod in param[\"MOD\"]:\n",
    "                                    run_param[\"MOD\"] = mod\n",
    "\n",
    "                                    if ((setting == \"AL\"  or setting==\"SSL_AL\" or setting==\"SSL_AL_SSL\") and (mod not in [\"confidence\", \"disagreement\", \"disagreement_diff\"])):\n",
    "                                        continue\n",
    "\n",
    "                                    if (setting == \"SSL\" and mod != \"ssl\"):\n",
    "                                        continue\n",
    "\n",
    "                                    if (setting == \"NORMAL\" and mod != \"normal\"):\n",
    "                                        continue\n",
    "\n",
    "                                    for expert_predict in param[\"EXPERT_PREDICT\"]:\n",
    "                                        run_param[\"EXPERT_PREDICT\"] = expert_predict\n",
    "\n",
    "                                        if ((setting == \"SSL\" or setting == \"SSL_AL\" or setting == \"SSL_AL_SSL\") and (expert_predict == \"right\")):\n",
    "                                            continue\n",
    "\n",
    "                                        if (expert_predict == \"target\") and (cost != param[\"AL\"][\"COST\"][0]):\n",
    "                                            continue\n",
    "                                        if (expert_predict == \"target\"):\n",
    "                                            run_param[\"AL\"][\"cost\"] = convert_cost_to_string((0, 0))\n",
    "\n",
    "                                        for sample_equal in param[\"SAMPLE_EQUAL\"]:\n",
    "                                            run_param[\"SAMPLE_EQUAL\"] = sample_equal\n",
    "\n",
    "                                            for epochs_pretrain in param[\"epochs_pretrain\"]:\n",
    "                                                run_param[\"epochs_pretrain\"] = epochs_pretrain\n",
    "\n",
    "                                                metrics_save = {}\n",
    "                                                metrics_save[\"labeler_ids\"] = labeler_ids\n",
    "                                                metrics_save[\"init_size\"] = init_size\n",
    "                                                metrics_save[\"labels_per_round\"] = labels_per_round\n",
    "                                                metrics_save[\"rounds\"] = rounds\n",
    "                                                metrics_save[\"labeled\"] = labeled\n",
    "                                                metrics_save[\"cost\"] = cost\n",
    "                                                metrics_save[\"overlap\"] = overlap\n",
    "                                                metrics_save[\"setting\"] = setting\n",
    "                                                metrics_save[\"mod\"] = mod\n",
    "                                                metrics_save[\"expert_predict\"] = expert_predict\n",
    "                                                metrics_save[\"sample_equal\"] = sample_equal\n",
    "                                                metrics_save[\"epochs_pretrain\"] = epochs_pretrain\n",
    "\n",
    "                                                \n",
    "                                                current_index = None\n",
    "                                                \n",
    "                                                #Compute the current index\n",
    "                                                if runs is not None:\n",
    "                                                    #If this parameter compination is in the already done runs\n",
    "                                                    if metrics_save in runs:\n",
    "                                                        #Get index of this combination\n",
    "                                                        current_index = runs.index(metrics_save)\n",
    "                                                        print(f\"Current index: {current_index}\")\n",
    "                            \n",
    "                                                NEPTUNE = param[\"NEPTUNE\"][\"NEPTUNE\"]\n",
    "                                                if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "                                                    global run\n",
    "                                                    run = neptune.init_run(\n",
    "                                                        project=config_neptune[\"project\"],\n",
    "                                                        api_token=config_neptune[\"api_token\"],\n",
    "                                                        #custom_run_id=\"AL_\" + \n",
    "                                                    )\n",
    "                                                    run[\"param\"] = run_param\n",
    "                                                    run_param[\"NEPTUNE\"][\"RUN\"] = run\n",
    "\n",
    "                                                print_text = f\"\"\"\\n \\n \\n #############################################################\n",
    "                                                NEW RUN\n",
    "\n",
    "                                                Initial size: {init_size}\n",
    "                                                Batch size AL: {labels_per_round}\n",
    "                                                Max rounds: {rounds}\n",
    "                                                Labeled images: {labeled}\n",
    "                                                Cost: {cost}\n",
    "                                                Setting: {setting}\n",
    "                                                Mod: {mod}\n",
    "                                                Overlap: {overlap}\n",
    "                                                Prediction Type: {expert_predict}\n",
    "                                                Sample equal: {sample_equal}\n",
    "                                                Epochs pretrain: {epochs_pretrain}\n",
    "                                                \"\"\"\n",
    "\n",
    "                                                start_time = time.time()\n",
    "                                                #dataManager, run_param, all_metrics, print_text, run_metrics, count, current_index=None\n",
    "                                                expert_metrics, verma_metrics, hemmer_metrics = one_run(dataManager, run_param, expert_metrics_all.copy(), print_text, metrics_save,\n",
    "                                                                                                       count, current_index)\n",
    "                                                print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "                                                metrics_save[\"expert metrics\"] = expert_metrics\n",
    "                                                metrics_save[\"verma\"] = verma_metrics\n",
    "                                                metrics_save[\"hemmer\"] = hemmer_metrics\n",
    "                                                ensure_count = 0 #Helps to save into the correct file if metrics are added to a run\n",
    "                                                if current_index is not None:\n",
    "                                                    expert_metrics_all[current_index] = metrics_save\n",
    "                                                    ensure_count = 1\n",
    "                                                else:\n",
    "                                                    expert_metrics_all.append(metrics_save)\n",
    "                                                with open(f'{param[\"Parent_PATH\"]}/Metrics_Folder/Metrics_{count - ensure_count}.pickle', 'wb') as handle:\n",
    "                                                    pickle.dump(expert_metrics_all, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                                                if current_index is None:\n",
    "                                                    count += 1\n",
    "                                                if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "                                                    run[\"metrics\"] = metrics_save\n",
    "\n",
    "                                                    run.stop()\n",
    "                                                return\n",
    "\n",
    "    return expert_metrics_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f63b284-8933-4876-8875-3ec3c9b35a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cost_to_string(tp):\n",
    "    return \"(\" + str(tp[0]) + \", \" + str(tp[1]) + \")\"\n",
    "\n",
    "def convert_ids_to_string(ids):\n",
    "    return f\"{ids[0]}, {ids[1]}\"\n",
    "\n",
    "def convert_list_to_string(li):\n",
    "    result = \"[\"\n",
    "    for el in li[:-2]:\n",
    "        result = result + str(el)\n",
    "    result = result + \"]\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b9b435-2f48-4591-abfb-d484668b4534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/joli/Masterarbeit'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dde2cce-c1ce-488a-9f5c-f9560d0d9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    path = args[0]\n",
    "\n",
    "    num_worker = 4\n",
    "    if len(args) >= 2:\n",
    "        num_worker = int(args[1])\n",
    "\n",
    "    if \"liebschner\" not in path and \"joli\" not in path:\n",
    "        return\n",
    "\n",
    "    param = {\n",
    "        \"PATH\": f\"{path}/Datasets/NIH/\",\n",
    "        \"Parent_PATH\": path,\n",
    "        \"TARGET\": \"Airspace_Opacity\",\n",
    "        #\"LABELER_IDS\": [[4323195249, 4295232296]],\n",
    "        \"LABELER_IDS\": [[4295349121, 4295342357]],\n",
    "        \"K\": 10, #Number of folds\n",
    "        #\"SEEDS\": [1, 2, 3, 4, 42], #Seeds for the experiments\n",
    "        \"SEEDS\": [1], #Seeds for the experiments\n",
    "        \"GT\": True, # Determines if the classifier gets all data with GT Label or only the labeld data\n",
    "        \"MOD\": [\"confidence\", \"disagreement\", \"disagreement_diff\", \"ssl\", \"normal\"], #Determines the experiment modus\n",
    "\n",
    "        \"OVERLAP\": [0, 100],\n",
    "        \"SAMPLE_EQUAL\": [False, True],\n",
    "\n",
    "        #\"SETTING\": [\"AL\", \"SSL\", \"SSL_AL\", \"NORMAL\", \"SSL_AL_SSL\"],\n",
    "        \"SETTING\": [\"SSL_AL\"],\n",
    "\n",
    "        \"NUM_EXPERTS\": 2,\n",
    "        \"NUM_CLASSES\": 2,\n",
    "\n",
    "        \"EXPERT_PREDICT\": [\"right\", \"target\"],\n",
    "\n",
    "        \"AL\": { #Parameter for Active Learning\n",
    "            \"INITIAL_SIZE\": [4, 8, 16, 32], #\n",
    "            \"EPOCH_TRAIN\": 40, #\n",
    "            \"n_dataset\": 2, #Number Classes\n",
    "            \"BATCH_SIZE\": 4,\n",
    "            \"BATCH_SIZE_VAL\": 32,\n",
    "            \"ROUNDS\": [2, 4, 8],\n",
    "            \"LABELS_PER_ROUND\": [4, 8, 16],\n",
    "            \"EPOCHS_DEFER\": 10,\n",
    "            \"COST\": [(0, 0), (5, 0)], #Cost for Cost sensitiv learning\n",
    "            #\"TRAIN REJECTOR\": False,\n",
    "            \"PRELOAD\": True,\n",
    "            \"PREPROCESS\": True,\n",
    "            \"SSL_EPOCHS\": 3\n",
    "        \n",
    "        },\n",
    "        \"SSL\": {\n",
    "            \"PREBUILD\": False,\n",
    "            #\"TRAIN_BATCH_SIZE\": 128,\n",
    "            \"TRAIN_BATCH_SIZE\": 254,\n",
    "            \"TEST_BATCH_SIZE\": 254,\n",
    "            \"N_EPOCHS\": 5, #number of training epoches\n",
    "            \"BATCHSIZE\": 16, #train batch size of labeled samples\n",
    "            #\"N_IMGS_PER_EPOCH\": 32768, #number of training images for each epoch\n",
    "            \"N_IMGS_PER_EPOCH\": 4381*1, #number of training images for each epoch\n",
    "        },\n",
    "        \"L2D\": { # Parameter for Learning to defer\n",
    "            \"TRAIN_BATCH_SIZE\": 128,\n",
    "            \"TEST_BATCH_SIZE\": 128,\n",
    "            \"PRELOAD\": True,\n",
    "            \"PREBUILD\": True,\n",
    "            \"EPOCHS\": 50,\n",
    "            \"VERMA\": {},\n",
    "            \"HEMMER\": {\n",
    "                \"EPOCHS\": 50,\n",
    "                \"LR\": 5e-3,\n",
    "                \"USE_LR_SCHEDULER\": False,\n",
    "                \"DROPOUT\": 0.00,\n",
    "                \"NUM_HIDDEN_UNITS\": 30,\n",
    "            },\n",
    "        \n",
    "        },\n",
    "        \"NEPTUNE\": {\n",
    "            \"NEPTUNE\": False,\n",
    "        },\n",
    "        \"EMBEDDED\": {\n",
    "            \"ARGS\": {\n",
    "                'dataset': \"nih\",\n",
    "                'model': \"resnet50\",\n",
    "                'num_classes': 2,\n",
    "                'batch': 128,\n",
    "                'lr': 0.001,\n",
    "            },\n",
    "            \"EPOCHS\": 30,\n",
    "        },\n",
    "    \n",
    "    \n",
    "        \"epochs_pretrain\": [0],\n",
    "        \"batch_size\": 64,\n",
    "        \"alpha\": 1.0, #scaling parameter for the loss function, default=1.0\n",
    "        \"epochs\": 50,\n",
    "        \"patience\": 35, #number of patience steps for early stopping the training\n",
    "        \"expert_type\": \"MLPMixer\", #specify the expert type. For the type of experts available, see-> models -> experts. defualt=predict\n",
    "        \"n_classes\": 2, #K for K class classification\n",
    "        \"k\": 0, #\n",
    "        \"n_experts\": 2, #\n",
    "        \"lr\": 0.001, #learning rate\n",
    "        \"weight_decay\": 5e-4, #\n",
    "        \"warmup_epochs\": 5, #\n",
    "        #\"loss_type\": \"softmax\", #surrogate loss type for learning to defer\n",
    "        \"loss_type\": \"ova\",\n",
    "        \"ckp_dir\": f\"{path}/Models\", #directory name to save the checkpoints\n",
    "        \"experiment_name\": \"multiple_experts\", #specify the experiment name. Checkpoints will be saved with this name\n",
    "\n",
    "        #Params for cluster training\n",
    "        \"num_worker\": num_worker,\n",
    "        \"cluster\": False\n",
    "    }\n",
    "\n",
    "    expert_metrics_all = run_experiment(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873cc81-13a4-427c-8867-22de29bc5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "main([\"/home/joli\", 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joli-env_kernel",
   "language": "python",
   "name": "joli-env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
