{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c923862-4c78-46d2-87e8-a617e07c32d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 09:07:39.046903: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import sklearn\n",
    "import copy\n",
    "\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import Verma.experts as vexp\n",
    "import Verma.losses as vlos\n",
    "from Verma.utils import AverageMeter, accuracy\n",
    "import Verma.resnet50 as vres\n",
    "from AL.utils import *\n",
    "from AL.metrics import *\n",
    "\n",
    "import Dataset.Dataset as ds\n",
    "\n",
    "import ssl_functions as ssl\n",
    "import active_learning as al\n",
    "from active_learning import NIHExpertDatasetMemory\n",
    "\n",
    "import expert as expert_module\n",
    "import verma as verm\n",
    "import hemmer as hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9104208e-aaa1-40e2-b3c6-1058f92fd31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed, fold=None, text=None):\n",
    "    if fold is not None and text is not None:\n",
    "        s = text + f\" + {seed} + {fold}\"\n",
    "        seed = int(hashlib.sha256(s.encode('utf-8')).hexdigest(), 16) % 10**8\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e071303-6599-454d-a430-c2b39165f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "import json\n",
    "\n",
    "with open('neptune_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config_neptune = config[\"neptune\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc80118e-ff9d-491c-b393-94569d4e4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def cleanTrainDir(path):\n",
    "    shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6272b79-d261-46c6-bc8e-d5b6fa8dc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertModelSSL_AL(dataManager, expert, labelerId, param=None, seed=None, fold=None, learning_mod=\"ssl\", prediction_type=\"target\"):\n",
    "    \n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "    train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "    usedFilenames = sslDataset.getLabeledFilenames(labelerId, fold)\n",
    "    \n",
    "    # initialize data, Erhält alle Indizes der Daten\n",
    "    all_indices = list(range(len(train_dataset.getAllIndices())))\n",
    "    all_data_filenames = np.array(train_dataset.getAllFilenames())[all_indices]\n",
    "    all_data_y = np.array(train_dataset.getAllTargets())[all_indices]\n",
    "\n",
    "    used_indices = [index for index in all_indices if all_data_filenames[index] in usedFilenames]\n",
    "    indices = used_indices\n",
    "\n",
    "    print(\"Len overlapping used indices: \" + str(len(used_indices)))\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "    metrics[\"Val\"] = {\n",
    "        \"Start\": met,\n",
    "    }\n",
    "\n",
    "    met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "    metrics[\"Test\"] = {\n",
    "        \"Start\": met,\n",
    "    }\n",
    "\n",
    "    metrics[\"Train\"] = {}\n",
    "\n",
    "    set_seed(seed, fold, text=\"\")\n",
    "    \n",
    "    Intial_random_set = indices\n",
    "    indices_labeled  = Intial_random_set\n",
    "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "    # Lädt die Datasets für die beschrifteten und unbeschrifteten Daten\n",
    "    dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], None , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataset_val_unlabeled = NIHExpertDatasetMemory(None, val_dataset.getAllFilenames(), np.array(val_dataset.getAllTargets()), expert.predict , [1]*len(val_dataset.getAllIndices()), val_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    \n",
    "    # Lädt die Dataloaders\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    dataLoaderValUnlabeled = DataLoader(dataset=dataset_val_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    for round in range(param[\"AL\"][\"ROUNDS\"]):\n",
    "\n",
    "        print(f'\\n \\n Round {round} \\n \\n')\n",
    "\n",
    "        # get points where expert model is least confident on\n",
    "        indices_confidence = al.get_least_confident_points(expert, dataLoaderTrainUnlabeled, param[\"AL\"][\"LABELS_PER_ROUND\"], mod=\"ssl\")\n",
    "        indices_labeled  = indices_labeled + list(indices_confidence) \n",
    "        indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "        dataset_train_labeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_labeled], all_data_y[indices_labeled], expert.predict , [1]*len(indices_labeled), indices_labeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "        dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "\n",
    "        dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "        \n",
    "        # train model on labeled data\n",
    "        dataloaders = (dataLoaderTrainLabeled, dataLoaderValUnlabeled)\n",
    "        n_images = param[\"AL\"][\"INITIAL_SIZE\"] + (round+1)*param[\"AL\"][\"LABELS_PER_ROUND\"]\n",
    "        train_metrics, val_metrics = al.run_expert(model=None, expert=expert, epochs=param[\"AL\"][\"EPOCH_TRAIN\"], dataloaders=dataloaders, param=param, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, mod=\"ssl\", prediction_type=\"target\")\n",
    "        \n",
    "        metrics[\"Train\"][n_images] = {\n",
    "            \"train_metrics\": train_metrics,\n",
    "            \"val_metrics\": val_metrics,\n",
    "        }\n",
    "    \n",
    "    dataset_test_unlabeled = NIHExpertDatasetMemory(None, test_dataset.getAllFilenames(), np.array(test_dataset.getAllTargets()), expert.predict , [1]*len(test_dataset.getAllIndices()), test_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataLoaderVal = DataLoader(dataset=dataset_test_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    met_test = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderVal, id=expert.labelerId, seed=seed, fold=fold, n_images=param[\"AL\"][\"INITIAL_SIZE\"] + param[\"AL\"][\"ROUNDS\"]*param[\"AL\"][\"LABELS_PER_ROUND\"], step=\"Test\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "\n",
    "    met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "    metrics[\"Val\"][\"End\"] = met\n",
    "\n",
    "    met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "    metrics[\"Test\"][\"End\"] = met\n",
    "    \n",
    "    #metrics[\"Test\"] = met\n",
    "    print(\"AL finished\")\n",
    "    return met_test, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e247c6-e640-4be7-9685-808d5f08f58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc438de-b6b0-463c-95ae-c62afdbbc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertModelsSSL_AL(dataManager, experts, param, seed, fold, learning_mod=\"ssl\", prediction_type=\"target\"):\n",
    "\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "    train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "    usedFilenames = []\n",
    "    for labelerId in param[\"LABELER_IDS\"]:\n",
    "        temp = usedFilenames + sslDataset.getLabeledFilenames(labelerId, fold)\n",
    "    usedFilenames = temp\n",
    "    \n",
    "    \n",
    "    # initialize data, Erhält alle Indizes der Daten\n",
    "    all_indices = list(range(len(train_dataset.getAllIndices())))\n",
    "    all_data_filenames = np.array(train_dataset.getAllFilenames())[all_indices]\n",
    "    all_data_y = np.array(train_dataset.getAllTargets())[all_indices]\n",
    "\n",
    "    unused_indices = [index for index in all_indices if all_data_filenames[index] not in usedFilenames]\n",
    "    \n",
    "    metrics = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        metrics[labelerId] = {}\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"] = {\n",
    "            \"Start\": met,\n",
    "        }\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"] = {\n",
    "            \"Start\": met,\n",
    "        }\n",
    "\n",
    "        metrics[labelerId][\"Train\"] = {}\n",
    "\n",
    "    set_seed(seed, fold, text=\"\")\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    indices_unlabeled = unused_indices\n",
    "    indices_labeled = list(set(all_indices) - set(indices_unlabeled))\n",
    "\n",
    "    dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], experts[param[\"LABELER_IDS\"][0]].predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    for round in range(param[\"AL\"][\"ROUNDS\"]):\n",
    "\n",
    "        print(f'\\n \\n Round {round} \\n \\n')\n",
    "\n",
    "        #Try to get better Points\n",
    "        if param[\"MOD\"] == \"disagreement\":\n",
    "            indices_qbq = al.getQbQPoints(experts, dataLoaderTrainUnlabeled, param[\"AL\"][\"LABELS_PER_ROUND\"], mod=\"ssl\", param=param)\n",
    "        if param[\"MOD\"] == \"disagreement_diff\":\n",
    "            indices_qbq = al.getQbQPointsDifference(experts, dataLoaderTrainUnlabeled, param[\"AL\"][\"LABELS_PER_ROUND\"], mod=\"ssl\", param=param)\n",
    "        \n",
    "        #indices_labeled  = indices_labeled + list(indices_confidence) \n",
    "        indices_labeled  = indices_labeled + list(indices_qbq) \n",
    "        indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "        \n",
    "        # train model on labeled data\n",
    "        for labelerId, expert in experts.items():\n",
    "\n",
    "            dataset_train_labeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_labeled], all_data_y[indices_labeled], expert.predict , [1]*len(indices_labeled), indices_labeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "            dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "            \n",
    "            dataset_val_unlabeled = NIHExpertDatasetMemory(None, val_dataset.getAllFilenames(), np.array(val_dataset.getAllTargets()), expert.predict , [1]*len(val_dataset.getAllIndices()), val_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "            dataLoaderValUnlabeled = DataLoader(dataset=dataset_val_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "            dataloaders = (dataLoaderTrainLabeled, dataLoaderValUnlabeled)\n",
    "            n_images = param[\"AL\"][\"INITIAL_SIZE\"] + (round+1)*param[\"AL\"][\"LABELS_PER_ROUND\"]\n",
    "            train_metrics, val_metrics = al.run_expert(model=None, expert=expert, epochs=param[\"AL\"][\"EPOCH_TRAIN\"], dataloaders=dataloaders, param=param, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, mod=\"ssl\", prediction_type=\"target\")\n",
    "\n",
    "            metrics[labelerId][\"Train\"][n_images] = {\n",
    "                \"train_metrics\": train_metrics,\n",
    "                \"val_metrics\": val_metrics\n",
    "            }\n",
    "        \n",
    "        dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    dataset_test_unlabeled = NIHExpertDatasetMemory(None, test_dataset.getAllFilenames(), np.array(test_dataset.getAllTargets()), expert.predict , [1]*len(test_dataset.getAllIndices()), test_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataLoaderVal = DataLoader(dataset=dataset_test_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    met_test = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        temp = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderVal, id=expert.labelerId, seed=seed, fold=fold, n_images=param[\"AL\"][\"INITIAL_SIZE\"] + param[\"AL\"][\"ROUNDS\"]*param[\"AL\"][\"LABELS_PER_ROUND\"], step=\"Test\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "        met_test[expert.labelerId] = temp\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"][\"End\"] = met\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"][\"End\"] = met\n",
    "        \n",
    "    return expert_models, met_test, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be36f3a5-859c-4d0a-956c-8ec5b8f57383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsSSL_AL(dataManager, param, fold, seed):\n",
    "\n",
    "    mod = \"ssl\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    sslDataset.createLabeledIndices(labelerIds=param[\"LABELER_IDS\"], n_L=param[\"AL\"][\"INITIAL_SIZE\"], k=round(param[\"AL\"][\"INITIAL_SIZE\"]*param[\"OVERLAP\"]/100), seed=seed, sample_equal=param[\"SAMPLE_EQUAL\"])\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = sslDataset.get_data_loader_for_fold(fold)\n",
    "    dataloaders = (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "    embedded_model = ssl.create_embedded_model(dataloaders, param, param[\"NEPTUNE\"], fold=fold, seed=seed)\n",
    "\n",
    "    experts = {}\n",
    "    for labelerId in param[\"LABELER_IDS\"]:\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId)\n",
    "        emb_model, model = ssl.getExpertModelSSL(labelerId=labelerId, sslDataset=sslDataset, seed=seed, fold_idx=fold, n_labeled=None, embedded_model=embedded_model, param=param, neptune_param=param[\"NEPTUNE\"])\n",
    "        nih_expert.setModel(expert_module.SSLModel(emb_model, model), mod=\"SSL\")\n",
    "        experts[labelerId] = nih_expert\n",
    "    metrics = {}\n",
    "    if param[\"MOD\"] == \"confidence\":\n",
    "        for i, labelerId in enumerate(param[\"LABELER_IDS\"]):\n",
    "            met, metrics_return = getExpertModelSSL_AL(dataManager=dataManager, expert=experts[labelerId], labelerId=labelerId, param=param, seed=seed, fold=fold, learning_mod=\"ssl\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "            metrics[labelerId] = metrics_return\n",
    "    elif param[\"MOD\"] == (\"disagreement\" or \"disagreement_diff\"):\n",
    "        expert_models, met, metrics = getExpertModelsSSL_AL(dataManager, experts, param, seed, fold, learning_mod=\"ssl\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "        \n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff5079e-b28c-42c8-a5e0-379f31fdd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsSSL(dataManager, param, fold, seed):\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    mod = \"ssl\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    sslDataset.createLabeledIndices(labelerIds=param[\"LABELER_IDS\"], n_L=param[\"LABELED\"], k=round(param[\"LABELED\"]*param[\"OVERLAP\"]/100), seed=seed, sample_equal=param[\"SAMPLE_EQUAL\"])\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = sslDataset.get_data_loader_for_fold(fold)\n",
    "    dataloaders = (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "    ssl.create_embedded_model(dataloaders, param, param[\"NEPTUNE\"], fold=fold, seed=seed)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    experts = {}\n",
    "    for labelerId in param[\"LABELER_IDS\"]:\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId)\n",
    "        emb_model, model = ssl.getExpertModelSSL(labelerId=labelerId, sslDataset=sslDataset, seed=seed, fold_idx=fold, n_labeled=None, embedded_model=None, param=param, neptune_param=param[\"NEPTUNE\"])\n",
    "        nih_expert.setModel(expert_module.SSLModel(emb_model, model), mod=\"SSL\")\n",
    "        experts[labelerId] = nih_expert\n",
    "\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "\n",
    "    val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    metrics = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        metrics[labelerId] = {}\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"] = {\n",
    "            \"End\": met,\n",
    "        }\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"] = {\n",
    "            \"End\": met\n",
    "        }\n",
    "        \n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f339e5-b0be-466d-b520-ac2f9680c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupEmbeddedModel(dataManager, param, fold, seed):\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    mod = \"ssl\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = sslDataset.get_data_loader_for_fold(fold)\n",
    "    dataloaders = (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "    ssl.create_embedded_model(dataloaders, param, param[\"NEPTUNE\"], fold=fold, seed=seed)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f63a5829-4507-4ce4-bb06-c99ea126c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsAL(dataManager, param, fold_idx, seed):\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold_idx)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "    expert_train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    expert_val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    expert_test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    setupEmbeddedModel(dataManager, param, fold_idx, seed)\n",
    "    #Get init labeled indices with k same images and n-k different images\n",
    "    #k=None means random indieces\n",
    "    k = param[\"OVERLAP\"]\n",
    "    all_indices = list(range(len(expert_train_dataset.getAllIndices())))\n",
    "    #If no k is set than it selects one randomly\n",
    "    k = round(param[\"AL\"][\"INITIAL_SIZE\"]*k/100)\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[\"param/overlap_k\"] = k\n",
    "    indices = al.sampleIndices(n = param[\"AL\"][\"INITIAL_SIZE\"], k = k, all_indices = all_indices, experten = list(param[\"LABELER_IDS\"]), seed = seed, fold=fold_idx)\n",
    "\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[f\"Seed_{seed}/Fold_{fold_idx}/Experts/Indices\"] = indices\n",
    "\n",
    "    print(\"Random indices:\")\n",
    "    print(indices)\n",
    "\n",
    "    experts = {}\n",
    "    metrics = {}\n",
    "    for i, labelerId in enumerate(list(param[\"LABELER_IDS\"])):\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId)\n",
    "        experts[labelerId] = nih_expert\n",
    "        if param[\"MOD\"] == \"confidence\":\n",
    "            expert_model, met_test, metric = al.getExpertModel(indices[labelerId], expert_train_dataset, expert_val_dataset, expert_test_dataset, nih_expert, param, seed, fold_idx, image_container=image_container, learning_mod=\"al\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "            nih_expert.setModel(expert_model, mod=\"AL\")\n",
    "            metrics[labelerId] = metric\n",
    "    if param[\"MOD\"] == \"disagreement\" or param[\"MOD\"]== \"disagreement_diff\":\n",
    "        expert_models, met, metrics = al.getExpertModels(indices, experts, expert_train_dataset, expert_val_dataset, expert_test_dataset, param, seed, fold_idx, mod=param[\"MOD\"], image_container=image_container, learning_mod=\"al\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "        for labelerId, expert in experts.items():\n",
    "            expert.setModel(expert_models[labelerId], mod=\"AL\")\n",
    "\n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d265f97f-07f8-493d-8de5-aa0d60b99eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsNormal(dataManager, param, fold_idx, seed):\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold_idx)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "    expert_train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    expert_val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    expert_test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    setupEmbeddedModel(dataManager, param, fold_idx, seed)\n",
    "    \n",
    "    #Get init labeled indices with k same images and n-k different images\n",
    "    #k=None means random indieces\n",
    "    k = param[\"OVERLAP\"]\n",
    "    all_indices = list(range(len(expert_train_dataset.getAllIndices())))\n",
    "    #If no k is set than it selects one randomly\n",
    "    k = round(param[\"LABELED\"]*k/100)\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[\"param/overlap_k\"] = k\n",
    "    indices = al.sampleIndices(n = param[\"LABELED\"], k = k, all_indices = all_indices, experten = list(param[\"LABELER_IDS\"]), seed = seed, fold=fold_idx)\n",
    "\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[f\"Seed_{seed}/Fold_{fold_idx}/Experts/Indices\"] = indices\n",
    "\n",
    "    print(\"Random indices:\")\n",
    "    print(indices)\n",
    "\n",
    "    experts = {}\n",
    "    #Create the experts\n",
    "    metrics = {}\n",
    "    for i, labelerId in enumerate(list(param[\"LABELER_IDS\"])):\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId)\n",
    "        experts[labelerId] = nih_expert\n",
    "\n",
    "        model, met, metric = al.getExpertModelNormal(indices[labelerId], expert_train_dataset, expert_val_dataset, expert_test_dataset, nih_expert, param, seed, fold_idx, image_container=image_container, learning_mod=\"al\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "        nih_expert.setModel(model, mod=\"AL\")\n",
    "        metrics[labelerId] = metric\n",
    "\n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1de88e94-d4cf-475b-bd7b-8c3f0c2eb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExperts(dataManager, param, seed, fold):\n",
    "      \n",
    "    #Creates expert models for the choosen method\n",
    "    if param[\"SETTING\"] == \"AL\":\n",
    "        experts, metrics = getExpertsAL(dataManager, param, fold, seed)\n",
    "    elif param[\"SETTING\"] == \"SSL\":\n",
    "        experts, metrics = getExpertsSSL(dataManager, param, fold, seed)\n",
    "    elif param[\"SETTING\"] == \"SSL_AL\":\n",
    "        experts, metrics = getExpertsSSL_AL(dataManager, param, fold, seed)\n",
    "    elif param[\"SETTING\"] == \"NORMAL\":\n",
    "        experts, f1_experts, ac_b, metrics = getExpertsNormal(dataManager, param, fold, seed)\n",
    "\n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36779aaf-d0a9-4116-8888-d629701db78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2D_Verma(train_loader, val_loader, test_loader, full_dataloader, expert_fns, param, seed, fold_idx, experts):\n",
    "    num_experts = len(expert_fns)\n",
    "            \n",
    "    model = model = vres.ResNet50_defer(int(param[\"n_classes\"]) + num_experts)\n",
    "\n",
    "    metrics_train_all, metrics_val_all, metrics_test, metrics_full = verm.train(model, train_loader, val_loader, test_loader, expert_fns, param, seed=seed, experts=experts, \n",
    "                                                                                fold=fold_idx, full_dataloader=full_dataloader, param=param)\n",
    "\n",
    "    return metrics_train_all, metrics_val_all, metrics_test, metrics_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c730b2-f947-44cf-95f5-aaf92081a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_run(dataManager, run_param):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    expert_metrics = {}\n",
    "    verma_metrics = {}\n",
    "    hemmer_metrics = {}\n",
    "\n",
    "    for seed in run_param[\"SEEDS\"]:\n",
    "        print(\"Seed: \" + str(seed))\n",
    "        \n",
    "\n",
    "        expert_metrics[seed] = {}\n",
    "        verma_metrics[seed] = {}\n",
    "        hemmer_metrics[seed] = {}\n",
    "\n",
    "        if os.path.isdir('SSL_Working'):\n",
    "            cleanTrainDir(\"SSL_Working\")\n",
    "\n",
    "        #for fold_idx in range(run_param[\"K\"]):\n",
    "        for fold_idx in range(4):\n",
    "\n",
    "            if seed != \"\":\n",
    "                set_seed(seed, fold_idx, text=\"\")\n",
    "\n",
    "            print(\"/n\")\n",
    "            print(f\"Seed: {seed} - Fold: {fold_idx} \\n\")\n",
    "\n",
    "            if os.path.isdir('SSL_Working/NIH/EmbeddingCM_bin'):\n",
    "                cleanTrainDir(\"SSL_Working/NIH/EmbeddingCM_bin\")\n",
    "\n",
    "            neptune = {\n",
    "                \"SEED\": seed,\n",
    "                \"FOLD\": fold_idx,\n",
    "            }\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            experts, expert_metric = getExperts(dataManager, run_param, seed, fold_idx)\n",
    "            expert_metrics[seed][fold_idx] = expert_metric\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            #print(f\"Got {len(experts)} experts\")\n",
    "\n",
    "            nih_dataloader = dataManager.getKFoldDataloader(seed=seed)\n",
    "\n",
    "            train_loader, val_loader, test_loader = nih_dataloader.get_data_loader_for_fold(fold_idx)\n",
    "            full_dataloader = nih_dataloader.getFullDataloader()\n",
    "\n",
    "            expert_fns = []\n",
    "            print(run_param[\"SETTING\"])\n",
    "            for labelerId, expert in experts.items():\n",
    "                if run_param[\"SETTING\"] == \"AL\":\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"AL\")\n",
    "                    expert_fns.append(expert.predict_model_predefined_al)\n",
    "                elif run_param[\"SETTING\"] == \"SSL\":\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"SSL\")\n",
    "                    expert_fns.append(expert.predict_model_predefined_ssl)\n",
    "                elif run_param[\"SETTING\"] == \"SSL_AL\":\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"SSL\")\n",
    "                    expert_fns.append(expert.predict_model_predefined_ssl)\n",
    "                elif run_param[\"SETTING\"] == \"NORMAL\":\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"AL\")\n",
    "                    expert_fns.append(expert.predict_model_predefined_al)\n",
    "\n",
    "            metrics_train_all, metrics_val_all, metrics_test_all, metrics_full_all = L2D_Verma(train_loader, val_loader, test_loader, full_dataloader, expert_fns, run_param, seed, fold_idx, experts=experts)\n",
    "\n",
    "            verma_metrics[seed][fold_idx] = {\n",
    "                \"train\": metrics_train_all,\n",
    "                \"val\": metrics_val_all,\n",
    "                \"test\": metrics_test_all,\n",
    "                \"full\": metrics_full_all,\n",
    "            }\n",
    "            \n",
    "            system_accuracy, classifier_coverage, all_train_metrics, all_val_metrics, all_test_metrics, all_full_metrics = hm.L2D_Hemmer(train_loader, val_loader, test_loader, full_dataloader, expert_fns, run_param, seed, fold_idx, experts)\n",
    "\n",
    "            hemmer_metrics[seed][fold_idx] = {\n",
    "                \"train\": all_train_metrics,\n",
    "                \"val\": all_val_metrics,\n",
    "                \"test\": all_test_metrics,\n",
    "                \"full\": all_full_metrics,\n",
    "            }\n",
    "\n",
    "            \n",
    "    return expert_metrics, verma_metrics, hemmer_metrics\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20baf936-e327-4025-94e4-9a06d2cbacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(param):\n",
    "    run_param = copy.deepcopy(param)\n",
    "\n",
    "    expert_metrics_all = []\n",
    "\n",
    "    with open('Metrics_Folder/Metrics_15.pickle', 'rb') as handle:\n",
    "        expert_metrics_all = pickle.load(handle)\n",
    "\n",
    "    runs = [{i:run[i] for i in run if i not in [\"expert metrics\", \"verma\", \"hemmer\"]} for run in expert_metrics_all]\n",
    "\n",
    "    count = 16\n",
    "\n",
    "    #Every pair of labeler ids\n",
    "    for labeler_ids in param[\"LABELER_IDS\"]:\n",
    "        run_param[\"LABELER_IDS\"] = labeler_ids\n",
    "        run_param[\"labeler_ids\"] = convert_ids_to_string(labeler_ids)\n",
    "        \n",
    "\n",
    "        dataManager = ds.DataManager(path=param[\"PATH\"], target=param[\"TARGET\"], param=run_param, seeds=param[\"SEEDS\"])\n",
    "        dataManager.createData()\n",
    "\n",
    "        for init_size in param[\"AL\"][\"INITIAL_SIZE\"]:\n",
    "            run_param[\"AL\"][\"INITIAL_SIZE\"] = init_size\n",
    "\n",
    "            for labels_per_round in param[\"AL\"][\"LABELS_PER_ROUND\"]:\n",
    "                run_param[\"AL\"][\"LABELS_PER_ROUND\"] = labels_per_round\n",
    "\n",
    "                for rounds in param[\"AL\"][\"ROUNDS\"]:\n",
    "                    run_param[\"AL\"][\"ROUNDS\"] = rounds\n",
    "\n",
    "                    labeled = init_size + rounds * labels_per_round\n",
    "\n",
    "                    run_param[\"LABELED\"] = labeled\n",
    "\n",
    "                    if (labeled >= 128): #Prevents from large amount of data\n",
    "                        continue\n",
    "\n",
    "                    for cost in param[\"AL\"][\"COST\"]:\n",
    "                        run_param[\"AL\"][\"COST\"] = cost\n",
    "                        run_param[\"AL\"][\"cost\"] = convert_cost_to_string(cost)\n",
    "\n",
    "                        for overlap in param[\"OVERLAP\"]:\n",
    "                            run_param[\"OVERLAP\"] = overlap\n",
    "\n",
    "                            for setting in param[\"SETTING\"]:\n",
    "                                run_param[\"SETTING\"] = setting\n",
    "                        \n",
    "                                for mod in param[\"MOD\"]:\n",
    "                                    run_param[\"MOD\"] = mod\n",
    "\n",
    "                                    if ((setting == \"AL\"  or setting==\"SSL_AL\") and (mod not in [\"confidence\", \"disagreement\", \"disagreement_diff\"])):\n",
    "                                        continue\n",
    "\n",
    "                                    if (setting == \"SSL\" and mod != \"ssl\"):\n",
    "                                        continue\n",
    "\n",
    "                                    if (setting == \"NORMAL\" and mod != \"normal\"):\n",
    "                                        continue\n",
    "\n",
    "                                    for expert_predict in param[\"EXPERT_PREDICT\"]:\n",
    "                                        run_param[\"EXPERT_PREDICT\"] = expert_predict\n",
    "\n",
    "                                        if ((setting == \"SSL\" or setting == \"SSL_AL\") and (expert_predict == \"right\")):\n",
    "                                            continue\n",
    "\n",
    "                                        if (expert_predict == \"target\") and (cost != param[\"AL\"][\"COST\"][0]):\n",
    "                                            continue\n",
    "                                        if (expert_predict == \"target\"):\n",
    "                                            run_param[\"AL\"][\"cost\"] = convert_cost_to_string((0, 0))\n",
    "\n",
    "                                        for sample_equal in param[\"SAMPLE_EQUAL\"]:\n",
    "                                            run_param[\"SAMPLE_EQUAL\"] = sample_equal\n",
    "\n",
    "                                            metrics_save = {}\n",
    "                                            metrics_save[\"labeler_ids\"] = labeler_ids\n",
    "                                            metrics_save[\"init_size\"] = init_size\n",
    "                                            metrics_save[\"labels_per_round\"] = labels_per_round\n",
    "                                            metrics_save[\"rounds\"] = rounds\n",
    "                                            metrics_save[\"labeled\"] = labeled\n",
    "                                            metrics_save[\"cost\"] = cost\n",
    "                                            metrics_save[\"overlap\"] = overlap\n",
    "                                            metrics_save[\"setting\"] = setting\n",
    "                                            metrics_save[\"mod\"] = mod\n",
    "                                            metrics_save[\"expert_predict\"] = expert_predict\n",
    "                                            metrics_save[\"sample_equal\"] = sample_equal\n",
    "\n",
    "                                            if metrics_save in runs:\n",
    "                                                continue\n",
    "                                    \n",
    "                            \n",
    "                                            NEPTUNE = param[\"NEPTUNE\"][\"NEPTUNE\"]\n",
    "                                            if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "                                                global run\n",
    "                                                run = neptune.init_run(\n",
    "                                                    project=config_neptune[\"project\"],\n",
    "                                                    api_token=config_neptune[\"api_token\"],\n",
    "                                                    #custom_run_id=\"AL_\" + \n",
    "                                                )\n",
    "                                                run[\"param\"] = run_param\n",
    "                                                run_param[\"NEPTUNE\"][\"RUN\"] = run\n",
    "\n",
    "                                            print(\"\\n #####################################################################################\")\n",
    "                                            print(\"\\n \\n \\n NEW RUN \\n\")\n",
    "                                            print(\"Initial size: \" + str(init_size))\n",
    "                                            print(\"Batch size: \" + str(labels_per_round))\n",
    "                                            print(\"Max rounds: \" + str(rounds))\n",
    "                                            print(\"Labeled: \" + str(labeled))\n",
    "                                            print(\"Cost: \" + str(cost))\n",
    "                                            print(\"Setting: \" + str(setting))\n",
    "                                            print(\"Mod: \" + str(mod))\n",
    "                                            print(\"Overlap: \" + str(overlap))\n",
    "                                            print(\"Prediction Type \" + str(expert_predict))\n",
    "                                            print(\"Sample equal \" + str(sample_equal))\n",
    "\n",
    "                                            \n",
    "\n",
    "\n",
    "                                            start_time = time.time()\n",
    "                                            expert_metrics, verma_metrics, hemmer_metrics = one_run(dataManager, \n",
    "                                                                                                                                                                                                 run_param)\n",
    "                                            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "                                            metrics_save[\"expert metrics\"] = expert_metrics\n",
    "                                            metrics_save[\"verma\"] = verma_metrics\n",
    "                                            metrics_save[\"hemmer\"] = hemmer_metrics\n",
    "                                            expert_metrics_all.append(metrics_save)\n",
    "                                            with open(f'Metrics_Folder/Metrics_{count}.pickle', 'wb') as handle:\n",
    "                                                pickle.dump(expert_metrics_all, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                                            count += 1\n",
    "                                            if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "                                                run[\"metrics\"] = metrics_save\n",
    "\n",
    "                                                run.stop()\n",
    "                                            #return experts, expert_metrics\n",
    "                                                \n",
    "\n",
    "    return expert_metrics_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f63b284-8933-4876-8875-3ec3c9b35a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cost_to_string(tp):\n",
    "    return \"(\" + str(tp[0]) + \", \" + str(tp[1]) + \")\"\n",
    "\n",
    "def convert_ids_to_string(ids):\n",
    "    return f\"{ids[0]}, {ids[1]}\"\n",
    "\n",
    "def convert_list_to_string(li):\n",
    "    result = \"[\"\n",
    "    for el in li[:-2]:\n",
    "        result = result + str(el)\n",
    "    result = result + \"]\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9b435-2f48-4591-abfb-d484668b4534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dde2cce-c1ce-488a-9f5c-f9560d0d9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"PATH\": \"../Datasets/NIH/\",\n",
    "    \"TARGET\": \"Airspace_Opacity\",\n",
    "    \"LABELER_IDS\": [[4323195249, 4295232296]],\n",
    "    \"K\": 10, #Number of folds\n",
    "    \"SEEDS\": [1, 2, 3], #Seeds for the experiments\n",
    "    \"GT\": True, # Determines if the classifier gets all data with GT Label or only the labeld data\n",
    "    \"MOD\": [\"confidence\", \"disagreement\", \"disagreement_diff\", \"ssl\", \"normal\"], #Determines the experiment modus\n",
    "    #\"MOD\": [\"confidence\", \"ssl\", \"normal\"],\n",
    "\n",
    "    \"OVERLAP\": [0, 100],\n",
    "    \"SAMPLE_EQUAL\": [False, True],\n",
    "    #\"INITAL_SIZE\": [8, 16, 32],\n",
    "    #\"ROUNDS\": [2, 4, 8],\n",
    "    #\"LABELS_PER_ROUND\": [4, 8, 16],\n",
    "\n",
    "    \"SETTING\": [\"AL\", \"SSL\", \"SSL_AL\", \"NORMAL\"],\n",
    "    #\"SETTING\": [\"SSL_AL\"],\n",
    "\n",
    "    \"NUM_EXPERTS\": 2,\n",
    "    \"NUM_CLASSES\": 2,\n",
    "\n",
    "    \"EXPERT_PREDICT\": [\"right\", \"target\"],\n",
    "\n",
    "    \"AL\": { #Parameter for Active Learning\n",
    "        \"INITIAL_SIZE\": [8, 16, 32], #\n",
    "        \"EPOCH_TRAIN\": 40, #\n",
    "        \"n_dataset\": 2, #Number Classes\n",
    "        \"BATCH_SIZE\": 4,\n",
    "        \"BATCH_SIZE_VAL\": 32,\n",
    "        \"ROUNDS\": [2, 4, 8],\n",
    "        \"LABELS_PER_ROUND\": [4, 8, 16],\n",
    "        \"EPOCHS_DEFER\": 10,\n",
    "        \"COST\": [(0, 0), (5, 0)], #Cost for Cost sensitiv learning\n",
    "        #\"TRAIN REJECTOR\": False,\n",
    "        \"PRELOAD\": True,\n",
    "        \"PREPROCESS\": True,\n",
    "        \n",
    "    },\n",
    "    \"SSL\": {\n",
    "        \"PREBUILD\": False,\n",
    "        #\"TRAIN_BATCH_SIZE\": 128,\n",
    "        \"TRAIN_BATCH_SIZE\": 254,\n",
    "        \"TEST_BATCH_SIZE\": 254,\n",
    "        \"N_EPOCHS\": 5, #number of training epoches\n",
    "        \"BATCHSIZE\": 16, #train batch size of labeled samples\n",
    "        #\"N_IMGS_PER_EPOCH\": 32768, #number of training images for each epoch\n",
    "        \"N_IMGS_PER_EPOCH\": 4381*1, #number of training images for each epoch\n",
    "    },\n",
    "    \"L2D\": { # Parameter for Learning to defer\n",
    "        \"TRAIN_BATCH_SIZE\": 128,\n",
    "        \"TEST_BATCH_SIZE\": 128,\n",
    "        \"PRELOAD\": True,\n",
    "        \"PREBUILD\": True,\n",
    "        \"EPOCHS\": 50,\n",
    "        \"VERMA\": {},\n",
    "        \"HEMMER\": {\n",
    "            \"EPOCHS\": 50,\n",
    "            \"LR\": 5e-3,\n",
    "            \"USE_LR_SCHEDULER\": False,\n",
    "            \"DROPOUT\": 0.00,\n",
    "            \"NUM_HIDDEN_UNITS\": 30,\n",
    "        },\n",
    "        \n",
    "    },\n",
    "    \"NEPTUNE\": {\n",
    "        \"NEPTUNE\": True,\n",
    "    },\n",
    "    \"EMBEDDED\": {\n",
    "        \"ARGS\": {\n",
    "            'dataset': \"nih\",\n",
    "            'model': \"resnet50\",\n",
    "            'num_classes': 2,\n",
    "            'batch': 128,\n",
    "            'lr': 0.001,\n",
    "        },\n",
    "        \"EPOCHS\": 30,\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"batch_size\": 64,\n",
    "    \"alpha\": 1.0, #scaling parameter for the loss function, default=1.0\n",
    "    \"epochs\": 50,\n",
    "    \"patience\": 25, #number of patience steps for early stopping the training\n",
    "    \"expert_type\": \"MLPMixer\", #specify the expert type. For the type of experts available, see-> models -> experts. defualt=predict\n",
    "    \"n_classes\": 2, #K for K class classification\n",
    "    \"k\": 0, #\n",
    "    \"n_experts\": 2, #\n",
    "    \"lr\": 0.001, #learning rate\n",
    "    \"weight_decay\": 5e-4, #\n",
    "    \"warmup_epochs\": 5, #\n",
    "    #\"loss_type\": \"softmax\", #surrogate loss type for learning to defer\n",
    "    \"loss_type\": \"ova\",\n",
    "    \"ckp_dir\": \"./Models\", #directory name to save the checkpoints\n",
    "    \"experiment_name\": \"multiple_experts\", #specify the experiment name. Checkpoints will be saved with this name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "373cf849-73ea-48c8-8beb-f874308f0711",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5ad03-8442-4120-80cb-b0daa8902444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images of the whole dataset: 4381\n",
      "Loaded image number: 0\n",
      "Loaded image number: 200\n",
      "Loaded image number: 400\n",
      "Loaded image number: 600\n",
      "Loaded image number: 800\n",
      "Loaded image number: 1000\n",
      "Loaded image number: 1200\n",
      "Loaded image number: 1400\n",
      "Loaded image number: 1600\n",
      "Loaded image number: 1800\n",
      "Loaded image number: 2000\n",
      "Loaded image number: 2200\n",
      "Loaded image number: 2400\n",
      "Loaded image number: 2600\n",
      "Loaded image number: 2800\n",
      "Loaded image number: 3000\n",
      "Loaded image number: 3200\n",
      "Loaded image number: 3400\n",
      "Loaded image number: 3600\n",
      "Loaded image number: 3800\n",
      "Loaded image number: 4000\n",
      "Loaded image number: 4200\n",
      "Full length: 4381\n",
      "Loaded image number: 0\n",
      "Loaded image number: 200\n",
      "Loaded image number: 400\n",
      "Loaded image number: 600\n",
      "Loaded image number: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Loaded set number 0\n",
      "Loaded set number 1\n",
      "Loaded set number 2\n",
      "Loaded set number 3\n",
      "Loaded set number 4\n",
      "Loaded set number 5\n",
      "Loaded set number 6\n",
      "Loaded set number 7\n",
      "Loaded set number 8\n",
      "Loaded set number 9\n",
      "Full length: 4381\n",
      "Loaded image number: 0\n",
      "Loaded image number: 200\n",
      "Loaded image number: 400\n",
      "Loaded image number: 600\n",
      "Loaded image number: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Loaded set number 0\n",
      "Loaded set number 1\n",
      "Loaded set number 2\n",
      "Loaded set number 3\n",
      "Loaded set number 4\n",
      "Loaded set number 5\n",
      "Loaded set number 6\n",
      "Loaded set number 7\n",
      "Loaded set number 8\n",
      "Loaded set number 9\n",
      "Full length: 4381\n",
      "Loaded image number: 0\n",
      "Loaded image number: 200\n",
      "Loaded image number: 400\n",
      "Loaded image number: 600\n",
      "Loaded image number: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2502551/3859129035.py:94: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  run = neptune.init_run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Loaded set number 0\n",
      "Loaded set number 1\n",
      "Loaded set number 2\n",
      "Loaded set number 3\n",
      "Loaded set number 4\n",
      "Loaded set number 5\n",
      "Loaded set number 6\n",
      "Loaded set number 7\n",
      "Loaded set number 8\n",
      "Loaded set number 9\n",
      "https://app.neptune.ai/jonasl/masterarbeit/e/MAS-354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/neptune/internal/utils/git.py:56: UserWarning: GitPython could not be initialized\n",
      "  warnings.warn(\"GitPython could not be initialized\")\n",
      "/tmp/ipykernel_2502551/3859129035.py:99: NeptuneUnsupportedType: You're attempting to log a type that is not directly supported by Neptune (<class 'list'>).\n",
      "        Convert the value to a supported type, such as a string or float, or use stringify_unsupported(obj)\n",
      "        for dictionaries or collections that contain unsupported values.\n",
      "        For more, see https://docs.neptune.ai/help/value_of_unsupported_type\n",
      "  run[\"param\"] = run_param\n",
      "/tmp/ipykernel_2502551/3859129035.py:99: NeptuneUnsupportedType: You're attempting to log a type that is not directly supported by Neptune (<class 'tuple'>).\n",
      "        Convert the value to a supported type, such as a string or float, or use stringify_unsupported(obj)\n",
      "        for dictionaries or collections that contain unsupported values.\n",
      "        For more, see https://docs.neptune.ai/help/value_of_unsupported_type\n",
      "  run[\"param\"] = run_param\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #####################################################################################\n",
      "\n",
      " \n",
      " \n",
      " NEW RUN \n",
      "\n",
      "Initial size: 8\n",
      "Batch size: 4\n",
      "Max rounds: 2\n",
      "Labeled: 16\n",
      "Cost: (0, 0)\n",
      "Setting: SSL_AL\n",
      "Mod: disagreement\n",
      "Overlap: 0\n",
      "Prediction Type target\n",
      "Sample equal False\n",
      "Seed: 1\n",
      "/n\n",
      "Seed: 1 - Fold: 0 \n",
      "\n",
      "Train dir: /home/joli/Masterarbeit/SSL_Working/NIH/emb_net@dataset-nih-model-resnet50-num_classes-2/\n",
      "load Resnet-50 checkpoint\n",
      "load Resnet-50 pretrained on ImageNet\n",
      "Loaded Model resnet50\n",
      "24\n",
      "No Checkpoint found\n",
      "Starting new from epoch 1\n",
      "ii 12 Epoch 1: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.45537757437070936 \n",
      "Test-Acc-Class [0.57048458 0.33095238]\n",
      "loss: 0.7102683186531067\n",
      "ii 12 Epoch 2: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.5503432494279176 \n",
      "Test-Acc-Class [0.92290749 0.14761905]\n",
      "loss: 0.6875206232070923\n",
      "ii 12 Epoch 3: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.5732265446224256 \n",
      "Test-Acc-Class [0.86123348 0.26190476]\n",
      "loss: 0.674466609954834\n",
      "ii 12 Epoch 4: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.6704805491990846 \n",
      "Test-Acc-Class [0.83039648 0.49761905]\n",
      "loss: 0.6622026562690735\n",
      "ii 12 Epoch 5: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7379862700228833 \n",
      "Test-Acc-Class [0.79955947 0.67142857]\n",
      "loss: 0.6356356739997864\n",
      "ii 12 Epoch 6: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7276887871853547 \n",
      "Test-Acc-Class [0.80176211 0.64761905]\n",
      "loss: 0.6398152709007263\n",
      "ii 12 Epoch 7: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7276887871853547 \n",
      "Test-Acc-Class [0.81277533 0.63571429]\n",
      "loss: 0.6889605522155762\n",
      "ii 12 Epoch 8: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7299771167048055 \n",
      "Test-Acc-Class [0.81718062 0.63571429]\n",
      "loss: 0.6717646718025208\n",
      "ii 12 Epoch 9: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7322654462242563 \n",
      "Test-Acc-Class [0.79295154 0.66666667]\n",
      "loss: 0.6532719731330872\n",
      "ii 12 Epoch 10: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7425629290617849 \n",
      "Test-Acc-Class [0.79955947 0.68095238]\n",
      "loss: 0.6608079075813293\n",
      "ii 12 Epoch 11: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7345537757437071 \n",
      "Test-Acc-Class [0.80396476 0.65952381]\n",
      "loss: 0.6243454217910767\n",
      "ii 12 Epoch 12: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7414187643020596 \n",
      "Test-Acc-Class [0.80396476 0.67380952]\n",
      "loss: 0.6417146921157837\n",
      "ii 12 Epoch 13: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7459954233409611 \n",
      "Test-Acc-Class [0.81938326 0.66666667]\n",
      "loss: 0.6319650411605835\n",
      "ii 12 Epoch 14: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7402745995423341 \n",
      "Test-Acc-Class [0.81718062 0.65714286]\n",
      "loss: 0.6440430283546448\n",
      "ii 12 Epoch 15: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7322654462242563 \n",
      "Test-Acc-Class [0.79955947 0.65952381]\n",
      "loss: 0.6191473603248596\n",
      "ii 12 Epoch 16: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7368421052631579 \n",
      "Test-Acc-Class [0.78854626 0.68095238]\n",
      "loss: 0.6183555126190186\n",
      "ii 12 Epoch 17: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7425629290617849 \n",
      "Test-Acc-Class [0.81277533 0.66666667]\n",
      "loss: 0.6779820919036865\n",
      "ii 12 Epoch 18: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7345537757437071 \n",
      "Test-Acc-Class [0.80176211 0.66190476]\n",
      "loss: 0.6848822832107544\n",
      "ii 12 Epoch 19: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7356979405034325 \n",
      "Test-Acc-Class [0.81938326 0.6452381 ]\n",
      "loss: 0.6459090709686279\n",
      "ii 12 Epoch 20: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7402745995423341 \n",
      "Test-Acc-Class [0.81277533 0.66190476]\n",
      "loss: 0.6644721627235413\n",
      "ii 12 Epoch 21: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7414187643020596 \n",
      "Test-Acc-Class [0.80396476 0.67380952]\n",
      "loss: 0.6404438018798828\n",
      "ii 12 Epoch 22: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7345537757437071 \n",
      "Test-Acc-Class [0.80837004 0.6547619 ]\n",
      "loss: 0.637545645236969\n",
      "ii 12 Epoch 23: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7402745995423341 \n",
      "Test-Acc-Class [0.80396476 0.67142857]\n",
      "loss: 0.6265249848365784\n",
      "ii 12 Epoch 24: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7391304347826086 \n",
      "Test-Acc-Class [0.81057269 0.66190476]\n",
      "loss: 0.6669752597808838\n",
      "ii 12 Epoch 25: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7391304347826086 \n",
      "Test-Acc-Class [0.81057269 0.66190476]\n",
      "loss: 0.6487410068511963\n",
      "ii 12 Epoch 26: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7402745995423341 \n",
      "Test-Acc-Class [0.80396476 0.67142857]\n",
      "loss: 0.6282607913017273\n",
      "ii 12 Epoch 27: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7414187643020596 \n",
      "Test-Acc-Class [0.79955947 0.67857143]\n",
      "loss: 0.6253215670585632\n",
      "ii 12 Epoch 28: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7345537757437071 \n",
      "Test-Acc-Class [0.79735683 0.66666667]\n",
      "loss: 0.605242908000946\n",
      "ii 12 Epoch 29: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7391304347826086 \n",
      "Test-Acc-Class [0.80176211 0.67142857]\n",
      "loss: 0.6694714426994324\n",
      "ii 12 Epoch 30: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7425629290617849 \n",
      "Test-Acc-Class [0.81497797 0.66428571]\n",
      "loss: 0.6585160493850708\n",
      "Test-Accuracy: 0.7425629290617849 \n",
      "Test-Acc-Class [0.81497797 0.66428571]\n",
      "NIH\n",
      "2023-07-20 09:13:03,937 - INFO - train -   {'dataset': 'NIH', 'wresnet_k': 2, 'wresnet_n': 28, 'n_classes': 2, 'mu': 7, 'eval_ema': True, 'ema_m': 0.999, 'lam_u': 1.0, 'lr': 0.03, 'weight_decay': 0.0005, 'momentum': 0.9, 'temperature': 0.2, 'low_dim': 64, 'lam_c': 1, 'contrast_th': 0.8, 'thr': 0.95, 'alpha': 0.9, 'queue_batch': 5, 'exp_dir': 'EmbeddingCM_bin', 'labelerId': 4323195249, 'ex_strength': 4323195249, 'n_labeled': None, 'seed': 1, 'n_epoches': 5, 'batchsize': 16, 'n_imgs_per_epoch': 4381, 'type': '50'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/Masterarbeit/expert.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.predictions[\"Image ID\"] = self.predictions[\"Image ID\"].astype('category').copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load Resnet-50 checkpoint\n",
      "None\n",
      "Loaded Model resnet50\n",
      "2023-07-20 09:13:04,620 - INFO - train -   Total params: 4.33M\n",
      "Index: 0\n",
      "Labels: 8\n",
      "Index: 0\n",
      "Index: 0\n",
      "No Checkpoint found at SSL_Working/NIH/EmbeddingCM_bin/ex4323195249_xNone_seed1/ckp.latest\n",
      "Starting new from epoch 1\n",
      "2023-07-20 09:13:05,181 - INFO - train -   -----------start training--------------\n",
      "2023-07-20 09:13:38,267 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 64. loss_u: 0.234. loss_x: 0.117. loss_c: 4.568. n_correct_u: 29.95/74.09. Mask:0.662. num_pos: 49.6. LR: 0.030. Time: 33.08\n",
      "2023-07-20 09:14:02,201 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 128. loss_u: 0.181. loss_x: 0.065. loss_c: 4.548. n_correct_u: 28.41/71.27. Mask:0.636. num_pos: 50.4. LR: 0.030. Time: 23.93\n",
      "2023-07-20 09:14:25,996 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 192. loss_u: 0.157. loss_x: 0.046. loss_c: 4.580. n_correct_u: 27.05/70.68. Mask:0.631. num_pos: 54.5. LR: 0.029. Time: 23.79\n",
      "2023-07-20 09:14:49,881 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 256. loss_u: 0.142. loss_x: 0.036. loss_c: 4.603. n_correct_u: 25.08/66.92. Mask:0.597. num_pos: 55.3. LR: 0.029. Time: 23.88\n",
      "2023-07-20 09:14:58,123 - INFO - train -   Epoch 0. Acc: 30.2687. Ema-Acc: 40.2460. best_acc: 30.2687 in epoch0\n",
      "2023-07-20 09:15:23,797 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 64. loss_u: 0.100. loss_x: 0.008. loss_c: 4.670. n_correct_u: 20.91/64.41. Mask:0.575. num_pos: 66.2. LR: 0.028. Time: 25.59\n",
      "2023-07-20 09:15:47,788 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 128. loss_u: 0.095. loss_x: 0.007. loss_c: 4.676. n_correct_u: 20.35/64.24. Mask:0.574. num_pos: 67.3. LR: 0.028. Time: 23.99\n",
      "2023-07-20 09:16:11,787 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 192. loss_u: 0.098. loss_x: 0.008. loss_c: 4.676. n_correct_u: 20.23/64.84. Mask:0.579. num_pos: 68.3. LR: 0.027. Time: 24.00\n",
      "2023-07-20 09:16:35,695 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 256. loss_u: 0.098. loss_x: 0.007. loss_c: 4.674. n_correct_u: 20.07/64.30. Mask:0.574. num_pos: 67.6. LR: 0.026. Time: 23.91\n",
      "2023-07-20 09:16:43,464 - INFO - train -   Epoch 1. Acc: 35.1036. Ema-Acc: 38.8603. best_acc: 35.1036 in epoch1\n",
      "2023-07-20 09:17:09,461 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:2, iter: 64. loss_u: 0.095. loss_x: 0.006. loss_c: 4.688. n_correct_u: 21.61/71.66. Mask:0.640. num_pos: 76.1. LR: 0.025. Time: 25.83\n"
     ]
    }
   ],
   "source": [
    "expert_metrics_all = run_experiment(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74125d0e-7586-4ca5-9d54-43f8c0bd8fe9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expert_metrics_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Store data (serialize)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetrics.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m----> 5\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mexpert_metrics_all\u001b[49m, handle, protocol\u001b[38;5;241m=\u001b[39mpickle\u001b[38;5;241m.\u001b[39mHIGHEST_PROTOCOL)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expert_metrics_all' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Store data (serialize)\n",
    "with open('Metrics.pickle', 'wb') as handle:\n",
    "    pickle.dump(expert_metrics_all, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load data (deserialize)\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    unserialized_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "728e8909-f61e-463b-98f8-f8cd0ca3db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a883849-9e6b-4a55-9a47-7378ec4e3600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26330993"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = f\"{10} + {2}\"\n",
    "int(hashlib.sha256(s.encode('utf-8')).hexdigest(), 16) % 10**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dba1fef-cf39-4866-ad07-7ad15cd224b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13151493"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = f\"{2} + {10}\"\n",
    "int(hashlib.sha256(s.encode('utf-8')).hexdigest(), 16) % 10**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e046cd1-945b-45f5-8fc9-f0e810fd25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"PATH\": \"../Datasets/NIH/\",\n",
    "    \"TARGET\": \"Airspace_Opacity\",\n",
    "    \"LABELER_IDS\": [[4323195249, 4295232296]],\n",
    "    \"K\": 10, #Number of folds\n",
    "    \"SEEDS\": [1], #Seeds for the experiments\n",
    "    \"GT\": True, # Determines if the classifier gets all data with GT Label or only the labeld data\n",
    "    #\"MOD\": [\"confidence\", \"disagreement\", \"disagreement_diff\", \"ssl\", \"normal\"], #Determines the experiment modus\n",
    "    \"MOD\": [\"confidence\"],\n",
    "\n",
    "    \"OVERLAP\": [100],\n",
    "    \"SAMPLE_EQUAL\": [True],\n",
    "    #\"INITAL_SIZE\": [8, 16, 32],\n",
    "    #\"ROUNDS\": [2, 4, 8],\n",
    "    #\"LABELS_PER_ROUND\": [4, 8, 16],\n",
    "\n",
    "    #\"SETTING\": [\"AL\", \"SSL\", \"SSL_AL\", \"NORMAL\"],\n",
    "    \"SETTING\": [\"SSL_AL\"],\n",
    "\n",
    "    \"NUM_EXPERTS\": 2,\n",
    "    \"NUM_CLASSES\": 2,\n",
    "\n",
    "    \"EXPERT_PREDICT\": [\"target\"],\n",
    "\n",
    "    \"AL\": { #Parameter for Active Learning\n",
    "        \"INITIAL_SIZE\": [32], #\n",
    "        \"EPOCH_TRAIN\": 40, #\n",
    "        \"n_dataset\": 2, #Number Classes\n",
    "        \"BATCH_SIZE\": 4,\n",
    "        \"BATCH_SIZE_VAL\": 32,\n",
    "        \"ROUNDS\": [8],\n",
    "        \"LABELS_PER_ROUND\": [4],\n",
    "        \"EPOCHS_DEFER\": 10,\n",
    "        \"COST\": [(0, 0)], #Cost for Cost sensitiv learning\n",
    "        #\"TRAIN REJECTOR\": False,\n",
    "        \"PRELOAD\": True,\n",
    "        \"PREPROCESS\": True,\n",
    "        \n",
    "    },\n",
    "    \"SSL\": {\n",
    "        \"PREBUILD\": False,\n",
    "        #\"TRAIN_BATCH_SIZE\": 128,\n",
    "        \"TRAIN_BATCH_SIZE\": 254,\n",
    "        \"TEST_BATCH_SIZE\": 254,\n",
    "        \"N_EPOCHS\": 5, #number of training epoches\n",
    "        \"BATCHSIZE\": 16, #train batch size of labeled samples\n",
    "        #\"N_IMGS_PER_EPOCH\": 32768, #number of training images for each epoch\n",
    "        \"N_IMGS_PER_EPOCH\": 4381*1, #number of training images for each epoch\n",
    "    },\n",
    "    \"L2D\": { # Parameter for Learning to defer\n",
    "        \"TRAIN_BATCH_SIZE\": 128,\n",
    "        \"TEST_BATCH_SIZE\": 128,\n",
    "        \"PRELOAD\": True,\n",
    "        \"PREBUILD\": True,\n",
    "        \"EPOCHS\": 50,\n",
    "        \"VERMA\": {},\n",
    "        \"HEMMER\": {\n",
    "            \"EPOCHS\": 50,\n",
    "            \"LR\": 5e-3,\n",
    "            \"USE_LR_SCHEDULER\": False,\n",
    "            \"DROPOUT\": 0.00,\n",
    "            \"NUM_HIDDEN_UNITS\": 30,\n",
    "        },\n",
    "        \n",
    "    },\n",
    "    \"NEPTUNE\": {\n",
    "        \"NEPTUNE\": False,\n",
    "    },\n",
    "    \"EMBEDDED\": {\n",
    "        \"ARGS\": {\n",
    "            'dataset': \"nih\",\n",
    "            'model': \"resnet50\",\n",
    "            'num_classes': 2,\n",
    "            'batch': 128,\n",
    "            'lr': 0.001,\n",
    "        },\n",
    "        \"EPOCHS\": 30,\n",
    "    },\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"batch_size\": 64,\n",
    "    \"alpha\": 1.0, #scaling parameter for the loss function, default=1.0\n",
    "    \"epochs\": 50,\n",
    "    \"patience\": 25, #number of patience steps for early stopping the training\n",
    "    \"expert_type\": \"MLPMixer\", #specify the expert type. For the type of experts available, see-> models -> experts. defualt=predict\n",
    "    \"n_classes\": 2, #K for K class classification\n",
    "    \"k\": 0, #\n",
    "    \"n_experts\": 2, #\n",
    "    \"lr\": 0.001, #learning rate\n",
    "    \"weight_decay\": 5e-4, #\n",
    "    \"warmup_epochs\": 5, #\n",
    "    #\"loss_type\": \"softmax\", #surrogate loss type for learning to defer\n",
    "    \"loss_type\": \"ova\",\n",
    "    \"ckp_dir\": \"./Models\", #directory name to save the checkpoints\n",
    "    \"experiment_name\": \"multiple_experts\", #specify the experiment name. Checkpoints will be saved with this name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bdf4bfd-752e-4848-a755-a4f49b2cbeaf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images of the whole dataset: 4381\n",
      "Loaded image number: 0\n",
      "Loaded image number: 200\n",
      "Loaded image number: 400\n",
      "Loaded image number: 600\n",
      "Loaded image number: 800\n",
      "Loaded image number: 1000\n",
      "Loaded image number: 1200\n",
      "Loaded image number: 1400\n",
      "Loaded image number: 1600\n",
      "Loaded image number: 1800\n",
      "Loaded image number: 2000\n",
      "Loaded image number: 2200\n",
      "Loaded image number: 2400\n",
      "Loaded image number: 2600\n",
      "Loaded image number: 2800\n",
      "Loaded image number: 3000\n",
      "Loaded image number: 3200\n",
      "Loaded image number: 3400\n",
      "Loaded image number: 3600\n",
      "Loaded image number: 3800\n",
      "Loaded image number: 4000\n",
      "Loaded image number: 4200\n",
      "Full length: 4381\n",
      "Loaded image number: 0\n",
      "Loaded image number: 200\n",
      "Loaded image number: 400\n",
      "Loaded image number: 600\n",
      "Loaded image number: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Loaded set number 0\n",
      "Loaded set number 1\n",
      "Loaded set number 2\n",
      "Loaded set number 3\n",
      "Loaded set number 4\n",
      "Loaded set number 5\n",
      "Loaded set number 6\n",
      "Loaded set number 7\n",
      "Loaded set number 8\n",
      "Loaded set number 9\n",
      "\n",
      " #####################################################################################\n",
      "\n",
      " \n",
      " \n",
      " NEW RUN \n",
      "\n",
      "Initial size: 32\n",
      "Batch size: 4\n",
      "Max rounds: 8\n",
      "Labeled: 64\n",
      "Cost: (0, 0)\n",
      "Setting: SSL_AL\n",
      "Mod: confidence\n",
      "Overlap: 100\n",
      "Prediction Type target\n",
      "Sample equal True\n",
      "Seed: 1\n",
      "/n\n",
      "Seed: 1 - Fold: 0 \n",
      "\n",
      "Train dir: /home/joli/Masterarbeit/SSL_Working/NIH/emb_net@dataset-nih-model-resnet50-num_classes-2/\n",
      "load Resnet-50 checkpoint\n",
      "load Resnet-50 pretrained on ImageNet\n",
      "Loaded Model resnet50\n",
      "24\n",
      "No Checkpoint found\n",
      "Starting new from epoch 1\n",
      "ii 12 Epoch 1: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.4450800915331808 \n",
      "Test-Acc-Class [0.44052863 0.45      ]\n",
      "loss: 0.6905777454376221\n",
      "ii 12 Epoch 2: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.5125858123569794 \n",
      "Test-Acc-Class [0.70044053 0.30952381]\n",
      "loss: 0.6826318502426147\n",
      "ii 12 Epoch 3: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.5594965675057209 \n",
      "Test-Acc-Class [0.90748899 0.18333333]\n",
      "loss: 0.685637354850769\n",
      "ii 12 Epoch 4: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.6292906178489702 \n",
      "Test-Acc-Class [0.84140969 0.4       ]\n",
      "loss: 0.6596149206161499\n",
      "ii 12 Epoch 5: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.6933638443935927 \n",
      "Test-Acc-Class [0.7753304 0.6047619]\n",
      "loss: 0.6281673312187195\n",
      "ii 12 Epoch 6: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.700228832951945 \n",
      "Test-Acc-Class [0.77312775 0.62142857]\n",
      "loss: 0.6302878856658936\n",
      "ii 12 Epoch 7: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7254004576659039 \n",
      "Test-Acc-Class [0.81277533 0.63095238]\n",
      "loss: 0.6831735372543335\n",
      "ii 12 Epoch 8: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7025171624713958 \n",
      "Test-Acc-Class [0.76872247 0.63095238]\n",
      "loss: 0.6716969013214111\n",
      "ii 12 Epoch 9: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7162471395881007 \n",
      "Test-Acc-Class [0.77973568 0.64761905]\n",
      "loss: 0.6646948456764221\n",
      "ii 12 Epoch 10: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7242562929061785 \n",
      "Test-Acc-Class [0.7753304  0.66904762]\n",
      "loss: 0.6806309819221497\n",
      "ii 12 Epoch 11: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7299771167048055 \n",
      "Test-Acc-Class [0.78634361 0.66904762]\n",
      "loss: 0.5911248922348022\n",
      "ii 12 Epoch 12: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7105263157894737 \n",
      "Test-Acc-Class [0.77312775 0.64285714]\n",
      "loss: 0.6328349113464355\n",
      "ii 12 Epoch 13: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7185354691075515 \n",
      "Test-Acc-Class [0.78193833 0.65      ]\n",
      "loss: 0.6445102095603943\n",
      "ii 12 Epoch 14: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.717391304347826 \n",
      "Test-Acc-Class [0.78193833 0.64761905]\n",
      "loss: 0.6341688632965088\n",
      "ii 12 Epoch 15: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7242562929061785 \n",
      "Test-Acc-Class [0.78634361 0.65714286]\n",
      "loss: 0.6027547121047974\n",
      "ii 12 Epoch 16: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7288329519450801 \n",
      "Test-Acc-Class [0.7753304  0.67857143]\n",
      "loss: 0.6372483968734741\n",
      "ii 12 Epoch 17: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7265446224256293 \n",
      "Test-Acc-Class [0.78193833 0.66666667]\n",
      "loss: 0.6560788154602051\n",
      "ii 12 Epoch 18: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7185354691075515 \n",
      "Test-Acc-Class [0.77973568 0.65238095]\n",
      "loss: 0.6771438717842102\n",
      "ii 12 Epoch 19: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7208237986270023 \n",
      "Test-Acc-Class [0.79295154 0.64285714]\n",
      "loss: 0.6500576734542847\n",
      "ii 12 Epoch 20: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7208237986270023 \n",
      "Test-Acc-Class [0.78414097 0.65238095]\n",
      "loss: 0.6467698812484741\n",
      "ii 12 Epoch 21: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7185354691075515 \n",
      "Test-Acc-Class [0.7753304  0.65714286]\n",
      "loss: 0.6275518536567688\n",
      "ii 12 Epoch 22: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7208237986270023 \n",
      "Test-Acc-Class [0.77973568 0.65714286]\n",
      "loss: 0.6072328090667725\n",
      "ii 12 Epoch 23: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.717391304347826 \n",
      "Test-Acc-Class [0.77092511 0.65952381]\n",
      "loss: 0.6201704740524292\n",
      "ii 12 Epoch 24: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.717391304347826 \n",
      "Test-Acc-Class [0.78193833 0.64761905]\n",
      "loss: 0.6601910591125488\n",
      "ii 12 Epoch 25: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7219679633867276 \n",
      "Test-Acc-Class [0.77973568 0.65952381]\n",
      "loss: 0.64423006772995\n",
      "ii 12 Epoch 26: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7288329519450801 \n",
      "Test-Acc-Class [0.78193833 0.67142857]\n",
      "loss: 0.6309360265731812\n",
      "ii 12 Epoch 27: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7242562929061785 \n",
      "Test-Acc-Class [0.77753304 0.66666667]\n",
      "loss: 0.6103562116622925\n",
      "ii 12 Epoch 28: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7219679633867276 \n",
      "Test-Acc-Class [0.78193833 0.65714286]\n",
      "loss: 0.6037197709083557\n",
      "ii 12 Epoch 29: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7254004576659039 \n",
      "Test-Acc-Class [0.7753304  0.67142857]\n",
      "loss: 0.6419118642807007\n",
      "ii 12 Epoch 30: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7219679633867276 \n",
      "Test-Acc-Class [0.7907489  0.64761905]\n",
      "loss: 0.6696614027023315\n",
      "Test-Accuracy: 0.7219679633867276 \n",
      "Test-Acc-Class [0.7907489  0.64761905]\n",
      "NIH\n",
      "2023-07-17 11:20:24,384 - INFO - train -   {'dataset': 'NIH', 'wresnet_k': 2, 'wresnet_n': 28, 'n_classes': 2, 'mu': 7, 'eval_ema': True, 'ema_m': 0.999, 'lam_u': 1.0, 'lr': 0.03, 'weight_decay': 0.0005, 'momentum': 0.9, 'temperature': 0.2, 'low_dim': 64, 'lam_c': 1, 'contrast_th': 0.8, 'thr': 0.95, 'alpha': 0.9, 'queue_batch': 5, 'exp_dir': 'EmbeddingCM_bin', 'labelerId': 4323195249, 'ex_strength': 4323195249, 'n_labeled': None, 'seed': 1, 'n_epoches': 5, 'batchsize': 16, 'n_imgs_per_epoch': 4381, 'type': '50'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/Masterarbeit/expert.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.predictions[\"Image ID\"] = self.predictions[\"Image ID\"].astype('category').copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load Resnet-50 checkpoint\n",
      "None\n",
      "Loaded Model resnet50\n",
      "2023-07-17 11:20:25,029 - INFO - train -   Total params: 4.33M\n",
      "Index: 0\n",
      "Labels: 32\n",
      "Index: 0\n",
      "Index: 0\n",
      "No Checkpoint found at SSL_Working/NIH/EmbeddingCM_bin/ex4323195249_xNone_seed1/ckp.latest\n",
      "Starting new from epoch 1\n",
      "2023-07-17 11:20:25,638 - INFO - train -   -----------start training--------------\n",
      "2023-07-17 11:20:58,211 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 64. loss_u: 0.188. loss_x: 0.189. loss_c: 4.551. n_correct_u: 25.09/60.78. Mask:0.543. num_pos: 40.4. LR: 0.030. Time: 32.57\n",
      "2023-07-17 11:21:22,316 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 128. loss_u: 0.152. loss_x: 0.101. loss_c: 4.472. n_correct_u: 26.20/61.60. Mask:0.550. num_pos: 38.8. LR: 0.030. Time: 24.10\n",
      "2023-07-17 11:21:46,318 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 192. loss_u: 0.134. loss_x: 0.070. loss_c: 4.415. n_correct_u: 27.22/63.10. Mask:0.563. num_pos: 38.2. LR: 0.029. Time: 24.00\n",
      "2023-07-17 11:22:10,358 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 256. loss_u: 0.125. loss_x: 0.054. loss_c: 4.380. n_correct_u: 28.21/64.68. Mask:0.577. num_pos: 38.3. LR: 0.029. Time: 24.04\n",
      "2023-07-17 11:22:18,800 - INFO - train -   Epoch 0. Acc: 39.6984. Ema-Acc: 39.2520. best_acc: 39.6984 in epoch0\n",
      "2023-07-17 11:22:45,527 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 64. loss_u: 0.093. loss_x: 0.006. loss_c: 4.244. n_correct_u: 30.94/69.98. Mask:0.625. num_pos: 38.6. LR: 0.028. Time: 26.65\n",
      "2023-07-17 11:23:09,995 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 128. loss_u: 0.091. loss_x: 0.007. loss_c: 4.237. n_correct_u: 30.84/69.63. Mask:0.622. num_pos: 38.8. LR: 0.028. Time: 24.46\n",
      "2023-07-17 11:23:34,318 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 192. loss_u: 0.091. loss_x: 0.007. loss_c: 4.222. n_correct_u: 31.02/70.08. Mask:0.626. num_pos: 38.6. LR: 0.027. Time: 24.32\n",
      "2023-07-17 11:23:58,669 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 256. loss_u: 0.090. loss_x: 0.006. loss_c: 4.221. n_correct_u: 31.27/70.52. Mask:0.630. num_pos: 38.9. LR: 0.026. Time: 24.35\n",
      "2023-07-17 11:24:06,544 - INFO - train -   Epoch 1. Acc: 38.0433. Ema-Acc: 38.7593. best_acc: 39.6984 in epoch0\n",
      "2023-07-17 11:24:33,396 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:2, iter: 64. loss_u: 0.086. loss_x: 0.006. loss_c: 4.188. n_correct_u: 32.25/71.89. Mask:0.642. num_pos: 39.3. LR: 0.025. Time: 26.67\n",
      "2023-07-17 11:24:57,701 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:2, iter: 128. loss_u: 0.087. loss_x: 0.006. loss_c: 4.191. n_correct_u: 32.64/72.66. Mask:0.649. num_pos: 39.7. LR: 0.023. Time: 24.30\n",
      "2023-07-17 11:25:22,080 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:2, iter: 192. loss_u: 0.087. loss_x: 0.006. loss_c: 4.188. n_correct_u: 32.45/72.35. Mask:0.646. num_pos: 39.5. LR: 0.022. Time: 24.38\n",
      "2023-07-17 11:25:46,374 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:2, iter: 256. loss_u: 0.086. loss_x: 0.006. loss_c: 4.189. n_correct_u: 32.39/72.39. Mask:0.646. num_pos: 39.6. LR: 0.021. Time: 24.29\n",
      "2023-07-17 11:25:54,340 - INFO - train -   Epoch 2. Acc: 37.8201. Ema-Acc: 38.4897. best_acc: 39.6984 in epoch0\n",
      "2023-07-17 11:26:21,146 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:3, iter: 64. loss_u: 0.087. loss_x: 0.005. loss_c: 4.175. n_correct_u: 32.52/73.89. Mask:0.660. num_pos: 40.2. LR: 0.019. Time: 26.64\n",
      "2023-07-17 11:26:45,458 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:3, iter: 128. loss_u: 0.087. loss_x: 0.005. loss_c: 4.161. n_correct_u: 32.20/73.29. Mask:0.654. num_pos: 39.5. LR: 0.017. Time: 24.31\n",
      "2023-07-17 11:27:09,681 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:3, iter: 192. loss_u: 0.087. loss_x: 0.005. loss_c: 4.159. n_correct_u: 32.15/73.28. Mask:0.654. num_pos: 39.7. LR: 0.016. Time: 24.22\n",
      "2023-07-17 11:27:33,963 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:3, iter: 256. loss_u: 0.086. loss_x: 0.005. loss_c: 4.154. n_correct_u: 32.31/73.21. Mask:0.654. num_pos: 39.7. LR: 0.014. Time: 24.28\n",
      "2023-07-17 11:27:41,822 - INFO - train -   Epoch 3. Acc: 38.9825. Ema-Acc: 38.2665. best_acc: 39.6984 in epoch0\n",
      "2023-07-17 11:28:08,603 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:4, iter: 64. loss_u: 0.086. loss_x: 0.004. loss_c: 4.158. n_correct_u: 33.69/75.44. Mask:0.674. num_pos: 41.0. LR: 0.012. Time: 26.61\n",
      "2023-07-17 11:28:32,893 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:4, iter: 128. loss_u: 0.086. loss_x: 0.005. loss_c: 4.143. n_correct_u: 33.36/75.34. Mask:0.673. num_pos: 40.7. LR: 0.010. Time: 24.29\n",
      "2023-07-17 11:28:57,066 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:4, iter: 192. loss_u: 0.084. loss_x: 0.005. loss_c: 4.143. n_correct_u: 33.50/75.52. Mask:0.674. num_pos: 40.7. LR: 0.008. Time: 24.17\n",
      "2023-07-17 11:29:21,283 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:4, iter: 256. loss_u: 0.083. loss_x: 0.004. loss_c: 4.138. n_correct_u: 33.52/75.36. Mask:0.673. num_pos: 40.7. LR: 0.006. Time: 24.22\n",
      "2023-07-17 11:29:29,124 - INFO - train -   Epoch 4. Acc: 38.7129. Ema-Acc: 38.2665. best_acc: 39.6984 in epoch0\n",
      "NIH\n",
      "2023-07-17 11:29:30,343 - INFO - train -   {'dataset': 'NIH', 'wresnet_k': 2, 'wresnet_n': 28, 'n_classes': 2, 'mu': 7, 'eval_ema': True, 'ema_m': 0.999, 'lam_u': 1.0, 'lr': 0.03, 'weight_decay': 0.0005, 'momentum': 0.9, 'temperature': 0.2, 'low_dim': 64, 'lam_c': 1, 'contrast_th': 0.8, 'thr': 0.95, 'alpha': 0.9, 'queue_batch': 5, 'exp_dir': 'EmbeddingCM_bin', 'labelerId': 4295232296, 'ex_strength': 4295232296, 'n_labeled': None, 'seed': 1, 'n_epoches': 5, 'batchsize': 16, 'n_imgs_per_epoch': 4381, 'type': '50'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/Masterarbeit/expert.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.predictions[\"Image ID\"] = self.predictions[\"Image ID\"].astype('category').copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load Resnet-50 checkpoint\n",
      "None\n",
      "Loaded Model resnet50\n",
      "2023-07-17 11:29:31,055 - INFO - train -   Total params: 4.33M\n",
      "Index: 0\n",
      "Labels: 32\n",
      "Index: 0\n",
      "Index: 0\n",
      "No Checkpoint found at SSL_Working/NIH/EmbeddingCM_bin/ex4295232296_xNone_seed1/ckp.latest\n",
      "Starting new from epoch 1\n",
      "2023-07-17 11:29:31,648 - INFO - train -   -----------start training--------------\n",
      "2023-07-17 11:29:58,141 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 64. loss_u: 0.156. loss_x: 0.194. loss_c: 4.551. n_correct_u: 7.67/52.11. Mask:0.465. num_pos: 40.2. LR: 0.030. Time: 26.49\n",
      "2023-07-17 11:30:22,375 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 128. loss_u: 0.142. loss_x: 0.104. loss_c: 4.489. n_correct_u: 8.12/55.84. Mask:0.499. num_pos: 39.8. LR: 0.030. Time: 24.23\n",
      "2023-07-17 11:30:46,741 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 192. loss_u: 0.133. loss_x: 0.074. loss_c: 4.435. n_correct_u: 8.23/56.58. Mask:0.505. num_pos: 38.4. LR: 0.029. Time: 24.36\n",
      "2023-07-17 11:31:11,269 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 256. loss_u: 0.124. loss_x: 0.058. loss_c: 4.399. n_correct_u: 8.46/57.79. Mask:0.516. num_pos: 38.2. LR: 0.029. Time: 24.53\n",
      "2023-07-17 11:31:19,220 - INFO - train -   Epoch 0. Acc: 14.3573. Ema-Acc: 14.8037. best_acc: 14.3573 in epoch0\n",
      "2023-07-17 11:31:45,916 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 64. loss_u: 0.092. loss_x: 0.010. loss_c: 4.234. n_correct_u: 8.52/59.55. Mask:0.532. num_pos: 34.6. LR: 0.028. Time: 26.61\n",
      "2023-07-17 11:32:10,310 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 128. loss_u: 0.088. loss_x: 0.010. loss_c: 4.227. n_correct_u: 8.60/60.14. Mask:0.537. num_pos: 35.3. LR: 0.028. Time: 24.39\n",
      "2023-07-17 11:32:34,620 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 192. loss_u: 0.090. loss_x: 0.010. loss_c: 4.235. n_correct_u: 8.93/61.72. Mask:0.551. num_pos: 36.1. LR: 0.027. Time: 24.31\n",
      "2023-07-17 11:32:58,954 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 256. loss_u: 0.090. loss_x: 0.010. loss_c: 4.236. n_correct_u: 9.08/62.63. Mask:0.559. num_pos: 36.7. LR: 0.026. Time: 24.33\n",
      "2023-07-17 11:33:06,798 - INFO - train -   Epoch 1. Acc: 14.9806. Ema-Acc: 15.0270. best_acc: 14.9806 in epoch1\n",
      "2023-07-17 11:33:33,790 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:2, iter: 64. loss_u: 0.095. loss_x: 0.009. loss_c: 4.236. n_correct_u: 9.80/66.81. Mask:0.597. num_pos: 38.4. LR: 0.025. Time: 26.82\n",
      "2023-07-17 11:33:58,197 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:2, iter: 128. loss_u: 0.091. loss_x: 0.008. loss_c: 4.224. n_correct_u: 9.62/64.85. Mask:0.579. num_pos: 37.8. LR: 0.023. Time: 24.40\n",
      "2023-07-17 11:34:22,630 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:2, iter: 192. loss_u: 0.090. loss_x: 0.008. loss_c: 4.218. n_correct_u: 9.50/64.91. Mask:0.580. num_pos: 37.8. LR: 0.022. Time: 24.43\n",
      "2023-07-17 11:34:47,055 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:2, iter: 256. loss_u: 0.091. loss_x: 0.008. loss_c: 4.212. n_correct_u: 9.61/65.94. Mask:0.589. num_pos: 38.1. LR: 0.021. Time: 24.42\n",
      "2023-07-17 11:34:54,967 - INFO - train -   Epoch 2. Acc: 14.7574. Ema-Acc: 15.0270. best_acc: 14.9806 in epoch1\n",
      "2023-07-17 11:35:21,829 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:3, iter: 64. loss_u: 0.094. loss_x: 0.011. loss_c: 4.224. n_correct_u: 9.56/67.36. Mask:0.601. num_pos: 40.2. LR: 0.019. Time: 26.69\n",
      "2023-07-17 11:35:46,342 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:3, iter: 128. loss_u: 0.093. loss_x: 0.009. loss_c: 4.211. n_correct_u: 9.55/66.85. Mask:0.597. num_pos: 39.5. LR: 0.017. Time: 24.51\n",
      "2023-07-17 11:36:10,800 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:3, iter: 192. loss_u: 0.091. loss_x: 0.008. loss_c: 4.206. n_correct_u: 9.61/67.33. Mask:0.601. num_pos: 39.6. LR: 0.016. Time: 24.46\n",
      "2023-07-17 11:36:35,106 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:3, iter: 256. loss_u: 0.090. loss_x: 0.008. loss_c: 4.198. n_correct_u: 9.66/67.27. Mask:0.601. num_pos: 39.5. LR: 0.014. Time: 24.30\n",
      "2023-07-17 11:36:43,031 - INFO - train -   Epoch 3. Acc: 14.9806. Ema-Acc: 14.9806. best_acc: 14.9806 in epoch1\n",
      "2023-07-17 11:37:09,764 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:4, iter: 64. loss_u: 0.089. loss_x: 0.006. loss_c: 4.179. n_correct_u: 9.91/69.00. Mask:0.616. num_pos: 39.2. LR: 0.012. Time: 26.58\n",
      "2023-07-17 11:37:33,990 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:4, iter: 128. loss_u: 0.088. loss_x: 0.006. loss_c: 4.166. n_correct_u: 9.98/69.08. Mask:0.617. num_pos: 39.2. LR: 0.010. Time: 24.22\n",
      "2023-07-17 11:37:58,154 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:4, iter: 192. loss_u: 0.088. loss_x: 0.006. loss_c: 4.156. n_correct_u: 9.96/69.11. Mask:0.617. num_pos: 38.9. LR: 0.008. Time: 24.16\n",
      "2023-07-17 11:38:22,472 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:4, iter: 256. loss_u: 0.088. loss_x: 0.006. loss_c: 4.158. n_correct_u: 9.99/69.25. Mask:0.618. num_pos: 39.1. LR: 0.006. Time: 24.32\n",
      "2023-07-17 11:38:30,194 - INFO - train -   Epoch 4. Acc: 15.2502. Ema-Acc: 14.9806. best_acc: 15.2502 in epoch4\n",
      "Index: 0\n",
      "Len overlapping used indices: 32\n",
      "\n",
      " \n",
      " Round 0 \n",
      " \n",
      "\n",
      "Epoch: [0][0/9]\tTime 0.379 (0.379)\tLoss 0.0015 (0.0015)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][0/9]\tTime 0.352 (0.352)\tLoss 0.0322 (0.0322)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][0/9]\tTime 0.341 (0.341)\tLoss 0.0398 (0.0398)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/9]\tTime 0.342 (0.342)\tLoss 0.0200 (0.0200)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/9]\tTime 0.340 (0.340)\tLoss 0.0000 (0.0000)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/9]\tTime 0.342 (0.342)\tLoss 0.0075 (0.0075)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/9]\tTime 0.346 (0.346)\tLoss 0.0148 (0.0148)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/9]\tTime 0.339 (0.339)\tLoss 0.0150 (0.0150)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/9]\tTime 0.346 (0.346)\tLoss 0.0081 (0.0081)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/9]\tTime 0.343 (0.343)\tLoss 0.0051 (0.0051)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/9]\tTime 0.343 (0.343)\tLoss 0.0003 (0.0003)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/9]\tTime 0.354 (0.354)\tLoss 0.0152 (0.0152)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/9]\tTime 0.351 (0.351)\tLoss 0.0094 (0.0094)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/9]\tTime 0.354 (0.354)\tLoss 0.0093 (0.0093)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/9]\tTime 0.340 (0.340)\tLoss 0.0096 (0.0096)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/9]\tTime 0.344 (0.344)\tLoss 0.0088 (0.0088)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/9]\tTime 0.354 (0.354)\tLoss 0.0020 (0.0020)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/9]\tTime 0.339 (0.339)\tLoss 0.0132 (0.0132)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/9]\tTime 0.342 (0.342)\tLoss 0.0098 (0.0098)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/9]\tTime 0.342 (0.342)\tLoss 0.0001 (0.0001)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/9]\tTime 0.348 (0.348)\tLoss 0.0064 (0.0064)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/9]\tTime 0.356 (0.356)\tLoss 0.0026 (0.0026)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/9]\tTime 0.338 (0.338)\tLoss 0.0019 (0.0019)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/9]\tTime 0.350 (0.350)\tLoss 0.0058 (0.0058)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/9]\tTime 0.349 (0.349)\tLoss 0.0172 (0.0172)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/9]\tTime 0.339 (0.339)\tLoss 0.0179 (0.0179)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/9]\tTime 0.343 (0.343)\tLoss 0.0037 (0.0037)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/9]\tTime 0.348 (0.348)\tLoss 0.0050 (0.0050)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/9]\tTime 0.338 (0.338)\tLoss 0.0060 (0.0060)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/9]\tTime 0.338 (0.338)\tLoss 0.0045 (0.0045)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/9]\tTime 0.342 (0.342)\tLoss 0.0020 (0.0020)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/9]\tTime 0.341 (0.341)\tLoss 0.0029 (0.0029)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/9]\tTime 0.342 (0.342)\tLoss 0.0153 (0.0153)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/9]\tTime 0.341 (0.341)\tLoss 0.0165 (0.0165)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/9]\tTime 0.341 (0.341)\tLoss 0.0007 (0.0007)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/9]\tTime 0.338 (0.338)\tLoss 0.0103 (0.0103)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/9]\tTime 0.341 (0.341)\tLoss 0.0048 (0.0048)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/9]\tTime 0.344 (0.344)\tLoss 0.0102 (0.0102)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/9]\tTime 0.342 (0.342)\tLoss 0.0029 (0.0029)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/9]\tTime 0.333 (0.333)\tLoss 0.0232 (0.0232)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 75.595 %\n",
      "Confusion Matrix:\n",
      "[[69 18]\n",
      " [23 58]]\n",
      "F1 Score: 0.7388535031847134\n",
      "Accuracy balanced\n",
      "0.7545764154959558\n",
      "\n",
      " \n",
      " Round 1 \n",
      " \n",
      "\n",
      "Epoch: [0][0/10]\tTime 0.341 (0.341)\tLoss 0.2876 (0.2876)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [1][0/10]\tTime 0.356 (0.356)\tLoss 0.0041 (0.0041)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][0/10]\tTime 0.342 (0.342)\tLoss 0.0033 (0.0033)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/10]\tTime 0.341 (0.341)\tLoss 0.0489 (0.0489)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/10]\tTime 0.344 (0.344)\tLoss 0.1044 (0.1044)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/10]\tTime 0.342 (0.342)\tLoss 0.0086 (0.0086)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/10]\tTime 0.338 (0.338)\tLoss 0.0056 (0.0056)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/10]\tTime 0.338 (0.338)\tLoss 0.0510 (0.0510)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/10]\tTime 0.333 (0.333)\tLoss 0.0594 (0.0594)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/10]\tTime 0.334 (0.334)\tLoss 0.0155 (0.0155)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/10]\tTime 0.341 (0.341)\tLoss 0.0055 (0.0055)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/10]\tTime 0.337 (0.337)\tLoss 0.0054 (0.0054)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/10]\tTime 0.343 (0.343)\tLoss 0.0051 (0.0051)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/10]\tTime 0.343 (0.343)\tLoss 0.0140 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/10]\tTime 0.338 (0.338)\tLoss 0.0116 (0.0116)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/10]\tTime 0.340 (0.340)\tLoss 0.0044 (0.0044)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/10]\tTime 0.332 (0.332)\tLoss 0.0228 (0.0228)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/10]\tTime 0.338 (0.338)\tLoss 0.0447 (0.0447)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/10]\tTime 0.346 (0.346)\tLoss 0.0068 (0.0068)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/10]\tTime 0.348 (0.348)\tLoss 0.0041 (0.0041)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/10]\tTime 0.346 (0.346)\tLoss 0.0180 (0.0180)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/10]\tTime 0.355 (0.355)\tLoss 0.0153 (0.0153)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/10]\tTime 0.339 (0.339)\tLoss 0.0251 (0.0251)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/10]\tTime 0.329 (0.329)\tLoss 0.0202 (0.0202)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/10]\tTime 0.337 (0.337)\tLoss 0.0190 (0.0190)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/10]\tTime 0.342 (0.342)\tLoss 0.0102 (0.0102)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/10]\tTime 0.343 (0.343)\tLoss 0.0208 (0.0208)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/10]\tTime 0.335 (0.335)\tLoss 0.0350 (0.0350)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/10]\tTime 0.350 (0.350)\tLoss 0.0069 (0.0069)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/10]\tTime 0.341 (0.341)\tLoss 0.0103 (0.0103)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/10]\tTime 0.336 (0.336)\tLoss 0.0046 (0.0046)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/10]\tTime 0.341 (0.341)\tLoss 0.0178 (0.0178)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/10]\tTime 0.345 (0.345)\tLoss 0.0279 (0.0279)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/10]\tTime 0.340 (0.340)\tLoss 0.0038 (0.0038)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/10]\tTime 0.342 (0.342)\tLoss 0.0231 (0.0231)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/10]\tTime 0.335 (0.335)\tLoss 0.0054 (0.0054)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/10]\tTime 0.337 (0.337)\tLoss 0.0119 (0.0119)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/10]\tTime 0.355 (0.355)\tLoss 0.0011 (0.0011)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/10]\tTime 0.342 (0.342)\tLoss 0.0051 (0.0051)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/10]\tTime 0.345 (0.345)\tLoss 0.0185 (0.0185)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 77.381 %\n",
      "Confusion Matrix:\n",
      "[[73 14]\n",
      " [24 57]]\n",
      "F1 Score: 0.75\n",
      "Accuracy balanced\n",
      "0.7713920817369093\n",
      "\n",
      " \n",
      " Round 2 \n",
      " \n",
      "\n",
      "Epoch: [0][0/11]\tTime 0.347 (0.347)\tLoss 0.2550 (0.2550)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/11]\tTime 0.016 (0.047)\tLoss 0.0059 (0.0942)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [1][0/11]\tTime 0.339 (0.339)\tLoss 0.0360 (0.0360)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/11]\tTime 0.016 (0.046)\tLoss 0.0500 (0.0636)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [2][0/11]\tTime 0.343 (0.343)\tLoss 0.0014 (0.0014)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/11]\tTime 0.016 (0.046)\tLoss 0.0194 (0.0382)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/11]\tTime 0.345 (0.345)\tLoss 0.0102 (0.0102)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/11]\tTime 0.016 (0.047)\tLoss 0.0137 (0.0312)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/11]\tTime 0.347 (0.347)\tLoss 0.0087 (0.0087)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/11]\tTime 0.016 (0.047)\tLoss 0.0423 (0.0251)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/11]\tTime 0.348 (0.348)\tLoss 0.0384 (0.0384)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/11]\tTime 0.016 (0.047)\tLoss 0.0276 (0.0241)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/11]\tTime 0.351 (0.351)\tLoss 0.0376 (0.0376)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/11]\tTime 0.016 (0.047)\tLoss 0.0419 (0.0214)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/11]\tTime 0.343 (0.343)\tLoss 0.0051 (0.0051)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/11]\tTime 0.016 (0.046)\tLoss 0.0425 (0.0206)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/11]\tTime 0.344 (0.344)\tLoss 0.0039 (0.0039)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/11]\tTime 0.016 (0.046)\tLoss 0.0383 (0.0191)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/11]\tTime 0.337 (0.337)\tLoss 0.0412 (0.0412)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/11]\tTime 0.016 (0.046)\tLoss 0.0044 (0.0181)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/11]\tTime 0.345 (0.345)\tLoss 0.0273 (0.0273)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/11]\tTime 0.016 (0.047)\tLoss 0.0022 (0.0173)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/11]\tTime 0.345 (0.345)\tLoss 0.0334 (0.0334)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/11]\tTime 0.016 (0.047)\tLoss 0.0196 (0.0168)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/11]\tTime 0.335 (0.335)\tLoss 0.0149 (0.0149)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/11]\tTime 0.016 (0.046)\tLoss 0.0198 (0.0163)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/11]\tTime 0.341 (0.341)\tLoss 0.0089 (0.0089)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/11]\tTime 0.016 (0.046)\tLoss 0.0167 (0.0157)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/11]\tTime 0.341 (0.341)\tLoss 0.0176 (0.0176)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/11]\tTime 0.016 (0.046)\tLoss 0.0234 (0.0152)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/11]\tTime 0.345 (0.345)\tLoss 0.0073 (0.0073)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/11]\tTime 0.016 (0.046)\tLoss 0.0217 (0.0149)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/11]\tTime 0.342 (0.342)\tLoss 0.0059 (0.0059)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/11]\tTime 0.016 (0.046)\tLoss 0.0041 (0.0146)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/11]\tTime 0.337 (0.337)\tLoss 0.0212 (0.0212)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/11]\tTime 0.016 (0.046)\tLoss 0.0223 (0.0144)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/11]\tTime 0.350 (0.350)\tLoss 0.0332 (0.0332)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/11]\tTime 0.016 (0.047)\tLoss 0.0193 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/11]\tTime 0.350 (0.350)\tLoss 0.0072 (0.0072)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/11]\tTime 0.016 (0.047)\tLoss 0.0256 (0.0139)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/11]\tTime 0.348 (0.348)\tLoss 0.0127 (0.0127)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/11]\tTime 0.017 (0.047)\tLoss 0.0313 (0.0136)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/11]\tTime 0.348 (0.348)\tLoss 0.0140 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/11]\tTime 0.016 (0.047)\tLoss 0.0058 (0.0134)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/11]\tTime 0.347 (0.347)\tLoss 0.0021 (0.0021)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/11]\tTime 0.016 (0.047)\tLoss 0.0050 (0.0133)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/11]\tTime 0.341 (0.341)\tLoss 0.0143 (0.0143)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/11]\tTime 0.016 (0.046)\tLoss 0.0017 (0.0131)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/11]\tTime 0.350 (0.350)\tLoss 0.0154 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/11]\tTime 0.016 (0.047)\tLoss 0.0023 (0.0130)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/11]\tTime 0.341 (0.341)\tLoss 0.0001 (0.0001)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/11]\tTime 0.016 (0.046)\tLoss 0.0118 (0.0129)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/11]\tTime 0.339 (0.339)\tLoss 0.0017 (0.0017)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/11]\tTime 0.016 (0.046)\tLoss 0.0130 (0.0128)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/11]\tTime 0.348 (0.348)\tLoss 0.0222 (0.0222)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/11]\tTime 0.023 (0.050)\tLoss 0.0247 (0.0127)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/11]\tTime 0.344 (0.344)\tLoss 0.0139 (0.0139)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/11]\tTime 0.016 (0.046)\tLoss 0.0004 (0.0126)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/11]\tTime 0.346 (0.346)\tLoss 0.0148 (0.0148)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/11]\tTime 0.021 (0.050)\tLoss 0.0125 (0.0126)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/11]\tTime 0.337 (0.337)\tLoss 0.0117 (0.0117)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/11]\tTime 0.016 (0.046)\tLoss 0.0239 (0.0125)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/11]\tTime 0.354 (0.354)\tLoss 0.0143 (0.0143)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/11]\tTime 0.016 (0.047)\tLoss 0.0101 (0.0125)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/11]\tTime 0.353 (0.353)\tLoss 0.0022 (0.0022)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/11]\tTime 0.016 (0.047)\tLoss 0.0035 (0.0124)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/11]\tTime 0.360 (0.360)\tLoss 0.0207 (0.0207)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/11]\tTime 0.016 (0.048)\tLoss 0.0023 (0.0124)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/11]\tTime 0.336 (0.336)\tLoss 0.0225 (0.0225)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/11]\tTime 0.016 (0.046)\tLoss 0.0007 (0.0124)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/11]\tTime 0.350 (0.350)\tLoss 0.0086 (0.0086)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/11]\tTime 0.016 (0.047)\tLoss 0.0137 (0.0124)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/11]\tTime 0.346 (0.346)\tLoss 0.0027 (0.0027)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/11]\tTime 0.016 (0.047)\tLoss 0.0209 (0.0124)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/11]\tTime 0.341 (0.341)\tLoss 0.0037 (0.0037)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/11]\tTime 0.016 (0.047)\tLoss 0.0195 (0.0124)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/11]\tTime 0.336 (0.336)\tLoss 0.0132 (0.0132)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/11]\tTime 0.016 (0.046)\tLoss 0.0112 (0.0124)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/11]\tTime 0.342 (0.342)\tLoss 0.0160 (0.0160)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/11]\tTime 0.016 (0.047)\tLoss 0.0166 (0.0124)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 76.190 %\n",
      "Confusion Matrix:\n",
      "[[68 19]\n",
      " [21 60]]\n",
      "F1 Score: 0.75\n",
      "Accuracy balanced\n",
      "0.7611749680715199\n",
      "\n",
      " \n",
      " Round 3 \n",
      " \n",
      "\n",
      "Epoch: [0][0/12]\tTime 0.347 (0.347)\tLoss 0.0205 (0.0205)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/12]\tTime 0.016 (0.047)\tLoss 0.5341 (0.1019)\tPrec@1 75.000 (97.727)\n",
      "Epoch: [1][0/12]\tTime 0.347 (0.347)\tLoss 0.1164 (0.1164)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/12]\tTime 0.017 (0.047)\tLoss 0.0055 (0.0671)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [2][0/12]\tTime 0.355 (0.355)\tLoss 0.0070 (0.0070)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/12]\tTime 0.016 (0.048)\tLoss 0.0813 (0.0465)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/12]\tTime 0.347 (0.347)\tLoss 0.0326 (0.0326)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/12]\tTime 0.022 (0.052)\tLoss 0.0135 (0.0267)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/12]\tTime 0.350 (0.350)\tLoss 0.0055 (0.0055)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/12]\tTime 0.016 (0.047)\tLoss 0.0290 (0.0218)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/12]\tTime 0.354 (0.354)\tLoss 0.0128 (0.0128)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/12]\tTime 0.016 (0.048)\tLoss 0.0102 (0.0208)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/12]\tTime 0.346 (0.346)\tLoss 0.0369 (0.0369)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/12]\tTime 0.017 (0.047)\tLoss 0.0385 (0.0213)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/12]\tTime 0.340 (0.340)\tLoss 0.0390 (0.0390)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/12]\tTime 0.021 (0.048)\tLoss 0.0211 (0.0216)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/12]\tTime 0.346 (0.346)\tLoss 0.0622 (0.0622)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/12]\tTime 0.020 (0.050)\tLoss 0.0022 (0.0212)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/12]\tTime 0.343 (0.343)\tLoss 0.0245 (0.0245)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/12]\tTime 0.023 (0.050)\tLoss 0.0336 (0.0166)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/12]\tTime 0.344 (0.344)\tLoss 0.0138 (0.0138)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/12]\tTime 0.019 (0.049)\tLoss 0.0280 (0.0165)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/12]\tTime 0.339 (0.339)\tLoss 0.0375 (0.0375)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/12]\tTime 0.016 (0.046)\tLoss 0.0444 (0.0194)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/12]\tTime 0.336 (0.336)\tLoss 0.0037 (0.0037)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/12]\tTime 0.016 (0.046)\tLoss 0.0067 (0.0159)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/12]\tTime 0.340 (0.340)\tLoss 0.0382 (0.0382)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/12]\tTime 0.016 (0.046)\tLoss 0.0248 (0.0181)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/12]\tTime 0.341 (0.341)\tLoss 0.0161 (0.0161)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/12]\tTime 0.016 (0.047)\tLoss 0.0149 (0.0178)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/12]\tTime 0.348 (0.348)\tLoss 0.0070 (0.0070)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/12]\tTime 0.016 (0.047)\tLoss 0.0412 (0.0160)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/12]\tTime 0.335 (0.335)\tLoss 0.0011 (0.0011)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/12]\tTime 0.016 (0.046)\tLoss 0.0211 (0.0153)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/12]\tTime 0.337 (0.337)\tLoss 0.0077 (0.0077)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/12]\tTime 0.016 (0.046)\tLoss 0.0315 (0.0167)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/12]\tTime 0.341 (0.341)\tLoss 0.0177 (0.0177)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/12]\tTime 0.016 (0.046)\tLoss 0.0179 (0.0138)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/12]\tTime 0.347 (0.347)\tLoss 0.0232 (0.0232)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/12]\tTime 0.021 (0.051)\tLoss 0.0026 (0.0164)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/12]\tTime 0.342 (0.342)\tLoss 0.0358 (0.0358)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/12]\tTime 0.021 (0.050)\tLoss 0.0070 (0.0160)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/12]\tTime 0.340 (0.340)\tLoss 0.0034 (0.0034)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/12]\tTime 0.016 (0.046)\tLoss 0.0198 (0.0150)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/12]\tTime 0.347 (0.347)\tLoss 0.0032 (0.0032)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/12]\tTime 0.018 (0.051)\tLoss 0.0148 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/12]\tTime 0.350 (0.350)\tLoss 0.0058 (0.0058)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/12]\tTime 0.021 (0.051)\tLoss 0.0150 (0.0137)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/12]\tTime 0.343 (0.343)\tLoss 0.0107 (0.0107)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/12]\tTime 0.016 (0.047)\tLoss 0.0031 (0.0129)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/12]\tTime 0.337 (0.337)\tLoss 0.0004 (0.0004)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/12]\tTime 0.016 (0.046)\tLoss 0.0320 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/12]\tTime 0.354 (0.354)\tLoss 0.0048 (0.0048)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/12]\tTime 0.019 (0.050)\tLoss 0.0064 (0.0144)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/12]\tTime 0.341 (0.341)\tLoss 0.0174 (0.0174)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/12]\tTime 0.016 (0.047)\tLoss 0.0043 (0.0132)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/12]\tTime 0.337 (0.337)\tLoss 0.0175 (0.0175)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/12]\tTime 0.016 (0.046)\tLoss 0.0169 (0.0137)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/12]\tTime 0.355 (0.355)\tLoss 0.0232 (0.0232)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/12]\tTime 0.016 (0.048)\tLoss 0.0201 (0.0148)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/12]\tTime 0.343 (0.343)\tLoss 0.0187 (0.0187)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/12]\tTime 0.016 (0.047)\tLoss 0.0092 (0.0147)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/12]\tTime 0.343 (0.343)\tLoss 0.0245 (0.0245)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/12]\tTime 0.016 (0.046)\tLoss 0.0104 (0.0133)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/12]\tTime 0.342 (0.342)\tLoss 0.0133 (0.0133)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/12]\tTime 0.016 (0.046)\tLoss 0.0032 (0.0105)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/12]\tTime 0.341 (0.341)\tLoss 0.0171 (0.0171)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/12]\tTime 0.016 (0.047)\tLoss 0.0186 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/12]\tTime 0.335 (0.335)\tLoss 0.0195 (0.0195)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/12]\tTime 0.023 (0.046)\tLoss 0.0167 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/12]\tTime 0.359 (0.359)\tLoss 0.0171 (0.0171)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/12]\tTime 0.016 (0.048)\tLoss 0.0080 (0.0127)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/12]\tTime 0.341 (0.341)\tLoss 0.0064 (0.0064)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/12]\tTime 0.016 (0.046)\tLoss 0.0185 (0.0125)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/12]\tTime 0.338 (0.338)\tLoss 0.0032 (0.0032)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/12]\tTime 0.016 (0.046)\tLoss 0.0371 (0.0141)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/12]\tTime 0.344 (0.344)\tLoss 0.0071 (0.0071)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/12]\tTime 0.016 (0.046)\tLoss 0.0247 (0.0138)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/12]\tTime 0.344 (0.344)\tLoss 0.0049 (0.0049)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/12]\tTime 0.016 (0.047)\tLoss 0.0101 (0.0134)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 75.000 %\n",
      "Confusion Matrix:\n",
      "[[65 22]\n",
      " [20 61]]\n",
      "F1 Score: 0.7439024390243902\n",
      "Accuracy balanced\n",
      "0.7501064282673477\n",
      "\n",
      " \n",
      " Round 4 \n",
      " \n",
      "\n",
      "Epoch: [0][0/13]\tTime 0.349 (0.349)\tLoss 0.0119 (0.0119)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/13]\tTime 0.023 (0.051)\tLoss 0.0070 (0.1244)\tPrec@1 100.000 (93.182)\n",
      "Epoch: [1][0/13]\tTime 0.344 (0.344)\tLoss 0.0147 (0.0147)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/13]\tTime 0.016 (0.047)\tLoss 0.0171 (0.0375)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][0/13]\tTime 0.339 (0.339)\tLoss 0.0151 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/13]\tTime 0.016 (0.046)\tLoss 0.0168 (0.0381)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/13]\tTime 0.350 (0.350)\tLoss 0.0088 (0.0088)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/13]\tTime 0.016 (0.047)\tLoss 0.0646 (0.0325)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/13]\tTime 0.344 (0.344)\tLoss 0.0010 (0.0010)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/13]\tTime 0.016 (0.047)\tLoss 0.0033 (0.0267)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/13]\tTime 0.340 (0.340)\tLoss 0.0271 (0.0271)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/13]\tTime 0.016 (0.047)\tLoss 0.0389 (0.0272)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/13]\tTime 0.338 (0.338)\tLoss 0.0199 (0.0199)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/13]\tTime 0.016 (0.046)\tLoss 0.0049 (0.0178)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/13]\tTime 0.337 (0.337)\tLoss 0.0375 (0.0375)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/13]\tTime 0.016 (0.046)\tLoss 0.0542 (0.0202)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/13]\tTime 0.338 (0.338)\tLoss 0.0116 (0.0116)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/13]\tTime 0.018 (0.046)\tLoss 0.0380 (0.0212)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/13]\tTime 0.343 (0.343)\tLoss 0.0079 (0.0079)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/13]\tTime 0.016 (0.047)\tLoss 0.0259 (0.0220)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/13]\tTime 0.344 (0.344)\tLoss 0.0314 (0.0314)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/13]\tTime 0.016 (0.047)\tLoss 0.0007 (0.0208)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/13]\tTime 0.339 (0.339)\tLoss 0.0121 (0.0121)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/13]\tTime 0.016 (0.047)\tLoss 0.0528 (0.0178)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/13]\tTime 0.339 (0.339)\tLoss 0.0085 (0.0085)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/13]\tTime 0.016 (0.046)\tLoss 0.0019 (0.0187)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/13]\tTime 0.343 (0.343)\tLoss 0.0323 (0.0323)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/13]\tTime 0.016 (0.047)\tLoss 0.0135 (0.0163)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/13]\tTime 0.344 (0.344)\tLoss 0.0060 (0.0060)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/13]\tTime 0.016 (0.047)\tLoss 0.0024 (0.0172)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/13]\tTime 0.343 (0.343)\tLoss 0.0106 (0.0106)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/13]\tTime 0.016 (0.047)\tLoss 0.0089 (0.0192)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/13]\tTime 0.339 (0.339)\tLoss 0.0157 (0.0157)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/13]\tTime 0.016 (0.046)\tLoss 0.0127 (0.0144)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/13]\tTime 0.343 (0.343)\tLoss 0.0038 (0.0038)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/13]\tTime 0.017 (0.047)\tLoss 0.0132 (0.0179)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/13]\tTime 0.344 (0.344)\tLoss 0.0146 (0.0146)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/13]\tTime 0.016 (0.047)\tLoss 0.0139 (0.0148)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/13]\tTime 0.352 (0.352)\tLoss 0.0248 (0.0248)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/13]\tTime 0.016 (0.048)\tLoss 0.0227 (0.0163)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/13]\tTime 0.349 (0.349)\tLoss 0.0030 (0.0030)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/13]\tTime 0.016 (0.048)\tLoss 0.0190 (0.0146)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/13]\tTime 0.340 (0.340)\tLoss 0.0003 (0.0003)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/13]\tTime 0.016 (0.046)\tLoss 0.0195 (0.0166)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/13]\tTime 0.350 (0.350)\tLoss 0.0182 (0.0182)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/13]\tTime 0.016 (0.048)\tLoss 0.0270 (0.0158)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/13]\tTime 0.344 (0.344)\tLoss 0.0177 (0.0177)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/13]\tTime 0.016 (0.047)\tLoss 0.0077 (0.0143)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/13]\tTime 0.329 (0.329)\tLoss 0.0220 (0.0220)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/13]\tTime 0.016 (0.045)\tLoss 0.0126 (0.0167)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/13]\tTime 0.346 (0.346)\tLoss 0.0280 (0.0280)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/13]\tTime 0.020 (0.050)\tLoss 0.0102 (0.0146)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/13]\tTime 0.357 (0.357)\tLoss 0.0224 (0.0224)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/13]\tTime 0.020 (0.053)\tLoss 0.0263 (0.0159)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/13]\tTime 0.345 (0.345)\tLoss 0.0276 (0.0276)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/13]\tTime 0.021 (0.051)\tLoss 0.0048 (0.0129)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/13]\tTime 0.347 (0.347)\tLoss 0.0018 (0.0018)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/13]\tTime 0.021 (0.050)\tLoss 0.0287 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/13]\tTime 0.355 (0.355)\tLoss 0.0135 (0.0135)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/13]\tTime 0.020 (0.052)\tLoss 0.0063 (0.0128)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/13]\tTime 0.340 (0.340)\tLoss 0.0151 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/13]\tTime 0.017 (0.048)\tLoss 0.0193 (0.0131)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/13]\tTime 0.342 (0.342)\tLoss 0.0059 (0.0059)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/13]\tTime 0.016 (0.047)\tLoss 0.0210 (0.0138)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/13]\tTime 0.342 (0.342)\tLoss 0.0117 (0.0117)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/13]\tTime 0.016 (0.046)\tLoss 0.0104 (0.0136)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/13]\tTime 0.343 (0.343)\tLoss 0.0078 (0.0078)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/13]\tTime 0.016 (0.046)\tLoss 0.0143 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/13]\tTime 0.340 (0.340)\tLoss 0.0117 (0.0117)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/13]\tTime 0.016 (0.046)\tLoss 0.0309 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/13]\tTime 0.343 (0.343)\tLoss 0.0000 (0.0000)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/13]\tTime 0.016 (0.046)\tLoss 0.0033 (0.0123)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/13]\tTime 0.334 (0.334)\tLoss 0.0037 (0.0037)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/13]\tTime 0.016 (0.046)\tLoss 0.0123 (0.0144)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/13]\tTime 0.340 (0.340)\tLoss 0.0141 (0.0141)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/13]\tTime 0.018 (0.046)\tLoss 0.0016 (0.0126)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/13]\tTime 0.344 (0.344)\tLoss 0.0008 (0.0008)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/13]\tTime 0.016 (0.047)\tLoss 0.0177 (0.0145)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/13]\tTime 0.341 (0.341)\tLoss 0.0127 (0.0127)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/13]\tTime 0.016 (0.046)\tLoss 0.0114 (0.0152)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 73.810 %\n",
      "Confusion Matrix:\n",
      "[[65 22]\n",
      " [22 59]]\n",
      "F1 Score: 0.7283950617283951\n",
      "Accuracy balanced\n",
      "0.7377607492550021\n",
      "\n",
      " \n",
      " Round 5 \n",
      " \n",
      "\n",
      "Epoch: [0][0/14]\tTime 0.346 (0.346)\tLoss 0.0092 (0.0092)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/14]\tTime 0.016 (0.047)\tLoss 0.0093 (0.0638)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [1][0/14]\tTime 0.336 (0.336)\tLoss 0.0524 (0.0524)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/14]\tTime 0.017 (0.046)\tLoss 0.0099 (0.0553)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [2][0/14]\tTime 0.338 (0.338)\tLoss 0.0069 (0.0069)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/14]\tTime 0.016 (0.046)\tLoss 0.0511 (0.0329)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/14]\tTime 0.336 (0.336)\tLoss 0.0371 (0.0371)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/14]\tTime 0.016 (0.046)\tLoss 0.0693 (0.0339)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/14]\tTime 0.339 (0.339)\tLoss 0.0065 (0.0065)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/14]\tTime 0.016 (0.046)\tLoss 0.0721 (0.0216)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/14]\tTime 0.369 (0.369)\tLoss 0.0059 (0.0059)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/14]\tTime 0.016 (0.049)\tLoss 0.0282 (0.0251)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/14]\tTime 0.342 (0.342)\tLoss 0.0082 (0.0082)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/14]\tTime 0.016 (0.047)\tLoss 0.0033 (0.0172)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/14]\tTime 0.345 (0.345)\tLoss 0.0279 (0.0279)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/14]\tTime 0.016 (0.047)\tLoss 0.0083 (0.0186)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/14]\tTime 0.344 (0.344)\tLoss 0.0048 (0.0048)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/14]\tTime 0.016 (0.047)\tLoss 0.0018 (0.0202)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/14]\tTime 0.338 (0.338)\tLoss 0.0148 (0.0148)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/14]\tTime 0.016 (0.047)\tLoss 0.0142 (0.0222)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/14]\tTime 0.335 (0.335)\tLoss 0.0105 (0.0105)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/14]\tTime 0.016 (0.046)\tLoss 0.0323 (0.0188)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/14]\tTime 0.345 (0.345)\tLoss 0.0099 (0.0099)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/14]\tTime 0.017 (0.047)\tLoss 0.0135 (0.0182)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/14]\tTime 0.349 (0.349)\tLoss 0.0002 (0.0002)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/14]\tTime 0.016 (0.047)\tLoss 0.0190 (0.0150)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/14]\tTime 0.340 (0.340)\tLoss 0.0086 (0.0086)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/14]\tTime 0.017 (0.047)\tLoss 0.0023 (0.0168)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/14]\tTime 0.347 (0.347)\tLoss 0.0204 (0.0204)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/14]\tTime 0.016 (0.047)\tLoss 0.0076 (0.0144)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/14]\tTime 0.345 (0.345)\tLoss 0.0175 (0.0175)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/14]\tTime 0.017 (0.048)\tLoss 0.0063 (0.0167)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/14]\tTime 0.360 (0.360)\tLoss 0.0355 (0.0355)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/14]\tTime 0.016 (0.049)\tLoss 0.0073 (0.0156)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/14]\tTime 0.341 (0.341)\tLoss 0.0207 (0.0207)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/14]\tTime 0.020 (0.050)\tLoss 0.0298 (0.0148)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/14]\tTime 0.346 (0.346)\tLoss 0.0000 (0.0000)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/14]\tTime 0.016 (0.048)\tLoss 0.0006 (0.0118)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/14]\tTime 0.348 (0.348)\tLoss 0.0084 (0.0084)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/14]\tTime 0.021 (0.050)\tLoss 0.0024 (0.0129)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/14]\tTime 0.336 (0.336)\tLoss 0.0429 (0.0429)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/14]\tTime 0.016 (0.046)\tLoss 0.0120 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/14]\tTime 0.336 (0.336)\tLoss 0.0142 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/14]\tTime 0.020 (0.049)\tLoss 0.0359 (0.0164)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/14]\tTime 0.344 (0.344)\tLoss 0.0001 (0.0001)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/14]\tTime 0.016 (0.047)\tLoss 0.0281 (0.0139)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/14]\tTime 0.341 (0.341)\tLoss 0.0198 (0.0198)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/14]\tTime 0.016 (0.047)\tLoss 0.0010 (0.0137)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/14]\tTime 0.341 (0.341)\tLoss 0.0056 (0.0056)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/14]\tTime 0.016 (0.046)\tLoss 0.0110 (0.0132)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/14]\tTime 0.343 (0.343)\tLoss 0.0153 (0.0153)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/14]\tTime 0.016 (0.048)\tLoss 0.0150 (0.0136)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/14]\tTime 0.347 (0.347)\tLoss 0.0127 (0.0127)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/14]\tTime 0.016 (0.047)\tLoss 0.0121 (0.0121)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/14]\tTime 0.338 (0.338)\tLoss 0.0085 (0.0085)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/14]\tTime 0.016 (0.046)\tLoss 0.0283 (0.0139)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/14]\tTime 0.335 (0.335)\tLoss 0.0189 (0.0189)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/14]\tTime 0.016 (0.046)\tLoss 0.0078 (0.0136)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/14]\tTime 0.341 (0.341)\tLoss 0.0038 (0.0038)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/14]\tTime 0.016 (0.046)\tLoss 0.0040 (0.0133)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/14]\tTime 0.343 (0.343)\tLoss 0.0159 (0.0159)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/14]\tTime 0.016 (0.047)\tLoss 0.0042 (0.0132)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/14]\tTime 0.325 (0.325)\tLoss 0.0083 (0.0083)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/14]\tTime 0.016 (0.045)\tLoss 0.0066 (0.0161)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/14]\tTime 0.346 (0.346)\tLoss 0.0049 (0.0049)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/14]\tTime 0.016 (0.047)\tLoss 0.0093 (0.0120)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/14]\tTime 0.343 (0.343)\tLoss 0.0085 (0.0085)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/14]\tTime 0.016 (0.047)\tLoss 0.0284 (0.0135)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/14]\tTime 0.343 (0.343)\tLoss 0.0120 (0.0120)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/14]\tTime 0.016 (0.047)\tLoss 0.0167 (0.0131)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/14]\tTime 0.345 (0.345)\tLoss 0.0286 (0.0286)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/14]\tTime 0.016 (0.047)\tLoss 0.0023 (0.0141)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/14]\tTime 0.347 (0.347)\tLoss 0.0097 (0.0097)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/14]\tTime 0.016 (0.047)\tLoss 0.0173 (0.0123)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/14]\tTime 0.329 (0.329)\tLoss 0.0233 (0.0233)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/14]\tTime 0.016 (0.045)\tLoss 0.0162 (0.0133)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/14]\tTime 0.345 (0.345)\tLoss 0.0017 (0.0017)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/14]\tTime 0.016 (0.047)\tLoss 0.0073 (0.0125)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/14]\tTime 0.342 (0.342)\tLoss 0.0168 (0.0168)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/14]\tTime 0.016 (0.047)\tLoss 0.0136 (0.0134)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 75.000 %\n",
      "Confusion Matrix:\n",
      "[[70 17]\n",
      " [25 56]]\n",
      "F1 Score: 0.7272727272727273\n",
      "Accuracy balanced\n",
      "0.7479778629203917\n",
      "\n",
      " \n",
      " Round 6 \n",
      " \n",
      "\n",
      "Epoch: [0][0/15]\tTime 0.345 (0.345)\tLoss 0.0149 (0.0149)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/15]\tTime 0.016 (0.047)\tLoss 0.0053 (0.1177)\tPrec@1 100.000 (93.182)\n",
      "Epoch: [1][0/15]\tTime 0.334 (0.334)\tLoss 0.0208 (0.0208)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/15]\tTime 0.016 (0.046)\tLoss 0.0047 (0.0628)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][0/15]\tTime 0.339 (0.339)\tLoss 0.1014 (0.1014)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/15]\tTime 0.016 (0.047)\tLoss 0.0995 (0.0395)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/15]\tTime 0.343 (0.343)\tLoss 0.0332 (0.0332)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/15]\tTime 0.016 (0.047)\tLoss 0.0721 (0.0241)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/15]\tTime 0.352 (0.352)\tLoss 0.0518 (0.0518)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/15]\tTime 0.016 (0.048)\tLoss 0.0034 (0.0217)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/15]\tTime 0.345 (0.345)\tLoss 0.0243 (0.0243)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/15]\tTime 0.016 (0.047)\tLoss 0.0058 (0.0238)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/15]\tTime 0.340 (0.340)\tLoss 0.0340 (0.0340)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/15]\tTime 0.016 (0.047)\tLoss 0.0182 (0.0209)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/15]\tTime 0.341 (0.341)\tLoss 0.0293 (0.0293)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/15]\tTime 0.016 (0.047)\tLoss 0.0405 (0.0205)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/15]\tTime 0.341 (0.341)\tLoss 0.0183 (0.0183)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/15]\tTime 0.016 (0.047)\tLoss 0.0288 (0.0230)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/15]\tTime 0.347 (0.347)\tLoss 0.0127 (0.0127)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/15]\tTime 0.016 (0.047)\tLoss 0.0036 (0.0193)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/15]\tTime 0.340 (0.340)\tLoss 0.0326 (0.0326)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/15]\tTime 0.016 (0.047)\tLoss 0.0180 (0.0201)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/15]\tTime 0.351 (0.351)\tLoss 0.0154 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/15]\tTime 0.016 (0.047)\tLoss 0.0235 (0.0184)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/15]\tTime 0.339 (0.339)\tLoss 0.0109 (0.0109)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/15]\tTime 0.016 (0.046)\tLoss 0.0040 (0.0169)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/15]\tTime 0.333 (0.333)\tLoss 0.0268 (0.0268)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/15]\tTime 0.016 (0.046)\tLoss 0.0271 (0.0170)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/15]\tTime 0.344 (0.344)\tLoss 0.0025 (0.0025)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/15]\tTime 0.016 (0.047)\tLoss 0.0113 (0.0172)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/15]\tTime 0.346 (0.346)\tLoss 0.0399 (0.0399)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/15]\tTime 0.016 (0.047)\tLoss 0.0482 (0.0185)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/15]\tTime 0.342 (0.342)\tLoss 0.0252 (0.0252)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/15]\tTime 0.016 (0.047)\tLoss 0.0206 (0.0155)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/15]\tTime 0.338 (0.338)\tLoss 0.0007 (0.0007)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/15]\tTime 0.016 (0.047)\tLoss 0.0268 (0.0175)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/15]\tTime 0.337 (0.337)\tLoss 0.0264 (0.0264)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/15]\tTime 0.016 (0.046)\tLoss 0.0109 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/15]\tTime 0.340 (0.340)\tLoss 0.0128 (0.0128)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/15]\tTime 0.016 (0.047)\tLoss 0.0168 (0.0135)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/15]\tTime 0.328 (0.328)\tLoss 0.0033 (0.0033)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/15]\tTime 0.016 (0.045)\tLoss 0.0025 (0.0122)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/15]\tTime 0.343 (0.343)\tLoss 0.0121 (0.0121)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/15]\tTime 0.016 (0.047)\tLoss 0.0041 (0.0121)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/15]\tTime 0.338 (0.338)\tLoss 0.0142 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/15]\tTime 0.016 (0.046)\tLoss 0.0006 (0.0138)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/15]\tTime 0.356 (0.356)\tLoss 0.0122 (0.0122)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/15]\tTime 0.020 (0.052)\tLoss 0.0222 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/15]\tTime 0.336 (0.336)\tLoss 0.0093 (0.0093)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/15]\tTime 0.016 (0.047)\tLoss 0.0051 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/15]\tTime 0.351 (0.351)\tLoss 0.0075 (0.0075)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/15]\tTime 0.017 (0.049)\tLoss 0.0012 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/15]\tTime 0.338 (0.338)\tLoss 0.0140 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/15]\tTime 0.019 (0.047)\tLoss 0.0123 (0.0143)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/15]\tTime 0.340 (0.340)\tLoss 0.0162 (0.0162)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/15]\tTime 0.018 (0.050)\tLoss 0.0008 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/15]\tTime 0.349 (0.349)\tLoss 0.0269 (0.0269)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/15]\tTime 0.020 (0.050)\tLoss 0.0296 (0.0144)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/15]\tTime 0.338 (0.338)\tLoss 0.0132 (0.0132)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/15]\tTime 0.016 (0.046)\tLoss 0.0079 (0.0135)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/15]\tTime 0.341 (0.341)\tLoss 0.0063 (0.0063)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/15]\tTime 0.019 (0.051)\tLoss 0.0140 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/15]\tTime 0.341 (0.341)\tLoss 0.0067 (0.0067)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/15]\tTime 0.016 (0.047)\tLoss 0.0313 (0.0133)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/15]\tTime 0.347 (0.347)\tLoss 0.0164 (0.0164)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/15]\tTime 0.016 (0.047)\tLoss 0.0181 (0.0157)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/15]\tTime 0.347 (0.347)\tLoss 0.0017 (0.0017)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/15]\tTime 0.023 (0.048)\tLoss 0.0208 (0.0115)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/15]\tTime 0.336 (0.336)\tLoss 0.0085 (0.0085)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/15]\tTime 0.016 (0.046)\tLoss 0.0188 (0.0139)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/15]\tTime 0.335 (0.335)\tLoss 0.0071 (0.0071)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/15]\tTime 0.016 (0.046)\tLoss 0.0151 (0.0123)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/15]\tTime 0.344 (0.344)\tLoss 0.0173 (0.0173)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/15]\tTime 0.016 (0.047)\tLoss 0.0054 (0.0148)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/15]\tTime 0.348 (0.348)\tLoss 0.0088 (0.0088)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/15]\tTime 0.016 (0.047)\tLoss 0.0176 (0.0135)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/15]\tTime 0.338 (0.338)\tLoss 0.0094 (0.0094)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/15]\tTime 0.016 (0.047)\tLoss 0.0136 (0.0141)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/15]\tTime 0.335 (0.335)\tLoss 0.0199 (0.0199)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/15]\tTime 0.016 (0.046)\tLoss 0.0328 (0.0131)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 75.595 %\n",
      "Confusion Matrix:\n",
      "[[68 19]\n",
      " [22 59]]\n",
      "F1 Score: 0.7421383647798742\n",
      "Accuracy balanced\n",
      "0.755002128565347\n",
      "\n",
      " \n",
      " Round 7 \n",
      " \n",
      "\n",
      "Epoch: [0][0/16]\tTime 0.347 (0.347)\tLoss 0.0133 (0.0133)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/16]\tTime 0.016 (0.047)\tLoss 0.0358 (0.0824)\tPrec@1 100.000 (95.455)\n",
      "Epoch: [1][0/16]\tTime 0.336 (0.336)\tLoss 0.0037 (0.0037)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/16]\tTime 0.016 (0.046)\tLoss 0.3380 (0.0715)\tPrec@1 75.000 (97.727)\n",
      "Epoch: [2][0/16]\tTime 0.337 (0.337)\tLoss 0.1288 (0.1288)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/16]\tTime 0.016 (0.046)\tLoss 0.0031 (0.0367)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/16]\tTime 0.337 (0.337)\tLoss 0.0105 (0.0105)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/16]\tTime 0.016 (0.046)\tLoss 0.0192 (0.0276)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/16]\tTime 0.333 (0.333)\tLoss 0.0091 (0.0091)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/16]\tTime 0.016 (0.046)\tLoss 0.0835 (0.0306)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/16]\tTime 0.341 (0.341)\tLoss 0.0123 (0.0123)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/16]\tTime 0.016 (0.047)\tLoss 0.0795 (0.0268)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/16]\tTime 0.340 (0.340)\tLoss 0.0367 (0.0367)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/16]\tTime 0.016 (0.047)\tLoss 0.0096 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/16]\tTime 0.351 (0.351)\tLoss 0.0484 (0.0484)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/16]\tTime 0.016 (0.048)\tLoss 0.0556 (0.0250)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/16]\tTime 0.338 (0.338)\tLoss 0.0075 (0.0075)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/16]\tTime 0.016 (0.047)\tLoss 0.0172 (0.0234)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/16]\tTime 0.336 (0.336)\tLoss 0.0083 (0.0083)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/16]\tTime 0.016 (0.046)\tLoss 0.0100 (0.0118)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/16]\tTime 0.334 (0.334)\tLoss 0.0381 (0.0381)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/16]\tTime 0.016 (0.046)\tLoss 0.0041 (0.0199)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/16]\tTime 0.344 (0.344)\tLoss 0.0488 (0.0488)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/16]\tTime 0.016 (0.047)\tLoss 0.0706 (0.0221)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/16]\tTime 0.338 (0.338)\tLoss 0.0383 (0.0383)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/16]\tTime 0.016 (0.047)\tLoss 0.0211 (0.0177)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/16]\tTime 0.342 (0.342)\tLoss 0.0024 (0.0024)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/16]\tTime 0.016 (0.047)\tLoss 0.0374 (0.0220)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/16]\tTime 0.344 (0.344)\tLoss 0.0052 (0.0052)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/16]\tTime 0.016 (0.047)\tLoss 0.0032 (0.0200)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/16]\tTime 0.330 (0.330)\tLoss 0.0035 (0.0035)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/16]\tTime 0.016 (0.046)\tLoss 0.0050 (0.0175)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/16]\tTime 0.335 (0.335)\tLoss 0.0015 (0.0015)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/16]\tTime 0.016 (0.046)\tLoss 0.0013 (0.0134)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/16]\tTime 0.344 (0.344)\tLoss 0.0104 (0.0104)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/16]\tTime 0.016 (0.047)\tLoss 0.0042 (0.0128)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/16]\tTime 0.338 (0.338)\tLoss 0.0071 (0.0071)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/16]\tTime 0.016 (0.046)\tLoss 0.0167 (0.0153)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/16]\tTime 0.346 (0.346)\tLoss 0.0049 (0.0049)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/16]\tTime 0.016 (0.047)\tLoss 0.0084 (0.0103)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/16]\tTime 0.335 (0.335)\tLoss 0.0231 (0.0231)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/16]\tTime 0.016 (0.046)\tLoss 0.0198 (0.0133)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/16]\tTime 0.343 (0.343)\tLoss 0.0016 (0.0016)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/16]\tTime 0.016 (0.047)\tLoss 0.0113 (0.0162)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/16]\tTime 0.345 (0.345)\tLoss 0.0160 (0.0160)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/16]\tTime 0.016 (0.048)\tLoss 0.0045 (0.0116)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/16]\tTime 0.334 (0.334)\tLoss 0.0258 (0.0258)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/16]\tTime 0.016 (0.046)\tLoss 0.0092 (0.0183)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/16]\tTime 0.338 (0.338)\tLoss 0.0135 (0.0135)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/16]\tTime 0.016 (0.046)\tLoss 0.0041 (0.0147)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/16]\tTime 0.342 (0.342)\tLoss 0.0212 (0.0212)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/16]\tTime 0.016 (0.047)\tLoss 0.0020 (0.0134)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/16]\tTime 0.341 (0.341)\tLoss 0.0010 (0.0010)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/16]\tTime 0.018 (0.047)\tLoss 0.0046 (0.0123)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/16]\tTime 0.335 (0.335)\tLoss 0.0023 (0.0023)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/16]\tTime 0.016 (0.046)\tLoss 0.0003 (0.0121)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/16]\tTime 0.349 (0.349)\tLoss 0.0129 (0.0129)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/16]\tTime 0.016 (0.047)\tLoss 0.0107 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/16]\tTime 0.345 (0.345)\tLoss 0.0119 (0.0119)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/16]\tTime 0.016 (0.047)\tLoss 0.0269 (0.0153)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/16]\tTime 0.340 (0.340)\tLoss 0.0181 (0.0181)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/16]\tTime 0.016 (0.047)\tLoss 0.0045 (0.0156)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/16]\tTime 0.339 (0.339)\tLoss 0.0009 (0.0009)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/16]\tTime 0.016 (0.047)\tLoss 0.0073 (0.0155)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/16]\tTime 0.348 (0.348)\tLoss 0.0128 (0.0128)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/16]\tTime 0.016 (0.047)\tLoss 0.0040 (0.0143)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/16]\tTime 0.345 (0.345)\tLoss 0.0249 (0.0249)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/16]\tTime 0.016 (0.047)\tLoss 0.0103 (0.0144)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/16]\tTime 0.343 (0.343)\tLoss 0.0284 (0.0284)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/16]\tTime 0.016 (0.047)\tLoss 0.0005 (0.0124)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/16]\tTime 0.341 (0.341)\tLoss 0.0124 (0.0124)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/16]\tTime 0.016 (0.047)\tLoss 0.0191 (0.0139)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/16]\tTime 0.347 (0.347)\tLoss 0.0037 (0.0037)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/16]\tTime 0.016 (0.047)\tLoss 0.0287 (0.0114)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/16]\tTime 0.340 (0.340)\tLoss 0.0231 (0.0231)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/16]\tTime 0.016 (0.047)\tLoss 0.0007 (0.0129)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/16]\tTime 0.342 (0.342)\tLoss 0.0304 (0.0304)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/16]\tTime 0.016 (0.047)\tLoss 0.0052 (0.0123)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/16]\tTime 0.337 (0.337)\tLoss 0.0054 (0.0054)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/16]\tTime 0.017 (0.046)\tLoss 0.0121 (0.0145)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 75.595 %\n",
      "Confusion Matrix:\n",
      "[[70 17]\n",
      " [24 57]]\n",
      "F1 Score: 0.735483870967742\n",
      "Accuracy balanced\n",
      "0.7541507024265646\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 84 test images: 75.000 %\n",
      "Confusion Matrix:\n",
      "[[30  8]\n",
      " [13 33]]\n",
      "F1 Score: 0.7586206896551724\n",
      "Accuracy balanced\n",
      "0.7534324942791761\n",
      "AL finished\n",
      "Index: 0\n",
      "Len overlapping used indices: 32\n",
      "\n",
      " \n",
      " Round 0 \n",
      " \n",
      "\n",
      "Epoch: [0][0/9]\tTime 0.348 (0.348)\tLoss 0.0062 (0.0062)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][0/9]\tTime 0.333 (0.333)\tLoss 0.0453 (0.0453)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][0/9]\tTime 0.332 (0.332)\tLoss 0.0072 (0.0072)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/9]\tTime 0.345 (0.345)\tLoss 0.0333 (0.0333)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/9]\tTime 0.344 (0.344)\tLoss 0.0136 (0.0136)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/9]\tTime 0.342 (0.342)\tLoss 0.0003 (0.0003)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/9]\tTime 0.343 (0.343)\tLoss 0.0250 (0.0250)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/9]\tTime 0.344 (0.344)\tLoss 0.0356 (0.0356)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/9]\tTime 0.330 (0.330)\tLoss 0.0246 (0.0246)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/9]\tTime 0.339 (0.339)\tLoss 0.0172 (0.0172)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/9]\tTime 0.336 (0.336)\tLoss 0.0478 (0.0478)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/9]\tTime 0.338 (0.338)\tLoss 0.0371 (0.0371)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/9]\tTime 0.342 (0.342)\tLoss 0.0140 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/9]\tTime 0.334 (0.334)\tLoss 0.0069 (0.0069)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/9]\tTime 0.345 (0.345)\tLoss 0.0125 (0.0125)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/9]\tTime 0.336 (0.336)\tLoss 0.0170 (0.0170)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/9]\tTime 0.336 (0.336)\tLoss 0.0004 (0.0004)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/9]\tTime 0.339 (0.339)\tLoss 0.0327 (0.0327)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/9]\tTime 0.345 (0.345)\tLoss 0.0168 (0.0168)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/9]\tTime 0.343 (0.343)\tLoss 0.0298 (0.0298)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/9]\tTime 0.337 (0.337)\tLoss 0.0116 (0.0116)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/9]\tTime 0.343 (0.343)\tLoss 0.0250 (0.0250)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/9]\tTime 0.345 (0.345)\tLoss 0.0024 (0.0024)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/9]\tTime 0.346 (0.346)\tLoss 0.0051 (0.0051)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/9]\tTime 0.333 (0.333)\tLoss 0.0164 (0.0164)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/9]\tTime 0.345 (0.345)\tLoss 0.0357 (0.0357)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/9]\tTime 0.346 (0.346)\tLoss 0.0275 (0.0275)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/9]\tTime 0.345 (0.345)\tLoss 0.0022 (0.0022)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/9]\tTime 0.335 (0.335)\tLoss 0.0021 (0.0021)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/9]\tTime 0.355 (0.355)\tLoss 0.0054 (0.0054)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/9]\tTime 0.346 (0.346)\tLoss 0.0258 (0.0258)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/9]\tTime 0.351 (0.351)\tLoss 0.0110 (0.0110)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/9]\tTime 0.348 (0.348)\tLoss 0.0102 (0.0102)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/9]\tTime 0.358 (0.358)\tLoss 0.0127 (0.0127)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/9]\tTime 0.332 (0.332)\tLoss 0.0083 (0.0083)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/9]\tTime 0.347 (0.347)\tLoss 0.0235 (0.0235)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/9]\tTime 0.337 (0.337)\tLoss 0.0069 (0.0069)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/9]\tTime 0.332 (0.332)\tLoss 0.0237 (0.0237)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/9]\tTime 0.331 (0.331)\tLoss 0.0135 (0.0135)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/9]\tTime 0.344 (0.344)\tLoss 0.0160 (0.0160)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 69.643 %\n",
      "Confusion Matrix:\n",
      "[[92 12]\n",
      " [39 25]]\n",
      "F1 Score: 0.49504950495049505\n",
      "Accuracy balanced\n",
      "0.6376201923076923\n",
      "\n",
      " \n",
      " Round 1 \n",
      " \n",
      "\n",
      "Epoch: [0][0/10]\tTime 0.342 (0.342)\tLoss 0.2959 (0.2959)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [1][0/10]\tTime 0.345 (0.345)\tLoss 0.0083 (0.0083)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][0/10]\tTime 0.333 (0.333)\tLoss 0.0251 (0.0251)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/10]\tTime 0.354 (0.354)\tLoss 0.1032 (0.1032)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/10]\tTime 0.338 (0.338)\tLoss 0.1415 (0.1415)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/10]\tTime 0.332 (0.332)\tLoss 0.0103 (0.0103)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/10]\tTime 0.341 (0.341)\tLoss 0.0304 (0.0304)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/10]\tTime 0.338 (0.338)\tLoss 0.0486 (0.0486)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/10]\tTime 0.339 (0.339)\tLoss 0.0443 (0.0443)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/10]\tTime 0.338 (0.338)\tLoss 0.0069 (0.0069)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/10]\tTime 0.340 (0.340)\tLoss 0.0258 (0.0258)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/10]\tTime 0.335 (0.335)\tLoss 0.0205 (0.0205)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/10]\tTime 0.342 (0.342)\tLoss 0.0142 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/10]\tTime 0.340 (0.340)\tLoss 0.0200 (0.0200)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/10]\tTime 0.335 (0.335)\tLoss 0.0109 (0.0109)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/10]\tTime 0.337 (0.337)\tLoss 0.0184 (0.0184)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/10]\tTime 0.343 (0.343)\tLoss 0.0079 (0.0079)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/10]\tTime 0.334 (0.334)\tLoss 0.0384 (0.0384)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/10]\tTime 0.343 (0.343)\tLoss 0.0272 (0.0272)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/10]\tTime 0.344 (0.344)\tLoss 0.0204 (0.0204)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/10]\tTime 0.340 (0.340)\tLoss 0.0199 (0.0199)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/10]\tTime 0.346 (0.346)\tLoss 0.0352 (0.0352)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/10]\tTime 0.335 (0.335)\tLoss 0.0051 (0.0051)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/10]\tTime 0.343 (0.343)\tLoss 0.0235 (0.0235)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/10]\tTime 0.338 (0.338)\tLoss 0.0161 (0.0161)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/10]\tTime 0.340 (0.340)\tLoss 0.0125 (0.0125)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/10]\tTime 0.351 (0.351)\tLoss 0.0163 (0.0163)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/10]\tTime 0.331 (0.331)\tLoss 0.0282 (0.0282)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/10]\tTime 0.335 (0.335)\tLoss 0.0174 (0.0174)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/10]\tTime 0.343 (0.343)\tLoss 0.0103 (0.0103)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/10]\tTime 0.353 (0.353)\tLoss 0.0105 (0.0105)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/10]\tTime 0.331 (0.331)\tLoss 0.0138 (0.0138)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/10]\tTime 0.343 (0.343)\tLoss 0.0167 (0.0167)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/10]\tTime 0.346 (0.346)\tLoss 0.0191 (0.0191)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/10]\tTime 0.337 (0.337)\tLoss 0.0310 (0.0310)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/10]\tTime 0.338 (0.338)\tLoss 0.0224 (0.0224)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/10]\tTime 0.335 (0.335)\tLoss 0.0144 (0.0144)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/10]\tTime 0.328 (0.328)\tLoss 0.0097 (0.0097)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/10]\tTime 0.329 (0.329)\tLoss 0.0141 (0.0141)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/10]\tTime 0.346 (0.346)\tLoss 0.0200 (0.0200)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 67.857 %\n",
      "Confusion Matrix:\n",
      "[[91 13]\n",
      " [41 23]]\n",
      "F1 Score: 0.45999999999999996\n",
      "Accuracy balanced\n",
      "0.6171875\n",
      "\n",
      " \n",
      " Round 2 \n",
      " \n",
      "\n",
      "Epoch: [0][0/11]\tTime 0.337 (0.337)\tLoss 0.2597 (0.2597)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [0][10/11]\tTime 0.016 (0.046)\tLoss 0.0008 (0.1062)\tPrec@1 100.000 (93.182)\n",
      "Epoch: [1][0/11]\tTime 0.344 (0.344)\tLoss 0.0236 (0.0236)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/11]\tTime 0.016 (0.046)\tLoss 0.1443 (0.0828)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [2][0/11]\tTime 0.337 (0.337)\tLoss 0.0309 (0.0309)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/11]\tTime 0.016 (0.046)\tLoss 0.0138 (0.0521)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/11]\tTime 0.345 (0.345)\tLoss 0.0257 (0.0257)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/11]\tTime 0.016 (0.047)\tLoss 0.0379 (0.0400)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/11]\tTime 0.333 (0.333)\tLoss 0.0221 (0.0221)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/11]\tTime 0.016 (0.046)\tLoss 0.0444 (0.0310)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/11]\tTime 0.347 (0.347)\tLoss 0.0120 (0.0120)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/11]\tTime 0.016 (0.047)\tLoss 0.0296 (0.0280)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/11]\tTime 0.334 (0.334)\tLoss 0.0366 (0.0366)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/11]\tTime 0.016 (0.046)\tLoss 0.0261 (0.0258)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/11]\tTime 0.345 (0.345)\tLoss 0.0174 (0.0174)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/11]\tTime 0.017 (0.048)\tLoss 0.0074 (0.0236)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/11]\tTime 0.341 (0.341)\tLoss 0.0225 (0.0225)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/11]\tTime 0.016 (0.046)\tLoss 0.0490 (0.0227)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/11]\tTime 0.332 (0.332)\tLoss 0.0335 (0.0335)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/11]\tTime 0.016 (0.045)\tLoss 0.0181 (0.0215)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/11]\tTime 0.339 (0.339)\tLoss 0.0300 (0.0300)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/11]\tTime 0.016 (0.046)\tLoss 0.0107 (0.0203)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/11]\tTime 0.335 (0.335)\tLoss 0.0210 (0.0210)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/11]\tTime 0.016 (0.046)\tLoss 0.0337 (0.0196)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/11]\tTime 0.345 (0.345)\tLoss 0.0096 (0.0096)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/11]\tTime 0.016 (0.047)\tLoss 0.0241 (0.0192)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/11]\tTime 0.339 (0.339)\tLoss 0.0079 (0.0079)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/11]\tTime 0.016 (0.046)\tLoss 0.0236 (0.0186)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/11]\tTime 0.338 (0.338)\tLoss 0.0167 (0.0167)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/11]\tTime 0.016 (0.046)\tLoss 0.0133 (0.0179)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/11]\tTime 0.339 (0.339)\tLoss 0.0116 (0.0116)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/11]\tTime 0.016 (0.046)\tLoss 0.0103 (0.0176)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/11]\tTime 0.338 (0.338)\tLoss 0.0073 (0.0073)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/11]\tTime 0.016 (0.046)\tLoss 0.0099 (0.0171)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/11]\tTime 0.335 (0.335)\tLoss 0.0236 (0.0236)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/11]\tTime 0.016 (0.046)\tLoss 0.0090 (0.0169)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/11]\tTime 0.344 (0.344)\tLoss 0.0087 (0.0087)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/11]\tTime 0.016 (0.046)\tLoss 0.0219 (0.0165)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/11]\tTime 0.340 (0.340)\tLoss 0.0070 (0.0070)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/11]\tTime 0.016 (0.046)\tLoss 0.0288 (0.0162)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/11]\tTime 0.336 (0.336)\tLoss 0.0139 (0.0139)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/11]\tTime 0.016 (0.046)\tLoss 0.0147 (0.0160)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/11]\tTime 0.337 (0.337)\tLoss 0.0105 (0.0105)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/11]\tTime 0.016 (0.046)\tLoss 0.0117 (0.0158)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/11]\tTime 0.340 (0.340)\tLoss 0.0002 (0.0002)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/11]\tTime 0.016 (0.046)\tLoss 0.0140 (0.0156)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/11]\tTime 0.334 (0.334)\tLoss 0.0173 (0.0173)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/11]\tTime 0.016 (0.045)\tLoss 0.0195 (0.0155)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/11]\tTime 0.332 (0.332)\tLoss 0.0036 (0.0036)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/11]\tTime 0.016 (0.045)\tLoss 0.0063 (0.0152)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/11]\tTime 0.333 (0.333)\tLoss 0.0099 (0.0099)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/11]\tTime 0.017 (0.046)\tLoss 0.0083 (0.0152)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/11]\tTime 0.337 (0.337)\tLoss 0.0126 (0.0126)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/11]\tTime 0.016 (0.046)\tLoss 0.0120 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/11]\tTime 0.341 (0.341)\tLoss 0.0207 (0.0207)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/11]\tTime 0.016 (0.047)\tLoss 0.0180 (0.0150)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/11]\tTime 0.335 (0.335)\tLoss 0.0091 (0.0091)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/11]\tTime 0.016 (0.046)\tLoss 0.0081 (0.0148)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/11]\tTime 0.335 (0.335)\tLoss 0.0143 (0.0143)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/11]\tTime 0.016 (0.046)\tLoss 0.0223 (0.0148)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/11]\tTime 0.332 (0.332)\tLoss 0.0190 (0.0190)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/11]\tTime 0.016 (0.046)\tLoss 0.0149 (0.0147)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/11]\tTime 0.330 (0.330)\tLoss 0.0072 (0.0072)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/11]\tTime 0.016 (0.045)\tLoss 0.0029 (0.0146)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/11]\tTime 0.347 (0.347)\tLoss 0.0064 (0.0064)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/11]\tTime 0.016 (0.047)\tLoss 0.0090 (0.0146)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/11]\tTime 0.333 (0.333)\tLoss 0.0125 (0.0125)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/11]\tTime 0.016 (0.046)\tLoss 0.0045 (0.0146)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/11]\tTime 0.335 (0.335)\tLoss 0.0157 (0.0157)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/11]\tTime 0.016 (0.046)\tLoss 0.0117 (0.0146)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/11]\tTime 0.336 (0.336)\tLoss 0.0227 (0.0227)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/11]\tTime 0.016 (0.046)\tLoss 0.0083 (0.0145)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/11]\tTime 0.335 (0.335)\tLoss 0.0069 (0.0069)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/11]\tTime 0.016 (0.046)\tLoss 0.0131 (0.0145)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/11]\tTime 0.330 (0.330)\tLoss 0.0096 (0.0096)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/11]\tTime 0.016 (0.045)\tLoss 0.0232 (0.0145)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/11]\tTime 0.340 (0.340)\tLoss 0.0106 (0.0106)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/11]\tTime 0.016 (0.046)\tLoss 0.0166 (0.0145)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/11]\tTime 0.341 (0.341)\tLoss 0.0138 (0.0138)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/11]\tTime 0.022 (0.049)\tLoss 0.0189 (0.0145)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 70.238 %\n",
      "Confusion Matrix:\n",
      "[[91 13]\n",
      " [37 27]]\n",
      "F1 Score: 0.5192307692307693\n",
      "Accuracy balanced\n",
      "0.6484375\n",
      "\n",
      " \n",
      " Round 3 \n",
      " \n",
      "\n",
      "Epoch: [0][0/12]\tTime 0.339 (0.339)\tLoss 0.0222 (0.0222)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/12]\tTime 0.016 (0.046)\tLoss 0.5121 (0.1037)\tPrec@1 75.000 (97.727)\n",
      "Epoch: [1][0/12]\tTime 0.334 (0.334)\tLoss 0.0656 (0.0656)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/12]\tTime 0.016 (0.046)\tLoss 0.0207 (0.0765)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [2][0/12]\tTime 0.344 (0.344)\tLoss 0.0235 (0.0235)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/12]\tTime 0.016 (0.047)\tLoss 0.0637 (0.0598)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/12]\tTime 0.342 (0.342)\tLoss 0.0209 (0.0209)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/12]\tTime 0.016 (0.047)\tLoss 0.0294 (0.0449)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/12]\tTime 0.337 (0.337)\tLoss 0.0245 (0.0245)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/12]\tTime 0.016 (0.046)\tLoss 0.0673 (0.0263)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/12]\tTime 0.337 (0.337)\tLoss 0.0082 (0.0082)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/12]\tTime 0.016 (0.046)\tLoss 0.0166 (0.0318)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/12]\tTime 0.342 (0.342)\tLoss 0.0237 (0.0237)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/12]\tTime 0.016 (0.046)\tLoss 0.0766 (0.0300)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/12]\tTime 0.357 (0.357)\tLoss 0.0716 (0.0716)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/12]\tTime 0.016 (0.048)\tLoss 0.0207 (0.0293)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/12]\tTime 0.359 (0.359)\tLoss 0.0979 (0.0979)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/12]\tTime 0.020 (0.050)\tLoss 0.0073 (0.0272)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/12]\tTime 0.344 (0.344)\tLoss 0.0150 (0.0150)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/12]\tTime 0.016 (0.047)\tLoss 0.0220 (0.0179)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/12]\tTime 0.339 (0.339)\tLoss 0.0146 (0.0146)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/12]\tTime 0.016 (0.046)\tLoss 0.0371 (0.0232)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/12]\tTime 0.336 (0.336)\tLoss 0.0459 (0.0459)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/12]\tTime 0.017 (0.046)\tLoss 0.0137 (0.0233)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/12]\tTime 0.343 (0.343)\tLoss 0.0078 (0.0078)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/12]\tTime 0.016 (0.047)\tLoss 0.0067 (0.0186)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/12]\tTime 0.343 (0.343)\tLoss 0.0183 (0.0183)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/12]\tTime 0.016 (0.046)\tLoss 0.0412 (0.0221)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/12]\tTime 0.342 (0.342)\tLoss 0.0236 (0.0236)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/12]\tTime 0.016 (0.047)\tLoss 0.0002 (0.0212)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/12]\tTime 0.353 (0.353)\tLoss 0.0167 (0.0167)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/12]\tTime 0.016 (0.048)\tLoss 0.0471 (0.0195)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/12]\tTime 0.349 (0.349)\tLoss 0.0084 (0.0084)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/12]\tTime 0.016 (0.047)\tLoss 0.0142 (0.0161)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/12]\tTime 0.339 (0.339)\tLoss 0.0063 (0.0063)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/12]\tTime 0.017 (0.046)\tLoss 0.0349 (0.0193)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/12]\tTime 0.334 (0.334)\tLoss 0.0118 (0.0118)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/12]\tTime 0.016 (0.046)\tLoss 0.0111 (0.0158)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/12]\tTime 0.342 (0.342)\tLoss 0.0189 (0.0189)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/12]\tTime 0.016 (0.046)\tLoss 0.0045 (0.0182)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/12]\tTime 0.329 (0.329)\tLoss 0.0198 (0.0198)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/12]\tTime 0.016 (0.045)\tLoss 0.0268 (0.0168)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/12]\tTime 0.348 (0.348)\tLoss 0.0016 (0.0016)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/12]\tTime 0.016 (0.047)\tLoss 0.0153 (0.0177)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/12]\tTime 0.348 (0.348)\tLoss 0.0043 (0.0043)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/12]\tTime 0.016 (0.047)\tLoss 0.0129 (0.0170)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/12]\tTime 0.340 (0.340)\tLoss 0.0119 (0.0119)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/12]\tTime 0.016 (0.047)\tLoss 0.0128 (0.0142)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/12]\tTime 0.339 (0.339)\tLoss 0.0184 (0.0184)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/12]\tTime 0.016 (0.046)\tLoss 0.0116 (0.0144)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/12]\tTime 0.331 (0.331)\tLoss 0.0091 (0.0091)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/12]\tTime 0.016 (0.045)\tLoss 0.0127 (0.0158)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/12]\tTime 0.344 (0.344)\tLoss 0.0114 (0.0114)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/12]\tTime 0.016 (0.047)\tLoss 0.0099 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/12]\tTime 0.337 (0.337)\tLoss 0.0049 (0.0049)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/12]\tTime 0.019 (0.047)\tLoss 0.0001 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/12]\tTime 0.348 (0.348)\tLoss 0.0136 (0.0136)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/12]\tTime 0.016 (0.047)\tLoss 0.0059 (0.0158)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/12]\tTime 0.331 (0.331)\tLoss 0.0181 (0.0181)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/12]\tTime 0.016 (0.046)\tLoss 0.0222 (0.0156)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/12]\tTime 0.334 (0.334)\tLoss 0.0029 (0.0029)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/12]\tTime 0.016 (0.046)\tLoss 0.0128 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/12]\tTime 0.339 (0.339)\tLoss 0.0337 (0.0337)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/12]\tTime 0.016 (0.047)\tLoss 0.0135 (0.0161)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/12]\tTime 0.334 (0.334)\tLoss 0.0011 (0.0011)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/12]\tTime 0.016 (0.046)\tLoss 0.0136 (0.0158)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/12]\tTime 0.334 (0.334)\tLoss 0.0151 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/12]\tTime 0.016 (0.046)\tLoss 0.0329 (0.0161)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/12]\tTime 0.348 (0.348)\tLoss 0.0017 (0.0017)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/12]\tTime 0.022 (0.051)\tLoss 0.0148 (0.0161)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/12]\tTime 0.338 (0.338)\tLoss 0.0255 (0.0255)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/12]\tTime 0.016 (0.046)\tLoss 0.0140 (0.0158)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/12]\tTime 0.347 (0.347)\tLoss 0.0096 (0.0096)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/12]\tTime 0.023 (0.050)\tLoss 0.0285 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/12]\tTime 0.349 (0.349)\tLoss 0.0069 (0.0069)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/12]\tTime 0.025 (0.052)\tLoss 0.0210 (0.0141)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/12]\tTime 0.338 (0.338)\tLoss 0.0111 (0.0111)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/12]\tTime 0.022 (0.050)\tLoss 0.0183 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/12]\tTime 0.337 (0.337)\tLoss 0.0103 (0.0103)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/12]\tTime 0.023 (0.047)\tLoss 0.0337 (0.0161)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 68.452 %\n",
      "Confusion Matrix:\n",
      "[[89 15]\n",
      " [38 26]]\n",
      "F1 Score: 0.4952380952380952\n",
      "Accuracy balanced\n",
      "0.6310096153846154\n",
      "\n",
      " \n",
      " Round 4 \n",
      " \n",
      "\n",
      "Epoch: [0][0/13]\tTime 0.342 (0.342)\tLoss 0.0043 (0.0043)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/13]\tTime 0.016 (0.047)\tLoss 0.0023 (0.0914)\tPrec@1 100.000 (95.455)\n",
      "Epoch: [1][0/13]\tTime 0.337 (0.337)\tLoss 0.0051 (0.0051)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/13]\tTime 0.016 (0.046)\tLoss 0.0276 (0.0535)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][0/13]\tTime 0.342 (0.342)\tLoss 0.0295 (0.0295)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/13]\tTime 0.016 (0.047)\tLoss 0.0329 (0.0405)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/13]\tTime 0.341 (0.341)\tLoss 0.0127 (0.0127)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/13]\tTime 0.016 (0.046)\tLoss 0.0524 (0.0367)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/13]\tTime 0.346 (0.346)\tLoss 0.0001 (0.0001)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/13]\tTime 0.016 (0.047)\tLoss 0.0129 (0.0393)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/13]\tTime 0.337 (0.337)\tLoss 0.0058 (0.0058)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/13]\tTime 0.016 (0.046)\tLoss 0.0443 (0.0416)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/13]\tTime 0.337 (0.337)\tLoss 0.0199 (0.0199)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/13]\tTime 0.016 (0.046)\tLoss 0.0199 (0.0187)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/13]\tTime 0.355 (0.355)\tLoss 0.0562 (0.0562)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/13]\tTime 0.017 (0.049)\tLoss 0.0897 (0.0295)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/13]\tTime 0.339 (0.339)\tLoss 0.0606 (0.0606)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/13]\tTime 0.016 (0.046)\tLoss 0.0069 (0.0281)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/13]\tTime 0.334 (0.334)\tLoss 0.0188 (0.0188)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/13]\tTime 0.016 (0.046)\tLoss 0.0305 (0.0294)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/13]\tTime 0.341 (0.341)\tLoss 0.0299 (0.0299)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/13]\tTime 0.017 (0.047)\tLoss 0.0020 (0.0242)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/13]\tTime 0.325 (0.325)\tLoss 0.0349 (0.0349)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/13]\tTime 0.016 (0.045)\tLoss 0.0473 (0.0265)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/13]\tTime 0.349 (0.349)\tLoss 0.0049 (0.0049)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/13]\tTime 0.018 (0.051)\tLoss 0.0171 (0.0241)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/13]\tTime 0.330 (0.330)\tLoss 0.0484 (0.0484)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/13]\tTime 0.016 (0.046)\tLoss 0.0056 (0.0190)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/13]\tTime 0.342 (0.342)\tLoss 0.0111 (0.0111)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/13]\tTime 0.016 (0.046)\tLoss 0.0138 (0.0199)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/13]\tTime 0.333 (0.333)\tLoss 0.0078 (0.0078)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/13]\tTime 0.016 (0.046)\tLoss 0.0161 (0.0236)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/13]\tTime 0.333 (0.333)\tLoss 0.0254 (0.0254)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/13]\tTime 0.016 (0.045)\tLoss 0.0198 (0.0201)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/13]\tTime 0.334 (0.334)\tLoss 0.0086 (0.0086)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/13]\tTime 0.016 (0.046)\tLoss 0.0213 (0.0234)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/13]\tTime 0.330 (0.330)\tLoss 0.0434 (0.0434)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/13]\tTime 0.016 (0.045)\tLoss 0.0060 (0.0184)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/13]\tTime 0.334 (0.334)\tLoss 0.0204 (0.0204)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/13]\tTime 0.016 (0.046)\tLoss 0.0214 (0.0206)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/13]\tTime 0.332 (0.332)\tLoss 0.0125 (0.0125)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/13]\tTime 0.016 (0.045)\tLoss 0.0052 (0.0186)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/13]\tTime 0.333 (0.333)\tLoss 0.0087 (0.0087)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/13]\tTime 0.016 (0.046)\tLoss 0.0323 (0.0192)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/13]\tTime 0.344 (0.344)\tLoss 0.0268 (0.0268)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/13]\tTime 0.016 (0.048)\tLoss 0.0628 (0.0209)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/13]\tTime 0.348 (0.348)\tLoss 0.0076 (0.0076)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/13]\tTime 0.016 (0.047)\tLoss 0.0115 (0.0173)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/13]\tTime 0.333 (0.333)\tLoss 0.0237 (0.0237)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/13]\tTime 0.016 (0.046)\tLoss 0.0117 (0.0195)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/13]\tTime 0.335 (0.335)\tLoss 0.0327 (0.0327)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/13]\tTime 0.016 (0.046)\tLoss 0.0088 (0.0186)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/13]\tTime 0.335 (0.335)\tLoss 0.0554 (0.0554)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/13]\tTime 0.016 (0.046)\tLoss 0.0086 (0.0187)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/13]\tTime 0.336 (0.336)\tLoss 0.0484 (0.0484)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/13]\tTime 0.016 (0.046)\tLoss 0.0060 (0.0160)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/13]\tTime 0.332 (0.332)\tLoss 0.0099 (0.0099)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/13]\tTime 0.016 (0.046)\tLoss 0.0204 (0.0187)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/13]\tTime 0.341 (0.341)\tLoss 0.0073 (0.0073)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/13]\tTime 0.016 (0.046)\tLoss 0.0251 (0.0149)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/13]\tTime 0.340 (0.340)\tLoss 0.0049 (0.0049)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/13]\tTime 0.016 (0.046)\tLoss 0.0449 (0.0155)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/13]\tTime 0.334 (0.334)\tLoss 0.0121 (0.0121)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/13]\tTime 0.016 (0.046)\tLoss 0.0046 (0.0168)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/13]\tTime 0.345 (0.345)\tLoss 0.0203 (0.0203)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/13]\tTime 0.016 (0.047)\tLoss 0.0059 (0.0148)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/13]\tTime 0.339 (0.339)\tLoss 0.0351 (0.0351)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/13]\tTime 0.016 (0.047)\tLoss 0.0120 (0.0166)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/13]\tTime 0.337 (0.337)\tLoss 0.0117 (0.0117)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/13]\tTime 0.016 (0.046)\tLoss 0.0530 (0.0189)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/13]\tTime 0.335 (0.335)\tLoss 0.0065 (0.0065)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/13]\tTime 0.016 (0.046)\tLoss 0.0048 (0.0155)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/13]\tTime 0.338 (0.338)\tLoss 0.0034 (0.0034)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/13]\tTime 0.016 (0.046)\tLoss 0.0167 (0.0187)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/13]\tTime 0.342 (0.342)\tLoss 0.0084 (0.0084)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/13]\tTime 0.016 (0.047)\tLoss 0.0141 (0.0147)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/13]\tTime 0.336 (0.336)\tLoss 0.0057 (0.0057)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/13]\tTime 0.016 (0.046)\tLoss 0.0069 (0.0150)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/13]\tTime 0.340 (0.340)\tLoss 0.0181 (0.0181)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/13]\tTime 0.016 (0.046)\tLoss 0.0160 (0.0176)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 68.452 %\n",
      "Confusion Matrix:\n",
      "[[87 17]\n",
      " [36 28]]\n",
      "F1 Score: 0.5137614678899083\n",
      "Accuracy balanced\n",
      "0.6370192307692308\n",
      "\n",
      " \n",
      " Round 5 \n",
      " \n",
      "\n",
      "Epoch: [0][0/14]\tTime 0.345 (0.345)\tLoss 0.0006 (0.0006)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/14]\tTime 0.016 (0.047)\tLoss 0.0143 (0.0645)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [1][0/14]\tTime 0.347 (0.347)\tLoss 0.0648 (0.0648)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/14]\tTime 0.016 (0.047)\tLoss 0.0160 (0.0561)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][0/14]\tTime 0.339 (0.339)\tLoss 0.0553 (0.0553)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/14]\tTime 0.016 (0.047)\tLoss 0.0717 (0.0418)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/14]\tTime 0.328 (0.328)\tLoss 0.0471 (0.0471)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/14]\tTime 0.018 (0.048)\tLoss 0.1151 (0.0423)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/14]\tTime 0.345 (0.345)\tLoss 0.0017 (0.0017)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/14]\tTime 0.016 (0.047)\tLoss 0.0516 (0.0288)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/14]\tTime 0.337 (0.337)\tLoss 0.0015 (0.0015)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/14]\tTime 0.018 (0.047)\tLoss 0.0212 (0.0339)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/14]\tTime 0.334 (0.334)\tLoss 0.0417 (0.0417)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/14]\tTime 0.016 (0.046)\tLoss 0.0047 (0.0267)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/14]\tTime 0.346 (0.346)\tLoss 0.0178 (0.0178)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/14]\tTime 0.016 (0.047)\tLoss 0.0178 (0.0311)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/14]\tTime 0.338 (0.338)\tLoss 0.0256 (0.0256)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/14]\tTime 0.016 (0.046)\tLoss 0.0084 (0.0290)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/14]\tTime 0.343 (0.343)\tLoss 0.0157 (0.0157)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/14]\tTime 0.016 (0.047)\tLoss 0.0247 (0.0290)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/14]\tTime 0.333 (0.333)\tLoss 0.0143 (0.0143)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/14]\tTime 0.016 (0.046)\tLoss 0.0336 (0.0230)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/14]\tTime 0.332 (0.332)\tLoss 0.0064 (0.0064)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/14]\tTime 0.016 (0.046)\tLoss 0.0207 (0.0258)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/14]\tTime 0.351 (0.351)\tLoss 0.0129 (0.0129)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/14]\tTime 0.016 (0.048)\tLoss 0.0142 (0.0196)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/14]\tTime 0.337 (0.337)\tLoss 0.0093 (0.0093)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/14]\tTime 0.016 (0.046)\tLoss 0.0115 (0.0209)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/14]\tTime 0.345 (0.345)\tLoss 0.0276 (0.0276)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/14]\tTime 0.016 (0.047)\tLoss 0.0250 (0.0208)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/14]\tTime 0.338 (0.338)\tLoss 0.0246 (0.0246)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/14]\tTime 0.016 (0.047)\tLoss 0.0037 (0.0233)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/14]\tTime 0.334 (0.334)\tLoss 0.0704 (0.0704)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/14]\tTime 0.016 (0.046)\tLoss 0.0125 (0.0198)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/14]\tTime 0.346 (0.346)\tLoss 0.0351 (0.0351)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/14]\tTime 0.016 (0.048)\tLoss 0.0146 (0.0193)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/14]\tTime 0.345 (0.345)\tLoss 0.0025 (0.0025)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/14]\tTime 0.016 (0.047)\tLoss 0.0155 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/14]\tTime 0.334 (0.334)\tLoss 0.0125 (0.0125)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/14]\tTime 0.016 (0.046)\tLoss 0.0014 (0.0178)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/14]\tTime 0.348 (0.348)\tLoss 0.0684 (0.0684)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/14]\tTime 0.016 (0.048)\tLoss 0.0257 (0.0234)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/14]\tTime 0.343 (0.343)\tLoss 0.0257 (0.0257)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/14]\tTime 0.016 (0.047)\tLoss 0.0079 (0.0236)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/14]\tTime 0.342 (0.342)\tLoss 0.0011 (0.0011)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/14]\tTime 0.016 (0.047)\tLoss 0.0634 (0.0194)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/14]\tTime 0.338 (0.338)\tLoss 0.0413 (0.0413)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/14]\tTime 0.016 (0.046)\tLoss 0.0140 (0.0196)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/14]\tTime 0.346 (0.346)\tLoss 0.0050 (0.0050)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/14]\tTime 0.016 (0.047)\tLoss 0.0034 (0.0166)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/14]\tTime 0.342 (0.342)\tLoss 0.0204 (0.0204)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/14]\tTime 0.016 (0.047)\tLoss 0.0032 (0.0180)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/14]\tTime 0.343 (0.343)\tLoss 0.0030 (0.0030)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/14]\tTime 0.016 (0.047)\tLoss 0.0336 (0.0127)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/14]\tTime 0.345 (0.345)\tLoss 0.0209 (0.0209)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/14]\tTime 0.016 (0.047)\tLoss 0.0360 (0.0191)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/14]\tTime 0.340 (0.340)\tLoss 0.0330 (0.0330)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/14]\tTime 0.016 (0.047)\tLoss 0.0174 (0.0193)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/14]\tTime 0.331 (0.331)\tLoss 0.0044 (0.0044)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/14]\tTime 0.024 (0.049)\tLoss 0.0062 (0.0167)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/14]\tTime 0.339 (0.339)\tLoss 0.0047 (0.0047)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/14]\tTime 0.016 (0.046)\tLoss 0.0060 (0.0159)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/14]\tTime 0.341 (0.341)\tLoss 0.0253 (0.0253)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/14]\tTime 0.016 (0.047)\tLoss 0.0111 (0.0209)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/14]\tTime 0.335 (0.335)\tLoss 0.0137 (0.0137)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/14]\tTime 0.017 (0.047)\tLoss 0.0066 (0.0136)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/14]\tTime 0.340 (0.340)\tLoss 0.0102 (0.0102)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/14]\tTime 0.016 (0.047)\tLoss 0.0462 (0.0194)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/14]\tTime 0.334 (0.334)\tLoss 0.0026 (0.0026)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/14]\tTime 0.016 (0.046)\tLoss 0.0035 (0.0159)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/14]\tTime 0.332 (0.332)\tLoss 0.0137 (0.0137)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/14]\tTime 0.016 (0.046)\tLoss 0.0072 (0.0159)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/14]\tTime 0.337 (0.337)\tLoss 0.0119 (0.0119)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/14]\tTime 0.016 (0.046)\tLoss 0.0071 (0.0202)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/14]\tTime 0.342 (0.342)\tLoss 0.0519 (0.0519)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/14]\tTime 0.016 (0.047)\tLoss 0.0056 (0.0166)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/14]\tTime 0.345 (0.345)\tLoss 0.0023 (0.0023)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/14]\tTime 0.016 (0.047)\tLoss 0.0029 (0.0189)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/14]\tTime 0.363 (0.363)\tLoss 0.0135 (0.0135)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/14]\tTime 0.016 (0.049)\tLoss 0.0042 (0.0167)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 67.857 %\n",
      "Confusion Matrix:\n",
      "[[88 16]\n",
      " [38 26]]\n",
      "F1 Score: 0.49056603773584906\n",
      "Accuracy balanced\n",
      "0.6262019230769231\n",
      "\n",
      " \n",
      " Round 6 \n",
      " \n",
      "\n",
      "Epoch: [0][0/15]\tTime 0.344 (0.344)\tLoss 0.0113 (0.0113)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/15]\tTime 0.016 (0.047)\tLoss 0.0134 (0.1182)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [1][0/15]\tTime 0.338 (0.338)\tLoss 0.0102 (0.0102)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/15]\tTime 0.017 (0.047)\tLoss 0.0088 (0.0774)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [2][0/15]\tTime 0.348 (0.348)\tLoss 0.1672 (0.1672)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/15]\tTime 0.017 (0.047)\tLoss 0.1695 (0.0684)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/15]\tTime 0.340 (0.340)\tLoss 0.0121 (0.0121)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/15]\tTime 0.016 (0.047)\tLoss 0.0643 (0.0420)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/15]\tTime 0.346 (0.346)\tLoss 0.1241 (0.1241)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/15]\tTime 0.016 (0.047)\tLoss 0.0267 (0.0388)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/15]\tTime 0.337 (0.337)\tLoss 0.0179 (0.0179)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/15]\tTime 0.016 (0.047)\tLoss 0.0169 (0.0456)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/15]\tTime 0.344 (0.344)\tLoss 0.0450 (0.0450)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/15]\tTime 0.016 (0.047)\tLoss 0.0353 (0.0435)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/15]\tTime 0.338 (0.338)\tLoss 0.0158 (0.0158)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/15]\tTime 0.016 (0.046)\tLoss 0.1027 (0.0322)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/15]\tTime 0.353 (0.353)\tLoss 0.0170 (0.0170)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/15]\tTime 0.017 (0.050)\tLoss 0.0423 (0.0371)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/15]\tTime 0.330 (0.330)\tLoss 0.0237 (0.0237)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/15]\tTime 0.016 (0.046)\tLoss 0.0277 (0.0349)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/15]\tTime 0.340 (0.340)\tLoss 0.0563 (0.0563)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/15]\tTime 0.016 (0.047)\tLoss 0.0639 (0.0331)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/15]\tTime 0.341 (0.341)\tLoss 0.0251 (0.0251)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/15]\tTime 0.016 (0.047)\tLoss 0.0458 (0.0242)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/15]\tTime 0.336 (0.336)\tLoss 0.0052 (0.0052)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/15]\tTime 0.016 (0.046)\tLoss 0.0159 (0.0272)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/15]\tTime 0.343 (0.343)\tLoss 0.0385 (0.0385)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/15]\tTime 0.020 (0.051)\tLoss 0.0226 (0.0285)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/15]\tTime 0.343 (0.343)\tLoss 0.0285 (0.0285)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/15]\tTime 0.017 (0.049)\tLoss 0.0029 (0.0266)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/15]\tTime 0.353 (0.353)\tLoss 0.0478 (0.0478)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/15]\tTime 0.016 (0.049)\tLoss 0.0663 (0.0223)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/15]\tTime 0.344 (0.344)\tLoss 0.0154 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/15]\tTime 0.023 (0.051)\tLoss 0.0542 (0.0250)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/15]\tTime 0.327 (0.327)\tLoss 0.0039 (0.0039)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/15]\tTime 0.017 (0.047)\tLoss 0.0284 (0.0272)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/15]\tTime 0.343 (0.343)\tLoss 0.0469 (0.0469)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/15]\tTime 0.020 (0.051)\tLoss 0.0215 (0.0227)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/15]\tTime 0.346 (0.346)\tLoss 0.0015 (0.0015)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/15]\tTime 0.017 (0.051)\tLoss 0.0340 (0.0178)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/15]\tTime 0.335 (0.335)\tLoss 0.0118 (0.0118)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/15]\tTime 0.016 (0.047)\tLoss 0.0198 (0.0208)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/15]\tTime 0.343 (0.343)\tLoss 0.0311 (0.0311)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/15]\tTime 0.016 (0.047)\tLoss 0.0119 (0.0200)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/15]\tTime 0.344 (0.344)\tLoss 0.0360 (0.0360)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/15]\tTime 0.016 (0.047)\tLoss 0.0000 (0.0167)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/15]\tTime 0.342 (0.342)\tLoss 0.0049 (0.0049)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/15]\tTime 0.016 (0.047)\tLoss 0.0543 (0.0203)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/15]\tTime 0.340 (0.340)\tLoss 0.0061 (0.0061)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/15]\tTime 0.016 (0.047)\tLoss 0.0271 (0.0204)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/15]\tTime 0.340 (0.340)\tLoss 0.0250 (0.0250)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/15]\tTime 0.016 (0.047)\tLoss 0.0086 (0.0232)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/15]\tTime 0.340 (0.340)\tLoss 0.0090 (0.0090)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/15]\tTime 0.016 (0.047)\tLoss 0.0086 (0.0227)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/15]\tTime 0.334 (0.334)\tLoss 0.0309 (0.0309)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/15]\tTime 0.016 (0.046)\tLoss 0.0005 (0.0177)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/15]\tTime 0.349 (0.349)\tLoss 0.0427 (0.0427)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/15]\tTime 0.016 (0.047)\tLoss 0.0280 (0.0227)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/15]\tTime 0.345 (0.345)\tLoss 0.0267 (0.0267)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/15]\tTime 0.016 (0.047)\tLoss 0.0277 (0.0211)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/15]\tTime 0.338 (0.338)\tLoss 0.0026 (0.0026)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/15]\tTime 0.016 (0.046)\tLoss 0.0172 (0.0198)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/15]\tTime 0.337 (0.337)\tLoss 0.0075 (0.0075)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/15]\tTime 0.016 (0.046)\tLoss 0.0526 (0.0226)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/15]\tTime 0.340 (0.340)\tLoss 0.0135 (0.0135)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/15]\tTime 0.016 (0.046)\tLoss 0.0300 (0.0217)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/15]\tTime 0.337 (0.337)\tLoss 0.0011 (0.0011)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/15]\tTime 0.016 (0.046)\tLoss 0.0239 (0.0171)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/15]\tTime 0.325 (0.325)\tLoss 0.0026 (0.0026)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/15]\tTime 0.016 (0.045)\tLoss 0.0421 (0.0176)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/15]\tTime 0.334 (0.334)\tLoss 0.0162 (0.0162)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/15]\tTime 0.016 (0.046)\tLoss 0.0126 (0.0183)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/15]\tTime 0.336 (0.336)\tLoss 0.0141 (0.0141)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/15]\tTime 0.016 (0.046)\tLoss 0.0056 (0.0223)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/15]\tTime 0.339 (0.339)\tLoss 0.0192 (0.0192)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/15]\tTime 0.016 (0.047)\tLoss 0.0233 (0.0193)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/15]\tTime 0.351 (0.351)\tLoss 0.0454 (0.0454)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/15]\tTime 0.016 (0.048)\tLoss 0.0105 (0.0206)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/15]\tTime 0.336 (0.336)\tLoss 0.0158 (0.0158)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/15]\tTime 0.016 (0.046)\tLoss 0.0541 (0.0194)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 67.262 %\n",
      "Confusion Matrix:\n",
      "[[89 15]\n",
      " [40 24]]\n",
      "F1 Score: 0.46601941747572817\n",
      "Accuracy balanced\n",
      "0.6153846153846154\n",
      "\n",
      " \n",
      " Round 7 \n",
      " \n",
      "\n",
      "Epoch: [0][0/16]\tTime 0.347 (0.347)\tLoss 0.0227 (0.0227)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][10/16]\tTime 0.016 (0.047)\tLoss 0.0686 (0.1106)\tPrec@1 100.000 (93.182)\n",
      "Epoch: [1][0/16]\tTime 0.328 (0.328)\tLoss 0.0094 (0.0094)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][10/16]\tTime 0.016 (0.046)\tLoss 0.2907 (0.0842)\tPrec@1 100.000 (97.727)\n",
      "Epoch: [2][0/16]\tTime 0.341 (0.341)\tLoss 0.0954 (0.0954)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][10/16]\tTime 0.016 (0.047)\tLoss 0.0044 (0.0442)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][0/16]\tTime 0.335 (0.335)\tLoss 0.0131 (0.0131)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [3][10/16]\tTime 0.017 (0.047)\tLoss 0.0097 (0.0287)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/16]\tTime 0.341 (0.341)\tLoss 0.0019 (0.0019)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][10/16]\tTime 0.016 (0.047)\tLoss 0.0939 (0.0417)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/16]\tTime 0.346 (0.346)\tLoss 0.0160 (0.0160)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][10/16]\tTime 0.016 (0.047)\tLoss 0.0763 (0.0328)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/16]\tTime 0.333 (0.333)\tLoss 0.0407 (0.0407)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][10/16]\tTime 0.016 (0.046)\tLoss 0.0422 (0.0259)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/16]\tTime 0.353 (0.353)\tLoss 0.0297 (0.0297)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][10/16]\tTime 0.017 (0.048)\tLoss 0.0833 (0.0341)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/16]\tTime 0.335 (0.335)\tLoss 0.0007 (0.0007)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][10/16]\tTime 0.016 (0.046)\tLoss 0.0075 (0.0304)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/16]\tTime 0.352 (0.352)\tLoss 0.0193 (0.0193)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][10/16]\tTime 0.016 (0.048)\tLoss 0.0157 (0.0190)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][0/16]\tTime 0.341 (0.341)\tLoss 0.0294 (0.0294)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [10][10/16]\tTime 0.016 (0.047)\tLoss 0.0234 (0.0275)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][0/16]\tTime 0.335 (0.335)\tLoss 0.0589 (0.0589)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [11][10/16]\tTime 0.016 (0.046)\tLoss 0.0275 (0.0278)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][0/16]\tTime 0.332 (0.332)\tLoss 0.0358 (0.0358)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [12][10/16]\tTime 0.016 (0.046)\tLoss 0.0395 (0.0242)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][0/16]\tTime 0.343 (0.343)\tLoss 0.0326 (0.0326)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [13][10/16]\tTime 0.016 (0.047)\tLoss 0.0100 (0.0261)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][0/16]\tTime 0.339 (0.339)\tLoss 0.0093 (0.0093)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [14][10/16]\tTime 0.016 (0.047)\tLoss 0.0102 (0.0243)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][0/16]\tTime 0.340 (0.340)\tLoss 0.0201 (0.0201)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [15][10/16]\tTime 0.022 (0.050)\tLoss 0.0005 (0.0242)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][0/16]\tTime 0.343 (0.343)\tLoss 0.0185 (0.0185)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [16][10/16]\tTime 0.016 (0.048)\tLoss 0.0213 (0.0182)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][0/16]\tTime 0.341 (0.341)\tLoss 0.0108 (0.0108)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [17][10/16]\tTime 0.016 (0.047)\tLoss 0.0120 (0.0196)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][0/16]\tTime 0.334 (0.334)\tLoss 0.0054 (0.0054)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [18][10/16]\tTime 0.016 (0.046)\tLoss 0.0263 (0.0228)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][0/16]\tTime 0.345 (0.345)\tLoss 0.0041 (0.0041)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [19][10/16]\tTime 0.016 (0.047)\tLoss 0.0071 (0.0171)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][0/16]\tTime 0.340 (0.340)\tLoss 0.0271 (0.0271)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [20][10/16]\tTime 0.016 (0.048)\tLoss 0.0053 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][0/16]\tTime 0.343 (0.343)\tLoss 0.0134 (0.0134)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [21][10/16]\tTime 0.016 (0.047)\tLoss 0.0118 (0.0187)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][0/16]\tTime 0.334 (0.334)\tLoss 0.0264 (0.0264)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [22][10/16]\tTime 0.016 (0.046)\tLoss 0.0064 (0.0189)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][0/16]\tTime 0.338 (0.338)\tLoss 0.0121 (0.0121)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [23][10/16]\tTime 0.016 (0.047)\tLoss 0.0190 (0.0222)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][0/16]\tTime 0.340 (0.340)\tLoss 0.0405 (0.0405)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [24][10/16]\tTime 0.016 (0.047)\tLoss 0.0147 (0.0198)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][0/16]\tTime 0.348 (0.348)\tLoss 0.0103 (0.0103)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [25][10/16]\tTime 0.016 (0.048)\tLoss 0.0046 (0.0187)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][0/16]\tTime 0.341 (0.341)\tLoss 0.0102 (0.0102)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [26][10/16]\tTime 0.016 (0.047)\tLoss 0.0006 (0.0170)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][0/16]\tTime 0.334 (0.334)\tLoss 0.0049 (0.0049)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [27][10/16]\tTime 0.016 (0.046)\tLoss 0.0012 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][0/16]\tTime 0.343 (0.343)\tLoss 0.0050 (0.0050)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [28][10/16]\tTime 0.016 (0.047)\tLoss 0.0044 (0.0195)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][0/16]\tTime 0.339 (0.339)\tLoss 0.0236 (0.0236)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [29][10/16]\tTime 0.016 (0.047)\tLoss 0.0349 (0.0205)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][0/16]\tTime 0.333 (0.333)\tLoss 0.0140 (0.0140)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [30][10/16]\tTime 0.016 (0.046)\tLoss 0.0008 (0.0169)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][0/16]\tTime 0.338 (0.338)\tLoss 0.0041 (0.0041)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [31][10/16]\tTime 0.016 (0.046)\tLoss 0.0105 (0.0187)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][0/16]\tTime 0.334 (0.334)\tLoss 0.0201 (0.0201)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [32][10/16]\tTime 0.016 (0.046)\tLoss 0.0029 (0.0184)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][0/16]\tTime 0.334 (0.334)\tLoss 0.0379 (0.0379)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [33][10/16]\tTime 0.016 (0.047)\tLoss 0.0393 (0.0193)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][0/16]\tTime 0.338 (0.338)\tLoss 0.0392 (0.0392)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [34][10/16]\tTime 0.016 (0.047)\tLoss 0.0041 (0.0153)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][0/16]\tTime 0.341 (0.341)\tLoss 0.0069 (0.0069)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [35][10/16]\tTime 0.020 (0.047)\tLoss 0.0227 (0.0154)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][0/16]\tTime 0.358 (0.358)\tLoss 0.0165 (0.0165)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [36][10/16]\tTime 0.016 (0.048)\tLoss 0.0190 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][0/16]\tTime 0.349 (0.349)\tLoss 0.0272 (0.0272)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [37][10/16]\tTime 0.016 (0.047)\tLoss 0.0063 (0.0151)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][0/16]\tTime 0.336 (0.336)\tLoss 0.0199 (0.0199)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [38][10/16]\tTime 0.016 (0.046)\tLoss 0.0009 (0.0147)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][0/16]\tTime 0.336 (0.336)\tLoss 0.0181 (0.0181)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [39][10/16]\tTime 0.016 (0.046)\tLoss 0.0131 (0.0169)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 168 test images: 66.667 %\n",
      "Confusion Matrix:\n",
      "[[90 14]\n",
      " [42 22]]\n",
      "F1 Score: 0.44000000000000006\n",
      "Accuracy balanced\n",
      "0.6045673076923077\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 84 test images: 70.238 %\n",
      "Confusion Matrix:\n",
      "[[46  4]\n",
      " [21 13]]\n",
      "F1 Score: 0.5098039215686274\n",
      "Accuracy balanced\n",
      "0.6511764705882352\n",
      "AL finished\n",
      "SSL_AL\n",
      "Len prebuild predictions: 852\n",
      "Len prebuild predictions: 852\n",
      "Start L2D Training\n",
      "Epoch: [0][0/5]\tTime 0.899 (0.899)\tLoss 4.0886 (4.0886)\tPrec@1 22.656 (22.656)\n",
      "{'coverage': '35 out of168', 'system_accuracy': 82.73809523809524, 'expert_accuracy': 86.46603538942047, 'classifier_accuracy': 68.57123265362098, 'alone_classifier': 67.26190476190476, 'validation_loss': 3.7768841981887817, 'n_experts': 2, 'expert_0': 90.14059115326435, 'expert_1': 82.25779916838978, 'expert_0_coverage': 71, 'expert_1_coverage': 62}\n",
      "Epoch: [1][0/5]\tTime 0.886 (0.886)\tLoss 3.6046 (3.6046)\tPrec@1 17.969 (17.969)\n",
      "{'coverage': '15 out of168', 'system_accuracy': 89.88095238095238, 'expert_accuracy': 91.50314836189756, 'classifier_accuracy': 73.33284444770368, 'alone_classifier': 75.0, 'validation_loss': 2.955859661102295, 'n_experts': 2, 'expert_0': 92.64692257805503, 'expert_1': 82.3519723297373, 'expert_0_coverage': 136, 'expert_1_coverage': 17}\n",
      "Epoch: [2][0/5]\tTime 0.872 (0.872)\tLoss 2.5505 (2.5505)\tPrec@1 14.844 (14.844)\n",
      "{'coverage': '36 out of168', 'system_accuracy': 91.66666666666667, 'expert_accuracy': 92.42410238772365, 'classifier_accuracy': 88.8886419759945, 'alone_classifier': 80.95238095238095, 'validation_loss': 2.4748514890670776, 'n_experts': 2, 'expert_0': 92.56183047631326, 'expert_1': 90.90743804658098, 'expert_0_coverage': 121, 'expert_1_coverage': 11}\n",
      "Epoch: [3][0/5]\tTime 0.857 (0.857)\tLoss 1.5147 (1.5147)\tPrec@1 32.031 (32.031)\n",
      "{'coverage': '109 out of168', 'system_accuracy': 86.9047619047619, 'expert_accuracy': 89.83020396541029, 'classifier_accuracy': 85.32102264126362, 'alone_classifier': 80.95238095238095, 'validation_loss': 3.27324378490448, 'n_experts': 2, 'expert_0': 90.19572472264815, 'expert_1': 87.49781255468613, 'expert_0_coverage': 51, 'expert_1_coverage': 8}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "3.27324378490448\n",
      "Epoch: [4][0/5]\tTime 0.853 (0.853)\tLoss 0.9543 (0.9543)\tPrec@1 68.750 (68.750)\n",
      "{'coverage': '134 out of168', 'system_accuracy': 82.14285714285714, 'expert_accuracy': 91.17593425921024, 'classifier_accuracy': 79.85068667859203, 'alone_classifier': 79.76190476190476, 'validation_loss': 4.340360879898071, 'n_experts': 2, 'expert_0': 93.10280618754354, 'expert_1': 79.99680012799487, 'expert_0_coverage': 29, 'expert_1_coverage': 5}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "4.340360879898071\n",
      "Epoch: [5][0/5]\tTime 0.867 (0.867)\tLoss 0.3100 (0.3100)\tPrec@1 75.781 (75.781)\n",
      "{'coverage': '117 out of168', 'system_accuracy': 83.33333333333333, 'expert_accuracy': 98.03883122026973, 'classifier_accuracy': 76.92301117691352, 'alone_classifier': 75.5952380952381, 'validation_loss': 4.7306623458862305, 'n_experts': 2, 'expert_0': 97.29677136880342, 'expert_1': 99.9985714489793, 'expert_0_coverage': 37, 'expert_1_coverage': 14}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "4.7306623458862305\n",
      "Epoch: [6][0/5]\tTime 0.871 (0.871)\tLoss 0.3715 (0.3715)\tPrec@1 78.125 (78.125)\n",
      "{'coverage': '122 out of168', 'system_accuracy': 84.52380952380952, 'expert_accuracy': 91.3039508523876, 'classifier_accuracy': 81.96714592856891, 'alone_classifier': 80.35714285714286, 'validation_loss': 4.3914148807525635, 'n_experts': 2, 'expert_0': 90.62443359729002, 'expert_1': 92.85581634548078, 'expert_0_coverage': 32, 'expert_1_coverage': 14}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "4.3914148807525635\n",
      "Epoch: [7][0/5]\tTime 0.856 (0.856)\tLoss 0.2717 (0.2717)\tPrec@1 75.000 (75.000)\n",
      "{'coverage': '115 out of168', 'system_accuracy': 85.71428571428571, 'expert_accuracy': 94.33926664427682, 'classifier_accuracy': 81.73905935733968, 'alone_classifier': 79.16666666666667, 'validation_loss': 4.8063530921936035, 'n_experts': 2, 'expert_0': 86.95576560203824, 'expert_1': 99.99933333777776, 'expert_0_coverage': 23, 'expert_1_coverage': 30}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "4.8063530921936035\n",
      "Epoch: [8][0/5]\tTime 0.868 (0.868)\tLoss 0.3179 (0.3179)\tPrec@1 73.438 (73.438)\n",
      "{'coverage': '114 out of168', 'system_accuracy': 84.52380952380952, 'expert_accuracy': 90.7404046651679, 'classifier_accuracy': 81.57887580800367, 'alone_classifier': 80.35714285714286, 'validation_loss': 5.314062595367432, 'n_experts': 2, 'expert_0': 82.60797732193633, 'expert_1': 96.77356920277934, 'expert_0_coverage': 23, 'expert_1_coverage': 31}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "5.314062595367432\n",
      "Epoch: [9][0/5]\tTime 0.875 (0.875)\tLoss 0.0950 (0.0950)\tPrec@1 76.562 (76.562)\n",
      "{'coverage': '103 out of168', 'system_accuracy': 82.73809523809524, 'expert_accuracy': 90.76895148014928, 'classifier_accuracy': 77.66982750502184, 'alone_classifier': 76.19047619047619, 'validation_loss': 6.594924449920654, 'n_experts': 2, 'expert_0': 87.0962122825014, 'expert_1': 94.11709342886219, 'expert_0_coverage': 31, 'expert_1_coverage': 34}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "6.594924449920654\n",
      "Epoch: [10][0/5]\tTime 0.852 (0.852)\tLoss 0.1038 (0.1038)\tPrec@1 64.062 (64.062)\n",
      "{'coverage': '102 out of168', 'system_accuracy': 82.14285714285714, 'expert_accuracy': 87.87852158023763, 'classifier_accuracy': 78.43129565559249, 'alone_classifier': 79.16666666666667, 'validation_loss': 5.011090278625488, 'n_experts': 2, 'expert_0': 87.17904010748663, 'expert_1': 88.88823045755217, 'expert_0_coverage': 39, 'expert_1_coverage': 27}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "5.011090278625488\n",
      "Epoch: [11][0/5]\tTime 0.858 (0.858)\tLoss 0.1392 (0.1392)\tPrec@1 67.188 (67.188)\n",
      "{'coverage': '103 out of168', 'system_accuracy': 81.54761904761905, 'expert_accuracy': 90.76895148014928, 'classifier_accuracy': 75.72808181739629, 'alone_classifier': 79.16666666666667, 'validation_loss': 4.50778591632843, 'n_experts': 2, 'expert_0': 89.65486325909221, 'expert_1': 99.99714293877317, 'expert_0_coverage': 58, 'expert_1_coverage': 7}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "4.50778591632843\n",
      "Epoch: [12][0/5]\tTime 0.893 (0.893)\tLoss 0.2831 (0.2831)\tPrec@1 59.375 (59.375)\n",
      "{'coverage': '85 out of168', 'system_accuracy': 86.9047619047619, 'expert_accuracy': 90.36122804523362, 'classifier_accuracy': 83.52931349492529, 'alone_classifier': 82.14285714285714, 'validation_loss': 5.3672449588775635, 'n_experts': 2, 'expert_0': 89.83020396541029, 'expert_1': 91.66590278414347, 'expert_0_coverage': 59, 'expert_1_coverage': 24}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "5.3672449588775635\n",
      "Epoch: [13][0/5]\tTime 0.884 (0.884)\tLoss 0.0692 (0.0692)\tPrec@1 53.906 (53.906)\n",
      "{'coverage': '90 out of168', 'system_accuracy': 79.16666666666667, 'expert_accuracy': 85.897215648165, 'classifier_accuracy': 73.33325185194238, 'alone_classifier': 74.4047619047619, 'validation_loss': 5.972326040267944, 'n_experts': 2, 'expert_0': 86.27417147383736, 'expert_1': 85.1845541884875, 'expert_0_coverage': 51, 'expert_1_coverage': 27}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "5.972326040267944\n",
      "Epoch: [14][0/5]\tTime 0.873 (0.873)\tLoss 0.1557 (0.1557)\tPrec@1 50.781 (50.781)\n",
      "{'coverage': '97 out of168', 'system_accuracy': 81.54761904761905, 'expert_accuracy': 87.32369767972484, 'classifier_accuracy': 77.31950791803307, 'alone_classifier': 76.19047619047619, 'validation_loss': 6.795570135116577, 'n_experts': 2, 'expert_0': 85.999656001376, 'expert_1': 90.47532880639233, 'expert_0_coverage': 50, 'expert_1_coverage': 21}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "6.795570135116577\n",
      "Epoch: [15][0/5]\tTime 0.869 (0.869)\tLoss 0.0794 (0.0794)\tPrec@1 53.125 (53.125)\n",
      "{'coverage': '91 out of168', 'system_accuracy': 88.69047619047619, 'expert_accuracy': 90.90885478219536, 'classifier_accuracy': 86.81309141418525, 'alone_classifier': 81.54761904761905, 'validation_loss': 5.207794189453125, 'n_experts': 2, 'expert_0': 90.38426775281634, 'expert_1': 91.99926400588795, 'expert_0_coverage': 52, 'expert_1_coverage': 25}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "5.207794189453125\n",
      "Epoch: [16][0/5]\tTime 0.845 (0.845)\tLoss 0.0730 (0.0730)\tPrec@1 55.469 (55.469)\n",
      "{'coverage': '103 out of168', 'system_accuracy': 86.9047619047619, 'expert_accuracy': 95.38432189439416, 'classifier_accuracy': 81.55331888027293, 'alone_classifier': 79.76190476190476, 'validation_loss': 5.954790115356445, 'n_experts': 2, 'expert_0': 93.18139463002441, 'expert_1': 99.99904762811784, 'expert_0_coverage': 44, 'expert_1_coverage': 21}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "5.954790115356445\n",
      "Epoch: [17][0/5]\tTime 0.885 (0.885)\tLoss 0.1905 (0.1905)\tPrec@1 52.344 (52.344)\n",
      "{'coverage': '102 out of168', 'system_accuracy': 87.5, 'expert_accuracy': 93.93910927542643, 'classifier_accuracy': 83.33325163406703, 'alone_classifier': 80.95238095238095, 'validation_loss': 6.076369524002075, 'n_experts': 2, 'expert_0': 91.48897238735154, 'expert_1': 99.99894737950127, 'expert_0_coverage': 47, 'expert_1_coverage': 19}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "6.076369524002075\n",
      "Epoch: [18][0/5]\tTime 0.873 (0.873)\tLoss 0.0052 (0.0052)\tPrec@1 60.938 (60.938)\n",
      "{'coverage': '95 out of168', 'system_accuracy': 87.5, 'expert_accuracy': 89.04085194287138, 'classifier_accuracy': 86.31569861505409, 'alone_classifier': 83.33333333333333, 'validation_loss': 6.614607810974121, 'n_experts': 2, 'expert_0': 87.75474385818833, 'expert_1': 91.66590278414347, 'expert_0_coverage': 49, 'expert_1_coverage': 24}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "6.614607810974121\n",
      "Epoch: [19][0/5]\tTime 0.872 (0.872)\tLoss 0.0843 (0.0843)\tPrec@1 61.719 (61.719)\n",
      "{'coverage': '94 out of168', 'system_accuracy': 85.11904761904762, 'expert_accuracy': 90.54029583703827, 'classifier_accuracy': 80.8509778181087, 'alone_classifier': 79.76190476190476, 'validation_loss': 6.447472810745239, 'n_experts': 2, 'expert_0': 90.69725257091828, 'expert_1': 90.32199792259405, 'expert_0_coverage': 43, 'expert_1_coverage': 31}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "6.447472810745239\n",
      "Epoch: [20][0/5]\tTime 0.859 (0.859)\tLoss 0.0274 (0.0274)\tPrec@1 55.469 (55.469)\n",
      "{'coverage': '99 out of168', 'system_accuracy': 89.28571428571429, 'expert_accuracy': 95.65189666116909, 'classifier_accuracy': 84.84839914303116, 'alone_classifier': 82.14285714285714, 'validation_loss': 7.4795379638671875, 'n_experts': 2, 'expert_0': 94.11709342886219, 'expert_1': 97.14230204398832, 'expert_0_coverage': 34, 'expert_1_coverage': 35}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "7.4795379638671875\n",
      "Epoch: [21][0/5]\tTime 0.863 (0.863)\tLoss 0.0044 (0.0044)\tPrec@1 50.000 (50.000)\n",
      "{'coverage': '91 out of168', 'system_accuracy': 86.9047619047619, 'expert_accuracy': 92.2075527076553, 'classifier_accuracy': 82.41749184891005, 'alone_classifier': 80.35714285714286, 'validation_loss': 7.591062545776367, 'n_experts': 2, 'expert_0': 88.88839506447187, 'expert_1': 95.1214872122575, 'expert_0_coverage': 36, 'expert_1_coverage': 41}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "7.591062545776367\n",
      "Epoch: [22][0/5]\tTime 0.877 (0.877)\tLoss 0.0122 (0.0122)\tPrec@1 47.656 (47.656)\n",
      "{'coverage': '87 out of168', 'system_accuracy': 87.5, 'expert_accuracy': 92.59236396947168, 'classifier_accuracy': 82.75852556491314, 'alone_classifier': 78.57142857142857, 'validation_loss': 8.03967809677124, 'n_experts': 2, 'expert_0': 89.18870708806979, 'expert_1': 95.45411157222013, 'expert_0_coverage': 37, 'expert_1_coverage': 44}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "8.03967809677124\n",
      "Epoch: [23][0/5]\tTime 0.849 (0.849)\tLoss 0.0238 (0.0238)\tPrec@1 51.562 (51.562)\n",
      "{'coverage': '90 out of168', 'system_accuracy': 85.71428571428571, 'expert_accuracy': 91.02540762715992, 'classifier_accuracy': 81.11102098775446, 'alone_classifier': 78.57142857142857, 'validation_loss': 7.023345947265625, 'n_experts': 2, 'expert_0': 86.66608889274072, 'expert_1': 93.7496093766276, 'expert_0_coverage': 30, 'expert_1_coverage': 48}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "7.023345947265625\n",
      "Epoch: [24][0/5]\tTime 0.847 (0.847)\tLoss 0.0091 (0.0091)\tPrec@1 55.469 (55.469)\n",
      "{'coverage': '89 out of168', 'system_accuracy': 88.69047619047619, 'expert_accuracy': 91.13900977465879, 'classifier_accuracy': 86.51675672274526, 'alone_classifier': 78.57142857142857, 'validation_loss': 7.704575061798096, 'n_experts': 2, 'expert_0': 88.2347750895583, 'expert_1': 93.33291852036213, 'expert_0_coverage': 34, 'expert_1_coverage': 45}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "7.704575061798096\n",
      "Epoch: [25][0/5]\tTime 0.867 (0.867)\tLoss 0.0048 (0.0048)\tPrec@1 45.312 (45.312)\n",
      "{'coverage': '85 out of168', 'system_accuracy': 88.69047619047619, 'expert_accuracy': 91.56604441917007, 'classifier_accuracy': 85.88225190323305, 'alone_classifier': 80.95238095238095, 'validation_loss': 6.828339338302612, 'n_experts': 2, 'expert_0': 87.87825528330131, 'expert_1': 93.99962400150399, 'expert_0_coverage': 33, 'expert_1_coverage': 50}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "6.828339338302612\n",
      "Epoch: [26][0/5]\tTime 0.869 (0.869)\tLoss 0.0032 (0.0032)\tPrec@1 47.656 (47.656)\n",
      "{'coverage': '82 out of168', 'system_accuracy': 89.28571428571429, 'expert_accuracy': 91.86025148778722, 'classifier_accuracy': 86.58526026187772, 'alone_classifier': 80.95238095238095, 'validation_loss': 7.479650020599365, 'n_experts': 2, 'expert_0': 88.2347750895583, 'expert_1': 94.23040680612768, 'expert_0_coverage': 34, 'expert_1_coverage': 52}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "7.479650020599365\n",
      "Epoch: [27][0/5]\tTime 0.869 (0.869)\tLoss 0.0036 (0.0036)\tPrec@1 44.531 (44.531)\n",
      "{'coverage': '81 out of168', 'system_accuracy': 89.28571428571429, 'expert_accuracy': 90.80438895542768, 'classifier_accuracy': 87.65421277257683, 'alone_classifier': 81.54761904761905, 'validation_loss': 6.578839302062988, 'n_experts': 2, 'expert_0': 86.11063271870712, 'expert_1': 94.11727797145893, 'expert_0_coverage': 36, 'expert_1_coverage': 51}\n",
      "Losses\n",
      "2.4748514890670776\n",
      "6.578839302062988\n",
      "Early Exiting Training.\n",
      "Evaluate on Test Data\n",
      "{'coverage': '44 out of84', 'system_accuracy': 76.19047619047619, 'expert_accuracy': 79.999600002, 'classifier_accuracy': 72.72710743839218, 'alone_classifier': 71.42857142857143, 'validation_loss': 9.445465087890625, 'n_experts': 2, 'expert_0': 91.66513891435143, 'expert_1': 74.9994642895408, 'expert_0_coverage': 12, 'expert_1_coverage': 28}\n",
      "Test on all Data\n",
      "{'coverage': '401 out of852', 'system_accuracy': 92.95774647887323, 'expert_accuracy': 91.13077998635033, 'classifier_accuracy': 95.01244513405359, 'alone_classifier': 93.30985915492958, 'validation_loss': 6.866114412035261, 'n_experts': 2, 'expert_0': 93.71417861236729, 'expert_1': 89.49268877341393, 'expert_0_coverage': 175, 'expert_1_coverage': 276}\n",
      "Team Performance Optimization with Our Approach\n",
      "load Resnet-18 pretrained on ImageNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:06<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "--- 2966.490520477295 seconds ---\n",
      "\n",
      " #####################################################################################\n",
      "\n",
      " \n",
      " \n",
      " NEW RUN \n",
      "\n",
      "Initial size: 32\n",
      "Batch size: 4\n",
      "Max rounds: 8\n",
      "Labeled: 64\n",
      "Cost: (0, 0)\n",
      "Setting: SSL_AL\n",
      "Mod: disagreement\n",
      "Overlap: 100\n",
      "Prediction Type target\n",
      "Sample equal True\n",
      "Seed: 1\n",
      "/n\n",
      "Seed: 1 - Fold: 0 \n",
      "\n",
      "Train dir: /home/joli/Masterarbeit/SSL_Working/NIH/emb_net@dataset-nih-model-resnet50-num_classes-2/\n",
      "load Resnet-50 checkpoint\n",
      "load Resnet-50 pretrained on ImageNet\n",
      "Loaded Model resnet50\n",
      "24\n",
      "No Checkpoint found\n",
      "Starting new from epoch 1\n",
      "ii 12 Epoch 1: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.4702517162471396 \n",
      "Test-Acc-Class [0.56387665 0.36904762]\n",
      "loss: 0.7056556344032288\n",
      "ii 12 Epoch 2: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.5263157894736842 \n",
      "Test-Acc-Class [0.85462555 0.17142857]\n",
      "loss: 0.6859255433082581\n",
      "ii 12 Epoch 3: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.5606407322654462 \n",
      "Test-Acc-Class [0.88546256 0.20952381]\n",
      "loss: 0.6900503635406494\n",
      "ii 12 Epoch 4: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.6384439359267735 \n",
      "Test-Acc-Class [0.84801762 0.41190476]\n",
      "loss: 0.6501054763793945\n",
      "ii 12 Epoch 5: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7116704805491991 \n",
      "Test-Acc-Class [0.82599119 0.58809524]\n",
      "loss: 0.6427245736122131\n",
      "ii 12 Epoch 6: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7196796338672768 \n",
      "Test-Acc-Class [0.80396476 0.62857143]\n",
      "loss: 0.6449323296546936\n",
      "ii 12 Epoch 7: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7013729977116705 \n",
      "Test-Acc-Class [0.78854626 0.60714286]\n",
      "loss: 0.666113555431366\n",
      "ii 12 Epoch 8: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7231121281464531 \n",
      "Test-Acc-Class [0.77973568 0.66190476]\n",
      "loss: 0.6774292588233948\n",
      "ii 12 Epoch 9: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7242562929061785 \n",
      "Test-Acc-Class [0.78193833 0.66190476]\n",
      "loss: 0.6624569892883301\n",
      "ii 12 Epoch 10: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7322654462242563 \n",
      "Test-Acc-Class [0.78414097 0.67619048]\n",
      "loss: 0.6927701234817505\n",
      "ii 12 Epoch 11: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7299771167048055 \n",
      "Test-Acc-Class [0.78414097 0.67142857]\n",
      "loss: 0.6062321662902832\n",
      "ii 12 Epoch 12: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7311212814645309 \n",
      "Test-Acc-Class [0.78193833 0.67619048]\n",
      "loss: 0.6267597079277039\n",
      "ii 12 Epoch 13: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7254004576659039 \n",
      "Test-Acc-Class [0.78634361 0.65952381]\n",
      "loss: 0.640286922454834\n",
      "ii 12 Epoch 14: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7242562929061785 \n",
      "Test-Acc-Class [0.79735683 0.6452381 ]\n",
      "loss: 0.6332880258560181\n",
      "ii 12 Epoch 15: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7311212814645309 \n",
      "Test-Acc-Class [0.79515419 0.66190476]\n",
      "loss: 0.6197225451469421\n",
      "ii 12 Epoch 16: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7299771167048055 \n",
      "Test-Acc-Class [0.77753304 0.67857143]\n",
      "loss: 0.644632875919342\n",
      "ii 12 Epoch 17: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7288329519450801 \n",
      "Test-Acc-Class [0.78854626 0.66428571]\n",
      "loss: 0.6677805781364441\n",
      "ii 12 Epoch 18: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7196796338672768 \n",
      "Test-Acc-Class [0.78854626 0.6452381 ]\n",
      "loss: 0.6649537086486816\n",
      "ii 12 Epoch 19: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7219679633867276 \n",
      "Test-Acc-Class [0.79955947 0.63809524]\n",
      "loss: 0.6518421173095703\n",
      "ii 12 Epoch 20: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7322654462242563 \n",
      "Test-Acc-Class [0.79295154 0.66666667]\n",
      "loss: 0.6416760087013245\n",
      "ii 12 Epoch 21: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7299771167048055 \n",
      "Test-Acc-Class [0.78414097 0.67142857]\n",
      "loss: 0.6368195414543152\n",
      "ii 12 Epoch 22: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7242562929061785 \n",
      "Test-Acc-Class [0.78854626 0.6547619 ]\n",
      "loss: 0.6440211534500122\n",
      "ii 12 Epoch 23: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7368421052631579 \n",
      "Test-Acc-Class [0.79515419 0.67380952]\n",
      "loss: 0.6094905734062195\n",
      "ii 12 Epoch 24: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7265446224256293 \n",
      "Test-Acc-Class [0.79295154 0.6547619 ]\n",
      "loss: 0.662905216217041\n",
      "ii 12 Epoch 25: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7311212814645309 \n",
      "Test-Acc-Class [0.78854626 0.66904762]\n",
      "loss: 0.6513336896896362\n",
      "ii 12 Epoch 26: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7276887871853547 \n",
      "Test-Acc-Class [0.78414097 0.66666667]\n",
      "loss: 0.6347949504852295\n",
      "ii 12 Epoch 27: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7334096109839817 \n",
      "Test-Acc-Class [0.78634361 0.67619048]\n",
      "loss: 0.6072696447372437\n",
      "ii 12 Epoch 28: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7322654462242563 \n",
      "Test-Acc-Class [0.78193833 0.67857143]\n",
      "loss: 0.6074658036231995\n",
      "ii 12 Epoch 29: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7299771167048055 \n",
      "Test-Acc-Class [0.78634361 0.66904762]\n",
      "loss: 0.6485159993171692\n",
      "ii 12 Epoch 30: |█████████████████████-------------------| 54.2% Complete\n",
      "Test-Accuracy: 0.7299771167048055 \n",
      "Test-Acc-Class [0.79955947 0.6547619 ]\n",
      "loss: 0.6535350680351257\n",
      "Test-Accuracy: 0.7299771167048055 \n",
      "Test-Acc-Class [0.79955947 0.6547619 ]\n",
      "NIH\n",
      "2023-07-17 12:09:53,345 - INFO - train -   {'dataset': 'NIH', 'wresnet_k': 2, 'wresnet_n': 28, 'n_classes': 2, 'mu': 7, 'eval_ema': True, 'ema_m': 0.999, 'lam_u': 1.0, 'lr': 0.03, 'weight_decay': 0.0005, 'momentum': 0.9, 'temperature': 0.2, 'low_dim': 64, 'lam_c': 1, 'contrast_th': 0.8, 'thr': 0.95, 'alpha': 0.9, 'queue_batch': 5, 'exp_dir': 'EmbeddingCM_bin', 'labelerId': 4323195249, 'ex_strength': 4323195249, 'n_labeled': None, 'seed': 1, 'n_epoches': 5, 'batchsize': 16, 'n_imgs_per_epoch': 4381, 'type': '50'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/Masterarbeit/expert.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.predictions[\"Image ID\"] = self.predictions[\"Image ID\"].astype('category').copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load Resnet-50 checkpoint\n",
      "None\n",
      "Loaded Model resnet50\n",
      "2023-07-17 12:09:53,994 - INFO - train -   Total params: 4.33M\n",
      "Index: 0\n",
      "Labels: 32\n",
      "Index: 0\n",
      "Index: 0\n",
      "No Checkpoint found at SSL_Working/NIH/EmbeddingCM_bin/ex4323195249_xNone_seed1/ckp.latest\n",
      "Starting new from epoch 1\n",
      "2023-07-17 12:09:54,604 - INFO - train -   -----------start training--------------\n",
      "2023-07-17 12:10:21,202 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 64. loss_u: 0.188. loss_x: 0.189. loss_c: 4.551. n_correct_u: 25.09/60.78. Mask:0.543. num_pos: 40.4. LR: 0.030. Time: 26.60\n",
      "2023-07-17 12:10:45,672 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 128. loss_u: 0.152. loss_x: 0.101. loss_c: 4.472. n_correct_u: 26.20/61.60. Mask:0.550. num_pos: 38.8. LR: 0.030. Time: 24.47\n",
      "2023-07-17 12:11:10,197 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 192. loss_u: 0.134. loss_x: 0.070. loss_c: 4.415. n_correct_u: 27.22/63.10. Mask:0.563. num_pos: 38.2. LR: 0.029. Time: 24.52\n",
      "2023-07-17 12:11:34,866 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 256. loss_u: 0.125. loss_x: 0.054. loss_c: 4.380. n_correct_u: 28.21/64.68. Mask:0.577. num_pos: 38.3. LR: 0.029. Time: 24.67\n",
      "2023-07-17 12:11:42,797 - INFO - train -   Epoch 0. Acc: 39.6984. Ema-Acc: 39.2520. best_acc: 39.6984 in epoch0\n",
      "2023-07-17 12:12:09,774 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:1, iter: 64. loss_u: 0.093. loss_x: 0.006. loss_c: 4.244. n_correct_u: 30.94/69.98. Mask:0.625. num_pos: 38.6. LR: 0.028. Time: 26.89\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexpert_metrics_all = run_experiment(param)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2414\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2412\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2413\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2414\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2417\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/IPython/core/magics/execution.py:298\u001b[0m, in \u001b[0;36mExecutionMagics.prun\u001b[0;34m(self, parameter_s, cell)\u001b[0m\n\u001b[1;32m    296\u001b[0m     arg_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m cell\n\u001b[1;32m    297\u001b[0m arg_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mtransform_cell(arg_str)\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_with_profiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_ns\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/IPython/core/magics/execution.py:320\u001b[0m, in \u001b[0;36mExecutionMagics._run_with_profiler\u001b[0;34m(self, code, opts, namespace)\u001b[0m\n\u001b[1;32m    318\u001b[0m prof \u001b[38;5;241m=\u001b[39m profile\u001b[38;5;241m.\u001b[39mProfile()\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     prof \u001b[38;5;241m=\u001b[39m \u001b[43mprof\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     sys_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m:\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/cProfile.py:100\u001b[0m, in \u001b[0;36mProfile.runctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable()\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "Cell \u001b[0;32mIn[15], line 109\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(param)\u001b[0m\n\u001b[1;32m    105\u001b[0m metrics_save[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_equal\n\u001b[1;32m    108\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 109\u001b[0m expert_metrics, verma_metrics, hemmer_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mone_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataManager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                                                                                                                                                     \u001b[49m\u001b[43mrun_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n\u001b[1;32m    113\u001b[0m metrics_save[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpert metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m expert_metrics\n",
      "Cell \u001b[0;32mIn[14], line 37\u001b[0m, in \u001b[0;36mone_run\u001b[0;34m(dataManager, run_param)\u001b[0m\n\u001b[1;32m     34\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     35\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m---> 37\u001b[0m experts, expert_metric \u001b[38;5;241m=\u001b[39m \u001b[43mgetExperts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataManager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m expert_metrics[seed][fold_idx] \u001b[38;5;241m=\u001b[39m expert_metric\n\u001b[1;32m     40\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m, in \u001b[0;36mgetExperts\u001b[0;34m(dataManager, param, seed, fold)\u001b[0m\n\u001b[1;32m      7\u001b[0m     experts, metrics \u001b[38;5;241m=\u001b[39m getExpertsSSL(dataManager, param, fold, seed)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m param[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSETTING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSL_AL\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 9\u001b[0m     experts, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mgetExpertsSSL_AL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataManager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m param[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSETTING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNORMAL\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     11\u001b[0m     experts, f1_experts, ac_b, metrics \u001b[38;5;241m=\u001b[39m getExpertsNormal(dataManager, param, fold, seed)\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mgetExpertsSSL_AL\u001b[0;34m(dataManager, param, fold, seed)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m labelerId \u001b[38;5;129;01min\u001b[39;00m param[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLABELER_IDS\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     17\u001b[0m     nih_expert \u001b[38;5;241m=\u001b[39m expert_module\u001b[38;5;241m.\u001b[39mExpert(dataset \u001b[38;5;241m=\u001b[39m dataManager\u001b[38;5;241m.\u001b[39mgetBasicDataset(), labeler_id\u001b[38;5;241m=\u001b[39mlabelerId)\n\u001b[0;32m---> 18\u001b[0m     emb_model, model \u001b[38;5;241m=\u001b[39m \u001b[43mssl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetExpertModelSSL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabelerId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabelerId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msslDataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msslDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_labeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneptune_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNEPTUNE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     nih_expert\u001b[38;5;241m.\u001b[39msetModel(expert_module\u001b[38;5;241m.\u001b[39mSSLModel(emb_model, model), mod\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     experts[labelerId] \u001b[38;5;241m=\u001b[39m nih_expert\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/ssl_functions.py:495\u001b[0m, in \u001b[0;36mgetExpertModelSSL\u001b[0;34m(labelerId, sslDataset, seed, fold_idx, n_labeled, embedded_model, param, neptune_param)\u001b[0m\n\u001b[1;32m    491\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-----------start training--------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_epoches\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    494\u001b[0m     loss_x, loss_u, loss_c, mask_mean, num_pos, guess_label_acc, queue_feats, queue_probs, queue_ptr, prob_list \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue_feats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43mqueue_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mqueue_ptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     top1, ema_top1 \u001b[38;5;241m=\u001b[39m evaluate(model, ema_model, emb_model, dlval)\n\u001b[1;32m    500\u001b[0m     tb_logger\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_x\u001b[39m\u001b[38;5;124m'\u001b[39m, loss_x, epoch)\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/ssl_functions.py:202\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, ema_model, emb_model, prob_list, criteria_x, optim, lr_schdlr, dltrain_x, dltrain_u, args, n_iters, logger, queue_feats, queue_probs, queue_ptr)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iters):\n\u001b[1;32m    201\u001b[0m     ims_x_weak, lbs_x, im_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dl_x)\n\u001b[0;32m--> 202\u001b[0m     (ims_u_weak, ims_u_strong0, ims_u_strong1), lbs_u_real, im_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdl_u\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     lbs_x \u001b[38;5;241m=\u001b[39m lbs_x\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor) \n\u001b[1;32m    205\u001b[0m     lbs_x \u001b[38;5;241m=\u001b[39m lbs_x\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:307\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[0;32m--> 307\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m         storage \u001b[38;5;241m=\u001b[39m storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction\u001b[38;5;241m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/multiprocessing/resource_sharer.py:86\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m     85\u001b[0m address, key \u001b[38;5;241m=\u001b[39m ident\n\u001b[0;32m---> 86\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m c\u001b[38;5;241m.\u001b[39msend((key, os\u001b[38;5;241m.\u001b[39mgetpid()))\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/multiprocessing/connection.py:508\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthkey should be a byte string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     \u001b[43manswer_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m     deliver_challenge(c, authkey)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/multiprocessing/connection.py:752\u001b[0m, in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(authkey, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    751\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthkey must be bytes, not \u001b[39m\u001b[38;5;132;01m{0!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(authkey)))\n\u001b[0;32m--> 752\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m message[:\u001b[38;5;28mlen\u001b[39m(CHALLENGE)] \u001b[38;5;241m==\u001b[39m CHALLENGE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage = \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m message\n\u001b[1;32m    754\u001b[0m message \u001b[38;5;241m=\u001b[39m message[\u001b[38;5;28mlen\u001b[39m(CHALLENGE):]\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%prun expert_metrics_all = run_experiment(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0d2ca-19c3-4bef-85fc-f175691af911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joli-env_kernel",
   "language": "python",
   "name": "joli-env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
