{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c923862-4c78-46d2-87e8-a617e07c32d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/joli/joli-env/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "2023-10-25 06:37:55.386755: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import sklearn\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "#import Verma.experts as vexp\n",
    "import Verma.losses as vlos\n",
    "from Verma.utils import AverageMeter, accuracy\n",
    "import Verma.resnet50 as vres\n",
    "from AL.utils import *\n",
    "from AL.metrics import *\n",
    "\n",
    "import Dataset.Dataset as ds\n",
    "\n",
    "import ssl_functions as ssl\n",
    "import active_learning as al\n",
    "from active_learning import NIHExpertDatasetMemory\n",
    "\n",
    "import expert as expert_module\n",
    "import verma as verm\n",
    "import hemmer as hm\n",
    "\n",
    "import neptune\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "#sys.path.append('..')\n",
    "\n",
    "#import Dataset.dataset_classes as ds\n",
    "import Dataset.cifar10_dataset as cif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9104208e-aaa1-40e2-b3c6-1058f92fd31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed, fold=None, text=None):\n",
    "    if fold is not None and text is not None:\n",
    "        s = text + f\" + {seed} + {fold}\"\n",
    "        seed = int(hashlib.sha256(s.encode('utf-8')).hexdigest(), 16) % 10**8\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e071303-6599-454d-a430-c2b39165f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "import json\n",
    "\n",
    "with open('neptune_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config_neptune = config[\"neptune\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc80118e-ff9d-491c-b393-94569d4e4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def cleanTrainDir(path):\n",
    "    shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6272b79-d261-46c6-bc8e-d5b6fa8dc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertModelSSL_AL(dataManager, expert, labelerId, param=None, seed=None, fold=None, learning_mod=\"ssl\", prediction_type=\"target\"):\n",
    "\n",
    "    if param[\"SETTING\"] == \"SSL_AL_SSL\":\n",
    "        learning_type = \"ssl\"\n",
    "    elif param[\"SETTING\"] == \"SSL_AL\":\n",
    "        learning_type = \"sl\"\n",
    "\n",
    "    assert learning_type != \"\", \"Need to define how experts should be trained with new AL data (sl or ssl)\"\n",
    "    \n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "\n",
    "    if param[\"DATASET\"] == \"NIH\":\n",
    "        train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"CIFAR10N\":\n",
    "        train_dataset = cif.CIFAR10NDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        val_dataset = cif.CIFAR10NDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = cif.CIFAR10NDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"VIN\":\n",
    "        train_dataset = vin.VINDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        val_dataset = vin.VINDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = vin.VINDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "    usedFilenames = sslDataset.getLabeledFilenames(labelerId, fold)\n",
    "    \n",
    "    # initialize data, Erhält alle Indizes der Daten\n",
    "    all_indices = list(range(len(train_dataset.getAllIndices())))\n",
    "    all_data_filenames = np.array(train_dataset.getAllFilenames())[all_indices]\n",
    "    all_data_y = np.array(train_dataset.getAllTargets())[all_indices]\n",
    "\n",
    "    used_indices = [index for index in all_indices if all_data_filenames[index] in usedFilenames]\n",
    "    indices = used_indices\n",
    "\n",
    "    print(\"Len overlapping used indices: \" + str(len(used_indices)))\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "    metrics[\"Val\"] = {\n",
    "        \"Start\": met,\n",
    "    }\n",
    "\n",
    "    met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "    metrics[\"Test\"] = {\n",
    "        \"Start\": met,\n",
    "    }\n",
    "\n",
    "    metrics[\"Train\"] = {}\n",
    "\n",
    "    set_seed(seed, fold, text=\"\")\n",
    "    \n",
    "    Intial_random_set = indices\n",
    "    indices_labeled  = Intial_random_set\n",
    "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "    # Lädt die Datasets für die beschrifteten und unbeschrifteten Daten\n",
    "    dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], None , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataset_val_unlabeled = NIHExpertDatasetMemory(None, val_dataset.getAllFilenames(), np.array(val_dataset.getAllTargets()), expert.predict , [1]*len(val_dataset.getAllIndices()), val_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    \n",
    "    # Lädt die Dataloaders\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    dataLoaderValUnlabeled = DataLoader(dataset=dataset_val_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    \n",
    "    for round in range(param[\"AL\"][\"ROUNDS\"]):\n",
    "\n",
    "        print(f'\\n \\n Round {round} \\n \\n')\n",
    "\n",
    "        # get points where expert model is least confident on\n",
    "        indices_confidence = al.get_least_confident_points(expert, dataLoaderTrainUnlabeled, param[\"AL\"][\"LABELS_PER_ROUND\"], mod=\"ssl\")\n",
    "        indices_labeled  = indices_labeled + list(indices_confidence) \n",
    "        indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "        dataset_train_labeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_labeled], all_data_y[indices_labeled], expert.predict , [1]*len(indices_labeled), indices_labeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "        dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "\n",
    "        dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "\n",
    "        if learning_type == \"ssl\": #If the experts should be trained with ssl\n",
    "            sslDataset = dataManager.getSSLDataset(seed)\n",
    "            sslDataset.addNewLabels(all_data_filenames[list(indices_confidence)], fold, expert.labelerId)\n",
    "            emb_model, model = ssl.getExpertModelSSL(labelerId=expert.labelerId, sslDataset=sslDataset, seed=seed, fold_idx=fold, n_labeled=None, embedded_model=None, param=param, neptune_param=param[\"NEPTUNE\"], added_epochs=(round+1)*param[\"AL\"][\"SSL_EPOCHS\"])\n",
    "            expert.setModel(expert_module.SSLModel(emb_model, model), mod=\"SSL\")\n",
    "\n",
    "\n",
    "            #TODO: Test experts and get metrics\n",
    "            n_images = param[\"AL\"][\"INITIAL_SIZE\"] + (round+1)*param[\"AL\"][\"LABELS_PER_ROUND\"]\n",
    "\n",
    "            train_metrics = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderTrainLabeled, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, step=\"Train\", param=param, mod=\"ssl\", prediction_type=\"target\", print_result=False)\n",
    "            val_metrics = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderValUnlabeled, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, step=\"Val\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "\n",
    "            metrics[\"Train\"][n_images] = {\n",
    "                \"train_metrics\": train_metrics,\n",
    "                \"val_metrics\": val_metrics,\n",
    "            }\n",
    "\n",
    "        elif learning_type == \"sl\": #supervised learning\n",
    "        \n",
    "            # train model on labeled data\n",
    "            dataloaders = (dataLoaderTrainLabeled, dataLoaderValUnlabeled)\n",
    "            n_images = param[\"AL\"][\"INITIAL_SIZE\"] + (round+1)*param[\"AL\"][\"LABELS_PER_ROUND\"]\n",
    "            train_metrics, val_metrics = al.run_expert(model=None, expert=expert, epochs=param[\"AL\"][\"EPOCH_TRAIN\"], dataloaders=dataloaders, param=param, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, mod=\"ssl\", prediction_type=\"target\")\n",
    "        \n",
    "            metrics[\"Train\"][n_images] = {\n",
    "                \"train_metrics\": train_metrics,\n",
    "                \"val_metrics\": val_metrics,\n",
    "            }\n",
    "    \n",
    "    dataset_test_unlabeled = NIHExpertDatasetMemory(None, test_dataset.getAllFilenames(), np.array(test_dataset.getAllTargets()), expert.predict , [1]*len(test_dataset.getAllIndices()), test_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataLoaderVal = DataLoader(dataset=dataset_test_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    met_test = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderVal, id=expert.labelerId, seed=seed, fold=fold, n_images=param[\"AL\"][\"INITIAL_SIZE\"] + param[\"AL\"][\"ROUNDS\"]*param[\"AL\"][\"LABELS_PER_ROUND\"], step=\"Test\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "\n",
    "    met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "    metrics[\"Val\"][\"End\"] = met\n",
    "\n",
    "    met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "    metrics[\"Test\"][\"End\"] = met\n",
    "    \n",
    "    #metrics[\"Test\"] = met\n",
    "    print(\"AL finished\")\n",
    "    return met_test, metrics, all_data_filenames[indices_labeled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc438de-b6b0-463c-95ae-c62afdbbc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertModelsSSL_AL(dataManager, experts, param, seed, fold, learning_mod=\"ssl\", prediction_type=\"target\"):\n",
    "\n",
    "    if param[\"SETTING\"] == \"SSL_AL_SSL\":\n",
    "        learning_type = \"ssl\"\n",
    "    elif param[\"SETTING\"] == \"SSL_AL\":\n",
    "        learning_type = \"sl\"\n",
    "\n",
    "    assert learning_type != \"\", \"Need to define how experts should be trained with new AL data (sl or ssl)\"\n",
    "\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "    if param[\"DATASET\"] == \"NIH\":\n",
    "        train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"CIFAR10N\":\n",
    "        train_dataset = cif.CIFAR10NDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        val_dataset = cif.CIFAR10NDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = cif.CIFAR10NDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"VIN\":\n",
    "        train_dataset = vin.VINDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        val_dataset = vin.VINDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = vin.VINDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "    usedFilenames = []\n",
    "    for labelerId in param[\"LABELER_IDS\"]:\n",
    "        temp = usedFilenames + sslDataset.getLabeledFilenames(labelerId, fold)\n",
    "    usedFilenames = temp\n",
    "    \n",
    "    \n",
    "    # initialize data, Erhält alle Indizes der Daten\n",
    "    all_indices = list(range(len(train_dataset.getAllIndices())))\n",
    "    all_data_filenames = np.array(train_dataset.getAllFilenames())[all_indices]\n",
    "    all_data_y = np.array(train_dataset.getAllTargets())[all_indices]\n",
    "\n",
    "    unused_indices = [index for index in all_indices if all_data_filenames[index] not in usedFilenames]\n",
    "    \n",
    "    metrics = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        metrics[labelerId] = {}\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"] = {\n",
    "            \"Start\": met,\n",
    "        }\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"] = {\n",
    "            \"Start\": met,\n",
    "        }\n",
    "\n",
    "        metrics[labelerId][\"Train\"] = {}\n",
    "\n",
    "    set_seed(seed, fold, text=\"\")\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    indices_unlabeled = unused_indices\n",
    "    indices_labeled = list(set(all_indices) - set(indices_unlabeled))\n",
    "\n",
    "    dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], experts[param[\"LABELER_IDS\"][0]].predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    \n",
    "    for round in range(param[\"AL\"][\"ROUNDS\"]):\n",
    "\n",
    "        print(f'\\n \\n Round {round} \\n \\n')\n",
    "\n",
    "        #Try to get better Points\n",
    "        if param[\"MOD\"] == \"disagreement\":\n",
    "            indices_qbq = al.getQbQPoints(experts, dataLoaderTrainUnlabeled, param[\"AL\"][\"LABELS_PER_ROUND\"], mod=\"ssl\", param=param)\n",
    "        if param[\"MOD\"] == \"disagreement_diff\":\n",
    "            indices_qbq = al.getQbQPointsDifference(experts, dataLoaderTrainUnlabeled, param[\"AL\"][\"LABELS_PER_ROUND\"], mod=\"ssl\", param=param)\n",
    "        \n",
    "        #indices_labeled  = indices_labeled + list(indices_confidence) \n",
    "        indices_labeled  = indices_labeled + list(indices_qbq) \n",
    "        indices_unlabeled= list(set(all_indices) - set(indices_labeled))     \n",
    "        \n",
    "        # train model on labeled data\n",
    "        for labelerId, expert in experts.items():\n",
    "\n",
    "            #Val Dataset, needed for SSL and AL\n",
    "            dataset_val_unlabeled = NIHExpertDatasetMemory(None, val_dataset.getAllFilenames(), np.array(val_dataset.getAllTargets()), expert.predict , [1]*len(val_dataset.getAllIndices()), val_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "            dataLoaderValUnlabeled = DataLoader(dataset=dataset_val_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "\n",
    "            #Create train dataset\n",
    "            dataset_train_labeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_labeled], all_data_y[indices_labeled], expert.predict , [1]*len(indices_labeled), indices_labeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "            dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "\n",
    "            if learning_type == \"ssl\": #If the experts should be trained with ssl\n",
    "                sslDataset = dataManager.getSSLDataset(seed)\n",
    "                sslDataset.addNewLabels(all_data_filenames[list(indices_qbq)], fold, labelerId)\n",
    "                emb_model, model = ssl.getExpertModelSSL(labelerId=labelerId, sslDataset=sslDataset, seed=seed, fold_idx=fold, n_labeled=None, embedded_model=None, param=param, neptune_param=param[\"NEPTUNE\"], added_epochs=(round+1)*param[\"AL\"][\"SSL_EPOCHS\"])\n",
    "                experts[labelerId].setModel(expert_module.SSLModel(emb_model, model), mod=\"SSL\")\n",
    "\n",
    "\n",
    "                #TODO: Test experts and get metrics\n",
    "                n_images = param[\"AL\"][\"INITIAL_SIZE\"] + (round+1)*param[\"AL\"][\"LABELS_PER_ROUND\"]\n",
    "\n",
    "                train_metrics = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderTrainLabeled, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, step=\"Train\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "                val_metrics = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderValUnlabeled, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, step=\"Val\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "\n",
    "                metrics[labelerId][\"Train\"][n_images] = {\n",
    "                    \"train_metrics\": train_metrics,\n",
    "                    \"val_metrics\": val_metrics,\n",
    "                }\n",
    "\n",
    "                \n",
    "            elif learning_type == \"sl\": # If the experts sould be trained with supervised learning\n",
    "\n",
    "                dataloaders = (dataLoaderTrainLabeled, dataLoaderValUnlabeled)\n",
    "                n_images = param[\"AL\"][\"INITIAL_SIZE\"] + (round+1)*param[\"AL\"][\"LABELS_PER_ROUND\"]\n",
    "                train_metrics, val_metrics = al.run_expert(model=None, expert=expert, epochs=param[\"AL\"][\"EPOCH_TRAIN\"], dataloaders=dataloaders, param=param, id=expert.labelerId, seed=seed, fold=fold, n_images=n_images, mod=\"ssl\", prediction_type=\"target\")\n",
    "\n",
    "                metrics[labelerId][\"Train\"][n_images] = {\n",
    "                    \"train_metrics\": train_metrics,\n",
    "                    \"val_metrics\": val_metrics\n",
    "                }\n",
    "        \n",
    "        dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    \n",
    "    dataset_test_unlabeled = NIHExpertDatasetMemory(None, test_dataset.getAllFilenames(), np.array(test_dataset.getAllTargets()), expert.predict , [1]*len(test_dataset.getAllIndices()), test_dataset.getAllIndices(), param=param, preload=param[\"AL\"][\"PRELOAD\"], image_container=image_container)\n",
    "    dataLoaderVal = DataLoader(dataset=dataset_test_unlabeled, batch_size=param[\"AL\"][\"BATCH_SIZE\"], shuffle=True, num_workers=param[\"num_worker\"], pin_memory=True)\n",
    "    met_test = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        temp = al.metrics_print_expert(model=None, expert=expert, data_loader=dataLoaderVal, id=expert.labelerId, seed=seed, fold=fold, n_images=param[\"AL\"][\"INITIAL_SIZE\"] + param[\"AL\"][\"ROUNDS\"]*param[\"AL\"][\"LABELS_PER_ROUND\"], step=\"Test\", param=param, mod=\"ssl\", prediction_type=\"target\")\n",
    "        met_test[expert.labelerId] = temp\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"][\"End\"] = met\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, learning_mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"][\"End\"] = met\n",
    "        \n",
    "    return met_test, metrics, all_data_filenames[indices_labeled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be36f3a5-859c-4d0a-956c-8ec5b8f57383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsSSL_AL(dataManager, param, fold, seed):\n",
    "\n",
    "    mod = \"ssl\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    sslDataset.createLabeledIndices(labelerIds=param[\"LABELER_IDS\"], n_L=param[\"AL\"][\"INITIAL_SIZE\"], k=round(param[\"AL\"][\"INITIAL_SIZE\"]*param[\"OVERLAP\"]/100), seed=seed, sample_equal=param[\"SAMPLE_EQUAL\"])\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = sslDataset.get_data_loader_for_fold(fold)\n",
    "    dataloaders = (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "    embedded_model = ssl.create_embedded_model(dataloaders, param, param[\"NEPTUNE\"], fold=fold, seed=seed)\n",
    "\n",
    "    indices = {}\n",
    "    experts = {}\n",
    "    for labelerId in param[\"LABELER_IDS\"]:\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId, modus=\"ssl_al\")\n",
    "        emb_model, model = ssl.getExpertModelSSL(labelerId=labelerId, sslDataset=sslDataset, seed=seed, fold_idx=fold, n_labeled=None, embedded_model=embedded_model, param=param, neptune_param=param[\"NEPTUNE\"])\n",
    "        nih_expert.setModel(expert_module.SSLModel(emb_model, model), mod=\"SSL\")\n",
    "        experts[labelerId] = nih_expert\n",
    "        indices[labelerId] = sslDataset.getLabeledFilenames(labelerId, fold)\n",
    "    metrics = {}\n",
    "    indices_labeled = {}\n",
    "    if param[\"MOD\"] == \"confidence\":\n",
    "        for i, labelerId in enumerate(param[\"LABELER_IDS\"]):\n",
    "            met, metrics_return, labeled = getExpertModelSSL_AL(dataManager=dataManager, expert=experts[labelerId], labelerId=labelerId, param=param, seed=seed, fold=fold, learning_mod=\"ssl\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "            metrics[labelerId] = metrics_return\n",
    "            indices_labeled[labelerId] = labeled\n",
    "    elif param[\"MOD\"] == \"disagreement\" or param[\"MOD\"] == \"disagreement_diff\":\n",
    "        met, metrics, indices_labeled = getExpertModelsSSL_AL(dataManager, experts, param, seed, fold, learning_mod=\"ssl\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "        \n",
    "    return experts, metrics, {\"starting labels\": indices, \"al labels\": indices_labeled}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff5079e-b28c-42c8-a5e0-379f31fdd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsSSL(dataManager, param, fold, seed):\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    mod = \"ssl\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    sslDataset.createLabeledIndices(labelerIds=param[\"LABELER_IDS\"], n_L=param[\"LABELED\"], k=round(param[\"LABELED\"]*param[\"OVERLAP\"]/100), seed=seed, sample_equal=param[\"SAMPLE_EQUAL\"])\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = sslDataset.get_data_loader_for_fold(fold)\n",
    "    dataloaders = (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "    ssl.create_embedded_model(dataloaders, param, param[\"NEPTUNE\"], fold=fold, seed=seed)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    indices = {}\n",
    "\n",
    "    experts = {}\n",
    "    for labelerId in param[\"LABELER_IDS\"]:\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId, modus=\"ssl\")\n",
    "        emb_model, model = ssl.getExpertModelSSL(labelerId=labelerId, sslDataset=sslDataset, seed=seed, fold_idx=fold, n_labeled=None, embedded_model=None, param=param, neptune_param=param[\"NEPTUNE\"])\n",
    "        nih_expert.setModel(expert_module.SSLModel(emb_model, model), mod=\"SSL\")\n",
    "        experts[labelerId] = nih_expert\n",
    "        indices[labelerId] = sslDataset.getLabeledFilenames(labelerId, fold)\n",
    "\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "\n",
    "    if param[\"DATASET\"] == \"NIH\":\n",
    "        val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"CIFAR10N\":\n",
    "        val_dataset = cif.CIFAR10NDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = cif.CIFAR10NDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"VIN\":\n",
    "        val_dataset = vin.VINDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = vin.VINDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    #val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    #test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    metrics = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        metrics[labelerId] = {}\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"] = {\n",
    "            \"End\": met,\n",
    "        }\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"] = {\n",
    "            \"End\": met\n",
    "        }\n",
    "        \n",
    "    return experts, metrics, {\"starting labels\": indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f339e5-b0be-466d-b520-ac2f9680c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupEmbeddedModel(dataManager, param, fold, seed):\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    mod = \"ssl\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    train_dataloader, val_dataloader, test_dataloader = sslDataset.get_data_loader_for_fold(fold)\n",
    "    dataloaders = (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "    ssl.create_embedded_model(dataloaders, param, param[\"NEPTUNE\"], fold=fold, seed=seed)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f63a5829-4507-4ce4-bb06-c99ea126c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsAL(dataManager, param, fold_idx, seed):\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold_idx)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "\n",
    "    if param[\"DATASET\"] == \"NIH\":\n",
    "        expert_train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"CIFAR10N\":\n",
    "        expert_train_dataset = cif.CIFAR10NDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_val_dataset = cif.CIFAR10NDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_test_dataset = cif.CIFAR10NDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"VIN\":\n",
    "        expert_train_dataset = vin.VINDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_val_dataset = vin.VINDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_test_dataset = vin.VINDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    \n",
    "    #expert_train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    #expert_val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    #expert_test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    setupEmbeddedModel(dataManager, param, fold_idx, seed)\n",
    "    #Get init labeled indices with k same images and n-k different images\n",
    "    #k=None means random indieces\n",
    "    k = param[\"OVERLAP\"]\n",
    "    all_indices = list(range(len(expert_train_dataset.getAllIndices())))\n",
    "    #If no k is set than it selects one randomly\n",
    "    k = round(param[\"AL\"][\"INITIAL_SIZE\"]*k/100)\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[\"param/overlap_k\"] = k\n",
    "    indices = al.sampleIndices(n = param[\"AL\"][\"INITIAL_SIZE\"], k = k, all_indices = all_indices, experten = list(param[\"LABELER_IDS\"]), seed = seed, fold=fold_idx)\n",
    "\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[f\"Seed_{seed}/Fold_{fold_idx}/Experts/Indices\"] = indices\n",
    "\n",
    "    print(\"Random indices:\")\n",
    "    print(indices)\n",
    "\n",
    "    labeld_filenames = {}\n",
    "\n",
    "    indeces_al = {}\n",
    "\n",
    "    experts = {}\n",
    "    metrics = {}\n",
    "    for i, labelerId in enumerate(list(param[\"LABELER_IDS\"])):\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId, modus=\"al\")\n",
    "        experts[labelerId] = nih_expert\n",
    "        print(\"DELETE ME\")\n",
    "        print(\"Drawn indices\")\n",
    "        print(indices)\n",
    "        print(f\"Len of all filenames: {len(expert_train_dataset.getAllFilenames())}\")\n",
    "        print(\"All indices\")\n",
    "        print(expert_train_dataset.getAllIndices())\n",
    "        labeld_filenames[labelerId] = np.array(expert_train_dataset.getAllFilenames())[indices[labelerId]]\n",
    "        if param[\"MOD\"] == \"confidence\":\n",
    "            expert_model, met_test, metric, indices_labeled = al.getExpertModel(indices[labelerId], expert_train_dataset, expert_val_dataset, expert_test_dataset, nih_expert, param, seed, fold_idx, image_container=image_container, learning_mod=\"al\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "            nih_expert.setModel(expert_model, mod=\"AL\")\n",
    "            metrics[labelerId] = metric\n",
    "            indeces_al[labelerId] = indices_labeled\n",
    "    if param[\"MOD\"] == \"disagreement\" or param[\"MOD\"]==\"disagreement_diff\":\n",
    "        expert_models, met, metrics, indeces_al = al.getExpertModels(indices, experts, expert_train_dataset, expert_val_dataset, expert_test_dataset, param, seed, fold_idx, mod=param[\"MOD\"], image_container=image_container, learning_mod=\"al\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "        for labelerId, expert in experts.items():\n",
    "            expert.setModel(expert_models[labelerId], mod=\"AL\")\n",
    "\n",
    "    return experts, metrics, {\"starting labels\": labeld_filenames, \"al labels\": indeces_al}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d265f97f-07f8-493d-8de5-aa0d60b99eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsNormal(dataManager, param, fold_idx, seed):\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold_idx)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "\n",
    "    if param[\"DATASET\"] == \"NIH\":\n",
    "        expert_train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"CIFAR10N\":\n",
    "        expert_train_dataset = cif.CIFAR10NDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_val_dataset = cif.CIFAR10NDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_test_dataset = cif.CIFAR10NDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"VIN\":\n",
    "        expert_train_dataset = vin.VINDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_val_dataset = vin.VINDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        expert_test_dataset = vin.VINDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        \n",
    "    #expert_train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    #expert_val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    #expert_test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    setupEmbeddedModel(dataManager, param, fold_idx, seed)\n",
    "    \n",
    "    #Get init labeled indices with k same images and n-k different images\n",
    "    #k=None means random indieces\n",
    "    k = param[\"OVERLAP\"]\n",
    "    all_indices = list(range(len(expert_train_dataset.getAllIndices())))\n",
    "    #If no k is set than it selects one randomly\n",
    "    k = round(param[\"LABELED\"]*k/100)\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[\"param/overlap_k\"] = k\n",
    "    indices = al.sampleIndices(n = param[\"LABELED\"], k = k, all_indices = all_indices, experten = list(param[\"LABELER_IDS\"]), seed = seed, fold=fold_idx)\n",
    "\n",
    "    if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "        run[f\"Seed_{seed}/Fold_{fold_idx}/Experts/Indices\"] = indices\n",
    "\n",
    "    print(\"Random indices:\")\n",
    "    print(indices)\n",
    "\n",
    "    labeled_filenames = {}\n",
    "\n",
    "    experts = {}\n",
    "    #Create the experts\n",
    "    metrics = {}\n",
    "    for i, labelerId in enumerate(list(param[\"LABELER_IDS\"])):\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId, modus=\"normal\")\n",
    "        experts[labelerId] = nih_expert\n",
    "        labeld_filenames[labelerId] = np.array(expert_train_dataset.getAllFilenames())[indices[labelerId]]\n",
    "\n",
    "        model, met, metric = al.getExpertModelNormal(indices[labelerId], expert_train_dataset, expert_val_dataset, expert_test_dataset, nih_expert, param, seed, fold_idx, image_container=image_container, learning_mod=\"al\", prediction_type=param[\"EXPERT_PREDICT\"])\n",
    "        nih_expert.setModel(model, mod=\"AL\")\n",
    "        metrics[labelerId] = metric\n",
    "\n",
    "    return experts, metrics, {\"starting labels\": labeled_filenames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39124366-b8e9-4c8d-89d2-f06a5b698ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertsPerfect(dataManager, param, fold, seed):\n",
    "\n",
    "    experts = {}\n",
    "    for i, labelerId in enumerate(list(param[\"LABELER_IDS\"])):\n",
    "        nih_expert = expert_module.Expert(dataset = dataManager.getBasicDataset(), labeler_id=labelerId, modus=\"perfect\")\n",
    "        experts[labelerId] = nih_expert\n",
    "\n",
    "\n",
    "    sslDataset = dataManager.getSSLDataset(seed)\n",
    "\n",
    "    mod = \"perfect\"\n",
    "    prediction_type = param[\"EXPERT_PREDICT\"]\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    nih_dataloader = dataManager.getKFoldDataloader(seed)\n",
    "    expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold)\n",
    "    image_container = nih_dataloader.get_ImageContainer()\n",
    "\n",
    "    if param[\"DATASET\"] == \"NIH\":\n",
    "        val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"CIFAR10N\":\n",
    "        val_dataset = cif.CIFAR10NDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = cif.CIFAR10NDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    elif param[\"DATASET\"] == \"VIN\":\n",
    "        val_dataset = vin.VINDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        test_dataset = vin.VINDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "        \n",
    "    #val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "    #test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param, image_container=image_container)\n",
    "\n",
    "    metrics = {}\n",
    "    for labelerId, expert in experts.items():\n",
    "        metrics[labelerId] = {}\n",
    "\n",
    "        met = al.testExpert(expert, val_dataset, image_container, param, mod, prediction_type, seed, fold, data_name=\"Val\")\n",
    "        metrics[labelerId][\"Val\"] = {\n",
    "            \"End\": met,\n",
    "        }\n",
    "\n",
    "        met = al.testExpert(expert, test_dataset, image_container, param, mod, prediction_type, seed, fold, data_name=\"Test\")\n",
    "        metrics[labelerId][\"Test\"] = {\n",
    "            \"End\": met\n",
    "        }\n",
    "\n",
    "    return experts, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1de88e94-d4cf-475b-bd7b-8c3f0c2eb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExperts(dataManager, param, seed, fold):\n",
    "      \n",
    "    #Creates expert models for the choosen method\n",
    "    if param[\"SETTING\"] == \"PERFECT\":\n",
    "        experts, metrics = getExpertsPerfect(dataManager, param, fold, seed)\n",
    "    if param[\"SETTING\"] == \"AL\":\n",
    "        experts, metrics, labeled_filenames = getExpertsAL(dataManager, param, fold, seed)\n",
    "    elif param[\"SETTING\"] == \"SSL\":\n",
    "        experts, metrics, labeled_filenames = getExpertsSSL(dataManager, param, fold, seed)\n",
    "    elif param[\"SETTING\"] == \"SSL_AL\" or param[\"SETTING\"] == \"SSL_AL_SSL\":\n",
    "        experts, metrics, labeled_filenames = getExpertsSSL_AL(dataManager, param, fold, seed)\n",
    "    elif param[\"SETTING\"] == \"NORMAL\":\n",
    "        experts, metrics, labeled_filenames = getExpertsNormal(dataManager, param, fold, seed)\n",
    "\n",
    "    return experts, metrics, labeled_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36779aaf-d0a9-4116-8888-d629701db78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2D_Verma(train_loader, val_loader, test_loader, full_dataloader, expert_fns, param, seed, fold_idx, experts):\n",
    "    num_experts = len(expert_fns)\n",
    "            \n",
    "    model = model = vres.ResNet50_defer(int(param[\"n_classes\"]) + num_experts)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Use \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    metrics_train_all, metrics_val_all, metrics_test, metrics_full, metrics_pretrain_all = verm.train(model, train_loader, val_loader, test_loader, expert_fns, param, seed=seed, experts=experts, \n",
    "                                                                                fold=fold_idx, full_dataloader=full_dataloader, param=param)\n",
    "\n",
    "    return metrics_train_all, metrics_val_all, metrics_test, metrics_full, metrics_pretrain_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39c730b2-f947-44cf-95f5-aaf92081a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_run(dataManager, run_param, all_metrics, print_text, run_metrics, count, current_index=None):\n",
    "    \"\"\"\n",
    "    Computes all seed-fold combinations for one parameter combination and saves the metrics into a file\n",
    "    \n",
    "    Param:\n",
    "        dataManager: DataManager for all data\n",
    "        run_param: dict of all relevant parameters for this run\n",
    "        all_metrics: list which contains all already computed results\n",
    "        print_text: output text to print the current paramater combination\n",
    "        run_metrics: core parameters for this run (which vary over different runs)\n",
    "        count: integer to identify the save file (and number of runs)\n",
    "        current_index: index of the current run in all_metrics, if it exists\n",
    "    \"\"\"\n",
    "\n",
    "    #Get device for cuda training\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #To ensure to only print the run text only one time\n",
    "    printed = False\n",
    "\n",
    "    #Metrics for this run\n",
    "    expert_metrics = {}\n",
    "    verma_metrics = {}\n",
    "    hemmer_metrics = {}\n",
    "\n",
    "    #Checks if there is data for this run in the save files\n",
    "    if current_index is not None:\n",
    "        #Load the current metrics\n",
    "        print(f\"Current index: {current_index}\")\n",
    "        current_metric = all_metrics[current_index]\n",
    "\n",
    "        #Save the already computed metrics in the working directories\n",
    "        expert_metrics = current_metric[\"expert metrics\"]\n",
    "        verma_metrics = current_metric[\"verma\"]\n",
    "        hemmer_metrics = current_metric[\"hemmer\"]\n",
    "\n",
    "        if \"artificial expert predictions\" in current_metric.keys():\n",
    "            labeled_dfs = current_metric[\"artificial expert predictions\"]\n",
    "            print(type(labeled_dfs))\n",
    "        else:\n",
    "            print(current_metric.keys())\n",
    "    #If not, create new element in list of all metrics\n",
    "    else:\n",
    "        all_metrics.append(run_metrics)\n",
    "        \n",
    "\n",
    "    #Iterate over all seeds\n",
    "    for seed in run_param[\"SEEDS\"]:\n",
    "\n",
    "        #If this seed is not already in the save file\n",
    "        if seed not in expert_metrics.keys():\n",
    "            print(f\"New seed: {seed}\")\n",
    "            expert_metrics[seed] = {}\n",
    "            verma_metrics[seed] = {}\n",
    "            hemmer_metrics[seed] = {}\n",
    "            labeled_dfs[seed] = {}\n",
    "\n",
    "        #Iterate over the folds\n",
    "        #for fold_idx in range(run_param[\"K\"]):\n",
    "        for fold_idx in range(2):\n",
    "\n",
    "            #Check if the seed-fold combination is already in the save files\n",
    "            if fold_idx in expert_metrics[seed].keys():\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Keys: {expert_metrics[seed].keys()}\")\n",
    "                print(f\"New fold: {fold_idx}\")\n",
    "                metrics_added = True\n",
    "\n",
    "            #Print run text if at least one computation is made for this parameter combination (run)\n",
    "            if not printed:\n",
    "                print(print_text)\n",
    "                printed = True\n",
    "\n",
    "            \n",
    "            if run_param[\"cluster\"]: #Keep the embedded model in cluster training\n",
    "                if os.path.isdir(f'{run_param[\"Parent_PATH\"]}/SSL_Working/{run_param[\"DATASET\"]}/SSL'):\n",
    "                    cleanTrainDir(f'{run_param[\"Parent_PATH\"]}/SSL_Working/{run_param[\"DATASET\"]}/SSL')\n",
    "            else: #delete everything if space is limited\n",
    "                if os.path.isdir(f'{run_param[\"Parent_PATH\"]}/SSL_Working/{run_param[\"DATASET\"]}'):\n",
    "                    cleanTrainDir(f'{run_param[\"Parent_PATH\"]}/SSL_Working/{run_param[\"DATASET\"]}')\n",
    "\n",
    "            if seed != \"\":\n",
    "                set_seed(seed, fold_idx, text=\"\")\n",
    "\n",
    "            print(\"/n\")\n",
    "            print(f\"Seed: {seed} - Fold: {fold_idx} \\n\")\n",
    "\n",
    "            neptune = {\n",
    "                \"SEED\": seed,\n",
    "                \"FOLD\": fold_idx,\n",
    "            }\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            experts, expert_metric, labeled_filenames = getExperts(dataManager, run_param, seed, fold_idx)\n",
    "            expert_metrics[seed][fold_idx] = expert_metric\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            #print(f\"Got {len(experts)} experts\")\n",
    "\n",
    "            nih_dataloader = dataManager.getKFoldDataloader(seed=seed)\n",
    "\n",
    "            train_loader, val_loader, test_loader = nih_dataloader.get_data_loader_for_fold(fold_idx)\n",
    "            full_dataloader = nih_dataloader.getFullDataloader()\n",
    "\n",
    "            expert_fns = []\n",
    "            print(run_param[\"SETTING\"])\n",
    "            for labelerId, expert in experts.items():\n",
    "                if run_param[\"SETTING\"] == \"AL\":\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"AL\", prediction_type=run_param[\"EXPERT_PREDICT\"])\n",
    "                    expert_fns.append(expert.predict_model_predefined_al)\n",
    "                elif run_param[\"SETTING\"] == \"SSL\":\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"SSL\", prediction_type=run_param[\"EXPERT_PREDICT\"])\n",
    "                    expert_fns.append(expert.predict_model_predefined_ssl)\n",
    "                elif (run_param[\"SETTING\"] == \"SSL_AL\" or run_param[\"SETTING\"] == \"SSL_AL_SSL\"):\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"SSL\", prediction_type=run_param[\"EXPERT_PREDICT\"])\n",
    "                    expert_fns.append(expert.predict_model_predefined_ssl)\n",
    "                elif run_param[\"SETTING\"] == \"NORMAL\":\n",
    "                    expert.init_model_predictions(full_dataloader, mod=\"AL\", prediction_type=run_param[\"EXPERT_PREDICT\"])\n",
    "                    expert_fns.append(expert.predict_model_predefined_al)\n",
    "                elif run_param[\"SETTING\"] == \"PERFECT\":\n",
    "                    expert_fns.append(expert.predict)\n",
    "\n",
    "            #print(\"DELETE ME\")\n",
    "            #return experts, dataManager, labeled_filenames\n",
    "\n",
    "            #Block to create df of artificial labels, real predictions and which images were labeled\n",
    "            fullDataset = nih_dataloader.getFullDataloader().dataset\n",
    "            labeled_df = save_expert_labels(fullDataset, experts, labeled_filenames)\n",
    "\n",
    "            labeled_dfs[seed][fold_idx] = labeled_df\n",
    "            \n",
    "\n",
    "            metrics_train_all, metrics_val_all, metrics_test_all, metrics_full_all, metrics_pretrain_all = L2D_Verma(train_loader, val_loader, test_loader, full_dataloader, expert_fns, run_param, seed, fold_idx, experts=experts)\n",
    "\n",
    "            verma_metrics[seed][fold_idx] = {\n",
    "                \"train\": metrics_train_all,\n",
    "                \"val\": metrics_val_all,\n",
    "                \"test\": metrics_test_all,\n",
    "                \"full\": metrics_full_all,\n",
    "                \"pretrain\": metrics_pretrain_all,\n",
    "            }\n",
    "            \n",
    "            system_accuracy, classifier_coverage, all_train_metrics, all_val_metrics, all_test_metrics, all_full_metrics = hm.L2D_Hemmer(train_loader, val_loader, test_loader, full_dataloader, expert_fns, run_param, seed, fold_idx, experts)\n",
    "\n",
    "            hemmer_metrics[seed][fold_idx] = {\n",
    "                \"train\": all_train_metrics,\n",
    "                \"val\": all_val_metrics,\n",
    "                \"test\": all_test_metrics,\n",
    "                \"full\": all_full_metrics,\n",
    "            }\n",
    "\n",
    "            run_metrics[\"artificial expert predictions\"] = labeled_df\n",
    "\n",
    "            run_metrics[\"expert metrics\"] = expert_metrics\n",
    "            run_metrics[\"verma\"] = verma_metrics\n",
    "            run_metrics[\"hemmer\"] = hemmer_metrics\n",
    "\n",
    "            #Write only into new file if a new run was computed\n",
    "            temp_count = count\n",
    "            if current_index is not None:\n",
    "                all_metrics[current_index] = run_metrics\n",
    "                temp_count = count - 1\n",
    "            else:\n",
    "                all_metrics[-1] = run_metrics\n",
    "            with open(f'{run_param[\"Parent_PATH\"]}/Metrics_Folder/{run_param[\"DATASET\"]}/Metrics_{temp_count}.pickle', 'wb') as handle:\n",
    "                pickle.dump(all_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return expert_metrics, verma_metrics, hemmer_metrics, labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20baf936-e327-4025-94e4-9a06d2cbacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(param):\n",
    "    run_param = copy.deepcopy(param)\n",
    "\n",
    "    runs = None\n",
    "\n",
    "    expert_metrics_all = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    list_of_files = glob.glob(f'{param[\"Parent_PATH\"]}/Metrics_Folder/{param[\"DATASET\"]}/*') # * means all if need specific format then *.csv\n",
    "    \n",
    "    if len(list_of_files) >= 1:\n",
    "        latest_file = max(list_of_files, key=os.path.getctime)\n",
    "      \n",
    "        print(f\"Open metrics file: {latest_file}\")\n",
    "\n",
    "        with open(latest_file, 'rb') as handle:\n",
    "            expert_metrics_all = pickle.load(handle)\n",
    "\n",
    "        runs = [{i:run[i] for i in run if i not in [\"expert metrics\", \"verma\", \"hemmer\", \"artificial expert predictions\"]} for run in expert_metrics_all]\n",
    "\n",
    "        print(f\"Len of runs: {len(runs)}\")\n",
    "\n",
    "        if \"pickle\" in latest_file:\n",
    "\n",
    "            count = int(latest_file.split(\"/\")[-1][8:-7]) + 1\n",
    "\n",
    "    #Every pair of labeler ids\n",
    "    for labeler_ids in param[\"LABELER_IDS\"]:\n",
    "        run_param[\"LABELER_IDS\"] = labeler_ids\n",
    "        run_param[\"labeler_ids\"] = convert_ids_to_string(labeler_ids)\n",
    "        \n",
    "\n",
    "        if param[\"DATASET\"] == \"NIH\":\n",
    "            dataManager = ds.DataManager(path=param[\"PATH\"], target=param[\"TARGET\"], param=run_param, seeds=param[\"SEEDS\"])\n",
    "        elif param[\"DATASET\"] == \"CIFAR10N\":\n",
    "            dataManager = cif.CIFAR10NDataManager(path=param[\"PATH\"], path_labels=f'{param[\"PATH\"]}{param[\"DATASET\"]}', path_data=f'{param[\"PATH\"]}/{param[\"DATASET\"]}', param=run_param, seeds=param[\"SEEDS\"])\n",
    "        elif param[\"DATASET\"] == \"VIN\":\n",
    "            dataManager = vin.VINDataManager(path=param[\"PATH\"], target=param[\"TARGET\"], param=run_param, seeds=param[\"SEEDS\"])\n",
    "        dataManager.createData()\n",
    "\n",
    "        run_param[\"DATASET\"] = param[\"DATASET\"]\n",
    "\n",
    "        for init_size in param[\"AL\"][\"INITIAL_SIZE\"]:\n",
    "            run_param[\"AL\"][\"INITIAL_SIZE\"] = init_size\n",
    "\n",
    "            for labels_per_round in param[\"AL\"][\"LABELS_PER_ROUND\"]:\n",
    "                run_param[\"AL\"][\"LABELS_PER_ROUND\"] = labels_per_round\n",
    "\n",
    "                for rounds in param[\"AL\"][\"ROUNDS\"]:\n",
    "                    run_param[\"AL\"][\"ROUNDS\"] = rounds\n",
    "\n",
    "                    labeled = init_size + rounds * labels_per_round\n",
    "\n",
    "                    run_param[\"LABELED\"] = labeled\n",
    "\n",
    "                    if (labeled >= 128): #Prevents from large amount of data\n",
    "                        continue\n",
    "\n",
    "                    for cost in param[\"AL\"][\"COST\"]:\n",
    "                        run_param[\"AL\"][\"COST\"] = cost\n",
    "                        run_param[\"AL\"][\"cost\"] = convert_cost_to_string(cost)\n",
    "\n",
    "                        for overlap in param[\"OVERLAP\"]:\n",
    "                            run_param[\"OVERLAP\"] = overlap\n",
    "\n",
    "                            for setting in param[\"SETTING\"]:\n",
    "                                run_param[\"SETTING\"] = setting\n",
    "                        \n",
    "                                for mod in param[\"MOD\"]:\n",
    "                                    run_param[\"MOD\"] = mod\n",
    "\n",
    "                                    if ((setting == \"AL\"  or setting==\"SSL_AL\" or setting==\"SSL_AL_SSL\") and (mod not in [\"confidence\", \"disagreement\", \"disagreement_diff\"])):\n",
    "                                        continue\n",
    "\n",
    "                                    if (setting == \"SSL\" and mod != \"ssl\"):\n",
    "                                        continue\n",
    "\n",
    "                                    if (setting == \"NORMAL\" and mod != \"normal\"):\n",
    "                                        continue\n",
    "\n",
    "                                    for expert_predict in param[\"EXPERT_PREDICT\"]:\n",
    "                                        run_param[\"EXPERT_PREDICT\"] = expert_predict\n",
    "\n",
    "                                        if ((setting == \"SSL\" or setting == \"SSL_AL\" or setting == \"SSL_AL_SSL\") and (expert_predict == \"right\")):\n",
    "                                            #continue\n",
    "                                            pass\n",
    "\n",
    "                                        if (expert_predict == \"target\") and (cost != param[\"AL\"][\"COST\"][0]):\n",
    "                                            continue\n",
    "                                        if (expert_predict == \"target\"):\n",
    "                                            run_param[\"AL\"][\"cost\"] = convert_cost_to_string((0, 0))\n",
    "\n",
    "                                        for sample_equal in param[\"SAMPLE_EQUAL\"]:\n",
    "                                            run_param[\"SAMPLE_EQUAL\"] = sample_equal\n",
    "\n",
    "                                            for epochs_pretrain in param[\"epochs_pretrain\"]:\n",
    "                                                run_param[\"epochs_pretrain\"] = epochs_pretrain\n",
    "\n",
    "                                                run_param = build_param(run_param)\n",
    "\n",
    "                                                metrics_save = {}\n",
    "                                                #metrics_save[\"dataset\"] = param[\"DATASET\"]\n",
    "                                                metrics_save[\"labeler_ids\"] = labeler_ids\n",
    "                                                metrics_save[\"init_size\"] = init_size\n",
    "                                                metrics_save[\"labels_per_round\"] = labels_per_round\n",
    "                                                metrics_save[\"rounds\"] = rounds\n",
    "                                                metrics_save[\"labeled\"] = labeled\n",
    "                                                metrics_save[\"cost\"] = cost\n",
    "                                                metrics_save[\"overlap\"] = overlap\n",
    "                                                metrics_save[\"setting\"] = setting\n",
    "                                                metrics_save[\"mod\"] = mod\n",
    "                                                metrics_save[\"expert_predict\"] = expert_predict\n",
    "                                                metrics_save[\"sample_equal\"] = sample_equal\n",
    "                                                metrics_save[\"epochs_pretrain\"] = epochs_pretrain\n",
    "\n",
    "                                                \n",
    "                                                current_index = None\n",
    "                                                \n",
    "                                                #Compute the current index\n",
    "                                                if runs is not None:\n",
    "                                                    #If this parameter compination is in the already done runs\n",
    "                                                    if metrics_save in runs:\n",
    "                                                        #Get index of this combination\n",
    "                                                        current_index = runs.index(metrics_save)\n",
    "                                                        print(f\"Current index: {current_index}\")\n",
    "                            \n",
    "                                                NEPTUNE = param[\"NEPTUNE\"][\"NEPTUNE\"]\n",
    "                                                if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "                                                    global run\n",
    "                                                    run = neptune.init_run(\n",
    "                                                        project=config_neptune[\"project\"],\n",
    "                                                        api_token=config_neptune[\"api_token\"],\n",
    "                                                        #custom_run_id=\"AL_\" + \n",
    "                                                    )\n",
    "                                                    run[\"param\"] = run_param\n",
    "                                                    run_param[\"NEPTUNE\"][\"RUN\"] = run\n",
    "\n",
    "                                                print_text = f\"\"\"\\n \\n \\n #############################################################\n",
    "                                                NEW RUN\n",
    "\n",
    "                                                Dataset: {param[\"DATASET\"]}\n",
    "                                                Labelerids: {labeler_ids}\n",
    "                                                Initial size: {init_size}\n",
    "                                                Batch size AL: {labels_per_round}\n",
    "                                                Max rounds: {rounds}\n",
    "                                                Labeled images: {labeled}\n",
    "                                                Cost: {cost}\n",
    "                                                Setting: {setting}\n",
    "                                                Mod: {mod}\n",
    "                                                Overlap: {overlap}\n",
    "                                                Prediction Type: {expert_predict}\n",
    "                                                Sample equal: {sample_equal}\n",
    "                                                Epochs pretrain: {epochs_pretrain}\n",
    "                                                \"\"\"\n",
    "\n",
    "                                                start_time = time.time()\n",
    "                                                #dataManager, run_param, all_metrics, print_text, run_metrics, count, current_index=None\n",
    "                                                expert_metrics, verma_metrics, hemmer_metrics, labeled_df = one_run(dataManager, run_param, expert_metrics_all.copy(), print_text, metrics_save,\n",
    "                                                                                                       count, current_index)\n",
    "\n",
    "                                                #print(\"DELETE ME\")\n",
    "                                                #return one_run(dataManager, run_param, expert_metrics_all.copy(), print_text, metrics_save, count, current_index)\n",
    "                                                \n",
    "                                                print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "                                                metrics_save[\"artificial expert predictions\"] = labeled_df\n",
    "                                                metrics_save[\"expert metrics\"] = expert_metrics\n",
    "                                                metrics_save[\"verma\"] = verma_metrics\n",
    "                                                metrics_save[\"hemmer\"] = hemmer_metrics\n",
    "                                                ensure_count = 0 #Helps to save into the correct file if metrics are added to a run\n",
    "                                                if current_index is not None:\n",
    "                                                    expert_metrics_all[current_index] = metrics_save\n",
    "                                                    ensure_count = 1\n",
    "                                                else:\n",
    "                                                    expert_metrics_all.append(metrics_save)\n",
    "                                                with open(f'{param[\"Parent_PATH\"]}/Metrics_Folder/{param[\"DATASET\"]}/Metrics_{count - ensure_count}.pickle', 'wb') as handle:\n",
    "                                                    pickle.dump(expert_metrics_all, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                                                if current_index is None:\n",
    "                                                    count += 1\n",
    "                                                if param[\"NEPTUNE\"][\"NEPTUNE\"]:\n",
    "                                                    run[\"metrics\"] = metrics_save\n",
    "\n",
    "                                                    run.stop()\n",
    "                                                return\n",
    "\n",
    "    return expert_metrics_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f63b284-8933-4876-8875-3ec3c9b35a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cost_to_string(tp):\n",
    "    return \"(\" + str(tp[0]) + \", \" + str(tp[1]) + \")\"\n",
    "\n",
    "def convert_ids_to_string(ids):\n",
    "    return f\"{ids[0]}, {ids[1]}\"\n",
    "\n",
    "def convert_list_to_string(li):\n",
    "    result = \"[\"\n",
    "    for el in li[:-2]:\n",
    "        result = result + str(el)\n",
    "    result = result + \"]\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87b9b435-2f48-4591-abfb-d484668b4534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/joli/Masterarbeit'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf5dc49-7518-42d9-8c92-d465795ed193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4295349121_prediction\n"
     ]
    }
   ],
   "source": [
    "def save_expert_labels(fullDataset, experts, labeled_filenames):\n",
    "    true_labels = build_experts_prediction_df(fullDataset, experts)\n",
    "    artificial_labels = get_labeled_images_df(labeled_filenames)\n",
    "\n",
    "    label_df = pd.merge(true_labels, artificial_labels, how=\"outer\")\n",
    "    return label_df\n",
    "\n",
    "#Functions to create the predictions\n",
    "\n",
    "def build_experts_prediction_df(fullDataset, experts):\n",
    "    \"\"\"\n",
    "    Creates a df which contains the filename, gt, [true_prediction, artificial_prediction for every expert]\n",
    "    \"\"\"\n",
    "    label_df = create_label_df(fullDataset, experts)\n",
    "    label_df.columns = [process_name_expert_artificial_labels(column) if \"prediction\" in column else column for column in list(label_df.columns)]\n",
    "\n",
    "    true_experts = create_true_expert_labels(fullDataset, experts)\n",
    "\n",
    "    return pd.merge(true_experts, label_df)\n",
    "\n",
    "def create_true_expert_labels(dataset, experts):\n",
    "    \"\"\"\n",
    "    Creates a df with filename, gt, [true expert predictions]\n",
    "    \"\"\"\n",
    "    gt = pd.DataFrame({\"filename\": dataset.getAllFilenames(), \"gt\": dataset.getAllTargets()})\n",
    "    result = gt.copy()\n",
    "    for expert_id, expert in experts.items():\n",
    "        expert_df = expert.predictions.reset_index(names=\"filename\")\n",
    "        expert_df.columns = [column + \"_true_prediction\" if \"filename\" not in column else column for column in list(expert_df.columns)]\n",
    "        result = pd.merge(result, expert_df)\n",
    "    return result\n",
    "\n",
    "def create_label_df(dataset, experts):\n",
    "    \"\"\"\n",
    "    Creates a df with filename, gt, [artificial expert predictions]\n",
    "    \"\"\"\n",
    "    gt = pd.DataFrame({\"filename\": dataset.getAllFilenames(), \"gt\": dataset.getAllTargets()})\n",
    "    result = gt.copy()\n",
    "    for expert_id, expert in experts.items():\n",
    "        if \"ssl\" in expert.modus:\n",
    "            expert_df = pd.DataFrame({\"filename\": expert.prebuild_filenames_ssl, f\"prediction_{expert_id}\": expert.prebuild_predictions_ssl})\n",
    "        else:\n",
    "            expert_df = pd.DataFrame({\"filename\": expert.prebuild_filenames_al, f\"prediction_{expert_id}\": expert.prebuild_predictions_al})\n",
    "        result = pd.merge(result, expert_df)\n",
    "    return result\n",
    "\n",
    "#Functions to create the artificial\n",
    "def swap_prediction_id(name):\n",
    "    result = \"\"\n",
    "    for element in name.split(\"_\")[::-1]:\n",
    "        result += element + \"_\"\n",
    "    return result[:-1]\n",
    "print(swap_prediction_id(\"prediction_4295349121\"))\n",
    "\n",
    "def process_name_expert_artificial_labels(name):\n",
    "    result = \"\"\n",
    "    for element in swap_prediction_id(name).split(\"_\"):\n",
    "        if \"prediction\" in element:\n",
    "            result += \"artificial_\"\n",
    "        result += element + \"_\"\n",
    "    return result[:-1]\n",
    "\n",
    "def get_labeled_images_df(labeled_filenames):\n",
    "    \"\"\"\n",
    "    Creates a df which contains the filename, [if initial labeled, if labeled after al for ever expert]\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for labelerId, filelist in labeled_filenames[\"starting labels\"].items():\n",
    "        dfs.append(pd.DataFrame({\"filename\": [str(j) for j in filelist], f\"{labelerId}_starting_label\": [1 for i in range(len(filelist))]}))\n",
    "    starting_labels = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        starting_labels = pd.merge(starting_labels, dfs[i], how=\"outer\")\n",
    "\n",
    "    dfs = []\n",
    "    for labelerId, filelist in labeled_filenames[\"al labels\"].items():\n",
    "        dfs.append(pd.DataFrame({\"filename\": filelist, f\"{labelerId}_al_label\": [1 for i in range(len(filelist))]}))\n",
    "    al_labels = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        al_labels = pd.merge(al_labels, dfs[i], how=\"outer\")\n",
    "\n",
    "    print(\"DELETE ME\")\n",
    "    print(\"get_labeled_images_df\")\n",
    "    print(labeled_filenames)\n",
    "    print(\"starting labels\")\n",
    "    print(starting_labels)\n",
    "    print(\"al_labels\")\n",
    "    print(al_labels)\n",
    "\n",
    "    return pd.merge(starting_labels, al_labels, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dde2cce-c1ce-488a-9f5c-f9560d0d9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    path = args[0]\n",
    "\n",
    "    num_worker = 4\n",
    "    if len(args) >= 2:\n",
    "        num_worker = int(args[1])\n",
    "\n",
    "    if \"liebschner\" not in path and \"joli\" not in path:\n",
    "        return\n",
    "\n",
    "    param = {\n",
    "        \"DATASET\": \"CIFAR10N\",\n",
    "        \"PATH\": f\"{path}/Datasets/\",\n",
    "        \"Parent_PATH\": path,\n",
    "        #\"TARGET\": \"Airspace_Opacity\",\n",
    "        #\"LABELER_IDS\": [[4323195249, 4295232296]],\n",
    "        \"LABELER_IDS\": [[1, 2]],\n",
    "        \"K\": 10, #Number of folds\n",
    "        #\"SEEDS\": [1, 2, 3, 4, 42], #Seeds for the experiments\n",
    "        \"SEEDS\": [1], #Seeds for the experiments\n",
    "        \"GT\": True, # Determines if the classifier gets all data with GT Label or only the labeld data\n",
    "        #\"MOD\": [\"confidence\", \"disagreement\", \"disagreement_diff\", \"ssl\", \"normal\"], #Determines the experiment modus\n",
    "        \"MOD\": [\"confidence\"],\n",
    "\n",
    "        \"OVERLAP\": [0, 100],\n",
    "        \"SAMPLE_EQUAL\": [False, True],\n",
    "\n",
    "        #\"SETTING\": [\"AL\", \"SSL\", \"SSL_AL\", \"NORMAL\", \"SSL_AL_SSL\"],\n",
    "        \"SETTING\": [\"SSL_AL\"],\n",
    "\n",
    "        \"NUM_EXPERTS\": 2,\n",
    "        \"NUM_CLASSES\": 11,\n",
    "\n",
    "        \"EXPERT_PREDICT\": [\"target\", \"right\"],\n",
    "\n",
    "        \"AL\": { #Parameter for Active Learning\n",
    "            \"INITIAL_SIZE\": [16, 32], #\n",
    "            #\"EPOCH_TRAIN\": 40, #\n",
    "            \"EPOCH_TRAIN\": 10, #\n",
    "            \"n_dataset\": 2, #Number Classes\n",
    "            \"BATCH_SIZE\": 4,\n",
    "            \"BATCH_SIZE_VAL\": 32,\n",
    "            \"ROUNDS\": [2, 4, 8],\n",
    "            \"LABELS_PER_ROUND\": [4, 8, 16],\n",
    "            \"EPOCHS_DEFER\": 10,\n",
    "            \"COST\": [(0, 0), (5, 0)], #Cost for Cost sensitiv learning\n",
    "            #\"TRAIN REJECTOR\": False,\n",
    "            \"PRELOAD\": True,\n",
    "            \"PREPROCESS\": True,\n",
    "            \"SSL_EPOCHS\": 3\n",
    "        \n",
    "        },\n",
    "        \"SSL\": {\n",
    "            \"PREBUILD\": False,\n",
    "            #\"TRAIN_BATCH_SIZE\": 128,\n",
    "            \"TRAIN_BATCH_SIZE\": 254,\n",
    "            \"TEST_BATCH_SIZE\": 254,\n",
    "            #\"N_EPOCHS\": 5, #number of training epoches\n",
    "            \"N_EPOCHS\": 1, #number of training epoches\n",
    "            \"BATCHSIZE\": 16, #train batch size of labeled samples\n",
    "            #\"N_IMGS_PER_EPOCH\": 32768, #number of training images for each epoch\n",
    "            #\"N_IMGS_PER_EPOCH\": 4381*1, #number of training images for each epoch\n",
    "            #\"N_IMGS_PER_EPOCH\": 35000, #number of training images for each epoch\n",
    "            \"N_IMGS_PER_EPOCH\": 800, #number of training images for each epoch\n",
    "        },\n",
    "        \"L2D\": { # Parameter for Learning to defer\n",
    "            \"TRAIN_BATCH_SIZE\": 128,\n",
    "            \"TEST_BATCH_SIZE\": 128,\n",
    "            \"PRELOAD\": True,\n",
    "            \"PREBUILD\": True,\n",
    "            #\"EPOCHS\": 50,\n",
    "            \"EPOCHS\": 2,\n",
    "            \"VERMA\": {},\n",
    "            \"HEMMER\": {\n",
    "                \"EPOCHS\": 50,\n",
    "                \"LR\": 5e-3,\n",
    "                \"USE_LR_SCHEDULER\": False,\n",
    "                \"DROPOUT\": 0.00,\n",
    "                \"NUM_HIDDEN_UNITS\": 30,\n",
    "            },\n",
    "        \n",
    "        },\n",
    "        \"NEPTUNE\": {\n",
    "            \"NEPTUNE\": False,\n",
    "        },\n",
    "        \"EMBEDDED\": {\n",
    "            \"ARGS\": {\n",
    "                'dataset': \"nih\",\n",
    "                'model': \"resnet50\",\n",
    "                'num_classes': 10,\n",
    "                'batch': 128,\n",
    "                'lr': 0.001,\n",
    "            },\n",
    "            \"EPOCHS\": 30,\n",
    "        },\n",
    "    \n",
    "    \n",
    "        \"epochs_pretrain\": [0],\n",
    "        \"batch_size\": 64,\n",
    "        \"alpha\": 1.0, #scaling parameter for the loss function, default=1.0\n",
    "        \"epochs\": 50,\n",
    "        \"patience\": 35, #number of patience steps for early stopping the training\n",
    "        \"expert_type\": \"MLPMixer\", #specify the expert type. For the type of experts available, see-> models -> experts. defualt=predict\n",
    "        \"n_classes\": 11, #K for K class classification\n",
    "        \"k\": 0, #\n",
    "        \"n_experts\": 2, #\n",
    "        \"lr\": 0.001, #learning rate\n",
    "        \"weight_decay\": 5e-4, #\n",
    "        \"warmup_epochs\": 5, #\n",
    "        #\"loss_type\": \"softmax\", #surrogate loss type for learning to defer\n",
    "        \"loss_type\": \"ova\",\n",
    "        \"ckp_dir\": f\"{path}/Models\", #directory name to save the checkpoints\n",
    "        \"experiment_name\": \"multiple_experts\", #specify the experiment name. Checkpoints will be saved with this name\n",
    "\n",
    "        #Params for cluster training\n",
    "        \"num_worker\": num_worker,\n",
    "        \"cluster\": True,\n",
    "        \"IMAGE_SIZE\": 128,\n",
    "    }\n",
    "\n",
    "    return run_experiment(param)\n",
    "\n",
    "    expert_metrics_all = run_experiment(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7dac3b3-ff73-478f-a006-e5f44f0d2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_param(param):\n",
    "    \"\"\"\n",
    "    Function to add parameters based on the selected dataset and other parameters\n",
    "    Makes it easier to try different things without manually changing each parameter\n",
    "    \"\"\"\n",
    "    if param[\"DATASET\"] == \"NIH\":\n",
    "        param[\"TARGET\"]: \"Airspace_Opacity\",\n",
    "        param[\"SSL\"][\"N_IMGS_PER_EPOCH\"] = 4000 # Eventuell berechnen?\n",
    "        param[\"IMAGE_SIZE\"] = 128\n",
    "        param[\"EMBEDDED\"][\"ARGS\"][\"num_classes\"] = 2\n",
    "        param[\"NUM_CLASSES\"] = 2\n",
    "        param[\"n_classes\"] = 2\n",
    "        if param[\"EXPERT_PREDICT\"] == \"right\":\n",
    "            pass\n",
    "        elif param[\"EXPERT_PREDICT\"] == \"target\":\n",
    "            pass\n",
    "    elif param[\"DATASET\"] == \"VIN\":\n",
    "        param[\"TARGET\"] == 0\n",
    "        param[\"SSL\"][\"N_IMGS_PER_EPOCH\"] = 4000 # Eventuell berechnen?\n",
    "        param[\"IMAGE_SIZE\"] = 128\n",
    "        param[\"EMBEDDED\"][\"ARGS\"][\"num_classes\"] = 2\n",
    "        param[\"NUM_CLASSES\"] = 2\n",
    "        param[\"n_classes\"] = 2\n",
    "        if param[\"EXPERT_PREDICT\"] == \"right\":\n",
    "            pass\n",
    "        elif param[\"EXPERT_PREDICT\"] == \"target\":\n",
    "            pass\n",
    "    elif param[\"DATASET\"] == \"CIFAR10N\":\n",
    "        param[\"SSL\"][\"N_IMGS_PER_EPOCH\"] = 800 # Anpassen\n",
    "        param[\"IMAGE_SIZE\"] = 32\n",
    "        param[\"EMBEDDED\"][\"ARGS\"][\"num_classes\"] = 10\n",
    "        if param[\"EXPERT_PREDICT\"] == \"right\":\n",
    "            param[\"NUM_CLASSES\"] = 2\n",
    "            param[\"n_classes\"] = 2\n",
    "        elif param[\"EXPERT_PREDICT\"] == \"target\":\n",
    "            param[\"NUM_CLASSES\"] = 10\n",
    "            param[\"n_classes\"] = 10\n",
    "            pass\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f947663b-90a5-4562-ac8c-a9b90dea8a33",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of images of the whole dataset: 50000\n",
      "Loaded image number: 0\n",
      "Loaded image number: 10000\n",
      "Loaded image number: 20000\n",
      "Loaded image number: 30000\n",
      "Loaded image number: 40000\n",
      "Full length: 50000\n",
      "Loaded image number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/Masterarbeit/Dataset/cifar10_dataset.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.labels[\"Image ID\"] = self.labels[\"Image ID\"].astype('category')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image number: 10000\n",
      "Loaded image number: 20000\n",
      "Loaded image number: 30000\n",
      "Loaded image number: 40000\n",
      "Length of train + test + val: 50000\n",
      "Length of train + test + val: 50000\n",
      "Length of train + test + val: 50000\n",
      "Length of train + test + val: 50000\n",
      "Length of train + test + val: 50000\n",
      "Length of train + test + val: 50000\n",
      "Length of train + test + val: 50000\n",
      "Length of train + test + val: 50000\n",
      "Length of train + test + val: 50000\n",
      "Length of train + test + val: 50000\n",
      "Loaded set number 0\n",
      "Loaded set number 1\n",
      "Loaded set number 2\n",
      "Loaded set number 3\n",
      "Loaded set number 4\n",
      "Loaded set number 5\n",
      "Loaded set number 6\n",
      "Loaded set number 7\n",
      "Loaded set number 8\n",
      "Loaded set number 9\n",
      "New seed: 1\n",
      "Keys: dict_keys([])\n",
      "New fold: 0\n",
      "\n",
      " \n",
      " \n",
      " #############################################################\n",
      "                                                NEW RUN\n",
      "\n",
      "                                                Dataset: CIFAR10N\n",
      "                                                Initial size: 16\n",
      "                                                Batch size AL: 4\n",
      "                                                Max rounds: 2\n",
      "                                                Labeled images: 24\n",
      "                                                Cost: (0, 0)\n",
      "                                                Setting: SSL_AL\n",
      "                                                Mod: confidence\n",
      "                                                Overlap: 0\n",
      "                                                Prediction Type: target\n",
      "                                                Sample equal: False\n",
      "                                                Epochs pretrain: 0\n",
      "                                                \n",
      "/n\n",
      "Seed: 1 - Fold: 0 \n",
      "\n",
      "DELETE ME\n",
      "sampleIndices\n",
      "SSL indices {1: [28198, 7214, 1837, 22901, 6969, 29650, 16441, 6470, 2125, 1054, 12686, 11766, 32203, 2087, 15882, 24576], 2: [11943, 15969, 17154, 11174, 5966, 10023, 10240, 25283, 13342, 28621, 24174, 9703, 18265, 19904, 6027, 19990]}\n",
      "DELETE ME\n",
      "sampleIndices\n",
      "SSL indices {1: [26616, 12298, 12273, 26185, 8409, 31669, 20277, 25686, 4097, 23496, 19112, 14573, 7865, 25156, 31070, 20207], 2: [11421, 17773, 11871, 3627, 24336, 874, 28528, 6055, 13663, 30018, 25259, 10410, 1229, 3938, 11737, 881]}\n",
      "DELETE ME\n",
      "sampleIndices\n",
      "SSL indices {1: [6923, 5442, 31666, 31841, 6012, 9641, 26159, 4694, 26150, 34835, 26564, 34562, 5918, 8820, 23901, 20595], 2: [18207, 20278, 33260, 9893, 18548, 1455, 14614, 18835, 29571, 15745, 15851, 16065, 23810, 5327, 13274, 27072]}\n",
      "DELETE ME\n",
      "sampleIndices\n",
      "SSL indices {1: [30059, 29065, 11062, 32005, 26771, 30989, 18372, 14305, 20691, 13827, 348, 6174, 24938, 29502, 9665, 1816], 2: [21576, 18859, 13420, 15142, 2217, 16142, 19281, 34791, 1402, 9254, 19220, 20051, 19923, 23647, 4865, 12135]}\n",
      "DELETE ME\n",
      "sampleIndices\n",
      "SSL indices {1: [31653, 4045, 20204, 3361, 3323, 22440, 6550, 12247, 28035, 17009, 22118, 22099, 1636, 2004, 6004, 26752], 2: [13267, 7095, 17932, 30442, 8044, 30507, 28038, 34358, 2546, 11230, 2525, 17807, 4127, 16816, 33767, 22218]}\n",
      "DELETE ME\n",
      "sampleIndices\n",
      "SSL indices {1: [14323, 22913, 12910, 34943, 9791, 3188, 5571, 19889, 28202, 1015, 26206, 3063, 19323, 6051, 27184, 4057], 2: [34623, 28175, 9975, 32182, 2882, 6078, 20345, 633, 6515, 7168, 28494, 14075, 8134, 5248, 25028, 2413]}\n",
      "DELETE ME\n",
      "sampleIndices\n",
      "SSL indices {1: [14591, 9414, 6767, 4607, 5391, 82, 6959, 23229, 1417, 31183, 5662, 8745, 4840, 30612, 13371, 4218], 2: [23561, 32913, 2781, 7471, 16579, 21997, 29121, 5225, 20006, 1019, 9111, 20682, 15734, 22583, 23253, 30332]}\n",
      "DELETE ME\n",
      "sampleIndices\n",
      "SSL indices {1: [10888, 8338, 29699, 32022, 3926, 14951, 17487, 18617, 27100, 21262, 3178, 14698, 27, 9275, 19674, 10498], 2: [34144, 9325, 11344, 24379, 4017, 24398, 29050, 7322, 32529, 34991, 22071, 1048, 5966, 26716, 25875, 34097]}\n",
      "DELETE ME\n",
      "sampleIndices\n",
      "SSL indices {1: [8459, 25373, 24243, 313, 179, 10230, 18531, 5103, 31028, 28828, 26433, 7907, 19815, 32694, 33382, 6015], 2: [12899, 1321, 3557, 24643, 32146, 24927, 6382, 4420, 21624, 14378, 30035, 22885, 11949, 29064, 7701, 1882]}\n",
      "DELETE ME\n",
      "sampleIndices\n",
      "SSL indices {1: [31806, 15713, 34851, 10302, 7465, 31919, 14374, 6395, 16320, 6405, 32354, 12610, 12809, 583, 18044, 34592], 2: [32901, 13958, 30932, 22624, 18446, 12890, 21212, 10152, 26906, 13440, 14905, 30020, 31551, 22631, 17520, 32881]}\n",
      "Train dir: /home/joli/SSL_Working//CIFAR10N/Embedded/Seed_1_Fold_0/emb_net@dataset-nih-model-resnet50-num_classes-10/\n",
      "load Resnet-50 checkpoint\n",
      "load Resnet-50 pretrained on ImageNet\n",
      "Loaded Model resnet50\n",
      "274\n",
      "Found latest checkpoint at /home/joli/SSL_Working//CIFAR10N/Embedded/Seed_1_Fold_0/emb_net@dataset-nih-model-resnet50-num_classes-10//checkpoints/checkpoint.latest\n",
      "Continuing in epoch 31\n",
      "Test-Accuracy: 0.1234 \n",
      "Test-Acc-Class [0.094 0.061 0.111 0.172 0.065 0.055 0.033 0.422 0.172 0.049]\n",
      "NIH\n",
      "2023-10-25 06:39:07,624 - INFO - train -   {'dataset': 'NIH', 'wresnet_k': 2, 'wresnet_n': 28, 'n_classes': 10, 'mu': 7, 'eval_ema': True, 'ema_m': 0.999, 'lam_u': 1.0, 'lr': 0.03, 'weight_decay': 0.0005, 'momentum': 0.9, 'temperature': 0.2, 'low_dim': 64, 'lam_c': 1, 'contrast_th': 0.8, 'thr': 0.95, 'alpha': 0.9, 'queue_batch': 5, 'exp_dir': 'EmbeddingCM_bin', 'labelerId': 1, 'ex_strength': 1, 'n_labeled': None, 'seed': 1, 'n_epoches': 1, 'batchsize': 16, 'n_imgs_per_epoch': 800, 'type': '50', 'expert_predict': 'target'}\n",
      "load Resnet-50 checkpoint\n",
      "load Resnet-50 pretrained on ImageNet\n",
      "Loaded Model resnet50\n",
      "2023-10-25 06:39:08,072 - INFO - train -   Total params: 4.35M\n",
      "Index: 0\n",
      "Labels: 16\n",
      "Index: 0\n",
      "Index: 0\n",
      "No Checkpoint found at /home/joli/SSL_Working/CIFAR10N/SSL/NIH/EmbeddingCM_bin/ex1_xNone_seed1/ckp.latest\n",
      "Starting new from epoch 1\n",
      "2023-10-25 06:39:17,193 - INFO - train -   -----------start training--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-25 06:39:31,087 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 50. loss_u: 0.390. loss_x: 0.062. loss_c: 4.301. n_correct_u: 12.54/40.04. Mask:0.358. num_pos: 19.6. LR: 0.006. Time: 13.89\n",
      "2023-10-25 06:39:34,529 - INFO - train -   Epoch 0. Acc: 22.3229. Ema-Acc: 15.6748. best_acc: 22.3229 in epoch0\n",
      "Index: 0\n",
      "NIH\n",
      "2023-10-25 06:39:39,707 - INFO - train -   {'dataset': 'NIH', 'wresnet_k': 2, 'wresnet_n': 28, 'n_classes': 10, 'mu': 7, 'eval_ema': True, 'ema_m': 0.999, 'lam_u': 1.0, 'lr': 0.03, 'weight_decay': 0.0005, 'momentum': 0.9, 'temperature': 0.2, 'low_dim': 64, 'lam_c': 1, 'contrast_th': 0.8, 'thr': 0.95, 'alpha': 0.9, 'queue_batch': 5, 'exp_dir': 'EmbeddingCM_bin', 'labelerId': 2, 'ex_strength': 2, 'n_labeled': None, 'seed': 1, 'n_epoches': 1, 'batchsize': 16, 'n_imgs_per_epoch': 800, 'type': '50', 'expert_predict': 'target'}\n",
      "load Resnet-50 checkpoint\n",
      "load Resnet-50 pretrained on ImageNet\n",
      "Loaded Model resnet50\n",
      "2023-10-25 06:39:40,118 - INFO - train -   Total params: 4.35M\n",
      "Index: 0\n",
      "Labels: 16\n",
      "Index: 0\n",
      "Index: 0\n",
      "No Checkpoint found at /home/joli/SSL_Working/CIFAR10N/SSL/NIH/EmbeddingCM_bin/ex2_xNone_seed1/ckp.latest\n",
      "Starting new from epoch 1\n",
      "2023-10-25 06:39:48,194 - INFO - train -   -----------start training--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-25 06:40:01,960 - INFO - train -   NIH-xNone-s1, EmbeddingCM_bin | epoch:0, iter: 50. loss_u: 0.411. loss_x: 0.081. loss_c: 4.479. n_correct_u: 11.16/62.30. Mask:0.556. num_pos: 47.8. LR: 0.006. Time: 13.76\n",
      "2023-10-25 06:40:05,388 - INFO - train -   Epoch 0. Acc: 16.4610. Ema-Acc: 17.8543. best_acc: 16.4610 in epoch0\n",
      "Index: 0\n",
      "Index: 0\n",
      "Len overlapping used indices: 0\n",
      "\n",
      " \n",
      " Round 0 \n",
      " \n",
      "\n",
      "Epoch: [0][0/1]\tTime 0.055 (0.055)\tLoss 3.5981 (3.5981)\tPrec@1 0.000 (0.000)\n",
      "Epoch: [1][0/1]\tTime 0.016 (0.016)\tLoss 3.3163 (3.3163)\tPrec@1 0.000 (0.000)\n",
      "Epoch: [2][0/1]\tTime 0.016 (0.016)\tLoss 2.9398 (2.9398)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [3][0/1]\tTime 0.016 (0.016)\tLoss 2.5241 (2.5241)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [4][0/1]\tTime 0.016 (0.016)\tLoss 2.1267 (2.1267)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/1]\tTime 0.025 (0.025)\tLoss 1.7919 (1.7919)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/1]\tTime 0.019 (0.019)\tLoss 1.5407 (1.5407)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/1]\tTime 0.016 (0.016)\tLoss 1.3728 (1.3728)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/1]\tTime 0.016 (0.016)\tLoss 1.2755 (1.2755)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/1]\tTime 0.016 (0.016)\tLoss 1.2309 (1.2309)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 10000 test images: 18.440 %\n",
      "Confusion Matrix:\n",
      "[[150  60   0   1   2   0   3 775   0   0]\n",
      " [  2 469   0   1   6   0   5 645   0   0]\n",
      " [ 15   5   4   2   7   0   2 973   0   0]\n",
      " [ 36   8   0  32   0   0  27 843   0   0]\n",
      " [  0  13   1   1  37   0   1 841   0   0]\n",
      " [ 54   6   0  26   5   0  14 971   0   0]\n",
      " [  3   7   0   1   7   0 171 757   0   0]\n",
      " [  9  17   0   8  34   0   6 974   0   0]\n",
      " [ 16 204   0   1   1   0   0 775   0   0]\n",
      " [  2 485   0   0   0   0   3 469   0   7]]\n",
      "F1 Score: 0.1844\n",
      "Accuracy balanced\n",
      "0.17637211083960597\n",
      "\n",
      " \n",
      " Round 1 \n",
      " \n",
      "\n",
      "Epoch: [0][0/2]\tTime 0.024 (0.024)\tLoss 3.0191 (3.0191)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [1][0/2]\tTime 0.016 (0.016)\tLoss 1.9403 (1.9403)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [2][0/2]\tTime 0.016 (0.016)\tLoss 1.4973 (1.4973)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [3][0/2]\tTime 0.016 (0.016)\tLoss 0.6859 (0.6859)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/2]\tTime 0.016 (0.016)\tLoss 1.2246 (1.2246)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/2]\tTime 0.016 (0.016)\tLoss 0.4695 (0.4695)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/2]\tTime 0.016 (0.016)\tLoss 0.8408 (0.8408)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/2]\tTime 0.016 (0.016)\tLoss 0.6060 (0.6060)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [8][0/2]\tTime 0.016 (0.016)\tLoss 0.2800 (0.2800)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [9][0/2]\tTime 0.016 (0.016)\tLoss 0.3140 (0.3140)\tPrec@1 100.000 (100.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 10000 test images: 20.620 %\n",
      "Confusion Matrix:\n",
      "[[157  83   0   4   2   0   3 740   0   2]\n",
      " [  2 524   0   3   6   0   6 577   0  10]\n",
      " [ 13   6  19   5   7   0   2 956   0   0]\n",
      " [ 30  12   1  97   0   0  26 780   0   0]\n",
      " [  0  13   2   3  39   0   1 835   0   1]\n",
      " [ 48   9   0  76   5   0  15 923   0   0]\n",
      " [  3   8   0   2   7   0 185 741   0   0]\n",
      " [  7  35   1  15  29   0   6 954   0   1]\n",
      " [ 12 359   0   1   1   0   0 621   0   3]\n",
      " [  2 462   1   3   0   0   5 406   0  87]]\n",
      "F1 Score: 0.2062\n",
      "Accuracy balanced\n",
      "0.19839029139059786\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 5000 test images: 20.460 %\n",
      "Confusion Matrix:\n",
      "[[ 65  49   0   0   2   0   3 385   0   0]\n",
      " [  1 258   0   0   1   0   1 277   0  11]\n",
      " [  5   3  15   2  11   0   2 471   0   1]\n",
      " [  9   5   1  58   0   0  15 392   0   0]\n",
      " [  1   2   0   0  15   0   0 425   0   1]\n",
      " [ 31   9   0  26   2   0  13 458   0   1]\n",
      " [  1   7   0   1   3   0  92 369   0   0]\n",
      " [  4  23   0   8  22   0   3 475   0   0]\n",
      " [ 10 155   0   0   0   0   0 301   0   0]\n",
      " [  1 230   0   0   0   0   0 223   0  45]]\n",
      "F1 Score: 0.2046\n",
      "Accuracy balanced\n",
      "0.19554764902410302\n",
      "AL finished\n",
      "Index: 0\n",
      "Len overlapping used indices: 0\n",
      "\n",
      " \n",
      " Round 0 \n",
      " \n",
      "\n",
      "Epoch: [0][0/1]\tTime 0.030 (0.030)\tLoss 3.8229 (3.8229)\tPrec@1 0.000 (0.000)\n",
      "Epoch: [1][0/1]\tTime 0.016 (0.016)\tLoss 3.5139 (3.5139)\tPrec@1 0.000 (0.000)\n",
      "Epoch: [2][0/1]\tTime 0.019 (0.019)\tLoss 3.1111 (3.1111)\tPrec@1 0.000 (0.000)\n",
      "Epoch: [3][0/1]\tTime 0.016 (0.016)\tLoss 2.6825 (2.6825)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [4][0/1]\tTime 0.016 (0.016)\tLoss 2.2929 (2.2929)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [5][0/1]\tTime 0.016 (0.016)\tLoss 1.9835 (1.9835)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [6][0/1]\tTime 0.016 (0.016)\tLoss 1.7645 (1.7645)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [7][0/1]\tTime 0.016 (0.016)\tLoss 1.6250 (1.6250)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [8][0/1]\tTime 0.016 (0.016)\tLoss 1.5466 (1.5466)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [9][0/1]\tTime 0.016 (0.016)\tLoss 1.5115 (1.5115)\tPrec@1 75.000 (75.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 10000 test images: 18.770 %\n",
      "Confusion Matrix:\n",
      "[[  51    0    0    0    0    1    2  946   16    3]\n",
      " [   0    0    0    0    0    0    0 1078    7   44]\n",
      " [  17    0    0    1    0    6    0  985    3    0]\n",
      " [   0    0    3    9    2   13    0  891    4    0]\n",
      " [   0    0    0    1    0    1    0  866    3    2]\n",
      " [   0    6    7    1    0   84    1  982    4    1]\n",
      " [   0    1    0    0    0    2    7  907   25    1]\n",
      " [   0    0    0    0    0    2    0 1035    7    4]\n",
      " [   0    0    0    0    0    0    0  600  400    4]\n",
      " [   1    0    9    0    0    2    0  658    3  291]]\n",
      "F1 Score: 0.18770000000000003\n",
      "Accuracy balanced\n",
      "0.1832450654273892\n",
      "\n",
      " \n",
      " Round 1 \n",
      " \n",
      "\n",
      "Epoch: [0][0/2]\tTime 0.022 (0.022)\tLoss 3.0548 (3.0548)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [1][0/2]\tTime 0.017 (0.017)\tLoss 1.6977 (1.6977)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][0/2]\tTime 0.016 (0.016)\tLoss 1.7164 (1.7164)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [3][0/2]\tTime 0.016 (0.016)\tLoss 1.2142 (1.2142)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [4][0/2]\tTime 0.016 (0.016)\tLoss 1.0795 (1.0795)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [5][0/2]\tTime 0.016 (0.016)\tLoss 1.0525 (1.0525)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [6][0/2]\tTime 0.016 (0.016)\tLoss 0.7333 (0.7333)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [7][0/2]\tTime 0.016 (0.016)\tLoss 0.8310 (0.8310)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [8][0/2]\tTime 0.016 (0.016)\tLoss 0.9314 (0.9314)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [9][0/2]\tTime 0.016 (0.016)\tLoss 0.8569 (0.8569)\tPrec@1 75.000 (75.000)\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 10000 test images: 20.720 %\n",
      "Confusion Matrix:\n",
      "[[  52    0    0    1    0   10    2  932   19    3]\n",
      " [   0    0    0    1    0    4    0 1071    8   45]\n",
      " [  17    0    0    1    0   19    0  972    3    0]\n",
      " [   0    0    2   19    2   41    0  848   10    0]\n",
      " [   0    0    0    1    0    4    0  863    3    2]\n",
      " [   0    4    1    6    0  260    0  810    4    1]\n",
      " [   0    0    0    0    0    8    8  900   26    1]\n",
      " [   1    0    0    0    0    4    0 1032    7    4]\n",
      " [   0    0    0    1    0    1    0  590  408    4]\n",
      " [   1    0    9    0    0    2    0  656    3  293]]\n",
      "F1 Score: 0.2072\n",
      "Accuracy balanced\n",
      "0.2014581276882823\n",
      "ssl\n",
      "target\n",
      "Accuracy of the network on the 5000 test images: 19.860 %\n",
      "Confusion Matrix:\n",
      "[[ 37   0   0   1   0   2   0 455  20   2]\n",
      " [  0   0   0   1   0   2   0 520   5  23]\n",
      " [  8   0   0   0   0  10   0 503   1   1]\n",
      " [  0   0   1   5   0  27   0 442   7   2]\n",
      " [  0   0   0   1   0   7   0 433   0   3]\n",
      " [  0   0   1   1   0 117   0 396   5   1]\n",
      " [  1   0   0   0   1   8   0 452  13   2]\n",
      " [  1   0   0   1   0   3   0 511   1   0]\n",
      " [  0   0   0   0   0   2   0 284 180   1]\n",
      " [  0   0   0   1   0   0   0 352   3 143]]\n",
      "F1 Score: 0.1986\n",
      "Accuracy balanced\n",
      "0.19668721504439643\n",
      "AL finished\n",
      "SSL_AL\n",
      "Len prebuild predictions: 50000\n",
      "Len prebuild predictions: 50000\n",
      "DELETE ME\n",
      "get_labeled_images_df\n",
      "{'starting labels': {1: [40280, 10355, 2620, 32805, 10000, 42365, 23668, 9292, 3041, 1495, 18264, 16972, 45977, 2992, 22875, 35134], 2: [17228, 23000, 24693, 16111, 8580, 14437, 14767, 36131, 19233, 40881, 34582, 13974, 26223, 28599, 8666, 28716]}, 'al labels': {1: array(['29165', '24718', '775', '35964', '21477', '27578', '40605',\n",
      "       '3662'], dtype='<U21'), 2: array(['43187', '18598', '29165', '1573', '31543', '26920', '48843',\n",
      "       '45519'], dtype='<U21')}}\n",
      "starting labels\n",
      "   filename  1_starting_label  2_starting_label\n",
      "0     40280               1.0               NaN\n",
      "1     10355               1.0               NaN\n",
      "2      2620               1.0               NaN\n",
      "3     32805               1.0               NaN\n",
      "4     10000               1.0               NaN\n",
      "5     42365               1.0               NaN\n",
      "6     23668               1.0               NaN\n",
      "7      9292               1.0               NaN\n",
      "8      3041               1.0               NaN\n",
      "9      1495               1.0               NaN\n",
      "10    18264               1.0               NaN\n",
      "11    16972               1.0               NaN\n",
      "12    45977               1.0               NaN\n",
      "13     2992               1.0               NaN\n",
      "14    22875               1.0               NaN\n",
      "15    35134               1.0               NaN\n",
      "16    17228               NaN               1.0\n",
      "17    23000               NaN               1.0\n",
      "18    24693               NaN               1.0\n",
      "19    16111               NaN               1.0\n",
      "20     8580               NaN               1.0\n",
      "21    14437               NaN               1.0\n",
      "22    14767               NaN               1.0\n",
      "23    36131               NaN               1.0\n",
      "24    19233               NaN               1.0\n",
      "25    40881               NaN               1.0\n",
      "26    34582               NaN               1.0\n",
      "27    13974               NaN               1.0\n",
      "28    26223               NaN               1.0\n",
      "29    28599               NaN               1.0\n",
      "30     8666               NaN               1.0\n",
      "31    28716               NaN               1.0\n",
      "al_labels\n",
      "   filename  1_al_label  2_al_label\n",
      "0     29165         1.0         1.0\n",
      "1     24718         1.0         NaN\n",
      "2       775         1.0         NaN\n",
      "3     35964         1.0         NaN\n",
      "4     21477         1.0         NaN\n",
      "5     27578         1.0         NaN\n",
      "6     40605         1.0         NaN\n",
      "7      3662         1.0         NaN\n",
      "8     43187         NaN         1.0\n",
      "9     18598         NaN         1.0\n",
      "10     1573         NaN         1.0\n",
      "11    31543         NaN         1.0\n",
      "12    26920         NaN         1.0\n",
      "13    48843         NaN         1.0\n",
      "14    45519         NaN         1.0\n",
      "Start L2D Training\n",
      "Epoch: [0][0/274]\tTime 14.852 (14.852)\tLoss 12.1844 (12.1844)\tPrec@1 7.812 (7.812)\n",
      "Epoch: [0][10/274]\tTime 14.940 (14.631)\tLoss 12.2446 (12.1849)\tPrec@1 7.812 (7.457)\n",
      "Epoch: [0][20/274]\tTime 13.627 (14.500)\tLoss 12.1005 (12.1568)\tPrec@1 5.469 (7.701)\n",
      "Epoch: [0][30/274]\tTime 14.213 (14.488)\tLoss 11.9188 (12.1062)\tPrec@1 4.688 (7.359)\n",
      "Epoch: [0][40/274]\tTime 15.557 (14.542)\tLoss 11.9397 (12.0486)\tPrec@1 6.250 (7.412)\n",
      "Epoch: [0][50/274]\tTime 14.757 (14.532)\tLoss 11.4855 (11.9688)\tPrec@1 6.250 (7.613)\n",
      "Epoch: [0][60/274]\tTime 15.109 (14.551)\tLoss 11.0114 (11.8504)\tPrec@1 10.938 (7.710)\n",
      "Epoch: [0][70/274]\tTime 15.117 (14.500)\tLoss 10.8307 (11.7129)\tPrec@1 7.812 (7.691)\n",
      "Epoch: [0][80/274]\tTime 14.216 (14.518)\tLoss 10.0596 (11.5416)\tPrec@1 11.719 (8.083)\n",
      "Epoch: [0][90/274]\tTime 14.288 (14.489)\tLoss 9.6558 (11.3564)\tPrec@1 7.812 (8.388)\n",
      "Epoch: [0][100/274]\tTime 14.019 (14.493)\tLoss 9.7874 (11.1690)\tPrec@1 13.281 (8.609)\n",
      "Epoch: [0][110/274]\tTime 15.255 (14.493)\tLoss 8.5417 (10.9590)\tPrec@1 16.406 (8.805)\n",
      "Epoch: [0][120/274]\tTime 14.246 (14.512)\tLoss 8.1586 (10.7319)\tPrec@1 13.281 (9.201)\n",
      "Epoch: [0][130/274]\tTime 14.313 (14.502)\tLoss 7.5374 (10.5095)\tPrec@1 17.969 (9.775)\n",
      "Epoch: [0][140/274]\tTime 15.624 (14.510)\tLoss 6.7185 (10.2680)\tPrec@1 25.781 (10.516)\n",
      "Epoch: [0][150/274]\tTime 14.872 (14.505)\tLoss 6.1916 (10.0227)\tPrec@1 32.812 (11.434)\n",
      "Epoch: [0][160/274]\tTime 14.763 (14.492)\tLoss 6.2593 (9.7819)\tPrec@1 28.125 (12.374)\n",
      "Epoch: [0][170/274]\tTime 14.449 (14.498)\tLoss 5.4634 (9.5421)\tPrec@1 30.469 (13.501)\n",
      "Epoch: [0][180/274]\tTime 13.523 (14.484)\tLoss 5.3758 (9.3104)\tPrec@1 32.812 (14.619)\n",
      "Epoch: [0][190/274]\tTime 14.876 (14.473)\tLoss 4.8702 (9.0853)\tPrec@1 42.188 (15.825)\n",
      "Epoch: [0][200/274]\tTime 15.133 (14.471)\tLoss 4.6591 (8.8671)\tPrec@1 30.469 (16.927)\n",
      "Epoch: [0][210/274]\tTime 14.516 (14.473)\tLoss 4.2796 (8.6590)\tPrec@1 42.969 (18.124)\n",
      "Epoch: [0][220/274]\tTime 13.637 (14.465)\tLoss 4.0632 (8.4548)\tPrec@1 50.000 (19.393)\n",
      "Epoch: [0][230/274]\tTime 15.813 (14.466)\tLoss 3.9787 (8.2655)\tPrec@1 49.219 (20.637)\n",
      "Epoch: [0][240/274]\tTime 14.100 (14.457)\tLoss 3.5913 (8.0838)\tPrec@1 55.469 (21.953)\n",
      "Epoch: [0][250/274]\tTime 13.872 (14.449)\tLoss 3.8961 (7.9116)\tPrec@1 50.781 (23.232)\n",
      "Epoch: [0][260/274]\tTime 13.998 (14.438)\tLoss 3.8030 (7.7398)\tPrec@1 54.688 (24.629)\n",
      "Epoch: [0][270/274]\tTime 14.727 (14.437)\tLoss 3.1227 (7.5824)\tPrec@1 67.188 (25.928)\n",
      "{'coverage': '9108 out of10000', 'system_accuracy': 69.59, 'expert_accuracy': 84.08069863661466, 'classifier_accuracy': 68.17083807454065, 'alone_classifier': 66.83, 'validation_loss': 8.23832335049593, 'n_experts': 2, 'expert_0': 85.13509678599243, 'expert_1': 83.03567721621553, 'expert_0_coverage': 444, 'expert_1_coverage': 448}\n",
      "Epoch: [1][0/274]\tTime 14.442 (14.442)\tLoss 3.0101 (3.0101)\tPrec@1 67.969 (67.969)\n",
      "Epoch: [1][10/274]\tTime 14.908 (14.741)\tLoss 2.8284 (2.9624)\tPrec@1 70.312 (65.980)\n",
      "Epoch: [1][20/274]\tTime 14.752 (14.603)\tLoss 2.7214 (2.9130)\tPrec@1 77.344 (67.448)\n",
      "Epoch: [1][30/274]\tTime 14.892 (14.609)\tLoss 2.4952 (2.8725)\tPrec@1 72.656 (68.473)\n",
      "Epoch: [1][40/274]\tTime 14.317 (14.591)\tLoss 2.9657 (2.8704)\tPrec@1 68.750 (68.864)\n",
      "Epoch: [1][50/274]\tTime 14.099 (14.558)\tLoss 2.7879 (2.8487)\tPrec@1 68.750 (69.194)\n",
      "Epoch: [1][60/274]\tTime 14.076 (14.518)\tLoss 2.3605 (2.8140)\tPrec@1 72.656 (69.685)\n",
      "Epoch: [1][70/274]\tTime 13.872 (14.477)\tLoss 2.5019 (2.8110)\tPrec@1 75.000 (69.663)\n",
      "Epoch: [1][80/274]\tTime 14.321 (14.502)\tLoss 2.4659 (2.7947)\tPrec@1 70.312 (69.821)\n",
      "Epoch: [1][90/274]\tTime 13.721 (14.487)\tLoss 2.3874 (2.7684)\tPrec@1 73.438 (70.046)\n",
      "Epoch: [1][100/274]\tTime 14.479 (14.494)\tLoss 2.6933 (2.7565)\tPrec@1 68.750 (70.274)\n",
      "Epoch: [1][110/274]\tTime 14.462 (14.498)\tLoss 2.1659 (2.7334)\tPrec@1 71.875 (70.474)\n",
      "Epoch: [1][120/274]\tTime 14.447 (14.502)\tLoss 2.4973 (2.7158)\tPrec@1 75.781 (70.758)\n",
      "Epoch: [1][130/274]\tTime 14.187 (14.476)\tLoss 2.0999 (2.7075)\tPrec@1 78.125 (70.885)\n",
      "Epoch: [1][140/274]\tTime 14.371 (14.475)\tLoss 2.5613 (2.6908)\tPrec@1 75.781 (71.083)\n",
      "Epoch: [1][150/274]\tTime 13.521 (14.470)\tLoss 2.1712 (2.6733)\tPrec@1 82.031 (71.389)\n",
      "Epoch: [1][160/274]\tTime 14.315 (14.472)\tLoss 2.8766 (2.6604)\tPrec@1 71.094 (71.652)\n",
      "Epoch: [1][170/274]\tTime 13.948 (14.489)\tLoss 2.2218 (2.6405)\tPrec@1 73.438 (71.925)\n",
      "Epoch: [1][180/274]\tTime 15.288 (14.504)\tLoss 2.2805 (2.6220)\tPrec@1 79.688 (72.242)\n",
      "Epoch: [1][190/274]\tTime 14.509 (14.495)\tLoss 2.3752 (2.6064)\tPrec@1 75.000 (72.493)\n",
      "Epoch: [1][200/274]\tTime 13.892 (14.499)\tLoss 2.4691 (2.5918)\tPrec@1 74.219 (72.722)\n",
      "Epoch: [1][210/274]\tTime 14.516 (14.497)\tLoss 2.1960 (2.5781)\tPrec@1 81.250 (72.912)\n",
      "Epoch: [1][220/274]\tTime 14.720 (14.492)\tLoss 2.5964 (2.5692)\tPrec@1 78.125 (73.077)\n",
      "Epoch: [1][230/274]\tTime 14.097 (14.495)\tLoss 2.4412 (2.5571)\tPrec@1 75.000 (73.275)\n",
      "Epoch: [1][240/274]\tTime 14.198 (14.489)\tLoss 2.2835 (2.5502)\tPrec@1 76.562 (73.438)\n",
      "Epoch: [1][250/274]\tTime 14.135 (14.474)\tLoss 2.3126 (2.5411)\tPrec@1 67.969 (73.534)\n",
      "Epoch: [1][260/274]\tTime 13.291 (14.469)\tLoss 2.1543 (2.5281)\tPrec@1 77.344 (73.722)\n",
      "Epoch: [1][270/274]\tTime 15.239 (14.462)\tLoss 2.1914 (2.5160)\tPrec@1 77.344 (73.930)\n",
      "{'coverage': '9682 out of10000', 'system_accuracy': 80.87, 'expert_accuracy': 81.13202444526765, 'classifier_accuracy': 80.86139143915109, 'alone_classifier': 79.87, 'validation_loss': 8.796486745906781, 'n_experts': 2, 'expert_0': 80.79987072020684, 'expert_1': 81.34706596158968, 'expert_0_coverage': 125, 'expert_1_coverage': 193}\n",
      "Losses\n",
      "8.23832335049593\n",
      "8.796486745906781\n",
      "Epoch: [2][0/274]\tTime 14.751 (14.751)\tLoss 1.4326 (1.4326)\tPrec@1 89.844 (89.844)\n",
      "Epoch: [2][10/274]\tTime 14.519 (14.759)\tLoss 1.6226 (1.5683)\tPrec@1 85.938 (87.571)\n",
      "Epoch: [2][20/274]\tTime 15.008 (14.718)\tLoss 1.9913 (1.5632)\tPrec@1 84.375 (86.458)\n",
      "Epoch: [2][30/274]\tTime 13.971 (14.575)\tLoss 1.7497 (1.5768)\tPrec@1 83.594 (85.685)\n",
      "Epoch: [2][40/274]\tTime 13.626 (14.613)\tLoss 1.7752 (1.5832)\tPrec@1 82.812 (85.728)\n",
      "Epoch: [2][50/274]\tTime 14.517 (14.645)\tLoss 1.6315 (1.5922)\tPrec@1 82.812 (85.600)\n",
      "Epoch: [2][60/274]\tTime 14.334 (14.644)\tLoss 1.4114 (1.5967)\tPrec@1 90.625 (85.669)\n",
      "Epoch: [2][70/274]\tTime 14.892 (14.630)\tLoss 1.6429 (1.5935)\tPrec@1 82.031 (85.750)\n",
      "Epoch: [2][80/274]\tTime 14.639 (14.613)\tLoss 1.6622 (1.6031)\tPrec@1 86.719 (85.658)\n",
      "Epoch: [2][90/274]\tTime 15.842 (14.620)\tLoss 1.5279 (1.6086)\tPrec@1 87.500 (85.706)\n",
      "Epoch: [2][100/274]\tTime 14.891 (14.611)\tLoss 1.9403 (1.6097)\tPrec@1 85.156 (85.597)\n",
      "Epoch: [2][110/274]\tTime 14.536 (14.602)\tLoss 1.6592 (1.6078)\tPrec@1 83.594 (85.543)\n",
      "Epoch: [2][120/274]\tTime 14.439 (14.599)\tLoss 1.6327 (1.6181)\tPrec@1 85.938 (85.369)\n",
      "Epoch: [2][130/274]\tTime 13.767 (14.612)\tLoss 1.3003 (1.6246)\tPrec@1 85.938 (85.317)\n",
      "Epoch: [2][140/274]\tTime 14.671 (14.605)\tLoss 1.3510 (1.6303)\tPrec@1 89.062 (85.322)\n",
      "Epoch: [2][150/274]\tTime 14.679 (14.600)\tLoss 2.1460 (1.6386)\tPrec@1 81.250 (85.280)\n",
      "Epoch: [2][160/274]\tTime 15.168 (14.610)\tLoss 1.7665 (1.6464)\tPrec@1 82.812 (85.151)\n",
      "Epoch: [2][170/274]\tTime 14.050 (14.588)\tLoss 1.3687 (1.6473)\tPrec@1 88.281 (85.202)\n",
      "Epoch: [2][180/274]\tTime 13.996 (14.579)\tLoss 1.7710 (1.6549)\tPrec@1 82.812 (85.212)\n",
      "Epoch: [2][190/274]\tTime 15.701 (14.591)\tLoss 1.7981 (1.6575)\tPrec@1 84.375 (85.238)\n",
      "Epoch: [2][200/274]\tTime 14.993 (14.584)\tLoss 2.1129 (1.6679)\tPrec@1 82.031 (85.145)\n",
      "Epoch: [2][210/274]\tTime 14.518 (14.579)\tLoss 1.6951 (1.6746)\tPrec@1 85.156 (85.030)\n",
      "Epoch: [2][220/274]\tTime 14.352 (14.575)\tLoss 2.0722 (1.6792)\tPrec@1 78.906 (84.895)\n",
      "Epoch: [2][230/274]\tTime 14.738 (14.571)\tLoss 2.1553 (1.6905)\tPrec@1 78.906 (84.771)\n",
      "Epoch: [2][240/274]\tTime 14.141 (14.569)\tLoss 1.8804 (1.6939)\tPrec@1 81.250 (84.754)\n",
      "Epoch: [2][250/274]\tTime 13.754 (14.550)\tLoss 1.4212 (1.6953)\tPrec@1 91.406 (84.720)\n",
      "Epoch: [2][260/274]\tTime 13.889 (14.539)\tLoss 1.8657 (1.6989)\tPrec@1 80.469 (84.677)\n",
      "Epoch: [2][270/274]\tTime 13.834 (14.539)\tLoss 1.7273 (1.7013)\tPrec@1 83.594 (84.632)\n",
      "{'coverage': '9775 out of10000', 'system_accuracy': 82.3, 'expert_accuracy': 77.77770864203676, 'classifier_accuracy': 82.40409122860265, 'alone_classifier': 81.85, 'validation_loss': 9.893174292166021, 'n_experts': 2, 'expert_0': 80.32760548326071, 'expert_1': 76.82917459856756, 'expert_0_coverage': 61, 'expert_1_coverage': 164}\n",
      "Losses\n",
      "8.23832335049593\n",
      "9.893174292166021\n",
      "Epoch: [3][0/274]\tTime 14.015 (14.015)\tLoss 1.3338 (1.3338)\tPrec@1 89.844 (89.844)\n",
      "Epoch: [3][10/274]\tTime 14.314 (14.721)\tLoss 1.1551 (1.2433)\tPrec@1 89.844 (90.199)\n",
      "Epoch: [3][20/274]\tTime 14.699 (14.841)\tLoss 1.1977 (1.2454)\tPrec@1 90.625 (90.327)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m experts, dataManager, labeled_filenames \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/joli\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 121\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     12\u001b[0m param \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASET\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR10N\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Datasets/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMAGE_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m    119\u001b[0m }\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m expert_metrics_all \u001b[38;5;241m=\u001b[39m run_experiment(param)\n",
      "Cell \u001b[0;32mIn[16], line 154\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(param)\u001b[0m\n\u001b[1;32m    152\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m#dataManager, run_param, all_metrics, print_text, run_metrics, count, current_index=None\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m expert_metrics, verma_metrics, hemmer_metrics, labeled_df \u001b[38;5;241m=\u001b[39m \u001b[43mone_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataManager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpert_metrics_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_save\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m#print(\"DELETE ME\")\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m#return one_run(dataManager, run_param, expert_metrics_all.copy(), print_text, metrics_save, count, current_index)\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "Cell \u001b[0;32mIn[15], line 128\u001b[0m, in \u001b[0;36mone_run\u001b[0;34m(dataManager, run_param, all_metrics, print_text, run_metrics, count, current_index)\u001b[0m\n\u001b[1;32m    124\u001b[0m fullDataset \u001b[38;5;241m=\u001b[39m nih_dataloader\u001b[38;5;241m.\u001b[39mgetFullDataloader()\u001b[38;5;241m.\u001b[39mdataset\n\u001b[1;32m    125\u001b[0m labeled_df \u001b[38;5;241m=\u001b[39m save_expert_labels(fullDataset, experts, labeled_filenames)\n\u001b[0;32m--> 128\u001b[0m metrics_train_all, metrics_val_all, metrics_test_all, metrics_full_all, metrics_pretrain_all \u001b[38;5;241m=\u001b[39m \u001b[43mL2D_Verma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpert_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m verma_metrics[seed][fold_idx] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics_train_all,\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics_val_all,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics_pretrain_all,\n\u001b[1;32m    136\u001b[0m }\n\u001b[1;32m    138\u001b[0m system_accuracy, classifier_coverage, all_train_metrics, all_val_metrics, all_test_metrics, all_full_metrics \u001b[38;5;241m=\u001b[39m hm\u001b[38;5;241m.\u001b[39mL2D_Hemmer(train_loader, val_loader, test_loader, full_dataloader, expert_fns, run_param, seed, fold_idx, experts)\n",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m, in \u001b[0;36mL2D_Verma\u001b[0;34m(train_loader, val_loader, test_loader, full_dataloader, expert_fns, param, seed, fold_idx, experts)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse \u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPUs!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDataParallel(model)\n\u001b[0;32m----> 9\u001b[0m metrics_train_all, metrics_val_all, metrics_test, metrics_full, metrics_pretrain_all \u001b[38;5;241m=\u001b[39m \u001b[43mverm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpert_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                                            \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics_train_all, metrics_val_all, metrics_test, metrics_full, metrics_pretrain_all\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/verma.py:109\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, valid_loader, test_loader, expert_fns, config, seed, experts, fold, full_dataloader, param)\u001b[0m\n\u001b[1;32m    106\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m--> 109\u001b[0m     iters, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpert_fns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     experts_fns_eval \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    126\u001b[0m     labelerIds \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/verma.py:313\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(iters, warmup_iters, lrate, train_loader, model, optimizer, scheduler, epoch, expert_fns, loss_fn, n_classes, alpha, config, classifier_only)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# We only support \\alpha=1\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(expert_fns):\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# We assume each expert function has access to the extra metadata, even if they don't use it.\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m#m = fn(hpred)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m#Possible optimization\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     m \u001b[38;5;241m=\u001b[39m [m[j] \u001b[38;5;241m==\u001b[39m target_cpu[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, batch_size)]\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/expert.py:156\u001b[0m, in \u001b[0;36mExpert.predict_model_predefined_ssl\u001b[0;34m(self, img, target, filenames)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_model_predefined_ssl\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, target, filenames):\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprebuild_predictions_ssl[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprebuild_filenames_ssl\u001b[38;5;241m.\u001b[39mindex(filename)] \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filenames]\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/expert.py:156\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_model_predefined_ssl\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, target, filenames):\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprebuild_predictions_ssl[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprebuild_filenames_ssl\u001b[38;5;241m.\u001b[39mindex(filename)] \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filenames]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experts, dataManager, labeled_filenames = main([\"/home/joli\", 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9b2b9-271b-4d6b-9ea8-dbe4cf29f406",
   "metadata": {},
   "source": [
    "# General expert analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3df2ebcf-eecd-4004-8941-bc9c6902a3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Image ID</th>\n",
       "      <th>GT</th>\n",
       "      <th>4295367682</th>\n",
       "      <th>4295232296</th>\n",
       "      <th>4323195249</th>\n",
       "      <th>4295194124</th>\n",
       "      <th>4325222456</th>\n",
       "      <th>4295354140</th>\n",
       "      <th>4295206903</th>\n",
       "      <th>...</th>\n",
       "      <th>4295246212</th>\n",
       "      <th>4295354117</th>\n",
       "      <th>4326615889</th>\n",
       "      <th>4322936986</th>\n",
       "      <th>4295369079</th>\n",
       "      <th>4295344101</th>\n",
       "      <th>4325221191</th>\n",
       "      <th>4295349028</th>\n",
       "      <th>4295393403</th>\n",
       "      <th>4295354708</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>00000013_008.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>00000013_026.png</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>00000032_002.png</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>00000032_009.png</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>00000032_011.png</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID          Image ID  GT  4295367682  4295232296  4323195249  \\\n",
       "0          13  00000013_008.png   1         1.0         1.0         1.0   \n",
       "1          13  00000013_026.png   0        -1.0        -1.0         0.0   \n",
       "2          32  00000032_002.png   1        -1.0        -1.0         1.0   \n",
       "3          32  00000032_009.png   1        -1.0         1.0         1.0   \n",
       "4          32  00000032_011.png   1        -1.0         1.0         1.0   \n",
       "\n",
       "   4295194124  4325222456  4295354140  4295206903  ...  4295246212  \\\n",
       "0        -1.0        -1.0        -1.0        -1.0  ...        -1.0   \n",
       "1         0.0         0.0        -1.0        -1.0  ...        -1.0   \n",
       "2         0.0        -1.0         0.0        -1.0  ...        -1.0   \n",
       "3        -1.0        -1.0        -1.0         1.0  ...        -1.0   \n",
       "4        -1.0        -1.0        -1.0        -1.0  ...        -1.0   \n",
       "\n",
       "   4295354117  4326615889  4322936986  4295369079  4295344101  4325221191  \\\n",
       "0        -1.0        -1.0        -1.0        -1.0        -1.0        -1.0   \n",
       "1        -1.0        -1.0        -1.0        -1.0        -1.0        -1.0   \n",
       "2        -1.0        -1.0        -1.0        -1.0        -1.0        -1.0   \n",
       "3        -1.0        -1.0        -1.0        -1.0        -1.0        -1.0   \n",
       "4        -1.0        -1.0        -1.0        -1.0        -1.0        -1.0   \n",
       "\n",
       "   4295349028  4295393403  4295354708  \n",
       "0        -1.0        -1.0        -1.0  \n",
       "1        -1.0        -1.0        -1.0  \n",
       "2        -1.0        -1.0        -1.0  \n",
       "3        -1.0        -1.0        -1.0  \n",
       "4        -1.0        -1.0        -1.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicDataset = dataManager.getBasicDataset()\n",
    "basicData = basicDataset.getData().copy()\n",
    "labelerIds = basicData.columns[3:]\n",
    "basicData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7998aeb-3a99-4ec9-98cd-7cf4e2153c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4295367682</th>\n",
       "      <th>4295232296</th>\n",
       "      <th>4323195249</th>\n",
       "      <th>4295194124</th>\n",
       "      <th>4325222456</th>\n",
       "      <th>4295354140</th>\n",
       "      <th>4295206903</th>\n",
       "      <th>4326829894</th>\n",
       "      <th>4295376896</th>\n",
       "      <th>4295349121</th>\n",
       "      <th>...</th>\n",
       "      <th>4295246212</th>\n",
       "      <th>4295354117</th>\n",
       "      <th>4326615889</th>\n",
       "      <th>4322936986</th>\n",
       "      <th>4295369079</th>\n",
       "      <th>4295344101</th>\n",
       "      <th>4325221191</th>\n",
       "      <th>4295349028</th>\n",
       "      <th>4295393403</th>\n",
       "      <th>4295354708</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4295367682</th>\n",
       "      <td>536</td>\n",
       "      <td>9</td>\n",
       "      <td>536</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295232296</th>\n",
       "      <td>9</td>\n",
       "      <td>853</td>\n",
       "      <td>852</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>256</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4323195249</th>\n",
       "      <td>536</td>\n",
       "      <td>852</td>\n",
       "      <td>2320</td>\n",
       "      <td>936</td>\n",
       "      <td>162</td>\n",
       "      <td>212</td>\n",
       "      <td>593</td>\n",
       "      <td>295</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>255</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295194124</th>\n",
       "      <td>319</td>\n",
       "      <td>162</td>\n",
       "      <td>936</td>\n",
       "      <td>938</td>\n",
       "      <td>64</td>\n",
       "      <td>122</td>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325222456</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>64</td>\n",
       "      <td>162</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295354140</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>212</td>\n",
       "      <td>122</td>\n",
       "      <td>6</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295206903</th>\n",
       "      <td>74</td>\n",
       "      <td>256</td>\n",
       "      <td>593</td>\n",
       "      <td>149</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>594</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4326829894</th>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>295</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295376896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295349121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1674</td>\n",
       "      <td>...</td>\n",
       "      <td>425</td>\n",
       "      <td>758</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295342357</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1635</td>\n",
       "      <td>...</td>\n",
       "      <td>521</td>\n",
       "      <td>901</td>\n",
       "      <td>419</td>\n",
       "      <td>298</td>\n",
       "      <td>26</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295359843</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295246212</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>425</td>\n",
       "      <td>...</td>\n",
       "      <td>521</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295354117</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>758</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>940</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4326615889</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "      <td>456</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322936986</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>323</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295369079</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295344101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325221191</th>\n",
       "      <td>90</td>\n",
       "      <td>98</td>\n",
       "      <td>255</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295349028</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295393403</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295354708</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            4295367682  4295232296  4323195249  4295194124  4325222456  \\\n",
       "4295367682         536           9         536         319           0   \n",
       "4295232296           9         853         852         162           0   \n",
       "4323195249         536         852        2320         936         162   \n",
       "4295194124         319         162         936         938          64   \n",
       "4325222456           0           0         162          64         162   \n",
       "4295354140           0          58         212         122           6   \n",
       "4295206903          74         256         593         149          69   \n",
       "4326829894           0         253         295           8           0   \n",
       "4295376896           0           0         100         101           0   \n",
       "4295349121           0           0           0           0           0   \n",
       "4295342357          20           0         332           0           0   \n",
       "4295359843           0           0           0           0           0   \n",
       "4295246212           0           0           0           0           0   \n",
       "4295354117           0           0          28           0           0   \n",
       "4326615889           0           0          32           0           0   \n",
       "4322936986          24           0         190           0           0   \n",
       "4295369079           0           0           0           0           0   \n",
       "4295344101           0           0          64           0           0   \n",
       "4325221191          90          98         255          11          23   \n",
       "4295349028           0           0          20           0           0   \n",
       "4295393403           0          12          12           0           0   \n",
       "4295354708           0           0           0           0           0   \n",
       "\n",
       "            4295354140  4295206903  4326829894  4295376896  4295349121  ...  \\\n",
       "4295367682           0          74           0           0           0  ...   \n",
       "4295232296          58         256         253           0           0  ...   \n",
       "4323195249         212         593         295         100           0  ...   \n",
       "4295194124         122         149           8         101           0  ...   \n",
       "4325222456           6          69           0           0           0  ...   \n",
       "4295354140         212           0           0           0           0  ...   \n",
       "4295206903           0         594          31           0           0  ...   \n",
       "4326829894           0          31         296           0           0  ...   \n",
       "4295376896           0           0           0         101           0  ...   \n",
       "4295349121           0           0           0           0        1674  ...   \n",
       "4295342357           0           0           0           0        1635  ...   \n",
       "4295359843           0           0           0           0         193  ...   \n",
       "4295246212           0           0           0           0         425  ...   \n",
       "4295354117           0           0           0           0         758  ...   \n",
       "4326615889           0           0           0           0         265  ...   \n",
       "4322936986           0           0           0           0           0  ...   \n",
       "4295369079           0           0           0           0           0  ...   \n",
       "4295344101           0           0           0           0           0  ...   \n",
       "4325221191          23          10           0           0           0  ...   \n",
       "4295349028           0           0           0           0          39  ...   \n",
       "4295393403           0           0           0           0           0  ...   \n",
       "4295354708           0           0           0           0          23  ...   \n",
       "\n",
       "            4295246212  4295354117  4326615889  4322936986  4295369079  \\\n",
       "4295367682           0           0           0          24           0   \n",
       "4295232296           0           0           0           0           0   \n",
       "4323195249           0          28          32         190           0   \n",
       "4295194124           0           0           0           0           0   \n",
       "4325222456           0           0           0           0           0   \n",
       "4295354140           0           0           0           0           0   \n",
       "4295206903           0           0           0           0           0   \n",
       "4326829894           0           0           0           0           0   \n",
       "4295376896           0           0           0           0           0   \n",
       "4295349121         425         758         265           0           0   \n",
       "4295342357         521         901         419         298          26   \n",
       "4295359843          20           0           0          54           0   \n",
       "4295246212         521          53          12           0           0   \n",
       "4295354117          53         940         118           0           0   \n",
       "4326615889          12         118         456          16           0   \n",
       "4322936986           0           0          16         323          26   \n",
       "4295369079           0           0           0          26          26   \n",
       "4295344101           0           0           4          33           0   \n",
       "4325221191           0           0           0           0           0   \n",
       "4295349028           9           0           0           0           0   \n",
       "4295393403           0           0           0           0           0   \n",
       "4295354708           0          15          46           0           0   \n",
       "\n",
       "            4295344101  4325221191  4295349028  4295393403  4295354708  \n",
       "4295367682           0          90           0           0           0  \n",
       "4295232296           0          98           0          12           0  \n",
       "4323195249          64         255          20          12           0  \n",
       "4295194124           0          11           0           0           0  \n",
       "4325222456           0          23           0           0           0  \n",
       "4295354140           0          23           0           0           0  \n",
       "4295206903           0          10           0           0           0  \n",
       "4326829894           0           0           0           0           0  \n",
       "4295376896           0           0           0           0           0  \n",
       "4295349121           0           0          39           0          23  \n",
       "4295342357         101           0          68           0          86  \n",
       "4295359843           0           0           0           0           0  \n",
       "4295246212           0           0           9           0           0  \n",
       "4295354117           0           0           0           0          15  \n",
       "4326615889           4           0           0           0          46  \n",
       "4322936986          33           0           0           0           0  \n",
       "4295369079           0           0           0           0           0  \n",
       "4295344101         101           0           0           0           0  \n",
       "4325221191           0         255           0           0           0  \n",
       "4295349028           0           0          68           0           0  \n",
       "4295393403           0           0           0          12           0  \n",
       "4295354708           0           0           0           0          86  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def equal_labeled_images(data, experts):\n",
    "    \"\"\"\n",
    "    Returns dataframe with only images which are labeled from every given expert\n",
    "    \"\"\"\n",
    "    for expertId in experts:\n",
    "        data = data[data[expertId] != -1].copy()\n",
    "    return data[[\"Patient ID\", \"Image ID\", \"GT\"] + experts]\n",
    "\n",
    "def number_labeled_images(data, experts):\n",
    "    \"\"\"\n",
    "    Returns number of images which every given expert has labeled\n",
    "    \"\"\"\n",
    "    return len(equal_labeled_images(data, experts))\n",
    "\n",
    "def get_pair_labeled(data, Ids):\n",
    "    \"\"\"\n",
    "    Returns matrix which contains the number of labeled images for every pair of experts\n",
    "    \"\"\"\n",
    "    images_dict = {}\n",
    "    for i in Ids:\n",
    "        labeler_dict = {}\n",
    "        for j in Ids:\n",
    "            labeler_dict[j] = number_labeled_images(basicData, [i, j])\n",
    "        images_dict[i] = labeler_dict\n",
    "    return pd.DataFrame(images_dict)\n",
    "\n",
    "pair_labeled = get_pair_labeled(basicData, labelerIds)\n",
    "pair_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984ab67-5b7a-427e-894e-dc55d46fcaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50fe7da-cf4e-4583-ad64-510e94a75ee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pair_labeled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpair_labeled\u001b[49m\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4323195249\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4295232296\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pair_labeled' is not defined"
     ]
    }
   ],
   "source": [
    "pair_labeled.loc[\"4323195249\", \"4295232296\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d5232-ea15-4808-b263-d55911ef62a2",
   "metadata": {},
   "source": [
    "### New functions for saving the labels from experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "16857242-a29c-466c-8bea-cec33c56803b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4295349121_prediction\n"
     ]
    }
   ],
   "source": [
    "def save_expert_labels(fullDataset, experts, labeled_filenames):\n",
    "    true_labels = build_experts_prediction_df(fullDataset, experts)\n",
    "    artificial_labels = get_labeled_images_df(labeled_filenames)\n",
    "\n",
    "    label_df = pd.merge(true_labels, artificial_labels, how=\"outer\")\n",
    "    return label_df\n",
    "\n",
    "#Functions to create the predictions\n",
    "\n",
    "def build_experts_prediction_df(fullDataset, experts):\n",
    "    \"\"\"\n",
    "    Creates a df which contains the filename, gt, [true_prediction, artificial_prediction for every expert]\n",
    "    \"\"\"\n",
    "    label_df = create_label_df(fullDataset, experts)\n",
    "    label_df.columns = [process_name_expert_artificial_labels(column) if \"prediction\" in column else column for column in list(label_df.columns)]\n",
    "\n",
    "    true_experts = create_true_expert_labels(fullDataset, experts)\n",
    "\n",
    "    return pd.merge(true_experts, label_df)\n",
    "\n",
    "def create_true_expert_labels(dataset, experts):\n",
    "    \"\"\"\n",
    "    Creates a df with filename, gt, [true expert predictions]\n",
    "    \"\"\"\n",
    "    gt = pd.DataFrame({\"filename\": dataset.getAllFilenames(), \"gt\": dataset.getAllTargets()})\n",
    "    result = gt.copy()\n",
    "    for expert_id, expert in experts.items():\n",
    "        expert_df = expert.predictions.reset_index(names=\"filename\")\n",
    "        expert_df.columns = [column + \"_true_prediction\" if \"filename\" not in column else column for column in list(expert_df.columns)]\n",
    "        result = pd.merge(result, expert_df)\n",
    "    return result\n",
    "\n",
    "def create_label_df(dataset, experts):\n",
    "    \"\"\"\n",
    "    Creates a df with filename, gt, [artificial expert predictions]\n",
    "    \"\"\"\n",
    "    gt = pd.DataFrame({\"filename\": dataset.getAllFilenames(), \"gt\": dataset.getAllTargets()})\n",
    "    result = gt.copy()\n",
    "    for expert_id, expert in experts.items():\n",
    "        if \"ssl\" in expert.modus:\n",
    "            expert_df = pd.DataFrame({\"filename\": expert.prebuild_filenames_ssl, f\"prediction_{expert_id}\": expert.prebuild_predictions_ssl})\n",
    "        else:\n",
    "            expert_df = pd.DataFrame({\"filename\": expert.prebuild_filenames_al, f\"prediction_{expert_id}\": expert.prebuild_predictions_al})\n",
    "        result = pd.merge(result, expert_df)\n",
    "    return result\n",
    "\n",
    "#Functions to create the artificial\n",
    "def swap_prediction_id(name):\n",
    "    result = \"\"\n",
    "    for element in name.split(\"_\")[::-1]:\n",
    "        result += element + \"_\"\n",
    "    return result[:-1]\n",
    "print(swap_prediction_id(\"prediction_4295349121\"))\n",
    "\n",
    "def process_name_expert_artificial_labels(name):\n",
    "    result = \"\"\n",
    "    for element in swap_prediction_id(name).split(\"_\"):\n",
    "        if \"prediction\" in element:\n",
    "            result += \"artificial_\"\n",
    "        result += element + \"_\"\n",
    "    return result[:-1]\n",
    "\n",
    "def get_labeled_images_df(labeled_filenames):\n",
    "    \"\"\"\n",
    "    Creates a df which contains the filename, [if initial labeled, if labeled after al for ever expert]\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for labelerId, filelist in labeled_filenames[\"starting labels\"].items():\n",
    "        dfs.append(pd.DataFrame({\"filename\": filelist, f\"{labelerId}_starting_label\": [1 for i in range(len(filelist))]}))\n",
    "    starting_labels = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        starting_labels = pd.merge(starting_labels, dfs[i], how=\"outer\")\n",
    "\n",
    "    dfs = []\n",
    "    for labelerId, filelist in labeled_filenames[\"al labels\"].items():\n",
    "        dfs.append(pd.DataFrame({\"filename\": filelist, f\"{labelerId}_al_label\": [1 for i in range(len(filelist))]}))\n",
    "    al_labels = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        al_labels = pd.merge(al_labels, dfs[i], how=\"outer\")\n",
    "\n",
    "    return pd.merge(starting_labels, al_labels, how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac203c46-9db9-45e9-a84b-2517a931aa2d",
   "metadata": {},
   "source": [
    "### New functions for training without gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6899113c-5223-4e79-9844-aa53958b4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_artificial_gt(dataManager, train_dataloader, experts, fold, seed, method=\"perfect\"):\n",
    "    if method == \"perfect\":\n",
    "        return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ff14a20-4e7a-4139-80d7-53968e85f9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "616327c8-4339-4c13-8ca6-effd17c9dea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "284ee017-a4fe-4675-affd-406d73304a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_labeled(df, labeled):\n",
    "    return df[df[\"filename\"].isin(labeled)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66d79e-2cec-4127-a54f-36fb491dfc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0a480fd-7e71-4290-aec6-f7d2126f6f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dataset.Dataset.NIHDataset at 0x7f813b66beb0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullDataset = dataManager.getKFoldDataloader(1).getFullDataloader().dataset\n",
    "fullDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef9b19-523d-4158-b1d2-ec7fcd315cbf",
   "metadata": {},
   "source": [
    "Create df with filename, gt, and artificial expert predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac560434-2db8-49c2-88bf-48c202023cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy expert 1: 67.58409785932722%\n",
      "Accuracy expert 2: 64.89296636085628%\n"
     ]
    }
   ],
   "source": [
    "label_df = create_label_df(fullDataset, experts)\n",
    "label_df.head(7)\n",
    "\n",
    "print(f'Accuracy expert 1: {len(label_df[label_df[\"gt\"] == label_df[\"prediction_4295349121\"]])/len(label_df)*100}%')\n",
    "print(f'Accuracy expert 2: {len(label_df[label_df[\"gt\"] == label_df[\"prediction_4295342357\"]])/len(label_df)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7284ee07-fee4-4d59-a1a8-468300dbe200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4295349121_prediction\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f9a9c36-82fb-4e73-a81a-adff7c871abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5f3fd4a8-a69b-4149-b4e8-99c0778c6283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f9420963-2090-4538-977d-e287eca8cfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gt</th>\n",
       "      <th>4295349121_true_prediction</th>\n",
       "      <th>4295342357_true_prediction</th>\n",
       "      <th>4295349121_artificial_prediction</th>\n",
       "      <th>4295342357_artificial_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000119_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000134_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000135_001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000156_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000156_001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>00019643_019.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>00019643_020.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>00019643_021.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>00019643_022.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>00019643_024.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1635 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  gt  4295349121_true_prediction  \\\n",
       "0     00000119_001.png   0                         0.0   \n",
       "1     00000134_000.png   1                         1.0   \n",
       "2     00000135_001.png   1                         0.0   \n",
       "3     00000156_000.png   1                         1.0   \n",
       "4     00000156_001.png   1                         1.0   \n",
       "...                ...  ..                         ...   \n",
       "1630  00019643_019.png   1                         1.0   \n",
       "1631  00019643_020.png   0                         0.0   \n",
       "1632  00019643_021.png   0                         0.0   \n",
       "1633  00019643_022.png   0                         0.0   \n",
       "1634  00019643_024.png   0                         0.0   \n",
       "\n",
       "      4295342357_true_prediction  4295349121_artificial_prediction  \\\n",
       "0                            0.0                                 0   \n",
       "1                            0.0                                 0   \n",
       "2                            0.0                                 1   \n",
       "3                            1.0                                 0   \n",
       "4                            1.0                                 0   \n",
       "...                          ...                               ...   \n",
       "1630                         0.0                                 1   \n",
       "1631                         0.0                                 0   \n",
       "1632                         0.0                                 1   \n",
       "1633                         0.0                                 0   \n",
       "1634                         0.0                                 0   \n",
       "\n",
       "      4295342357_artificial_prediction  \n",
       "0                                    0  \n",
       "1                                    0  \n",
       "2                                    0  \n",
       "3                                    0  \n",
       "4                                    0  \n",
       "...                                ...  \n",
       "1630                                 1  \n",
       "1631                                 1  \n",
       "1632                                 1  \n",
       "1633                                 0  \n",
       "1634                                 0  \n",
       "\n",
       "[1635 rows x 6 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_experts_prediction_df(fullDataset, experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7fca6c39-f524-4a32-8b45-47147bb12ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 4295349121 with 22 images\n",
      "ID: 4295342357 with 20 images\n"
     ]
    }
   ],
   "source": [
    "for id, label_list in labeled_filenames[\"al labels\"].items():\n",
    "    print(f\"ID: {id} with {len(label_list)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "71ad4016-971d-4fa6-8b4d-ac6d33ce8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for labelerId, filelist in labeled_filenames[\"starting labels\"].items():\n",
    "    dfs.append(pd.DataFrame({\"filename\": filelist, f\"{labelerId}_starting_label\": [1 for i in range(len(filelist))]}))\n",
    "starting_labels = dfs[0]\n",
    "for i in range(1, len(dfs)):\n",
    "    starting_labels = pd.merge(starting_labels, dfs[i], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1f24540d-f387-4cdc-8a1a-70bae9f4b7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00015698_001.png',\n",
       " '00012387_001.png',\n",
       " '00001722_004.png',\n",
       " '00014715_013.png',\n",
       " '00019260_007.png',\n",
       " '00012233_001.png',\n",
       " '00016052_006.png',\n",
       " '00013894_047.png',\n",
       " '00018557_011.png',\n",
       " '00018829_005.png',\n",
       " '00012184_002.png',\n",
       " '00001792_003.png',\n",
       " '00018546_002.png',\n",
       " '00001470_000.png',\n",
       " '00013601_003.png',\n",
       " '00013443_001.png']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_filenames[\"starting labels\"][4295349121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "94fe74b1-0417-43ec-9cfd-0595999efa9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[np.array(df[\"4295342357_starting_label\"] == 1.0) | np.array(df[\"4295342357_al_label\"] == 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "28448825-da27-426f-81b0-b08b1b42cd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>4295349121_starting_label</th>\n",
       "      <th>4295342357_starting_label</th>\n",
       "      <th>4295349121_al_label</th>\n",
       "      <th>4295342357_al_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00015698_001.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00012387_001.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001722_004.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00014715_013.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00019260_007.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00012233_001.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00016052_006.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00013894_047.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00018557_011.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00018829_005.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00012184_002.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00001792_003.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00018546_002.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00001470_000.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00013601_003.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00013443_001.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00018546_006.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00019576_023.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00013739_002.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00016052_011.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00012543_010.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00013844_001.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00019643_004.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00013916_002.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00012219_007.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00006123_000.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00012010_026.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00012010_035.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00016561_003.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00026292_007.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>00013073_006.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>00018829_022.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>00019576_030.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>00016778_028.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>00015564_008.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>00016778_029.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>00018611_004.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>00018629_001.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>00013894_017.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>00015549_002.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>00013894_003.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>00013572_005.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>00018363_006.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00013408_000.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>00001620_004.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>00018949_006.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>00016778_026.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  4295349121_starting_label  4295342357_starting_label  \\\n",
       "0   00015698_001.png                        1.0                        NaN   \n",
       "1   00012387_001.png                        1.0                        NaN   \n",
       "2   00001722_004.png                        1.0                        1.0   \n",
       "3   00014715_013.png                        1.0                        NaN   \n",
       "4   00019260_007.png                        1.0                        NaN   \n",
       "5   00012233_001.png                        1.0                        NaN   \n",
       "6   00016052_006.png                        1.0                        NaN   \n",
       "7   00013894_047.png                        1.0                        NaN   \n",
       "8   00018557_011.png                        1.0                        NaN   \n",
       "9   00018829_005.png                        1.0                        NaN   \n",
       "10  00012184_002.png                        1.0                        NaN   \n",
       "11  00001792_003.png                        1.0                        NaN   \n",
       "12  00018546_002.png                        1.0                        NaN   \n",
       "13  00001470_000.png                        1.0                        NaN   \n",
       "14  00013601_003.png                        1.0                        NaN   \n",
       "15  00013443_001.png                        1.0                        NaN   \n",
       "16  00018546_006.png                        NaN                        1.0   \n",
       "17  00019576_023.png                        NaN                        1.0   \n",
       "18  00013739_002.png                        NaN                        1.0   \n",
       "19  00016052_011.png                        NaN                        1.0   \n",
       "20  00012543_010.png                        NaN                        1.0   \n",
       "21  00013844_001.png                        NaN                        1.0   \n",
       "22  00019643_004.png                        NaN                        1.0   \n",
       "23  00013916_002.png                        NaN                        1.0   \n",
       "24  00012219_007.png                        NaN                        1.0   \n",
       "25  00006123_000.png                        NaN                        1.0   \n",
       "26  00012010_026.png                        NaN                        1.0   \n",
       "27  00012010_035.png                        NaN                        1.0   \n",
       "28  00016561_003.png                        NaN                        1.0   \n",
       "29  00026292_007.png                        NaN                        1.0   \n",
       "30  00013073_006.png                        NaN                        1.0   \n",
       "31  00018829_022.png                        NaN                        NaN   \n",
       "32  00019576_030.png                        NaN                        NaN   \n",
       "33  00016778_028.png                        NaN                        NaN   \n",
       "34  00015564_008.png                        NaN                        NaN   \n",
       "35  00016778_029.png                        NaN                        NaN   \n",
       "36  00018611_004.png                        NaN                        NaN   \n",
       "37  00018629_001.png                        NaN                        NaN   \n",
       "38  00013894_017.png                        NaN                        NaN   \n",
       "39  00015549_002.png                        NaN                        NaN   \n",
       "40  00013894_003.png                        NaN                        NaN   \n",
       "41  00013572_005.png                        NaN                        NaN   \n",
       "42  00018363_006.png                        NaN                        NaN   \n",
       "43  00013408_000.png                        NaN                        NaN   \n",
       "44  00001620_004.png                        NaN                        NaN   \n",
       "45  00018949_006.png                        NaN                        NaN   \n",
       "46  00016778_026.png                        NaN                        NaN   \n",
       "\n",
       "    4295349121_al_label  4295342357_al_label  \n",
       "0                   1.0                  NaN  \n",
       "1                   1.0                  NaN  \n",
       "2                   1.0                  1.0  \n",
       "3                   NaN                  NaN  \n",
       "4                   1.0                  NaN  \n",
       "5                   1.0                  NaN  \n",
       "6                   1.0                  NaN  \n",
       "7                   NaN                  NaN  \n",
       "8                   1.0                  NaN  \n",
       "9                   1.0                  NaN  \n",
       "10                  1.0                  NaN  \n",
       "11                  1.0                  NaN  \n",
       "12                  1.0                  NaN  \n",
       "13                  1.0                  NaN  \n",
       "14                  1.0                  NaN  \n",
       "15                  1.0                  NaN  \n",
       "16                  NaN                  1.0  \n",
       "17                  NaN                  1.0  \n",
       "18                  NaN                  NaN  \n",
       "19                  NaN                  NaN  \n",
       "20                  NaN                  1.0  \n",
       "21                  NaN                  1.0  \n",
       "22                  NaN                  1.0  \n",
       "23                  NaN                  1.0  \n",
       "24                  NaN                  1.0  \n",
       "25                  NaN                  NaN  \n",
       "26                  NaN                  1.0  \n",
       "27                  NaN                  1.0  \n",
       "28                  NaN                  1.0  \n",
       "29                  NaN                  NaN  \n",
       "30                  NaN                  1.0  \n",
       "31                  1.0                  NaN  \n",
       "32                  1.0                  NaN  \n",
       "33                  1.0                  NaN  \n",
       "34                  1.0                  NaN  \n",
       "35                  1.0                  NaN  \n",
       "36                  1.0                  NaN  \n",
       "37                  1.0                  NaN  \n",
       "38                  1.0                  NaN  \n",
       "39                  NaN                  1.0  \n",
       "40                  NaN                  1.0  \n",
       "41                  NaN                  1.0  \n",
       "42                  NaN                  1.0  \n",
       "43                  NaN                  1.0  \n",
       "44                  NaN                  1.0  \n",
       "45                  NaN                  1.0  \n",
       "46                  NaN                  1.0  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_labeled_images_df(labeled_filenames)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "560b2b39-a10e-4fa6-b847-fa49e1882552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1641 entries, 0 to 1640\n",
      "Data columns (total 10 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   filename                          1641 non-null   object \n",
      " 1   gt                                1635 non-null   float64\n",
      " 2   4295349121_true_prediction        1635 non-null   float64\n",
      " 3   4295342357_true_prediction        1635 non-null   float64\n",
      " 4   4295349121_artificial_prediction  1635 non-null   float64\n",
      " 5   4295342357_artificial_prediction  1635 non-null   float64\n",
      " 6   4295349121_starting_label         16 non-null     float64\n",
      " 7   4295342357_starting_label         16 non-null     float64\n",
      " 8   4295349121_al_label               22 non-null     float64\n",
      " 9   4295342357_al_label               20 non-null     float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 141.0+ KB\n"
     ]
    }
   ],
   "source": [
    "true_labels = build_experts_prediction_df(fullDataset, experts)\n",
    "artificial_labels = get_labeled_images_df(labeled_filenames)\n",
    "\n",
    "label_df = pd.merge(true_labels, artificial_labels, how=\"outer\")\n",
    "label_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8a2356f2-3497-4167-8387-2832d4edcc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([False, True]) | np.array([True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "43909fd2-3e5b-48d3-9b97-7cd8158abfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_df[(np.array(label_df[\"4295342357_al_label\"] == 1.0) | np.array(label_df[\"4295349121_al_label\"] == 1.0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b36c860c-f30c-47b7-959a-8d5a4c345a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_df[(np.array(label_df[\"4295349121_starting_label\"] == 1.0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bea95b21-0739-425b-804f-797d7aab04d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_df[(np.array(label_df[\"4295342357_al_label\"] == 1.0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e508057d-5e74-4023-8c65-f3abd9c05274",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\"test\": \"1\", \"df\": label_df}\n",
    "with open(f'./test.pickle', 'wb') as handle:\n",
    "    pickle.dump(test, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9b4a37ab-0b1a-47bd-94d1-b99bb5c84c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./test.pickle\", 'rb') as handle:\n",
    "    test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9b0149eb-5352-493e-b0b2-fa74082e19ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gt</th>\n",
       "      <th>4295349121_true_prediction</th>\n",
       "      <th>4295342357_true_prediction</th>\n",
       "      <th>4295349121_artificial_prediction</th>\n",
       "      <th>4295342357_artificial_prediction</th>\n",
       "      <th>4295349121_starting_label</th>\n",
       "      <th>4295342357_starting_label</th>\n",
       "      <th>4295349121_al_label</th>\n",
       "      <th>4295342357_al_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000119_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000134_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000135_001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000156_000.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000156_001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>00019643_019.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>00019643_020.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>00019643_021.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>00019643_022.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>00019643_024.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1635 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  gt  4295349121_true_prediction  \\\n",
       "0     00000119_001.png   0                         0.0   \n",
       "1     00000134_000.png   1                         1.0   \n",
       "2     00000135_001.png   1                         0.0   \n",
       "3     00000156_000.png   1                         1.0   \n",
       "4     00000156_001.png   1                         1.0   \n",
       "...                ...  ..                         ...   \n",
       "1630  00019643_019.png   1                         1.0   \n",
       "1631  00019643_020.png   0                         0.0   \n",
       "1632  00019643_021.png   0                         0.0   \n",
       "1633  00019643_022.png   0                         0.0   \n",
       "1634  00019643_024.png   0                         0.0   \n",
       "\n",
       "      4295342357_true_prediction  4295349121_artificial_prediction  \\\n",
       "0                            0.0                                 0   \n",
       "1                            0.0                                 0   \n",
       "2                            0.0                                 1   \n",
       "3                            1.0                                 0   \n",
       "4                            1.0                                 0   \n",
       "...                          ...                               ...   \n",
       "1630                         0.0                                 1   \n",
       "1631                         0.0                                 0   \n",
       "1632                         0.0                                 1   \n",
       "1633                         0.0                                 0   \n",
       "1634                         0.0                                 0   \n",
       "\n",
       "      4295342357_artificial_prediction  4295349121_starting_label  \\\n",
       "0                                    0                        NaN   \n",
       "1                                    0                        NaN   \n",
       "2                                    0                        NaN   \n",
       "3                                    0                        NaN   \n",
       "4                                    0                        NaN   \n",
       "...                                ...                        ...   \n",
       "1630                                 1                        NaN   \n",
       "1631                                 1                        NaN   \n",
       "1632                                 1                        NaN   \n",
       "1633                                 0                        NaN   \n",
       "1634                                 0                        NaN   \n",
       "\n",
       "      4295342357_starting_label  4295349121_al_label  4295342357_al_label  \n",
       "0                           NaN                  NaN                  NaN  \n",
       "1                           NaN                  NaN                  NaN  \n",
       "2                           NaN                  NaN                  NaN  \n",
       "3                           NaN                  NaN                  NaN  \n",
       "4                           NaN                  NaN                  NaN  \n",
       "...                         ...                  ...                  ...  \n",
       "1630                        NaN                  NaN                  NaN  \n",
       "1631                        NaN                  NaN                  NaN  \n",
       "1632                        NaN                  NaN                  NaN  \n",
       "1633                        NaN                  NaN                  NaN  \n",
       "1634                        NaN                  NaN                  NaN  \n",
       "\n",
       "[1635 rows x 10 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"df\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03689a58-ee03-48ce-8331-796f511a853b",
   "metadata": {},
   "source": [
    "Processing the list of labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "46ede6cf-224d-43e2-b214-30c693bac300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00012233_001.png', '00001792_003.png', '00015698_001.png',\n",
       "       '00001722_004.png', '00013443_001.png', '00001470_000.png',\n",
       "       '00018546_002.png', '00018557_011.png', '00019260_007.png',\n",
       "       '00013601_003.png', '00012184_002.png', '00012387_001.png',\n",
       "       '00018829_005.png', '00016052_006.png', '00018019_005.png',\n",
       "       '00014558_011.png', '00014715_011.png', '00001449_002.png',\n",
       "       '00016887_000.png', '00019643_007.png', '00019240_005.png',\n",
       "       '00012010_005.png', '00013073_006.png', '00012010_035.png',\n",
       "       '00001722_004.png', '00013844_001.png', '00019576_023.png',\n",
       "       '00019643_004.png', '00018546_006.png', '00012010_026.png',\n",
       "       '00012219_007.png', '00013916_002.png', '00012543_010.png',\n",
       "       '00016561_003.png', '00018250_000.png', '00013613_013.png',\n",
       "       '00018335_012.png', '00019576_060.png', '00013601_022.png',\n",
       "       '00013613_016.png', '00018329_007.png', '00001249_004.png'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.empty(0, dtype=\"str\")\n",
    "for key, item in labeled_list[\"ssl_al\"][\"al labels\"].items():\n",
    "    result = np.append(result, item)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a5dd0d-084c-4add-87ae-a370d690ae1e",
   "metadata": {},
   "source": [
    "Filter expert predictions for only labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6986e8d7-1652-4c3b-93cb-8816494cc1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gt</th>\n",
       "      <th>4295349121</th>\n",
       "      <th>4295342357</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00001249_004.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>00001449_002.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>00001470_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>00001722_004.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>00001792_003.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  gt  4295349121  4295342357\n",
       "21  00001249_004.png   1         1.0         0.0\n",
       "34  00001449_002.png   0         0.0         0.0\n",
       "35  00001470_000.png   0         0.0         0.0\n",
       "64  00001722_004.png   0         0.0         0.0\n",
       "70  00001792_003.png   0         0.0         0.0"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_labeled(true_experts, result).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130cc49-f8d1-499c-b08b-1806ddac3bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b42b7251-9595-42e7-8c3f-f24250a61ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dataset.Dataset.NIHDataset at 0x7f4c2b5a0400>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c70b09a-5a02-4674-9402-329b159a5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_train, expert_val, expert_test = dataManager.getKFoldDataloader(1).get_dataset_for_folder(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44edbb4f-92c2-4dcc-8391-fa1eac223257",
   "metadata": {},
   "source": [
    "{4295349121: [440, 112, 28, 357, 759, 108, 463, 256, 675, 703, 101, 33, 663, 16, 198, 183], 4295342357: [701, 770, 503, 32, 776, 577, 733, 248, 384, 186, 729, 249, 591, 268, 174, 93]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4eff7da0-02db-4c90-88c4-4c4a204186ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_list[\"ssl_al\"] = labeled_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e77933d-5fdf-4942-98a2-5af670cb6ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "af56b0a3-6b22-457c-ba20-5dc28498d68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy expert 1: 68.68501529051989%\n",
      "Accuracy expert 2: 56.513761467889914%\n"
     ]
    }
   ],
   "source": [
    "label_df = create_label_df(fullDataset, experts)\n",
    "label_df.head(7)\n",
    "\n",
    "print(f'Accuracy expert 1: {len(label_df[label_df[\"gt\"] == label_df[\"prediction_4295349121\"]])/len(label_df)*100}%')\n",
    "print(f'Accuracy expert 2: {len(label_df[label_df[\"gt\"] == label_df[\"prediction_4295342357\"]])/len(label_df)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6c29cb38-b39a-4838-a42e-f7ed8178bb6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: empty expression not allowed (2971499285.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[266], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    name = f\"labeler_{}_seed_{}_fold_{}_gt_{param[\"GT\"]}_training_{param[\"SETTING\"]}_mod_{param[\"MOD\"]}_overlap_{param[\"OVERLAP\"]}_sample_equal_{param[\"SAMPLE_EQUAL\"]}_labeled_{param[\"LABELED\"]}_initSize_{param[\"AL\"][\"INITIAL_SIZE\"]}_rounds_{param[\"AL\"][\"ROUNDS\"]}_labelsPerRound_{param[\"AL\"][\"LABELS_PER_ROUND\"]}\"\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: empty expression not allowed\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01430b49-ab03-4c52-a0aa-a87f428b5670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e5be4375-a46c-42e1-aa1f-cd2e1f1a02f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4295349121: array(['00012233_001.png', '00001792_003.png', '00015698_001.png',\n",
       "        '00001722_004.png', '00013443_001.png', '00001470_000.png',\n",
       "        '00018546_002.png', '00018557_011.png', '00019260_007.png',\n",
       "        '00013601_003.png', '00012184_002.png', '00012387_001.png',\n",
       "        '00018829_005.png', '00016052_006.png', '00018019_005.png',\n",
       "        '00014558_011.png', '00014715_011.png', '00001449_002.png',\n",
       "        '00016887_000.png', '00019643_007.png', '00019240_005.png',\n",
       "        '00012010_005.png'], dtype='<U16'),\n",
       " 4295342357: array(['00013073_006.png', '00012010_035.png', '00001722_004.png',\n",
       "        '00013844_001.png', '00019576_023.png', '00019643_004.png',\n",
       "        '00018546_006.png', '00012010_026.png', '00012219_007.png',\n",
       "        '00013916_002.png', '00012543_010.png', '00016561_003.png',\n",
       "        '00018250_000.png', '00013613_013.png', '00018335_012.png',\n",
       "        '00019576_060.png', '00013601_022.png', '00013613_016.png',\n",
       "        '00018329_007.png', '00001249_004.png'], dtype='<U16')}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_list[\"ssl_al\"][\"al labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2abcf545-2c75-478a-9b40-65cf441ed60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00012233_001.png', '00001792_003.png', '00015698_001.png',\n",
       "       '00001722_004.png', '00013443_001.png', '00001470_000.png',\n",
       "       '00018546_002.png', '00018557_011.png', '00019260_007.png',\n",
       "       '00013601_003.png', '00012184_002.png', '00012387_001.png',\n",
       "       '00018829_005.png', '00016052_006.png', '00018019_005.png',\n",
       "       '00014558_011.png', '00014715_011.png', '00001449_002.png',\n",
       "       '00016887_000.png', '00019643_007.png', '00019240_005.png',\n",
       "       '00012010_005.png', '00013073_006.png', '00012010_035.png',\n",
       "       '00001722_004.png', '00013844_001.png', '00019576_023.png',\n",
       "       '00019643_004.png', '00018546_006.png', '00012010_026.png',\n",
       "       '00012219_007.png', '00013916_002.png', '00012543_010.png',\n",
       "       '00016561_003.png', '00018250_000.png', '00013613_013.png',\n",
       "       '00018335_012.png', '00019576_060.png', '00013601_022.png',\n",
       "       '00013613_016.png', '00018329_007.png', '00001249_004.png'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.empty(0, dtype=\"str\")\n",
    "for key, item in labeled_list[\"ssl_al\"][\"al labels\"].items():\n",
    "    result = np.append(result, item)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bf026b2d-1554-4ab6-80f7-11f5e2189427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gt</th>\n",
       "      <th>prediction_4295349121</th>\n",
       "      <th>prediction_4295342357</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00001249_004.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>00001449_002.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>00001470_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>00001722_004.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>00001792_003.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>00012010_005.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>00012010_026.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>00012010_035.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>00012184_002.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>00012219_007.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>00012233_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>00012387_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>00012543_010.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>00013073_006.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>00013443_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>00013601_003.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>00013601_022.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>00013613_013.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>00013613_016.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>00013844_001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>00013916_002.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>00014558_011.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>00014715_011.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>00015698_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>00016052_006.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>00016561_003.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>00016887_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>00018019_005.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>00018250_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>00018329_007.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>00018335_012.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>00018546_002.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>00018546_006.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>00018557_011.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>00018829_005.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>00019240_005.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>00019260_007.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>00019576_023.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>00019576_060.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>00019643_004.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>00019643_007.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  gt  prediction_4295349121  prediction_4295342357\n",
       "21    00001249_004.png   1                      1                      0\n",
       "34    00001449_002.png   0                      0                      0\n",
       "35    00001470_000.png   0                      0                      0\n",
       "64    00001722_004.png   0                      0                      0\n",
       "70    00001792_003.png   0                      0                      0\n",
       "121   00012010_005.png   1                      1                      0\n",
       "135   00012010_026.png   1                      1                      0\n",
       "142   00012010_035.png   1                      1                      0\n",
       "184   00012184_002.png   0                      0                      0\n",
       "192   00012219_007.png   0                      0                      0\n",
       "197   00012233_001.png   0                      0                      0\n",
       "217   00012387_001.png   0                      0                      0\n",
       "245   00012543_010.png   0                      0                      0\n",
       "354   00013073_006.png   1                      1                      0\n",
       "420   00013443_001.png   0                      0                      0\n",
       "469   00013601_003.png   0                      0                      0\n",
       "484   00013601_022.png   1                      1                      0\n",
       "499   00013613_013.png   1                      1                      1\n",
       "502   00013613_016.png   1                      1                      1\n",
       "526   00013844_001.png   1                      1                      0\n",
       "578   00013916_002.png   0                      0                      0\n",
       "691   00014558_011.png   0                      0                      0\n",
       "738   00014715_011.png   1                      1                      0\n",
       "895   00015698_001.png   0                      0                      0\n",
       "936   00016052_006.png   1                      1                      0\n",
       "978   00016561_003.png   0                      0                      0\n",
       "1058  00016887_000.png   0                      0                      0\n",
       "1228  00018019_005.png   1                      0                      0\n",
       "1263  00018250_000.png   0                      1                      0\n",
       "1278  00018329_007.png   1                      1                      1\n",
       "1285  00018335_012.png   0                      0                      0\n",
       "1334  00018546_002.png   0                      0                      0\n",
       "1336  00018546_006.png   0                      0                      0\n",
       "1349  00018557_011.png   0                      0                      0\n",
       "1410  00018829_005.png   1                      1                      0\n",
       "1489  00019240_005.png   0                      0                      0\n",
       "1495  00019260_007.png   0                      0                      0\n",
       "1575  00019576_023.png   1                      1                      0\n",
       "1604  00019576_060.png   1                      1                      1\n",
       "1617  00019643_004.png   1                      0                      1\n",
       "1620  00019643_007.png   1                      1                      0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_label_df(fullDataset, experts)\n",
    "df[df[\"filename\"].isin(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "cde37bcc-c2b1-434f-ba8f-bfe375b2bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelDataset():\n",
    "    def __init__(self, data):\n",
    "        self.y = data[\"gt\"]\n",
    "        self.x = data.copy().drop([\"filename\", \"gt\"], axis=1)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return np.array(self.x.iloc[index], dtype=\"float32\"), self.y.iloc[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.y)\n",
    "\n",
    "trainLabels = LabelDataset(df[df[\"filename\"].isin(result)])\n",
    "train_dataloader = DataLoader(datasetLabels, batch_size=8, shuffle=True)\n",
    "\n",
    "valLabels = LabelDataset(create_label_df(fullDataset, experts))\n",
    "val_dataloader = DataLoader(datasetLabels, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "48aa55ac-176e-4668-aac3-1977cc6f1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2),\n",
    "            #nn.Softmax(dim=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = LabelNet()#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "80553ccc-168b-40ea-a33d-536d17c109aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_label_model(model, dataloader):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.7)\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for epoch in range(5):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0 and i != 0:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "            \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9402017d-2a99-4672-865c-c8b82526bd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   101] loss: 0.705\n",
      "[1,   201] loss: 0.694\n",
      "[2,   101] loss: 0.726\n",
      "[2,   201] loss: 0.691\n",
      "[3,   101] loss: 0.724\n",
      "[3,   201] loss: 0.688\n",
      "[4,   101] loss: 0.722\n",
      "[4,   201] loss: 0.689\n",
      "[5,   101] loss: 0.720\n",
      "[5,   201] loss: 0.687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelNet(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=4, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LabelNet()\n",
    "train_label_model(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db540b-9387-4503-9acf-56cd92253f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in val_dataloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "709b4661-6861-461b-ba55-eaa919d74d99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[263], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[178], line 7\u001b[0m, in \u001b[0;36mLabelDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39miloc[index], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[index]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a361c7d-1474-4cc3-bbfd-175fc9e5cdc8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATASET': 'NIH',\n",
       " 'PATH': '/Datasets/',\n",
       " 'TARGET': 'Airspace_Opacity',\n",
       " 'LABELER_IDS': [[4323195249, 4295232296],\n",
       "  [4295349121, 4295342357],\n",
       "  [4295342357, 4295354117]],\n",
       " 'K': 10,\n",
       " 'SEEDS': [1, 2, 3, 4],\n",
       " 'GT': True,\n",
       " 'MOD': ['confidence'],\n",
       " 'OVERLAP': [0, 100],\n",
       " 'SAMPLE_EQUAL': [False, True],\n",
       " 'SETTING': ['SSL_AL'],\n",
       " 'NUM_EXPERTS': 2,\n",
       " 'NUM_CLASSES': 2,\n",
       " 'EXPERT_PREDICT': ['target', 'right'],\n",
       " 'AL': {'INITIAL_SIZE': [4, 8, 16, 32],\n",
       "  'EPOCH_TRAIN': 40,\n",
       "  'n_dataset': 2,\n",
       "  'BATCH_SIZE': 4,\n",
       "  'BATCH_SIZE_VAL': 32,\n",
       "  'ROUNDS': [2, 4],\n",
       "  'LABELS_PER_ROUND': [4, 8, 16],\n",
       "  'EPOCHS_DEFER': 10,\n",
       "  'COST': [0, 0],\n",
       "  'PRELOAD': True,\n",
       "  'PREPROCESS': True,\n",
       "  'SSL_EPOCHS': 3},\n",
       " 'SSL': {'PREBUILD': False,\n",
       "  'TRAIN_BATCH_SIZE': 254,\n",
       "  'TEST_BATCH_SIZE': 254,\n",
       "  'N_EPOCHS': 5,\n",
       "  'BATCHSIZE': 16,\n",
       "  'N_IMGS_PER_EPOCH': 4381},\n",
       " 'L2D': {'TRAIN_BATCH_SIZE': 128,\n",
       "  'TEST_BATCH_SIZE': 128,\n",
       "  'PRELOAD': True,\n",
       "  'PREBUILD': True,\n",
       "  'EPOCHS': 50,\n",
       "  'VERMA': {},\n",
       "  'HEMMER': {'EPOCHS': 50,\n",
       "   'LR': 0.005,\n",
       "   'USE_LR_SCHEDULER': False,\n",
       "   'DROPOUT': 0.0,\n",
       "   'NUM_HIDDEN_UNITS': 30}},\n",
       " 'NEPTUNE': {'NEPTUNE': False},\n",
       " 'EMBEDDED': {'ARGS': {'dataset': 'nih',\n",
       "   'model': 'resnet50',\n",
       "   'num_classes': 2,\n",
       "   'batch': 128,\n",
       "   'lr': 0.001},\n",
       "  'EPOCHS': 30},\n",
       " 'CIFAR100': {'EXPERTS': {'123': {'strength': 60,\n",
       "    'binary': False,\n",
       "    'num_classes': 20,\n",
       "    'per_s': 1.0,\n",
       "    'per_w': 0.0},\n",
       "   '456': {'strength': 60,\n",
       "    'binary': False,\n",
       "    'num_classes': 20,\n",
       "    'per_s': 1.0,\n",
       "    'per_w': 0.0}}},\n",
       " 'epochs_pretrain': [0],\n",
       " 'batch_size': 64,\n",
       " 'alpha': 1.0,\n",
       " 'epochs': 50,\n",
       " 'patience': 35,\n",
       " 'expert_type': 'MLPMixer',\n",
       " 'n_classes': 2,\n",
       " 'k': 0,\n",
       " 'n_experts': 2,\n",
       " 'lr': 0.001,\n",
       " 'weight_decay': 0.0005,\n",
       " 'warmup_epochs': 5,\n",
       " 'loss_type': 'ova',\n",
       " 'ckp_dir': '/Models',\n",
       " 'experiment_name': 'multiple_experts',\n",
       " 'cluster': True,\n",
       " 'IMAGE_SIZE': 128}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('NIH_Experiment.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed72294-b2a4-487d-8240-558c8666e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_param_from_json(data, path, num_worker):\n",
    "    param = data.copy()\n",
    "    param[\"Parent_PATH\"] = path\n",
    "    param[\"PATH\"] = f{path}/{data[\"PATH\"]}\n",
    "    param[\"ckp_dir\"] = f{path}/{data[\"ckp_dir\"]}\n",
    "    param[\"num_worker\"] = num_worker\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "941a4fb9-e905-46bb-b208-9b04b413063f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_worker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 106\u001b[0m\n\u001b[1;32m      1\u001b[0m param \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASET\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR10N\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Datasets/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParent_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m: path,\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m#\"TARGET\": \"Airspace_Opacity\",\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m#\"LABELER_IDS\": [[4323195249, 4295232296]],\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLABELER_IDS\u001b[39m\u001b[38;5;124m\"\u001b[39m: [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]],\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m, \u001b[38;5;66;03m#Number of folds\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m#\"SEEDS\": [1, 2, 3, 4, 42], #Seeds for the experiments\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEEDS\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m1\u001b[39m], \u001b[38;5;66;03m#Seeds for the experiments\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# Determines if the classifier gets all data with GT Label or only the labeld data\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m#\"MOD\": [\"confidence\", \"disagreement\", \"disagreement_diff\", \"ssl\", \"normal\"], #Determines the experiment modus\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMOD\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOVERLAP\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMPLE_EQUAL\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m],\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m#\"SETTING\": [\"AL\", \"SSL\", \"SSL_AL\", \"NORMAL\", \"SSL_AL_SSL\"],\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSETTING\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSL_AL\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUM_EXPERTS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUM_CLASSES\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m11\u001b[39m,\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXPERT_PREDICT\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAL\u001b[39m\u001b[38;5;124m\"\u001b[39m: { \u001b[38;5;66;03m#Parameter for Active Learning\u001b[39;00m\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINITIAL_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m], \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;66;03m#\"EPOCH_TRAIN\": 40, #\u001b[39;00m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH_TRAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m, \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m#Number Classes\u001b[39;00m\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBATCH_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBATCH_SIZE_VAL\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROUNDS\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m],\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLABELS_PER_ROUND\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m],\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCHS_DEFER\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOST\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0\u001b[39m)], \u001b[38;5;66;03m#Cost for Cost sensitiv learning\u001b[39;00m\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;66;03m#\"TRAIN REJECTOR\": False,\u001b[39;00m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRELOAD\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPREPROCESS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSL_EPOCHS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     41\u001b[0m         \n\u001b[1;32m     42\u001b[0m         },\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSSL\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPREBUILD\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;66;03m#\"TRAIN_BATCH_SIZE\": 128,\u001b[39;00m\n\u001b[1;32m     46\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAIN_BATCH_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m254\u001b[39m,\n\u001b[1;32m     47\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEST_BATCH_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m254\u001b[39m,\n\u001b[1;32m     48\u001b[0m             \u001b[38;5;66;03m#\"N_EPOCHS\": 5, #number of training epoches\u001b[39;00m\n\u001b[1;32m     49\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN_EPOCHS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m#number of training epoches\u001b[39;00m\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBATCHSIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m16\u001b[39m, \u001b[38;5;66;03m#train batch size of labeled samples\u001b[39;00m\n\u001b[1;32m     51\u001b[0m             \u001b[38;5;66;03m#\"N_IMGS_PER_EPOCH\": 32768, #number of training images for each epoch\u001b[39;00m\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;66;03m#\"N_IMGS_PER_EPOCH\": 4381*1, #number of training images for each epoch\u001b[39;00m\n\u001b[1;32m     53\u001b[0m             \u001b[38;5;66;03m#\"N_IMGS_PER_EPOCH\": 35000, #number of training images for each epoch\u001b[39;00m\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN_IMGS_PER_EPOCH\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m800\u001b[39m, \u001b[38;5;66;03m#number of training images for each epoch\u001b[39;00m\n\u001b[1;32m     55\u001b[0m         },\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL2D\u001b[39m\u001b[38;5;124m\"\u001b[39m: { \u001b[38;5;66;03m# Parameter for Learning to defer\u001b[39;00m\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAIN_BATCH_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEST_BATCH_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     59\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRELOAD\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     60\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPREBUILD\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     61\u001b[0m             \u001b[38;5;66;03m#\"EPOCHS\": 50,\u001b[39;00m\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCHS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVERMA\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEMMER\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCHS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     66\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5e-3\u001b[39m,\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE_LR_SCHEDULER\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROPOUT\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.00\u001b[39m,\n\u001b[1;32m     69\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUM_HIDDEN_UNITS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m     70\u001b[0m             },\n\u001b[1;32m     71\u001b[0m         \n\u001b[1;32m     72\u001b[0m         },\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEPTUNE\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEPTUNE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m         },\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEMBEDDED\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mARGS\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     78\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnih\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     79\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet50\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     81\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     82\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m     83\u001b[0m             },\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCHS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m     85\u001b[0m         },\n\u001b[1;32m     86\u001b[0m     \n\u001b[1;32m     87\u001b[0m     \n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs_pretrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;66;03m#scaling parameter for the loss function, default=1.0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m35\u001b[39m, \u001b[38;5;66;03m#number of patience steps for early stopping the training\u001b[39;00m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpert_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLPMixer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#specify the expert type. For the type of experts available, see-> models -> experts. defualt=predict\u001b[39;00m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m11\u001b[39m, \u001b[38;5;66;03m#K for K class classification\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_experts\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;66;03m#learning rate\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5e-4\u001b[39m, \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarmup_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;66;03m#\"loss_type\": \"softmax\", #surrogate loss type for learning to defer\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mova\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mckp_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Models\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#directory name to save the checkpoints\u001b[39;00m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiple_experts\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#specify the experiment name. Checkpoints will be saved with this name\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[1;32m    105\u001b[0m         \u001b[38;5;66;03m#Params for cluster training\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_worker\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mnum_worker\u001b[49m,\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMAGE_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m    109\u001b[0m     }\n\u001b[1;32m    110\u001b[0m param\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_worker' is not defined"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "        \"DATASET\": \"CIFAR10N\",\n",
    "        \"PATH\": f\"{path}/Datasets/\",\n",
    "        \"Parent_PATH\": path,\n",
    "        #\"TARGET\": \"Airspace_Opacity\",\n",
    "        #\"LABELER_IDS\": [[4323195249, 4295232296]],\n",
    "        \"LABELER_IDS\": [[1, 2]],\n",
    "        \"K\": 10, #Number of folds\n",
    "        #\"SEEDS\": [1, 2, 3, 4, 42], #Seeds for the experiments\n",
    "        \"SEEDS\": [1], #Seeds for the experiments\n",
    "        \"GT\": True, # Determines if the classifier gets all data with GT Label or only the labeld data\n",
    "        #\"MOD\": [\"confidence\", \"disagreement\", \"disagreement_diff\", \"ssl\", \"normal\"], #Determines the experiment modus\n",
    "        \"MOD\": [\"confidence\"],\n",
    "\n",
    "        \"OVERLAP\": [0, 100],\n",
    "        \"SAMPLE_EQUAL\": [False, True],\n",
    "\n",
    "        #\"SETTING\": [\"AL\", \"SSL\", \"SSL_AL\", \"NORMAL\", \"SSL_AL_SSL\"],\n",
    "        \"SETTING\": [\"SSL_AL\"],\n",
    "\n",
    "        \"NUM_EXPERTS\": 2,\n",
    "        \"NUM_CLASSES\": 11,\n",
    "\n",
    "        \"EXPERT_PREDICT\": [\"target\", \"right\"],\n",
    "\n",
    "        \"AL\": { #Parameter for Active Learning\n",
    "            \"INITIAL_SIZE\": [16, 32], #\n",
    "            #\"EPOCH_TRAIN\": 40, #\n",
    "            \"EPOCH_TRAIN\": 10, #\n",
    "            \"n_dataset\": 2, #Number Classes\n",
    "            \"BATCH_SIZE\": 4,\n",
    "            \"BATCH_SIZE_VAL\": 32,\n",
    "            \"ROUNDS\": [2, 4, 8],\n",
    "            \"LABELS_PER_ROUND\": [4, 8, 16],\n",
    "            \"EPOCHS_DEFER\": 10,\n",
    "            \"COST\": [(0, 0), (5, 0)], #Cost for Cost sensitiv learning\n",
    "            #\"TRAIN REJECTOR\": False,\n",
    "            \"PRELOAD\": True,\n",
    "            \"PREPROCESS\": True,\n",
    "            \"SSL_EPOCHS\": 3\n",
    "        \n",
    "        },\n",
    "        \"SSL\": {\n",
    "            \"PREBUILD\": False,\n",
    "            #\"TRAIN_BATCH_SIZE\": 128,\n",
    "            \"TRAIN_BATCH_SIZE\": 254,\n",
    "            \"TEST_BATCH_SIZE\": 254,\n",
    "            #\"N_EPOCHS\": 5, #number of training epoches\n",
    "            \"N_EPOCHS\": 1, #number of training epoches\n",
    "            \"BATCHSIZE\": 16, #train batch size of labeled samples\n",
    "            #\"N_IMGS_PER_EPOCH\": 32768, #number of training images for each epoch\n",
    "            #\"N_IMGS_PER_EPOCH\": 4381*1, #number of training images for each epoch\n",
    "            #\"N_IMGS_PER_EPOCH\": 35000, #number of training images for each epoch\n",
    "            \"N_IMGS_PER_EPOCH\": 800, #number of training images for each epoch\n",
    "        },\n",
    "        \"L2D\": { # Parameter for Learning to defer\n",
    "            \"TRAIN_BATCH_SIZE\": 128,\n",
    "            \"TEST_BATCH_SIZE\": 128,\n",
    "            \"PRELOAD\": True,\n",
    "            \"PREBUILD\": True,\n",
    "            #\"EPOCHS\": 50,\n",
    "            \"EPOCHS\": 2,\n",
    "            \"VERMA\": {},\n",
    "            \"HEMMER\": {\n",
    "                \"EPOCHS\": 50,\n",
    "                \"LR\": 5e-3,\n",
    "                \"USE_LR_SCHEDULER\": False,\n",
    "                \"DROPOUT\": 0.00,\n",
    "                \"NUM_HIDDEN_UNITS\": 30,\n",
    "            },\n",
    "        \n",
    "        },\n",
    "        \"NEPTUNE\": {\n",
    "            \"NEPTUNE\": False,\n",
    "        },\n",
    "        \"EMBEDDED\": {\n",
    "            \"ARGS\": {\n",
    "                'dataset': \"nih\",\n",
    "                'model': \"resnet50\",\n",
    "                'num_classes': 10,\n",
    "                'batch': 128,\n",
    "                'lr': 0.001,\n",
    "            },\n",
    "            \"EPOCHS\": 30,\n",
    "        },\n",
    "    \n",
    "    \n",
    "        \"epochs_pretrain\": [0],\n",
    "        \"batch_size\": 64,\n",
    "        \"alpha\": 1.0, #scaling parameter for the loss function, default=1.0\n",
    "        \"epochs\": 50,\n",
    "        \"patience\": 35, #number of patience steps for early stopping the training\n",
    "        \"expert_type\": \"MLPMixer\", #specify the expert type. For the type of experts available, see-> models -> experts. defualt=predict\n",
    "        \"n_classes\": 11, #K for K class classification\n",
    "        \"k\": 0, #\n",
    "        \"n_experts\": 2, #\n",
    "        \"lr\": 0.001, #learning rate\n",
    "        \"weight_decay\": 5e-4, #\n",
    "        \"warmup_epochs\": 5, #\n",
    "        #\"loss_type\": \"softmax\", #surrogate loss type for learning to defer\n",
    "        \"loss_type\": \"ova\",\n",
    "        \"ckp_dir\": f\"{path}/Models\", #directory name to save the checkpoints\n",
    "        \"experiment_name\": \"multiple_experts\", #specify the experiment name. Checkpoints will be saved with this name\n",
    "\n",
    "        #Params for cluster training\n",
    "        \"num_worker\": num_worker,\n",
    "        \"cluster\": True,\n",
    "        \"IMAGE_SIZE\": 128,\n",
    "    }\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ffaca-816c-4a53-8268-db27fb6a40fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joli-env_kernel",
   "language": "python",
   "name": "joli-env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
