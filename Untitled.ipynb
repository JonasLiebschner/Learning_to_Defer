{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "246892c3-8a32-4d60-9858-ed5090d26f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46631461],\n",
       "       [0.88948035],\n",
       "       [0.87511819],\n",
       "       [0.78909928],\n",
       "       [0.48919428],\n",
       "       [0.24808446],\n",
       "       [0.8046332 ],\n",
       "       [0.41460963],\n",
       "       [0.41979619],\n",
       "       [0.10531617],\n",
       "       [0.53173025],\n",
       "       [0.96045359],\n",
       "       [0.54964918],\n",
       "       [0.81252507],\n",
       "       [0.58855949],\n",
       "       [0.83056961],\n",
       "       [0.33498131],\n",
       "       [0.42052107],\n",
       "       [0.72133411],\n",
       "       [0.18877035]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "matrix = np.random.rand(20, 1)\n",
    "indices_all = [i for i in range(10,30)]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02511785-7d1d-406a-bd34-0cfb818e3b47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(len(matrix))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fb675cc-6935-4f46-bee6-7a099901c0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, False, True, False, False, True, True, True, True]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixx = [ for row in matrix if disagree(np.round(row))]\n",
    "matrixx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d40f80-379f-4734-bda2-c9c0619df3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_loader:\n",
    "        images, labels, _, indices, _, filenames = data\n",
    "        experts_preds = []\n",
    "        for j, expert_model in enumerate(expert_models):\n",
    "            images = images.to(device)\n",
    "            outputs_exp = expert_model(images)\n",
    "            preds = []\n",
    "            for i in range(outputs_exp.size()[0]):\n",
    "                pred_exp = outputs_exp.data[i].cpu().numpy()\n",
    "                pred_exp = pred_exp[1]\n",
    "                #preds.append(round(pred_exp))\n",
    "                preds.append(pred_exp)\n",
    "                if (j == 0): #Add the indices only the first time\n",
    "                    indices_all.append(indices[i].item())\n",
    "            experts_preds.append(np.array(preds))\n",
    "        prediction_matrix.append(np.reshape(np.swapaxes(np.array(experts_preds), 0, 1), (-1, 2)))\n",
    "    predictions_matrix = np.reshape(np.array(prediction_matrix), (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c3943403-14bd-4cad-b647-83015c91f718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [2., 3.],\n",
       "       [3., 4.],\n",
       "       [4., 5.],\n",
       "       [5., 6.],\n",
       "       [1., 2.],\n",
       "       [2., 3.],\n",
       "       [3., 4.],\n",
       "       [4., 5.],\n",
       "       [5., 6.],\n",
       "       [1., 2.],\n",
       "       [2., 3.],\n",
       "       [3., 4.],\n",
       "       [4., 5.],\n",
       "       [5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_matrix = None\n",
    "for k in range(3):\n",
    "    experts_preds = []\n",
    "    for i in range(2):   \n",
    "        #experts_preds.append(np.array(np.random.rand(5, 1), dtype=np.float32))\n",
    "        if k == 3:\n",
    "            experts_preds.append(np.array([1 + i, 2  + i, 3  + i], dtype=np.float32))\n",
    "        else:\n",
    "            experts_preds.append(np.array([1 + i, 2  + i, 3  + i, 4  + i, 5  + i], dtype=np.float32))\n",
    "    if prediction_matrix is None:\n",
    "        prediction_matrix = np.swapaxes(np.array(experts_preds), 0, 1)\n",
    "    else:\n",
    "        prediction_matrix = np.concatenate((prediction_matrix, np.swapaxes(np.array(experts_preds), 0, 1)), axis=0)\n",
    "tmp = np.array(experts_preds)\n",
    "tmp\n",
    "prediction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44e33d77-0cd8-4ad2-9e4a-bae12b9497c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(matrix >= 0.97)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdac581-74fe-4f59-9205-92c9c6e806c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75f7bd7e-ac73-415f-b2a3-ffb4019568f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 18, 19, 26, 15, 29, 10, 14, 20, 27, 21]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def disagree(array):\n",
    "    start = array[0]\n",
    "    for el in array[1:]:\n",
    "        if start != el:\n",
    "            return start != el\n",
    "    return False\n",
    "\n",
    "matrixx = [row for row in matrix if disagree(np.round(row))]\n",
    "points = np.array([np.sum(np.abs(row - 0.5)) for row in matrixx])\n",
    "\n",
    "budget = 20\n",
    "ind = []\n",
    "for row in np.array(matrixx)[points.argsort()[:budget].tolist()]:\n",
    "    ind.append(indices_all[np.argwhere(matrix == row)[0][0]])\n",
    "    #indices.append(np.argwhere(matrix == row)[0][0])\n",
    "#indices\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23d6c389-bf27-41c9-b2dc-40faedfea3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 23, 17, 24, 29, 15, 22]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b171cd5-4061-4953-91d2-167f4c3318dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 12, 17, 11, 13, 23, 28, 25, 22]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixx = [row for row in matrix if not disagree(np.round(row))]\n",
    "points = np.array([np.sum(np.abs(row - 0.5)) for row in matrixx])\n",
    "\n",
    "indices = []\n",
    "for row in np.array(matrixx)[points.argsort()[:200].tolist()]:\n",
    "    indices.append(indices_all[np.argwhere(matrix == row)[0][0]])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2251c465-c370-49a2-a1a4-9bcd83f41855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagree(array):\n",
    "    start = array[0]\n",
    "    for el in array[1:]:\n",
    "        if start != el:\n",
    "            return start != el\n",
    "    return False\n",
    "\n",
    "def test2():\n",
    "    matrixx = [row for row in matrix if disagree(np.round(row))]\n",
    "    indices = []\n",
    "    ind=[]\n",
    "    for row in np.array(matrixx):\n",
    "        #indices.append(np.argwhere(matrix == row)[0][0])\n",
    "        ind.append(indices_all[np.argwhere(matrix == row)[0][0]])\n",
    "    ind\n",
    "\n",
    "def test3():\n",
    "    matrixx = [disagree(np.round(row)) for row in matrix]\n",
    "    ind = np.array(indices_all)[matrixx]\n",
    "    print(len(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3b70b5b2-5698-4f98-87aa-139db5d3a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "matrixx = [disagree(np.round(row)) for row in matrix]\n",
    "ind = np.array(indices_all)[matrixx][:2]\n",
    "print(len(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ba918ea3-a6d9-422d-9137-16c0c55f361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disagreement on 12 Points\n",
      "[19, 13, 10, 15, 29, 25, 27, 11, 22, 20, 16, 18, 13, 21, 10, 14, 25, 27, 11, 26]\n"
     ]
    }
   ],
   "source": [
    "matrixx = [row for row in matrix if disagree(np.round(row))]\n",
    "points = np.array([np.sum(np.abs(row - 0.5)) for row in matrixx])\n",
    "\n",
    "print(\"Disagreement on \" + str(len(points)) + \" Points\")\n",
    "\n",
    "ids = []\n",
    "for row in np.array(matrixx)[points.argsort()[:budget].tolist()]:\n",
    "    ids.append(indices_all[np.argwhere(matrix == row)[0][0]])\n",
    "\n",
    "if len(ids) < budget:\n",
    "    matrixx = [row for row in predictions_matrix if not disagree(np.round(row))]\n",
    "    points = np.array([np.sum(np.abs(row - 0.5)) for row in matrixx])\n",
    "\n",
    "    for row in np.array(matrixx)[points.argsort()[:(budget - len(ids))].tolist()]:\n",
    "        ids.append(indices_all[np.argwhere(predictions_matrix == row)[0][0]])\n",
    "\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d118660b-2e67-4379-8ceb-e7292f3660e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c9b8cd3-37e7-4ce9-98b4-0f9f0bb1d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "014640a9-1614-4147-bb7f-05ae84255861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    #torch.manual_seed(seed)\n",
    "    #if torch.cuda.is_available():\n",
    "    #    torch.cuda.manual_seed(seed)\n",
    "    #    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac73435c-8ab9-4ae1-85d8-869bb3d5ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleIndices(n, k, all_indices, experten, seed=None):\n",
    "    if seed is not None:\n",
    "        set_seed(seed)\n",
    "    same_indices = random.sample(all_indices, k)\n",
    "    diff_indices = []\n",
    "    used_indices = same_indices\n",
    "    indices = []\n",
    "    if k == n:\n",
    "        for expert in experten:\n",
    "            indices.append(same_indices)\n",
    "    if k < n:\n",
    "        for expert in experten:\n",
    "            temp_indices = []\n",
    "            count = 0 # To avoid infinity loop\n",
    "            while len(temp_indices) < (n - k):\n",
    "                count += 1\n",
    "                temp = random.sample(all_indices, 1)\n",
    "                if temp not in used_indices:\n",
    "                    temp_indices = temp_indices + temp\n",
    "                    used_indices = used_indices + temp\n",
    "                if count >= 1000:\n",
    "                    temp = random.sample(used_indices, n-k-len(temp_indices))\n",
    "                    if isinstance(temp, list):\n",
    "                        temp_indices = temp_indices + temp\n",
    "                    else:\n",
    "                        temp_indices.append(temp)\n",
    "                    break\n",
    "            indices.append(same_indices + temp_indices)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6686da0e-84c5-424d-8dfd-09012c0efbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndicesWithoutLabel(all_indices, labeled_indices):\n",
    "    temp = all_indices\n",
    "    for indices in labeled_indices:\n",
    "        temp = [x for x in temp if x not in indices]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b26c676e-4d91-4f86-b6a6-bb92649dec76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 8\n",
    "p = 20\n",
    "k2 = round((n * p/100))\n",
    "k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "23a7f6e2-c95a-4ce9-ae8c-73c060a46fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 72, 97, 8, 32, 15, 63, 97, 57, 60],\n",
       " [17, 72, 97, 8, 32, 83, 48, 26, 12, 62],\n",
       " [17, 72, 97, 8, 32, 3, 49, 55, 77, 97]]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "k = 5\n",
    "all_indices = [x for x in range(100)]\n",
    "experten = [1, 2, 3]\n",
    "indices = sampleIndices(n, k, all_indices, experten, 1)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8a523a42-3008-492d-adc0-3eb52401a968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee320d59-3914-41a2-a6e6-2c7f35602862",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 30,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 84,\n",
       " 86,\n",
       " 88,\n",
       " 89,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getIndicesWithoutLabel(all_indices, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2475f6b3-dbf1-4639-926c-7c6974201b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, 2], [3, 4]]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ccade3-66a2-494a-97f2-908d1c80d534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1dc468-49bf-4a1d-a004-d98562402b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0901d42-8b04-4a5b-b856-cf9d305d4b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Expert:\n",
    "    def __init__(self, dataset, labeler_id, modus=\"perfect\", param=None, nLabels=800, prob=0.5):\n",
    "        self.labelerId = labeler_id\n",
    "        self.dataset = dataset\n",
    "        self.data = dataset.getData()[[\"Image ID\", str(self.labelerId)]]\n",
    "        self.nLabels = nLabels\n",
    "        self.param = param\n",
    "        self.prob = prob\n",
    "        self.modus = modus\n",
    "\n",
    "        if self.modus == \"perfect\":\n",
    "            self.predictions = self.data.values.flatten()\n",
    "\n",
    "    def predict(self, img, target, fnames):\n",
    "        \"\"\"\n",
    "        img: the input image\n",
    "        target: the GT label\n",
    "        fname: filename (id for the image)\n",
    "        \"\"\"\n",
    "        return np.array([self.predictions[self.predictions[:, 0] == image_id][:, 1] for image_id in fnames]).ravel()\n",
    "\n",
    "    def setModel(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def predictModel(self, img, target, fnames):\n",
    "        if len(img.shape) == 3:\n",
    "            img = img.unsqueeze(0) \n",
    "        outputs = self.model(img)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        return predicted\n",
    "    \n",
    "    def predictImage(self, img):\n",
    "        return self.predictModel(img, None, None)\n",
    "    \n",
    "    def getModel(self):\n",
    "        return self.model\n",
    "    \n",
    "    def saveModel(self, path, name):\n",
    "        torch.save(self.model, path + \"/\" + name + \"_\" + str(self.labeler_id))\n",
    "        \n",
    "    def loadModel(self, path, name):\n",
    "        self.model = torch.load(path + \"/\" + name + \"_\" + str(self.labeler_id))\n",
    "        self.model.eval()\n",
    "        \n",
    "    def predictWithModel(self, img, target, filenames):\n",
    "        \"\"\"\n",
    "        Checks with the model if the expert would be correct\n",
    "        If it predicts 1 than it returns the true label\n",
    "        If it predicts 0 than is returns the opposite label\n",
    "        \"\"\"\n",
    "        predicted = self.predictModel(img, target, filenames)\n",
    "        result = []\n",
    "        targets = target.cpu().detach().numpy()\n",
    "        for i, pred in enumerate(predicted):\n",
    "            if pred == 1:\n",
    "                result.append(targets[i])\n",
    "            else:\n",
    "                result.append(0 if targets[i] == 1 else 1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09dd87-e8e5-4a4c-a585-680e525eac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIHExpertDatasetMemory(Dataset):\n",
    "    def __init__(self, images, filenames, targets, expert_fn, labeled, indices=None, expert_preds=None, param=None):\n",
    "        \"\"\"\n",
    "        Original CIFAR dataset\n",
    "        images: images\n",
    "        filenames: filenames\n",
    "        targets: labels\n",
    "        expert_fn: expert function\n",
    "        labeled: indicator array if images are labeled\n",
    "        indices: indices in the original CIFAR dataset (if this subset is subsampled)\n",
    "        expert_preds: used if expert_fn or have different expert model\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.filenames = filenames\n",
    "        self.targets = torch.tensor(targets)\n",
    "        self.expert_fn = expert_fn\n",
    "        self.labeled = torch.tensor(labeled)\n",
    "        \n",
    "        self.image_ids = filenames\n",
    "        self.preload = False\n",
    "        self.PATH = param[\"PATH\"]\n",
    "        \n",
    "        normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3]],\n",
    "                                         std=[x / 255.0 for x in [63.0]])\n",
    "        self.transform_test = transforms.Compose([transforms.Resize(128), transforms.ToTensor(), normalize])\n",
    "        \n",
    "        if expert_preds is not None:\n",
    "            self.expert_preds = torch.tensor(expert_preds)\n",
    "        else:\n",
    "            self.expert_preds = torch.tensor(expert_fn(self.images, torch.FloatTensor(targets), fnames=self.filenames))\n",
    "            \n",
    "        self.expert_preds[~self.labeled.bool()] = -1  # Set expert predictions to -1 for unlabeled images\n",
    "        \n",
    "        if indices is not None:\n",
    "            self.indices = torch.tensor(indices)\n",
    "        else:\n",
    "            self.indices = torch.arange(len(self.targets))\n",
    "            \n",
    "    def load_image(self, idx):\n",
    "        \"\"\"\n",
    "        Load a single image\n",
    "        \"\"\"\n",
    "        return Image.open(os.path.join(self.PATH, \"images\", self.image_ids[idx])).convert(\"RGB\").resize((244, 244))\n",
    "            \n",
    "    def get_image(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the image at index idx\n",
    "        \"\"\"\n",
    "        if self.preload:\n",
    "            return self.images[idx]\n",
    "        else:\n",
    "            return self.load_image(idx)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Take the index of an item and return the image, label, expert prediction, and index in the original dataset\"\"\"\n",
    "        label = self.targets[index]\n",
    "        img = self.get_image(index)\n",
    "        image = self.transform_test(img)\n",
    "        filename = self.filenames[index]\n",
    "        expert_pred = self.expert_preds[index]\n",
    "        indice = self.indices[index]\n",
    "        labeled = self.labeled[index]\n",
    "        return image, label, expert_pred, indice, labeled, filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790023b3-bb28-451b-8108-54968448b98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f23a6e-8819-4474-b57b-f6d668c3c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, expert_fns, loss_fn, n_classes, data_loader, config, print_m=True):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "\n",
    "    expert_correct_dic = {k: 0 for k in range(len(expert_fns))}\n",
    "    expert_total_dic = {k: 0 for k in range(len(expert_fns))}\n",
    "\n",
    "    alpha = config[\"alpha\"]\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, hpred in data_loader:\n",
    "            images, labels, hpred = images.to(device), labels.to(device), hpred\n",
    "\n",
    "            outputs = model(images)\n",
    "            if config[\"loss_type\"] == \"softmax\":\n",
    "                outputs = F.softmax(outputs, dim=1)\n",
    "            elif config[\"loss_type\"] == \"ova\":\n",
    "                outputs = F.sigmoid(outputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_size = outputs.size(0)\n",
    "\n",
    "            expert_predictions = []\n",
    "            collection_Ms = []\n",
    "\n",
    "            for i, fn in enumerate(expert_fns):\n",
    "                exp_prediction1 = fn(images, labels, hpred)\n",
    "\n",
    "                m = torch.tensor([1 if pred == label.item() else 0 for pred, label in zip(exp_prediction1, labels)])\n",
    "                m2 = torch.tensor([alpha if pred == label.item() else 1 for pred, label in zip(exp_prediction1, labels)])\n",
    "\n",
    "                collection_Ms.append((m.to(device), m2.to(device)))\n",
    "                expert_predictions.append(exp_prediction1)\n",
    "\n",
    "            loss = loss_fn(outputs, labels, collection_Ms, n_classes)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                predicted_i = predicted[i].item()\n",
    "                if predicted_i >= n_classes - len(expert_fns):\n",
    "                    max_idx = 0\n",
    "                    for j in range(n_classes - len(expert_fns)):\n",
    "                        if outputs.data[i][j] >= outputs.data[i][max_idx]:\n",
    "                            max_idx = j\n",
    "                    prediction = max_idx\n",
    "                else:\n",
    "                    prediction = predicted_i\n",
    "\n",
    "                alone_correct += (prediction == labels[i]).item()\n",
    "\n",
    "                if prediction == labels[i].item():\n",
    "                    total += 1\n",
    "                    correct += 1\n",
    "                    correct_sys += 1\n",
    "                elif predicted_i >= n_classes - len(expert_fns):\n",
    "                    deferred_exp = predicted_i - (n_classes - len(expert_fns))\n",
    "                    exp_prediction = expert_predictions[deferred_exp][i]\n",
    "                    exp += (exp_prediction == labels[i].item())\n",
    "                    exp_total += 1\n",
    "\n",
    "                    expert_correct_dic[deferred_exp] += (exp_prediction == labels[i].item())\n",
    "                    expert_total_dic[deferred_exp] += 1\n",
    "\n",
    "                    correct_sys += (exp_prediction == labels[i].item())\n",
    "\n",
    "                real_total += 1\n",
    "\n",
    "    cov = f\"{total} out of {real_total}\"\n",
    "\n",
    "    expert_accuracies = {\n",
    "        f\"expert_{k}\": 100 * expert_correct_dic[k] / (expert_total_dic[k] + 0.0002)\n",
    "        for k in range(len(expert_fns))\n",
    "    }\n",
    "\n",
    "    to_print = {\n",
    "        \"coverage\": cov,\n",
    "        \"system_accuracy\": 100 * correct_sys / real_total,\n",
    "        \"expert_accuracy\": 100 * exp / (exp_total + 0.0002),\n",
    "        \"classifier_accuracy\": 100 * correct / (total + 0.0001),\n",
    "        \"alone_classifier\": 100 * alone_correct / real_total,\n",
    "        \"validation_loss\": np.average(losses),\n",
    "        \"n_experts\": len(expert_fns),\n",
    "        **expert_accuracies,\n",
    "    }\n",
    "\n",
    "    if print_m:\n",
    "        print(to_print, flush=True)\n",
    "\n",
    "    to_print[\"cov_classifier\"] = total\n",
    "    return to_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3accb-2e59-4225-9dd9-6d52f65b273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    iters,\n",
    "    warmup_iters,\n",
    "    lrate,\n",
    "    train_loader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    epoch,\n",
    "    expert_fns,\n",
    "    loss_fn,\n",
    "    n_classes,\n",
    "    alpha,\n",
    "    config,\n",
    "):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    epoch_train_loss = []\n",
    "\n",
    "    for i, (input, target, hpred) in enumerate(train_loader):\n",
    "        if iters < warmup_iters:\n",
    "            lr = lrate * float(iters) / warmup_iters\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "\n",
    "        target = target.to(device)\n",
    "        input = input.to(device)\n",
    "        hpred = hpred.to(device)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "\n",
    "        if config[\"loss_type\"] == \"softmax\":\n",
    "            output = F.softmax(output, dim=1)\n",
    "\n",
    "        # get expert predictions and costs\n",
    "        batch_size = output.size(0)\n",
    "        collection_Ms = []\n",
    "\n",
    "        for _, fn in enumerate(expert_fns):\n",
    "            m = fn(input, target, hpred)\n",
    "            m2 = torch.where(m == target, alpha, 1)\n",
    "            m = torch.where(m == target, 1, 0)\n",
    "            collection_Ms.append((m.to(device), m2.to(device)))\n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_fn(output, target, collection_Ms, n_classes)\n",
    "        epoch_train_loss.append(loss.item())\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if not iters < warmup_iters:\n",
    "            scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        iters += 1\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}]\\t\"\n",
    "                \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
    "                \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
    "                \"Prec@1 {top1.val:.3f} ({top1.avg:.3f})\".format(\n",
    "                    epoch,\n",
    "                    i,\n",
    "                    len(train_loader),\n",
    "                    batch_time=batch_time,\n",
    "                    loss=losses,\n",
    "                    top1=top1,\n",
    "                ),\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    return iters, np.average(epoch_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34235635-fb19-47fa-9cc6-0499afce1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert:\n",
    "    def __init__(self, dataset, labeler_id, modus=\"perfect\", param=None, nLabels=800, prob=0.5):\n",
    "        self.labelerId = labeler_id\n",
    "        self.dataset = dataset\n",
    "        self.data = dataset.getData()[[\"Image ID\", str(self.labelerId)]]\n",
    "        self.nLabels = nLabels\n",
    "        self.param = param\n",
    "        self.prob = prob\n",
    "        self.modus = modus\n",
    "\n",
    "        if self.modus == \"perfect\":\n",
    "            self.predictions = self.data\n",
    "\n",
    "    def predict(self, img, target, fnames):\n",
    "        \"\"\"\n",
    "        img: the input image\n",
    "        target: the GT label\n",
    "        fname: filename (id for the image)\n",
    "        \"\"\"\n",
    "        return np.array([self.predictions.loc[self.predictions[\"Image ID\"] == image_id, str(self.labelerId)].values[0] for image_id in fnames])\n",
    "\n",
    "    def setModel(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predictModel(self, img, target, fnames):\n",
    "        if img.dim() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(img)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "        return predicted.numpy()\n",
    "\n",
    "    def predictImage(self, img):\n",
    "        return self.predictModel(img, None, None)\n",
    "\n",
    "    def getModel(self):\n",
    "        return self.model\n",
    "\n",
    "    def saveModel(self, path, name):\n",
    "        torch.save(self.model, path + \"/\" + name + \"_\" + str(self.labelerId))\n",
    "\n",
    "    def loadModel(self, path, name):\n",
    "        self.model = torch.load(path + \"/\" + name + \"_\" + str(self.labelerId))\n",
    "        self.model.eval()\n",
    "\n",
    "    def predictWithModel(self, img, target, filename):\n",
    "        \"\"\"\n",
    "        Checks with the model if the expert would be correct\n",
    "        If it predicts 1 than it returns the true label\n",
    "        If it predicts 0 than it returns the opposite label\n",
    "        \"\"\"\n",
    "        predicted = self.predictModel(img, target, filename)\n",
    "        result = []\n",
    "        for pred, gt in zip(predicted, target.cpu().detach().numpy()):\n",
    "            if pred == 1:\n",
    "                result.append(gt)\n",
    "            else:\n",
    "                result.append(1 - gt)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301aa707-4b16-4d2c-b8a1-fe98da00487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_expert_confidence(train_loader, model, optimizer, scheduler, epoch, apply_softmax, param=None, id=\"\"):\n",
    "    \"\"\"Train for one epoch the model to predict expert agreement with label\"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for i, (input, label, expert_pred, _, _, filenames) in enumerate(train_loader):\n",
    "        expert_pred = expert_pred.long()\n",
    "        expert_pred = (expert_pred == label).float()\n",
    "        target = expert_pred.to(device)\n",
    "        input = input.to(device)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "\n",
    "        # compute loss\n",
    "        if apply_softmax:\n",
    "            loss = my_CrossEntropyLossWithSoftmax(output, target)\n",
    "        else:\n",
    "            loss = my_CrossEntropyLoss(output, target, cost=param[\"COST\"])\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                loss=losses, top1=top1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e66b7-73c5-452d-b42d-185ec82a5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_print_expert(model, data_loader, defer_net=False, id=0, seed=None, fold=None, n_images=None, test=False):\n",
    "    '''\n",
    "    Computes metrics for expert model error prediction\n",
    "    model: model\n",
    "    data_loader: data loader\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    label_list = []\n",
    "    predictions_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, label, expert_pred, _, _, filenames in data_loader:\n",
    "            expert_pred = expert_pred.long()\n",
    "            expert_pred = (expert_pred == label).float()\n",
    "            images, labels = images.to(device), expert_pred.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "\n",
    "            label_list.extend(labels.cpu().numpy())\n",
    "            predictions_list.extend(predictions.cpu().numpy())\n",
    "    \n",
    "    label_list = np.array(label_list)\n",
    "    predictions_list = np.array(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504352c-22b7-4aea-a01b-8756524969aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIHExpertDatasetMemory():\n",
    "    def __init__(self, images, filenames, targets, expert_fn, labeled, indices = None, expert_preds = None, param=None, preload=False, preprocess=True, image_container=None):\n",
    "        \"\"\"\n",
    "        Original cifar dataset\n",
    "        images: images\n",
    "        targets: labels\n",
    "        expert_fn: expert function\n",
    "        labeled: indicator array if images is labeled\n",
    "        indices: indices in original CIFAR dataset (if this subset is subsampled)\n",
    "        expert_preds: used if expert_fn or have different expert model\n",
    "        \"\"\"\n",
    "        self.preprocess = preprocess\n",
    "        self.filenames = filenames\n",
    "        self.targets = np.array(targets)\n",
    "        self.expert_fn = expert_fn\n",
    "        self.labeled = np.array(labeled)\n",
    "        \n",
    "        self.image_ids = filenames\n",
    "        self.preload = False\n",
    "        self.PATH = param[\"PATH\"]\n",
    "        \n",
    "        normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3]],\n",
    "                                         std=[x / 255.0 for x in [63.0]])\n",
    "        self.transform_test = transforms.Compose([transforms.Resize(128), transforms.ToTensor(), normalize])\n",
    "\n",
    "        self.image_container = image_container\n",
    "\n",
    "        self.images = images\n",
    "        if images is not None:\n",
    "            self.images = images\n",
    "            self.preload = True\n",
    "        else:\n",
    "            self.preload = preload\n",
    "            if self.preload:\n",
    "                self.images = []\n",
    "                self.loadImages()\n",
    "        \n",
    "        if expert_preds is not None:\n",
    "            self.expert_preds = expert_preds\n",
    "        else:\n",
    "            self.expert_preds = np.array(expert_fn(self.images, torch.FloatTensor(targets), fnames = self.filenames))\n",
    "        for i in range(len(self.expert_preds)):\n",
    "            if self.labeled[i] == 0:\n",
    "                self.expert_preds[i] = -1 # not labeled by expert\n",
    "        if indices is not None:\n",
    "            self.indices = indices\n",
    "        else:\n",
    "            self.indices = np.array(list(range(len(self.targets))))\n",
    "            \n",
    "    def loadImage(self, idx):\n",
    "        \"\"\"\n",
    "        Load one single image\n",
    "        \"\"\"\n",
    "        if self.image_container is not None:\n",
    "            return self.image_container.get_image_from_name(self.image_ids[idx])\n",
    "        else:\n",
    "            return Image.open(self.PATH + \"images/\" + self.image_ids[idx]).convert(\"RGB\").resize((244,244))\n",
    "            \n",
    "    def getImage(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the image from index idx\n",
    "        \"\"\"\n",
    "        if self.preload:\n",
    "            return self.images[idx]\n",
    "        else:\n",
    "            return self.loadImage(idx)\n",
    "\n",
    "    def loadImages(self):\n",
    "        \"\"\"\n",
    "        Load all images\n",
    "        \"\"\"\n",
    "        if self.image_container is not None:\n",
    "            self.images = self.image_container.get_images_from_name(self.image_ids)\n",
    "            if self.preprocess:\n",
    "                self.images = [self.transformImage(img) for img in self.images]\n",
    "        else:\n",
    "            for idx in range(len(self.image_ids)):\n",
    "                if self.preprocess:\n",
    "                    self.images.append(self.transformImage(self.loadImage(idx)))\n",
    "                else:\n",
    "                    self.images.append(self.loadImage(idx))\n",
    "\n",
    "    def transformImage(self, img):\n",
    "        return self.transform_test(img)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Take the index of item and returns the image, label, expert prediction and index in original dataset\"\"\"\n",
    "        label = self.targets[index]\n",
    "        img = self.getImage(index)\n",
    "        if self.preprocess:\n",
    "            image = img\n",
    "        else:\n",
    "            image = self.transform_test(img)\n",
    "        #image = self.transform_test(self.images[index])\n",
    "        filename = self.filenames[index]\n",
    "        expert_pred = self.expert_preds[index]\n",
    "        indice = self.indices[index]\n",
    "        labeled = self.labeled[index]\n",
    "        return torch.FloatTensor(image), label, expert_pred, indice, labeled, filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd632b3-31d7-47a4-bd15-4fa716828599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b2dfa-f686-47d9-b74d-7433e09cd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_predictions(self, train_dataloader):\n",
    "    for i, (input, target, hpred) in enumerate(train_dataloader):\n",
    "        result = self.predictWithModel(input, target, hpred)\n",
    "        self.prebuild_predictions += result\n",
    "        self.prebuild_filenames += hpred\n",
    "    \n",
    "def predict_model_predefined(self, img, target, filenames):\n",
    "    return [self.prebuild_predictions[self.prebuild_filenames.index(filename)] for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6949e-5c04-447e-bf38-7cc28049f148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c4393d1-d9d3-4d6f-8df6-26b0ab13d52e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prebuild_predictions = []\n",
    "prebuild_filenames = []\n",
    "for i in range(10):\n",
    "    result = [j for j in range(i)]\n",
    "    prebuild_predictions += result\n",
    "    prebuild_filenames += [str(j*100) for j in range(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc0a707a-31ae-4b5f-ae11-555232ca04c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_model_predefined(img, target, filenames):\n",
    "    return [prebuild_predictions[prebuild_filenames.index(filename)] for filename in filenames]\n",
    "\n",
    "predict_model_predefined(None, None, [\"100\", \"200\", \"300\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce064677-235d-42a3-8342-cb9d1ffe8622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fb1839-8b4a-4030-a72e-ad7cf0d1b196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num</th>\n",
       "      <th>Text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num  Text   \n",
       "0    1     2  3\n",
       "1    1     1  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, 2, 3], [1, 1, 1]], columns=[\"Num\", \"Text\", \"\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cad0ec1-f5c2-4a26-b021-5c36aab6de7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0af555bb-741a-4e15-85a2-dd6fbdc6a7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "Name: Text, dtype: category\n",
       "Categories (2, int64): [1, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca951db5-85a8-4afb-b941-5bbaa5a612d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joli-env_kernel",
   "language": "python",
   "name": "joli-env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
