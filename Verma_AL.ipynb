{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe97cdf-2ce6-44f8-9cc4-286ee98c54f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/joli/joli-env/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "\n",
    "import sklearn\n",
    "import copy\n",
    "\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390d926d-f1be-4655-9384-aef0905db0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Verma.main_increase_experts_hard_coded as verm\n",
    "import Verma.experts as vexp\n",
    "import Verma.losses as vlos\n",
    "from Verma.utils import AverageMeter, accuracy\n",
    "import Verma.resnet50 as vres\n",
    "from AL.utils import *\n",
    "from AL.metrics import *\n",
    "from AL.neural_network import NetSimple\n",
    "\n",
    "import NIH.Dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51330197-0c1a-4b7b-ac19-5f83fdbb3411",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"AL\": { #Parameter for Active Learning\n",
    "        \"INITIAL_SIZE\": 32, #\n",
    "        \"EPOCH_TRAIN\": 8, #\n",
    "        \"n_dataset\": 2, #Number Classes\n",
    "        \"BATCH_SIZE\": 8,\n",
    "        \"MAX_ROUNDS\": 4,\n",
    "        \"BATCH_SIZE_AL\": 8,\n",
    "        \"EPOCHS_DEFER\": 5,\n",
    "        \"COST\": (7, 0), #Cost for Cost sensitiv learning\n",
    "        \"TRAIN REJECTOR\": True,\n",
    "    },\n",
    "    \"L2D\": { # Parameter for Learning to defer\n",
    "        \"maxLabels\": 16,\n",
    "    },\n",
    "    \"TARGET\": \"Airspace_Opacity\",\n",
    "    \"PATH\": \"../Datasets/NIH/\",\n",
    "    \"K\": 10, #Number of folds\n",
    "    \"LABELER_IDS\": [4323195249, 4295232296],\n",
    "    \n",
    "    \"batch_size\": 64,\n",
    "    \"alpha\": 1.0, #scaling parameter for the loss function, default=1.0\n",
    "    \"epochs\": 150,\n",
    "    \"patience\": 50, #number of patience steps for early stopping the training\n",
    "    \"expert_type\": \"MLPMixer\", #specify the expert type. For the type of experts available, see-> models -> experts. defualt=predict\n",
    "    \"n_classes\": 2, #K for K class classification\n",
    "    \"k\": 0, #\n",
    "    \"n_experts\": 2, #\n",
    "    \"lr\": 0.001, #learning rate\n",
    "    \"weight_decay\": 5e-4, #\n",
    "    \"warmup_epochs\": 5, #\n",
    "    \"loss_type\": \"softmax\", #surrogate loss type for learning to defer\n",
    "    \"ckp_dir\": \"./Models\", #directory name to save the checkpoints\n",
    "    \"experiment_name\": \"multiple_experts\", #specify the experiment name. Checkpoints will be saved with this name\n",
    "    #\n",
    "    \"TRAIN_BATCH_SIZE\": 64,\n",
    "    \"TEST_BATCH_SIZE\": 64,\n",
    "    \"NUM_EXPERTS\": 2,\n",
    "\n",
    "    \"GT\": True, # Determines if the classifier gets all data with GT Label or only the labeld data\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db687a4-4af0-4fc0-81f7-78636323af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec342940-c404-40d9-aa4e-b10a102f569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert:\n",
    "    def __init__(self, dataset, labeler_id, modus=\"perfect\", param=None, nLabels=800, prob=0.5):\n",
    "        self.labelerId = labeler_id\n",
    "        self.dataset = dataset\n",
    "        self.data = dataset.getData()[[\"Image ID\", str(self.labelerId)]]\n",
    "        self.nLabels = nLabels\n",
    "        self.param = param\n",
    "        self.prob = prob\n",
    "        self.modus = modus\n",
    "\n",
    "        if self.modus == \"perfect\":\n",
    "            self.predictions = self.data\n",
    "\n",
    "    def predict(self, img, target, fnames):\n",
    "        \"\"\"\n",
    "        img: the input image\n",
    "        target: the GT label\n",
    "        fname: filename (id for the image)\n",
    "        \"\"\"\n",
    "        return np.array([self.predictions[self.predictions[\"Image ID\"] == image_id][str(self.labelerId)].values for image_id in fnames]).ravel()\n",
    "\n",
    "    def setModel(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def predictModel(self, img, target, fnames):\n",
    "        if len(img.shape) == 3:\n",
    "            img = img.unsqueeze(0) \n",
    "        outputs = self.model(img)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        return predicted\n",
    "    \n",
    "    def predictImage(self, img):\n",
    "        return self.predictModel(img, None, None)\n",
    "    \n",
    "    def getModel(self):\n",
    "        return self.model\n",
    "    \n",
    "    def saveModel(self, path, name):\n",
    "        torch.save(self.model, PATH + \"/\" + name + \"_\" + str(labeler_id))\n",
    "        \n",
    "    def loadModel(self, path, name):\n",
    "        self.model = torch.load(path + \"/\" + name + \"_\" + str(labeler_id))\n",
    "        model.eval()\n",
    "        \n",
    "    def predictWithModel(self, img, target, filename):\n",
    "        \"\"\"\n",
    "        Checks with the model if the expert would be correct\n",
    "        If it predicts 1 than it returns the true label\n",
    "        If it predicts 0 than is returns the opposit label\n",
    "        \"\"\"\n",
    "        predicted = self.predictModel(img, target, filename)\n",
    "        result = []\n",
    "        for i, pred in enumerate(predicted):\n",
    "            if pred == 1:\n",
    "                result.append(target.cpu().detach().numpy()[i])\n",
    "            else:\n",
    "                if target.cpu().detach().numpy()[i] == 1:\n",
    "                    result.append(0)\n",
    "                else:\n",
    "                    result.append(1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3cd4c1-958c-43b8-9140-f7cbac04ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIHExpertDataset():\n",
    "    def __init__(self, images, filenames, targets, expert_fn, labeled, indices = None, expert_preds = None):\n",
    "        \"\"\"\n",
    "        Original cifar dataset\n",
    "        images: images\n",
    "        targets: labels\n",
    "        expert_fn: expert function\n",
    "        labeled: indicator array if images is labeled\n",
    "        indices: indices in original CIFAR dataset (if this subset is subsampled)\n",
    "        expert_preds: used if expert_fn or have different expert model\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.filenames = filenames\n",
    "        self.targets = np.array(targets)\n",
    "        self.expert_fn = expert_fn\n",
    "        self.labeled = np.array(labeled)\n",
    "        normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3]],\n",
    "                                         std=[x / 255.0 for x in [63.0]])\n",
    "        self.transform_test = transforms.Compose([transforms.Resize(128),transforms.ToTensor(), normalize])\n",
    "        if expert_preds is not None:\n",
    "            self.expert_preds = expert_preds\n",
    "        else:\n",
    "            self.expert_preds = np.array(expert_fn(self.images, torch.FloatTensor(targets), self.filenames))\n",
    "        for i in range(len(self.expert_preds)):\n",
    "            if self.labeled[i] == 0:\n",
    "                self.expert_preds[i] = -1 # not labeled by expert\n",
    "        if indices is not None:\n",
    "            self.indices = indices\n",
    "        else:\n",
    "            self.indices = np.array(list(range(len(self.targets))))\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Take the index of item and returns the image, label, expert prediction and index in original dataset\"\"\"\n",
    "        label = self.targets[index]\n",
    "        image = self.transform_test(self.images[index])\n",
    "        filename = self.filenames[index]\n",
    "        expert_pred = self.expert_preds[index]\n",
    "        indice = self.indices[index]\n",
    "        labeled = self.labeled[index]\n",
    "        return torch.FloatTensor(image), label, expert_pred, indice, labeled\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "class NIHExpertDatasetMemory():\n",
    "    def __init__(self, images, filenames, targets, expert_fn, labeled, indices = None, expert_preds = None, param=None):\n",
    "        \"\"\"\n",
    "        Original cifar dataset\n",
    "        images: images\n",
    "        targets: labels\n",
    "        expert_fn: expert function\n",
    "        labeled: indicator array if images is labeled\n",
    "        indices: indices in original CIFAR dataset (if this subset is subsampled)\n",
    "        expert_preds: used if expert_fn or have different expert model\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.filenames = filenames\n",
    "        self.targets = np.array(targets)\n",
    "        self.expert_fn = expert_fn\n",
    "        self.labeled = np.array(labeled)\n",
    "        \n",
    "        self.image_ids = filenames\n",
    "        self.preload = False\n",
    "        self.PATH = param[\"PATH\"]\n",
    "        \n",
    "        normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3]],\n",
    "                                         std=[x / 255.0 for x in [63.0]])\n",
    "        self.transform_test = transforms.Compose([transforms.Resize(128), transforms.ToTensor(), normalize])\n",
    "        if expert_preds is not None:\n",
    "            self.expert_preds = expert_preds\n",
    "        else:\n",
    "            self.expert_preds = np.array(expert_fn(self.images, torch.FloatTensor(targets), fnames = self.filenames))\n",
    "        for i in range(len(self.expert_preds)):\n",
    "            if self.labeled[i] == 0:\n",
    "                self.expert_preds[i] = -1 # not labeled by expert\n",
    "        if indices is not None:\n",
    "            self.indices = indices\n",
    "        else:\n",
    "            self.indices = np.array(list(range(len(self.targets))))\n",
    "            \n",
    "    def loadImage(self, idx):\n",
    "        \"\"\"\n",
    "        Load one single image\n",
    "        \"\"\"\n",
    "        return Image.open(self.PATH + \"images/\" + self.image_ids[idx]).convert(\"RGB\").resize((244,244))\n",
    "            \n",
    "    def getImage(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the image from index idx\n",
    "        \"\"\"\n",
    "        if self.preload:\n",
    "            return self.images[idx]\n",
    "        else:\n",
    "            return self.loadImage(idx)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Take the index of item and returns the image, label, expert prediction and index in original dataset\"\"\"\n",
    "        label = self.targets[index]\n",
    "        img = self.getImage(index)\n",
    "        image = self.transform_test(img)\n",
    "        #image = self.transform_test(self.images[index])\n",
    "        filename = self.filenames[index]\n",
    "        expert_pred = self.expert_preds[index]\n",
    "        indice = self.indices[index]\n",
    "        labeled = self.labeled[index]\n",
    "        return torch.FloatTensor(image), label, expert_pred, indice, labeled, filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dee1822-e167-4210-9ffd-c6853de04441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "def get_least_confident_points(model, data_loader, budget):\n",
    "    '''\n",
    "    based on entropy score get points, can chagnge, but make sure to get max or min accordingly\n",
    "    '''\n",
    "    uncertainty_estimates = []\n",
    "    indices_all = []\n",
    "    for data in data_loader:\n",
    "        images, labels, expert_preds, indices, _, filenames = data\n",
    "        images, labels, expert_preds = images.to(device), labels.to(device), expert_preds.to(device)\n",
    "        outputs = model(images)\n",
    "        batch_size = outputs.size()[0]  \n",
    "        for i in range(0, batch_size):\n",
    "            output_i =  outputs.data[i].cpu().numpy()\n",
    "            entropy_i = entropy(output_i)\n",
    "            #entropy_i = 1 - max(output_i)\n",
    "            uncertainty_estimates.append(entropy_i)\n",
    "            indices_all.append(indices[i].item())\n",
    "    indices_all = np.array(indices_all)\n",
    "    top_budget_indices = np.argsort(uncertainty_estimates)[-budget:]\n",
    "    actual_indices = indices_all[top_budget_indices]\n",
    "    uncertainty_estimates = np.array(uncertainty_estimates)\n",
    "    return actual_indices\n",
    "\n",
    "\n",
    "\n",
    "#for trial in range(MAX_TRIALS):\n",
    "def getExpertModel(train_dataset, val_dataset, test_dataset, expert, param=None):\n",
    "    \n",
    "    error_confidence_trials_LCE = []\n",
    "    \n",
    "    # initialize data, Erhält alle Indizes der Daten\n",
    "    all_indices = list(range(len(train_dataset.getAllIndices())))\n",
    "    train_dataset.getAllImagesNP().shape\n",
    "    all_data_x = train_dataset.getAllImagesNP()[all_indices]\n",
    "    all_data_filenames = np.array(train_dataset.getAllFilenames())[all_indices]\n",
    "    all_data_y = np.array(train_dataset.getAllTargets())[all_indices]\n",
    "    \n",
    "    print(\"Complete first data generation\")\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Bestimmt die Indizes, welche gelabelt und welche ungelabelt sind\n",
    "    \n",
    "    Intial_random_set = random.sample(all_indices, param[\"INITIAL_SIZE\"])\n",
    "    indices_labeled  = Intial_random_set\n",
    "    indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Lädt die Datasets für die beschrifteten und unbeschrifteten Daten\n",
    "    dataset_train_labeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_labeled], all_data_y[indices_labeled], expert.predict , [1]*len(indices_labeled), indices_labeled, param=param)\n",
    "    dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param)\n",
    "    \n",
    "    \n",
    "    # Lädt die Dataloaders\n",
    "    dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=param[\"BATCH_SIZE\"], shuffle=True,  num_workers=0, pin_memory=False)\n",
    "    dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"BATCH_SIZE\"], shuffle=True,  num_workers=0, pin_memory=False)\n",
    "    \n",
    "    print(\"Complete dataloader generation\")\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # train expert model on labeled data\n",
    "    # Expertenmodell variabel\n",
    "    model_expert = NetSimple(2, 3, 100, 100, 1000,500).to(device)\n",
    "    # Trainier Modell um Experten vorherzusagen\n",
    "    \n",
    "    param_size = 0\n",
    "    for paramn in model_expert.parameters():\n",
    "        param_size += paramn.nelement() * paramn.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model_expert.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))\n",
    "    \n",
    "    run_expert(model_expert, param[\"EPOCH_TRAIN\"], dataLoaderTrainLabeled, dataLoaderTrainLabeled, param=param) \n",
    "    \n",
    "    print(\"Expert trained\")\n",
    "\n",
    "    \n",
    "\n",
    "    data_sizes = []\n",
    "    error_confidence = []\n",
    "    data_sizes.append(param[\"INITIAL_SIZE\"])\n",
    "\n",
    "    #Trainiere Rejector nur noch, wenn notwendig\n",
    "    if param[\"TRAIN REJECTOR\"]:\n",
    "        train_indices = list(range(len(train_dataset.getAllIndices())))\n",
    "        val_indices = list(range(len(val_dataset.getAllIndices())))\n",
    "        test_indices = list(range(len(test_dataset.getAllIndices())))\n",
    "\n",
    "        dataset_train = NIHExpertDatasetMemory(None, np.array(train_dataset.getAllFilenames()), np.array(train_dataset.getAllTargets()), expert.predict , [1]*len(train_indices), param=param)\n",
    "        dataset_val = NIHExpertDatasetMemory(None, np.array(val_dataset.getAllFilenames()), np.array(val_dataset.getAllTargets()), expert.predict , [1]*len(val_indices), param=param)\n",
    "        dataset_test = NIHExpertDatasetMemory(None, np.array(test_dataset.getAllFilenames()), np.array(test_dataset.getAllTargets()), expert.predict , [1]*len(test_indices), param=param)\n",
    "    \n",
    "        dataLoaderTrain = DataLoader(dataset=dataset_train, batch_size=param[\"BATCH_SIZE\"], shuffle=True,  num_workers=0, pin_memory=True)\n",
    "        dataLoaderVal = DataLoader(dataset=dataset_val, batch_size=param[\"BATCH_SIZE\"], shuffle=False,  num_workers=0, pin_memory=True)\n",
    "        dataLoaderTest = DataLoader(dataset=dataset_test, batch_size=param[\"BATCH_SIZE\"], shuffle=False,  num_workers=0, pin_memory=True)\n",
    "\n",
    "        # train model to do classification & Rejector\n",
    "        #model_lce = NetSimple(n_dataset + 1, 3, 100, 100, 1000,500).to(device)\n",
    "        model_lce = NetSimple(param[\"n_dataset\"] + 1, 3, 50, 50, 500,256).to(device)\n",
    "\n",
    "        ##Veränderung: Statt mit allen Daten zu trainieren, wird hier nur noch mit den verfügbaren Daten trainiert\n",
    "        if param[\"GT\"]: #Train with all data\n",
    "            run_reject_class(model_lce, param[\"EPOCH_TRAIN\"], dataLoaderTrain, dataLoaderVal)\n",
    "        else: #Train with only the labeled data\n",
    "            run_reject_class(model_lce, param[\"EPOCH_TRAIN\"], dataset_train_labeled, dataLoaderVal)\n",
    "\n",
    "        model_lce_saved = copy.deepcopy(model_lce.state_dict())\n",
    "\n",
    "        print(\"Classificator trained\")\n",
    "        \n",
    "    gc.collect()\n",
    "\n",
    "    #Trainiere Rejector nur noch, wenn notwendig\n",
    "    if param[\"TRAIN REJECTOR\"]:\n",
    "\n",
    "        # get expert model predictions on unlabeled data\n",
    "        dataLoaderTrainUnlabeledUnshuffled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"BATCH_SIZE\"], shuffle=False,  num_workers=0, pin_memory=True)\n",
    "        expert_preds_arr = []\n",
    "        for data in dataLoaderTrainUnlabeledUnshuffled:\n",
    "            images, labels, _, _, _, filenames = data\n",
    "            images = images.to(device)\n",
    "            outputs_exp = model_expert(images)\n",
    "            for i in range(outputs_exp.size()[0]):\n",
    "                #pred_exp = np.argmax(outputs_exp.data[i].cpu().numpy())\n",
    "                pred_exp = outputs_exp.data[i].cpu().numpy()\n",
    "                pred_exp = pred_exp[1]\n",
    "                expert_preds_arr.append(pred_exp)\n",
    "        expert_preds_unlabeled = np.array(expert_preds_arr)\n",
    "        expert_preds_labeled = np.array(expert.predict(all_data_x[indices_labeled], torch.FloatTensor(all_data_y[indices_labeled]), all_data_filenames[indices_labeled]))\n",
    "        expert_preds_labeled = ( expert_preds_labeled == all_data_y[indices_labeled]) * 1\n",
    "        expert_preds_combined = np.concatenate(( expert_preds_labeled, expert_preds_unlabeled))\n",
    "    \n",
    "        print(\"Got predictions for all data\")\n",
    "    \n",
    "        # create pseudo-labeled dataset\n",
    "        dataset_train_pseudolabeled = NIHExpertDatasetMemory(None, np.concatenate((all_data_filenames[indices_labeled], all_data_filenames[indices_unlabeled])), \n",
    "                                                             np.concatenate((all_data_y[indices_labeled] , all_data_y[indices_unlabeled])), \n",
    "                                                             expert.predict , [1]*(len(indices_labeled) + len(indices_unlabeled)), None,\n",
    "                                                             expert_preds_combined, param=param)\n",
    "    \n",
    "        dataLoaderTrainPseudoLabeled = DataLoader(dataset=dataset_train_pseudolabeled, batch_size=param[\"BATCH_SIZE\"], shuffle=True,  num_workers=0, pin_memory=True)\n",
    "        \n",
    "        # train model on pseudo-labeled data\n",
    "        run_reject_pseudo(model_lce, param[\"n_dataset\"], expert.predict, param[\"EPOCHS_DEFER\"], 1, dataLoaderTrainPseudoLabeled, dataLoaderTrainLabeled)\n",
    "    \n",
    "        print(\"Model with pseudo labels trained\")\n",
    "    \n",
    "        metrics_confidence = metrics_print(model_lce, expert.predict, param[\"n_dataset\"], dataLoaderTest)\n",
    "        error_confidence.append(metrics_confidence['system accuracy'])\n",
    "    \n",
    "    print(\"Starting with AL\")\n",
    "    for round in range(param[\"MAX_ROUNDS\"]):\n",
    "\n",
    "        print(f'\\n \\n Round {round} \\n \\n')\n",
    "\n",
    "        # get points where expert model is least confident on\n",
    "        #indices_confidence =  random.sample(indices_unlabeled, BATCH_SIZE_AL)\n",
    "        indices_confidence = get_least_confident_points(model_expert, dataLoaderTrainUnlabeled, param[\"BATCH_SIZE_AL\"])\n",
    "        indices_labeled  = indices_labeled + list(indices_confidence) \n",
    "        indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "        dataset_train_labeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_labeled], all_data_y[indices_labeled], expert.predict , [1]*len(indices_labeled), indices_labeled, param=param)\n",
    "        dataset_train_unlabeled = NIHExpertDatasetMemory(None, all_data_filenames[indices_unlabeled], all_data_y[indices_unlabeled], expert.predict , [0]*len(indices_unlabeled), indices_unlabeled, param=param)\n",
    "        \n",
    "        dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=param[\"BATCH_SIZE\"], shuffle=True,  num_workers=0, pin_memory=True)\n",
    "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"BATCH_SIZE\"], shuffle=True,  num_workers=0, pin_memory=True)\n",
    "        \n",
    "        # train model on labeled data\n",
    "        run_expert(model_expert, param[\"EPOCH_TRAIN\"], dataLoaderTrainLabeled, dataLoaderTrainLabeled, param=param)\n",
    "\n",
    "        #Trainiere Rejector nur noch, wenn notwendig\n",
    "        if param[\"TRAIN REJECTOR\"]:\n",
    "            model_lce.load_state_dict(model_lce_saved)\n",
    "        \n",
    "            # get expert predictions on unlabeled data\n",
    "            dataLoaderTrainUnlabeledUnshuffled = DataLoader(dataset=dataset_train_unlabeled, batch_size=param[\"BATCH_SIZE\"], shuffle=False,  num_workers=0, pin_memory=True)\n",
    "            expert_preds_arr = []\n",
    "            for data in dataLoaderTrainUnlabeledUnshuffled:\n",
    "                images, labels, _, _, _, filenames = data\n",
    "                images = images.to(device)\n",
    "                outputs_exp = model_expert(images)\n",
    "                for i in range(outputs_exp.size()[0]):\n",
    "                    #pred_exp = np.argmax(outputs_exp.data[i].cpu().numpy())\n",
    "                    pred_exp = outputs_exp.data[i].cpu().numpy()\n",
    "                    pred_exp = pred_exp[1]\n",
    "                    expert_preds_arr.append(pred_exp)\n",
    "            expert_preds_unlabeled = np.array(expert_preds_arr)\n",
    "            expert_preds_labeled = np.array(expert.predict (all_data_x[indices_labeled], torch.FloatTensor(all_data_y[indices_labeled]), all_data_filenames[indices_labeled]))\n",
    "            expert_preds_labeled = ( expert_preds_labeled == all_data_y[indices_labeled]) * 1\n",
    "            expert_preds_combined = np.concatenate(( expert_preds_labeled, expert_preds_unlabeled))\n",
    "            # create pseudo-labeled dataset\n",
    "        \n",
    "            dataset_train_pseudolabeled = NIHExpertDatasetMemory(None, np.concatenate((all_data_filenames[indices_labeled], all_data_filenames[indices_unlabeled])),\n",
    "                                                                 np.concatenate((all_data_y[indices_labeled] , all_data_y[indices_unlabeled])), \n",
    "                                                                 expert.predict , [1]*(len(indices_labeled) + len(indices_unlabeled)), None,\n",
    "                                                                 expert_preds_combined, param=param)\n",
    "        \n",
    "            dataLoaderTrainPseudoLabeled = DataLoader(dataset=dataset_train_pseudolabeled, batch_size=param[\"BATCH_SIZE\"], shuffle=True,  num_workers=0, pin_memory=True)\n",
    "\n",
    "            # train model on pseudo labeled data\n",
    "            best_score = 0\n",
    "            best_model = None\n",
    "            for alpha in [1]:\n",
    "                print(f'alpha {alpha}')\n",
    "                model_lce.load_state_dict(model_lce_saved)\n",
    "                model_dict_alpha = run_reject_pseudo(model_lce, param[\"n_dataset\"], expert.predict, param[\"EPOCHS_DEFER\"], 1, dataLoaderTrainPseudoLabeled, dataLoaderTest, True, param[\"EPOCHS_DEFER\"]-1)\n",
    "                model_lce.load_state_dict(model_dict_alpha)\n",
    "                score = metrics_print(model_lce, expert.predict, param[\"n_dataset\"], dataLoaderTest)['system accuracy']\n",
    "                if score >= best_score:\n",
    "                    best_score =  score\n",
    "                    best_model = model_dict_alpha\n",
    "            model_lce.load_state_dict(best_model)\n",
    "\n",
    "            #run_reject(model_lce, 10, Expert.predict, EPOCHS_DEFER, 1, dataLoaderTrainPseudoLabeled, dataLoaderTrainLabeled)\n",
    "            metrics_confidence = metrics_print(model_lce, expert.predict, param[\"n_dataset\"], dataLoaderTest)\n",
    "            error_confidence.append(metrics_confidence['system accuracy'])\n",
    "            data_sizes.append((round+1)*param[\"BATCH_SIZE_AL\"] + param[\"INITIAL_SIZE\"])\n",
    "    \n",
    "        error_confidence_trials_LCE.append(error_confidence)\n",
    "\n",
    "    print(\"AL finished\")\n",
    "    return model_expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a31ef22-2255-40c8-b139-988511547d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_expert_confidence(train_loader, model, optimizer, scheduler, epoch, apply_softmax, param=None):\n",
    "    \"\"\"Train for one epoch the model to predict expert agreement with label\"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, label, expert_pred, _, _, filenames ) in enumerate(train_loader):\n",
    "        #print(input)\n",
    "        #print(label)\n",
    "        expert_pred = expert_pred.long()\n",
    "        expert_pred = (expert_pred == label) *1\n",
    "        target = expert_pred.to(device)\n",
    "        input = input.to(device)\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "\n",
    "        # compute loss\n",
    "        \n",
    "        if apply_softmax:\n",
    "            loss = my_CrossEntropyLossWithSoftmax(output, target)\n",
    "        else:\n",
    "            #loss = my_CrossEntropyLoss(output, target)\n",
    "            loss = my_CrossEntropyLoss(output, target, cost=param[\"COST\"])\n",
    "        \n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                loss=losses, top1=top1))\n",
    "            \n",
    "\n",
    "def run_expert(model, epochs, train_loader, val_loader, apply_softmax = False, param=param):\n",
    "    '''\n",
    "    train expert model to predict disagreement with label\n",
    "    model: WideResNet model or pytorch model (2 outputs)\n",
    "    epochs: number of epochs to train\n",
    "    '''\n",
    "    # get the number of model parameters\n",
    "    print('Number of model parameters: {}'.format(\n",
    "        sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    #optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 0.001, #0.001\n",
    "                                momentum=0.9, nesterov=True,\n",
    "                                weight_decay=5e-4)\n",
    "    # cosine learning rate\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * epochs)\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        # train for one epoch\n",
    "        train_expert_confidence(train_loader, model, optimizer, scheduler, epoch, apply_softmax, param=param)\n",
    "        if epoch % 10 == 0:\n",
    "            metrics_print_expert(model, val_loader)\n",
    "            \n",
    "    metrics_print_expert(model, val_loader)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "515587c9-0cba-422f-af72-383907bd4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reject_class(model, epochs, train_loader, val_loader, apply_softmax = False):\n",
    "    '''\n",
    "    only train classifier\n",
    "    model: WideResNet model\n",
    "    epochs: number of epochs to train\n",
    "    train_loader:\n",
    "    val_loader:\n",
    "    apply_softmax: apply softmax on top of model\n",
    "    '''\n",
    "    # get the number of model parameters\n",
    "    print('Number of model parameters: {}'.format(\n",
    "        sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "\n",
    "\n",
    "    # cosine learning rate\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * epochs)\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        # train for one epoch\n",
    "        train_reject_class(train_loader, model, optimizer, scheduler, epoch, apply_softmax)\n",
    "        #if epoch % 10 == 0:\n",
    "            #metrics_print_classifier(model, val_loader)\n",
    "\n",
    "def train_reject_class(train_loader, model, optimizer, scheduler, epoch, apply_softmax):\n",
    "    \"\"\"Train for one epoch on the training set without deferral\n",
    "    apply_softmax: boolean to apply softmax, if model last layer doesn't have softmax \n",
    "    \"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target, expert, _, _, filenames ) in enumerate(train_loader):\n",
    "        target = target.to(device)\n",
    "        input = input.to(device)\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "\n",
    "        # compute loss\n",
    "        if apply_softmax:\n",
    "            loss = my_CrossEntropyLossWithSoftmax(output, target)\n",
    "        else:\n",
    "            loss = my_CrossEntropyLoss(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                loss=losses, top1=top1))\n",
    "\n",
    "def train_reject_pseudo(train_loader, model, optimizer, scheduler, epoch, n_classes, alpha = 1):\n",
    "    \"\"\"Train for one epoch on the training set with deferral with pseudo labels\"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target, expert, _, _, filenames ) in enumerate(train_loader):\n",
    "        target = target.to(device)\n",
    "        input = input.to(device)\n",
    "        m = expert.to(device)\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "\n",
    "        # get expert  predictions and costs\n",
    "        batch_size = output.size()[0]  # batch_size\n",
    "        m2 = [1] * batch_size * alpha\n",
    "\n",
    "        #m = torch.tensor(m)\n",
    "        m2 = torch.tensor(m2)\n",
    "        \n",
    "        m = m.clone().detach().requires_grad_(True)\n",
    "        #m2 = m2.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        m = m.to(device)\n",
    "        m2 = m2.to(device)\n",
    "        # done getting expert predictions and costs \n",
    "        # compute loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = reject_CrossEntropyLoss(output, m, target, m2, n_classes)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                loss=losses, top1=top1))\n",
    "\n",
    "\n",
    "def run_reject_pseudo(model, n_dataset, expert_fn, epochs, alpha, train_loader, val_loader, best_on_val = False, epoch_freq = 10):\n",
    "    '''\n",
    "    This trains the model with labeled and pseudo labeled data, same mechanics as run_reject\n",
    "    '''\n",
    "    # Data loading code\n",
    "   \n",
    "    # get the number of model parameters\n",
    "    print('Number of model parameters: {}'.format(\n",
    "        sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "    # for training on multiple GPUs.\n",
    "    # Use CUDA_VISIBLE_DEVICES=0,1 to specify which GPUs to use\n",
    "    # model = torch.nn.DataParallel(model).cuda()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "\n",
    "    # cosine learning rate\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * epochs)\n",
    "    \n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_val_score = 0\n",
    "    for epoch in range(0, epochs):\n",
    "        # train for one epoch\n",
    "        train_reject_pseudo(train_loader, model, optimizer, scheduler, epoch, n_dataset, alpha)\n",
    "        if epoch % epoch_freq == 0:\n",
    "            score = metrics_print(model, expert_fn, n_dataset, val_loader)['system accuracy']\n",
    "            if score > best_val_score:\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "    if best_on_val:\n",
    "        return  best_model \n",
    "    \n",
    "def reject_CrossEntropyLoss(outputs, m, labels, m2, n_classes):\n",
    "    '''\n",
    "    The L_{CE} loss implementation for CIFAR\n",
    "    ----\n",
    "    outputs: network outputs\n",
    "    m: cost of deferring to expert cost of classifier predicting (I_{m =y})\n",
    "    labels: target\n",
    "    m2:  cost of classifier predicting (alpha* I_{m\\neq y} + I_{m =y})\n",
    "    n_classes: number of classes\n",
    "    '''\n",
    "    batch_size = outputs.size()[0]  # batch_size\n",
    "    rc = [n_classes] * batch_size\n",
    "    outputs = -m * torch.log2(outputs[range(batch_size), rc]) - m2 * torch.log2(\n",
    "        outputs[range(batch_size), labels])  \n",
    "    return torch.mean(outputs)\n",
    "\n",
    "def metrics_print(net, expert_fn, n_classes, loader):\n",
    "    '''\n",
    "    Computes metrics for deferal (L_{CE} loss method)\n",
    "    -----\n",
    "    Arguments:\n",
    "    net: model\n",
    "    expert_fn: expert model\n",
    "    n_classes: number of classes\n",
    "    loader: data loader\n",
    "    '''\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    correct_pred = {classname: 0 for classname in cifar_classes}\n",
    "    total_pred = {classname: 0 for classname in cifar_classes}\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels, _, _ ,_, filenames = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_size = outputs.size()[0]  # batch_size\n",
    "            exp_prediction = expert_fn(images, labels, filenames)\n",
    "            for i in range(0, batch_size):\n",
    "                r = (predicted[i].item() == n_classes)\n",
    "                prediction = predicted[i]\n",
    "                final_pred = 0\n",
    "                if predicted[i] == n_classes:\n",
    "                    max_idx = 0\n",
    "                    # get second max\n",
    "                    for j in range(0, n_classes):\n",
    "                        if outputs.data[i][j] >= outputs.data[i][max_idx]:\n",
    "                            max_idx = j\n",
    "                    prediction = max_idx\n",
    "                else:\n",
    "                    prediction = predicted[i]\n",
    "                alone_correct += (prediction == labels[i]).item()\n",
    "                if r == 0:\n",
    "                    total += 1\n",
    "                    final_pred = predicted[i]\n",
    "                    correct += (predicted[i] == labels[i]).item()\n",
    "                    correct_sys += (predicted[i] == labels[i]).item()\n",
    "                if r == 1:\n",
    "                    final_pred = exp_prediction[i]\n",
    "                    exp += (exp_prediction[i] == labels[i].item())\n",
    "                    correct_sys += (exp_prediction[i] == labels[i].item())\n",
    "                    exp_total += 1\n",
    "                real_total += 1\n",
    "                if labels[i].item() == final_pred:\n",
    "                    correct_pred[cifar_classes[labels[i].item()]] += 1\n",
    "                total_pred[cifar_classes[labels[i].item()]] += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total) + str(\" are covered from classifier\")\n",
    "    to_print = {\"coverage\": cov, \"system accuracy\": 100 * correct_sys / real_total,\n",
    "                \"expert accuracy\": 100 * exp / (exp_total + 0.0002),\n",
    "                \"classifier accuracy\": 100 * correct / (total + 0.0001),\n",
    "                \"alone classifier (if ask every time)\": 100 * alone_correct / real_total, }\n",
    "    print(to_print)\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(\"Accuracy for class {:5s} is: {:.3f} %\".format(classname,\n",
    "                                                    accuracy))\n",
    "    return to_print\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def metrics_print_expert(model, data_loader, defer_net = False):\n",
    "    '''\n",
    "    Computes metrics for expert model error prediction\n",
    "    model: model\n",
    "    data_loader: data loader\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    label_list = np.empty(0)\n",
    "    predictions_list = np.empty(0)\n",
    "    # again no gradients needed\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, label, expert_pred, _ ,_, filenames = data\n",
    "            expert_pred = expert_pred.long()\n",
    "            expert_pred = (expert_pred == label) *1\n",
    "            images, labels = images.to(device), expert_pred.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs.data, 1) # maybe no .data\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            \n",
    "            label_list = np.concatenate((label_list, labels.cpu().numpy()), axis=0)\n",
    "            predictions_list = np.concatenate((predictions_list, predictions.cpu().numpy()), axis=0)\n",
    "\n",
    "    print('Accuracy of the network on the %d test images: %.3f %%' % (total,\n",
    "        100 * correct / total))\n",
    "    \n",
    "    tn, fp, fn, tp = sklearn.metrics.confusion_matrix(label_list, predictions_list).ravel()\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(sklearn.metrics.confusion_matrix(label_list, predictions_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5424a-e964-4e3a-b8b0-9aad35fda126",
   "metadata": {},
   "source": [
    "# Run Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d9e9309-2fd9-4947-955f-f5bfd6027b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76de2f6b-3158-4b3d-9038-8fd3c9690b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run = neptune.init_run(\\n    project=config_neptune[\"project\"],\\n    api_token=config_neptune[\"api_token\"],\\n    custom_run_id=\"AI\"\\n)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('neptune_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config_neptune = config[\"neptune\"]\n",
    "\"\"\"run = neptune.init_run(\n",
    "    project=config_neptune[\"project\"],\n",
    "    api_token=config_neptune[\"api_token\"],\n",
    "    custom_run_id=\"AI\"\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aad0c8ab-b875-42ea-83ed-543847afc570",
   "metadata": {},
   "outputs": [],
   "source": [
    "al_param = param[\"AL\"]\n",
    "al_param[\"PATH\"] = param[\"PATH\"]\n",
    "l2d_param = param[\"L2D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fba3560-e7ac-473a-8e61-2c33ec1239cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "basic_Dataset = ds.BasicDataset(param[\"PATH\"], param[\"TARGET\"])\n",
    "nih_dataloader = ds.NIH_K_Fold_Dataloader(\n",
    "            dataset = basic_Dataset,\n",
    "            k = param[\"K\"],\n",
    "            labelerIds = param[\"LABELER_IDS\"],\n",
    "            train_batch_size = param[\"TRAIN_BATCH_SIZE\"],\n",
    "            test_batch_size = param[\"TEST_BATCH_SIZE\"],\n",
    "            param = param\n",
    "        )\n",
    "expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(1)\n",
    "expert_train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param)\n",
    "expert_val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param)\n",
    "expert_test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdabcf74-7228-4f68-bfaa-29116ea23f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5667aef5-d269-4620-a1af-1d4d92cdb2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_expert = Expert(dataset = basic_Dataset, labeler_id=param[\"LABELER_IDS\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89bb507f-de1c-4ecd-8ca4-2cb9ef867b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#nih_expert.setModel(getExpertModel(expert_train_dataset, expert_val_dataset, expert_test_dataset, nih_expert, al_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32505732-0b05-4924-90be-759f4da4f8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "377705ad-823e-46f5-8da8-7e144d618816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, target, filename = next(iter(expert_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe0ede79-8a6a-47b7-bbae-0b350b6f2da7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(img.shape) == 3:\n",
    "    img = img.unsqueeze(0) \n",
    "outputs = nih_expert.model(img)\n",
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e35fdadd-2400-4b3b-a5e3-3e6b69aac7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, target, filename = next(iter(expert_train_dataset))\n",
    "img = img.to(device).unsqueeze(0) \n",
    "outputs = nih_expert.model(img)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "predicted\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50b3a0c3-8b9f-40f1-83eb-5511c789768b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_train_dataset.targets\n",
    "expert_train_dataset.__getitem__(21)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17df98ef-6b3c-4700-8504-87003a813366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00002763_027.png'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, target, filename = next(iter(expert_train_dataset))\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9633277-0ade-4d3a-a7c1-502efe47187a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, (img, target, _, _, _, filename) = next(enumerate(dataLoaderTrain))\n",
    "target\n",
    "#img = img.to(device)\n",
    "#nih_expert.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "610592b0-8b69-4b7b-8cad-b5b3b59eb386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df906d-7d10-40f7-926c-642deac385f0",
   "metadata": {},
   "source": [
    "# L2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8fbe7d-1b2d-4712-9a00-439812eb0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import expert as ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7a913a9-2de8-4584-a8b5-9deaed9348e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_experts(param):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    al_param = param[\"AL\"]\n",
    "    al_param[\"PATH\"] = param[\"PATH\"]\n",
    "    al_param[\"TRAIN REJECTOR\"] = False\n",
    "    l2d_param = param[\"L2D\"]\n",
    "\n",
    "    use_AL = True\n",
    "\n",
    "    basic_Dataset = ds.BasicDataset(param[\"PATH\"], param[\"TARGET\"])\n",
    "    \n",
    "    for seed in [948, 625, 436]:\n",
    "        print(\"run for seed {}\".format(seed))\n",
    "        if seed != \"\":\n",
    "            set_seed(seed)\n",
    "        log = {\"selected_experts\": [], \"selected_expert_fns\": []}\n",
    "        \n",
    "        #Use new Dataset\n",
    "        nih_dataloader = ds.NIH_K_Fold_Dataloader(\n",
    "            dataset = basic_Dataset,\n",
    "            k = param[\"K\"],\n",
    "            labelerIds = param[\"LABELER_IDS\"],\n",
    "            train_batch_size = param[\"TRAIN_BATCH_SIZE\"],\n",
    "            test_batch_size = param[\"TEST_BATCH_SIZE\"],\n",
    "            seed = seed,\n",
    "            #maxLabels = maxL,\n",
    "            preload = False,\n",
    "            prebuild = False,\n",
    "            param = param\n",
    "        )\n",
    "            \n",
    "        for fold_idx in range(param[\"K\"]):\n",
    "            print(f'Running fold {fold_idx+1} out of {param[\"K\"]}')\n",
    "\n",
    "            expert_train, expert_val, expert_test = nih_dataloader.get_dataset_for_folder(fold_idx)\n",
    "            expert_train_dataset = ds.NIHDataset(expert_train, preload=False, preprocess=False, param=param)\n",
    "            expert_val_dataset = ds.NIHDataset(expert_val, preload=False, preprocess=False, param=param)\n",
    "            expert_test_dataset = ds.NIHDataset(expert_test, preload=False, preprocess=False, param=param)\n",
    "\n",
    "            expert_fns = []\n",
    "            experts = []\n",
    "            for labelerId in list(param[\"LABELER_IDS\"]):\n",
    "                #nih_expert = ex.Expert(dataset = basic_Dataset, labeler_id=labelerId)\n",
    "                nih_expert = Expert(dataset = basic_Dataset, labeler_id=labelerId)\n",
    "                experts.append(nih_expert)\n",
    "                if (use_AL):\n",
    "                    nih_expert.setModel(getExpertModel(expert_train_dataset, expert_val_dataset, expert_test_dataset, nih_expert, al_param))\n",
    "                    expert_fns.append(nih_expert.predictWithModel)\n",
    "                else:\n",
    "                    expert_fns.append(nih_expert.predict)\n",
    "            \n",
    "            num_experts = len(expert_fns)\n",
    "\n",
    "            #Use new Expert\n",
    "            #expert_fns = [experts[j] for j in range(n)]\n",
    "            \n",
    "            model = model = vres.ResNet50_defer(int(param[\"n_classes\"]) + num_experts)\n",
    "            # print(model)\n",
    "            #trainD = GalaxyZooDataset()\n",
    "            #valD = GalaxyZooDataset(split=\"val\")\n",
    "            \n",
    "            train_loader, val_loader, test_loader = nih_dataloader.get_data_loader_for_fold(fold_idx)\n",
    "            \n",
    "            train(model, train_loader, val_loader, test_loader, expert_fns, param, seed=seed, experts=experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c66c22a-68e6-4b91-b997-d63f0932e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, test_loader, expert_fns, config, seed=\"\", experts=None):\n",
    "\n",
    "    print(\"Start L2D Training\")\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    n_classes = config[\"n_classes\"] + len(expert_fns)\n",
    "    kwargs = {\"num_workers\": 0, \"pin_memory\": True}\n",
    "\n",
    "    model = model.to(device)\n",
    "    cudnn.benchmark = True\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), config[\"lr\"], weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "    criterion = vlos.Criterion()\n",
    "    loss_fn = getattr(criterion, config[\"loss_type\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, len(train_loader) * config[\"epochs\"]\n",
    "    )\n",
    "    best_validation_loss = np.inf\n",
    "    patience = 0\n",
    "    iters = 0\n",
    "    warmup_iters = config[\"warmup_epochs\"] * len(train_loader)\n",
    "    lrate = config[\"lr\"]\n",
    "\n",
    "    for epoch in range(0, config[\"epochs\"]):\n",
    "        iters, train_loss = train_epoch(\n",
    "            iters,\n",
    "            warmup_iters,\n",
    "            lrate,\n",
    "            train_loader,\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            epoch,\n",
    "            expert_fns,\n",
    "            loss_fn,\n",
    "            n_classes,\n",
    "            config[\"alpha\"],\n",
    "            config,\n",
    "        )\n",
    "\n",
    "        experts_fns_eval = []\n",
    "        for expert in experts:\n",
    "            experts_fns_eval.append(expert.predict)\n",
    "        #metrics = evaluate(model, expert_fns, loss_fn, n_classes, valid_loader, config)\n",
    "        metrics = evaluate(model, experts_fns_eval, loss_fn, n_classes, valid_loader, config)\n",
    "\n",
    "        validation_loss = metrics[\"validation_loss\"]\n",
    "\n",
    "        if validation_loss < best_validation_loss:\n",
    "            \"\"\"best_validation_loss = validation_loss\n",
    "            print(\n",
    "                \"Saving the model with classifier accuracy {}\".format(\n",
    "                    metrics[\"classifier_accuracy\"]\n",
    "                ),\n",
    "                flush=True,\n",
    "            )\n",
    "            save_path = os.path.join(\n",
    "                config[\"ckp_dir\"],\n",
    "                config[\"experiment_name\"]\n",
    "                + \"_\"\n",
    "                + str(len(expert_fns))\n",
    "                + \"_experts\"\n",
    "                + \"_seed_\"\n",
    "                + str(seed),\n",
    "            )\"\"\"\n",
    "            #torch.save(model.state_dict(), save_path + \".pt\")\n",
    "            # Additionally save the whole config dict\n",
    "            #with open(save_path + \".json\", \"w\") as f:\n",
    "            #    json.dump(config, f)\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        if patience >= config[\"patience\"]:\n",
    "            print(\"Early Exiting Training.\", flush=True)\n",
    "            break\n",
    "            \n",
    "    print(\"Evaluate on Test Data\")\n",
    "    metrics = evaluate(model, expert_fns, loss_fn, n_classes, test_loader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5241fb99-074b-45e8-a841-704b812d2a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    iters,\n",
    "    warmup_iters,\n",
    "    lrate,\n",
    "    train_loader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    epoch,\n",
    "    expert_fns,\n",
    "    loss_fn,\n",
    "    n_classes,\n",
    "    alpha,\n",
    "    config,\n",
    "):\n",
    "    \"\"\" Train for one epoch \"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    epoch_train_loss = []\n",
    "\n",
    "    for i, (input, target, hpred) in enumerate(train_loader):\n",
    "        if iters < warmup_iters:\n",
    "            lr = lrate * float(iters) / warmup_iters\n",
    "            #print(iters, lr)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "\n",
    "        target = target.to(device)\n",
    "        input = input.to(device)\n",
    "        hpred = hpred\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "\n",
    "        if config[\"loss_type\"] == \"softmax\":\n",
    "            output = F.softmax(output, dim=1)\n",
    "\n",
    "        # get expert  predictions and costs\n",
    "        batch_size = output.size()[0]  # batch_size\n",
    "        collection_Ms = []\n",
    "        # We only support \\alpha=1\n",
    "        for _, fn in enumerate(expert_fns):\n",
    "            # We assume each expert function has access to the extra metadata, even if they don't use it.\n",
    "            m = fn(input, target, hpred)\n",
    "            #m = fn(hpred)\n",
    "            m2 = [0] * batch_size\n",
    "            for j in range(0, batch_size):\n",
    "                if m[j] == target[j].item():\n",
    "                    m[j] = 1\n",
    "                    m2[j] = alpha\n",
    "                else:\n",
    "                    m[j] = 0\n",
    "                    m2[j] = 1\n",
    "            m = torch.tensor(m)\n",
    "            m2 = torch.tensor(m2)\n",
    "            m = m.to(device)\n",
    "            m2 = m2.to(device)\n",
    "            collection_Ms.append((m, m2))\n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_fn(output, target, collection_Ms, n_classes)\n",
    "        epoch_train_loss.append(loss.item())\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if not iters < warmup_iters:\n",
    "            scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        iters += 1\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}]\\t\"\n",
    "                \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
    "                \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
    "                \"Prec@1 {top1.val:.3f} ({top1.avg:.3f})\".format(\n",
    "                    epoch,\n",
    "                    i,\n",
    "                    len(train_loader),\n",
    "                    batch_time=batch_time,\n",
    "                    loss=losses,\n",
    "                    top1=top1,\n",
    "                ),\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    return iters, np.average(epoch_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "714149aa-58eb-458d-bfad-f7ba0f24b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, expert_fns, loss_fn, n_classes, data_loader, config):\n",
    "    \"\"\"\n",
    "    Computes metrics for deferal\n",
    "    -----\n",
    "    Arguments:\n",
    "    net: model\n",
    "    expert_fn: expert model\n",
    "    n_classes: number of classes\n",
    "    loader: data loader\n",
    "    \"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    #  === Individual Expert Accuracies === #\n",
    "    expert_correct_dic = {k: 0 for k in range(len(expert_fns))}\n",
    "    expert_total_dic = {k: 0 for k in range(len(expert_fns))}\n",
    "    #  === Individual  Expert Accuracies === #\n",
    "    alpha = config[\"alpha\"]\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels, hpred = data\n",
    "            images, labels, hpred = images.to(device), labels.to(device), hpred\n",
    "            outputs = model(images)\n",
    "            if config[\"loss_type\"] == \"softmax\":\n",
    "                outputs = F.softmax(outputs, dim=1)\n",
    "            if config[\"loss_type\"] == \"ova\":\n",
    "                ouputs = F.sigmoid(outputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_size = outputs.size()[0]  # batch_size\n",
    "\n",
    "            expert_predictions = []\n",
    "            collection_Ms = []  # a collection of 3-tuple\n",
    "            for i, fn in enumerate(expert_fns, 0):\n",
    "                exp_prediction1 = fn(images, labels, hpred)\n",
    "                #exp_prediction1 = fn(hpred)\n",
    "                m = [0] * batch_size\n",
    "                m2 = [0] * batch_size\n",
    "                for j in range(0, batch_size):\n",
    "                    if exp_prediction1[j] == labels[j].item():\n",
    "                        m[j] = 1\n",
    "                        m2[j] = alpha\n",
    "                    else:\n",
    "                        m[j] = 0\n",
    "                        m2[j] = 1\n",
    "\n",
    "                m = torch.tensor(m)\n",
    "                m2 = torch.tensor(m2)\n",
    "                m = m.to(device)\n",
    "                m2 = m2.to(device)\n",
    "                collection_Ms.append((m, m2))\n",
    "                expert_predictions.append(exp_prediction1)\n",
    "\n",
    "            loss = loss_fn(outputs, labels, collection_Ms, n_classes)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            for i in range(0, batch_size):\n",
    "                r = predicted[i].item() >= n_classes - len(expert_fns)\n",
    "                prediction = predicted[i]\n",
    "                if predicted[i] >= n_classes - len(expert_fns):\n",
    "                    max_idx = 0\n",
    "                    # get second max\n",
    "                    for j in range(0, n_classes - len(expert_fns)):\n",
    "                        if outputs.data[i][j] >= outputs.data[i][max_idx]:\n",
    "                            max_idx = j\n",
    "                    prediction = max_idx\n",
    "                else:\n",
    "                    prediction = predicted[i]\n",
    "                alone_correct += (prediction == labels[i]).item()\n",
    "                if r == 0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == labels[i]).item()\n",
    "                    correct_sys += (predicted[i] == labels[i]).item()\n",
    "                if r == 1:\n",
    "                    deferred_exp = (predicted[i] - (n_classes - len(expert_fns))).item()\n",
    "                    # cdeferred_exp = ((n_classes - 1) - predicted[i]).item()  # reverse order, as in loss function\n",
    "                    exp_prediction = expert_predictions[deferred_exp][i]\n",
    "                    #\n",
    "                    # Deferral accuracy: No matter expert ===\n",
    "                    exp += exp_prediction == labels[i].item()\n",
    "                    exp_total += 1\n",
    "                    # Individual Expert Accuracy ===\n",
    "                    expert_correct_dic[deferred_exp] += (\n",
    "                        exp_prediction == labels[i].item()\n",
    "                    )\n",
    "                    expert_total_dic[deferred_exp] += 1\n",
    "                    #\n",
    "                    correct_sys += exp_prediction == labels[i].item()\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "\n",
    "    #  === Individual Expert Accuracies === #\n",
    "    expert_accuracies = {\n",
    "        \"expert_{}\".format(str(k)): 100\n",
    "        * expert_correct_dic[k]\n",
    "        / (expert_total_dic[k] + 0.0002)\n",
    "        for k in range(len(expert_fns))\n",
    "    }\n",
    "    # Add expert accuracies dict\n",
    "    to_print = {\n",
    "        \"coverage\": cov,\n",
    "        \"system_accuracy\": 100 * correct_sys / real_total,\n",
    "        \"expert_accuracy\": 100 * exp / (exp_total + 0.0002),\n",
    "        \"classifier_accuracy\": 100 * correct / (total + 0.0001),\n",
    "        \"alone_classifier\": 100 * alone_correct / real_total,\n",
    "        \"validation_loss\": np.average(losses),\n",
    "        \"n_experts\": len(expert_fns),\n",
    "        **expert_accuracies,\n",
    "    }\n",
    "    print(to_print, flush=True)\n",
    "    return to_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7d15a8e-9340-4300-b898-4f60b717b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run for seed 948\n",
      "Running fold 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete first data generation\n",
      "Complete dataloader generation\n",
      "model size: 323.716MB\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/4]\tTime 1.412 (1.412)\tLoss 0.9704 (0.9704)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 32 test images: 15.625 %\n",
      "Confusion Matrix:\n",
      "[[ 5  0]\n",
      " [27  0]]\n",
      "Epoch: [1][0/4]\tTime 0.160 (0.160)\tLoss 1.7886 (1.7886)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [2][0/4]\tTime 0.159 (0.159)\tLoss 2.3453 (2.3453)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [3][0/4]\tTime 0.158 (0.158)\tLoss 2.0974 (2.0974)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [4][0/4]\tTime 0.158 (0.158)\tLoss 2.5248 (2.5248)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [5][0/4]\tTime 0.159 (0.159)\tLoss 1.6723 (1.6723)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [6][0/4]\tTime 0.162 (0.162)\tLoss 1.3719 (1.3719)\tPrec@1 50.000 (50.000)\n",
      "Epoch: [7][0/4]\tTime 0.166 (0.166)\tLoss 1.5040 (1.5040)\tPrec@1 25.000 (25.000)\n",
      "Accuracy of the network on the 32 test images: 53.125 %\n",
      "Confusion Matrix:\n",
      "[[ 5  0]\n",
      " [15 12]]\n",
      "Expert trained\n",
      "Starting with AL\n",
      "\n",
      " \n",
      " Round 0 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/5]\tTime 0.165 (0.165)\tLoss 1.8607 (1.8607)\tPrec@1 37.500 (37.500)\n",
      "Accuracy of the network on the 40 test images: 30.000 %\n",
      "Confusion Matrix:\n",
      "[[ 6  0]\n",
      " [28  6]]\n",
      "Epoch: [1][0/5]\tTime 0.165 (0.165)\tLoss 1.4247 (1.4247)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [2][0/5]\tTime 0.163 (0.163)\tLoss 1.4063 (1.4063)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [3][0/5]\tTime 0.159 (0.159)\tLoss 1.6355 (1.6355)\tPrec@1 62.500 (62.500)\n",
      "Epoch: [4][0/5]\tTime 0.160 (0.160)\tLoss 1.9017 (1.9017)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/5]\tTime 0.157 (0.157)\tLoss 2.0123 (2.0123)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [6][0/5]\tTime 0.157 (0.157)\tLoss 0.6786 (0.6786)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [7][0/5]\tTime 0.160 (0.160)\tLoss 0.9575 (0.9575)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 40 test images: 85.000 %\n",
      "Confusion Matrix:\n",
      "[[ 6  0]\n",
      " [ 6 28]]\n",
      "\n",
      " \n",
      " Round 1 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/6]\tTime 0.167 (0.167)\tLoss 0.4296 (0.4296)\tPrec@1 87.500 (87.500)\n",
      "Accuracy of the network on the 48 test images: 27.083 %\n",
      "Confusion Matrix:\n",
      "[[ 6  0]\n",
      " [35  7]]\n",
      "Epoch: [1][0/6]\tTime 0.162 (0.162)\tLoss 4.5836 (4.5836)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [2][0/6]\tTime 0.159 (0.159)\tLoss 0.9509 (0.9509)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [3][0/6]\tTime 0.158 (0.158)\tLoss 0.2133 (0.2133)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/6]\tTime 0.158 (0.158)\tLoss 0.5544 (0.5544)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [5][0/6]\tTime 0.167 (0.167)\tLoss 0.3468 (0.3468)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [6][0/6]\tTime 0.169 (0.169)\tLoss 0.3289 (0.3289)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [7][0/6]\tTime 0.166 (0.166)\tLoss 0.2387 (0.2387)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 48 test images: 93.750 %\n",
      "Confusion Matrix:\n",
      "[[ 6  0]\n",
      " [ 3 39]]\n",
      "\n",
      " \n",
      " Round 2 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/7]\tTime 0.164 (0.164)\tLoss 0.2820 (0.2820)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 56 test images: 30.357 %\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [39 10]]\n",
      "Epoch: [1][0/7]\tTime 0.156 (0.156)\tLoss 1.5701 (1.5701)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [2][0/7]\tTime 0.163 (0.163)\tLoss 1.7912 (1.7912)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [3][0/7]\tTime 0.168 (0.168)\tLoss 2.6935 (2.6935)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [4][0/7]\tTime 0.155 (0.155)\tLoss 3.2624 (3.2624)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/7]\tTime 0.157 (0.157)\tLoss 2.1879 (2.1879)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [6][0/7]\tTime 0.166 (0.166)\tLoss 1.4859 (1.4859)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [7][0/7]\tTime 0.159 (0.159)\tLoss 0.8447 (0.8447)\tPrec@1 75.000 (75.000)\n",
      "Accuracy of the network on the 56 test images: 71.429 %\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [16 33]]\n",
      "\n",
      " \n",
      " Round 3 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/8]\tTime 0.166 (0.166)\tLoss 1.4229 (1.4229)\tPrec@1 87.500 (87.500)\n",
      "Accuracy of the network on the 64 test images: 78.125 %\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [14 43]]\n",
      "Epoch: [1][0/8]\tTime 0.166 (0.166)\tLoss 0.6872 (0.6872)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [2][0/8]\tTime 0.168 (0.168)\tLoss 0.7178 (0.7178)\tPrec@1 62.500 (62.500)\n",
      "Epoch: [3][0/8]\tTime 0.157 (0.157)\tLoss 0.4699 (0.4699)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [4][0/8]\tTime 0.164 (0.164)\tLoss 1.0273 (1.0273)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [5][0/8]\tTime 0.152 (0.152)\tLoss 0.0831 (0.0831)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/8]\tTime 0.165 (0.165)\tLoss 0.2705 (0.2705)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [7][0/8]\tTime 0.157 (0.157)\tLoss 0.0707 (0.0707)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 64 test images: 100.000 %\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [ 0 57]]\n",
      "AL finished\n",
      "Complete first data generation\n",
      "Complete dataloader generation\n",
      "model size: 323.716MB\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/4]\tTime 0.167 (0.167)\tLoss 0.9784 (0.9784)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 32 test images: 21.875 %\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [25  0]]\n",
      "Epoch: [1][0/4]\tTime 0.165 (0.165)\tLoss 1.8747 (1.8747)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [2][0/4]\tTime 0.159 (0.159)\tLoss 2.5038 (2.5038)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [3][0/4]\tTime 0.163 (0.163)\tLoss 2.2958 (2.2958)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [4][0/4]\tTime 0.166 (0.166)\tLoss 1.8536 (1.8536)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [5][0/4]\tTime 0.164 (0.164)\tLoss 1.8836 (1.8836)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [6][0/4]\tTime 0.166 (0.166)\tLoss 1.8740 (1.8740)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [7][0/4]\tTime 0.160 (0.160)\tLoss 1.6662 (1.6662)\tPrec@1 0.000 (0.000)\n",
      "Accuracy of the network on the 32 test images: 21.875 %\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [25  0]]\n",
      "Expert trained\n",
      "Starting with AL\n",
      "\n",
      " \n",
      " Round 0 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/5]\tTime 0.168 (0.168)\tLoss 2.4538 (2.4538)\tPrec@1 37.500 (37.500)\n",
      "Accuracy of the network on the 40 test images: 20.000 %\n",
      "Confusion Matrix:\n",
      "[[ 8  0]\n",
      " [32  0]]\n",
      "Epoch: [1][0/5]\tTime 0.159 (0.159)\tLoss 2.3716 (2.3716)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [2][0/5]\tTime 0.164 (0.164)\tLoss 2.9377 (2.9377)\tPrec@1 50.000 (50.000)\n",
      "Epoch: [3][0/5]\tTime 0.172 (0.172)\tLoss 2.2878 (2.2878)\tPrec@1 50.000 (50.000)\n",
      "Epoch: [4][0/5]\tTime 0.175 (0.175)\tLoss 1.7808 (1.7808)\tPrec@1 62.500 (62.500)\n",
      "Epoch: [5][0/5]\tTime 0.166 (0.166)\tLoss 1.6927 (1.6927)\tPrec@1 50.000 (50.000)\n",
      "Epoch: [6][0/5]\tTime 0.159 (0.159)\tLoss 1.2032 (1.2032)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [7][0/5]\tTime 0.162 (0.162)\tLoss 1.5782 (1.5782)\tPrec@1 25.000 (25.000)\n",
      "Accuracy of the network on the 40 test images: 57.500 %\n",
      "Confusion Matrix:\n",
      "[[ 7  1]\n",
      " [16 16]]\n",
      "\n",
      " \n",
      " Round 1 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/6]\tTime 0.167 (0.167)\tLoss 0.8142 (0.8142)\tPrec@1 87.500 (87.500)\n",
      "Accuracy of the network on the 48 test images: 33.333 %\n",
      "Confusion Matrix:\n",
      "[[10  0]\n",
      " [32  6]]\n",
      "Epoch: [1][0/6]\tTime 0.164 (0.164)\tLoss 1.6041 (1.6041)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [2][0/6]\tTime 0.166 (0.166)\tLoss 1.7487 (1.7487)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [3][0/6]\tTime 0.167 (0.167)\tLoss 1.4203 (1.4203)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [4][0/6]\tTime 0.164 (0.164)\tLoss 1.2441 (1.2441)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [5][0/6]\tTime 0.171 (0.171)\tLoss 1.2324 (1.2324)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [6][0/6]\tTime 0.164 (0.164)\tLoss 0.5845 (0.5845)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/6]\tTime 0.164 (0.164)\tLoss 0.9629 (0.9629)\tPrec@1 75.000 (75.000)\n",
      "Accuracy of the network on the 48 test images: 83.333 %\n",
      "Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 8 30]]\n",
      "\n",
      " \n",
      " Round 2 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/7]\tTime 0.163 (0.163)\tLoss 0.7631 (0.7631)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 56 test images: 33.929 %\n",
      "Confusion Matrix:\n",
      "[[12  0]\n",
      " [37  7]]\n",
      "Epoch: [1][0/7]\tTime 0.153 (0.153)\tLoss 2.0155 (2.0155)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [2][0/7]\tTime 0.161 (0.161)\tLoss 1.5246 (1.5246)\tPrec@1 62.500 (62.500)\n",
      "Epoch: [3][0/7]\tTime 0.170 (0.170)\tLoss 0.5787 (0.5787)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [4][0/7]\tTime 0.164 (0.164)\tLoss 0.5635 (0.5635)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/7]\tTime 0.160 (0.160)\tLoss 0.2378 (0.2378)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/7]\tTime 0.169 (0.169)\tLoss 0.7332 (0.7332)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [7][0/7]\tTime 0.164 (0.164)\tLoss 1.3141 (1.3141)\tPrec@1 75.000 (75.000)\n",
      "Accuracy of the network on the 56 test images: 92.857 %\n",
      "Confusion Matrix:\n",
      "[[12  0]\n",
      " [ 4 40]]\n",
      "\n",
      " \n",
      " Round 3 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/8]\tTime 0.164 (0.164)\tLoss 1.8148 (1.8148)\tPrec@1 62.500 (62.500)\n",
      "Accuracy of the network on the 64 test images: 67.188 %\n",
      "Confusion Matrix:\n",
      "[[14  0]\n",
      " [21 29]]\n",
      "Epoch: [1][0/8]\tTime 0.164 (0.164)\tLoss 0.9959 (0.9959)\tPrec@1 62.500 (62.500)\n",
      "Epoch: [2][0/8]\tTime 0.158 (0.158)\tLoss 1.6910 (1.6910)\tPrec@1 50.000 (50.000)\n",
      "Epoch: [3][0/8]\tTime 0.161 (0.161)\tLoss 0.5287 (0.5287)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/8]\tTime 0.158 (0.158)\tLoss 0.8093 (0.8093)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [5][0/8]\tTime 0.164 (0.164)\tLoss 0.2536 (0.2536)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/8]\tTime 0.161 (0.161)\tLoss 0.3666 (0.3666)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [7][0/8]\tTime 0.163 (0.163)\tLoss 0.0639 (0.0639)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 64 test images: 95.312 %\n",
      "Confusion Matrix:\n",
      "[[14  0]\n",
      " [ 3 47]]\n",
      "AL finished\n",
      "Start L2D Training\n",
      "Epoch: [0][0/9]\tTime 3.208 (3.208)\tLoss 5.5024 (5.5024)\tPrec@1 17.188 (17.188)\n",
      "{'coverage': '0 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 89.17186092756569, 'classifier_accuracy': 0.0, 'alone_classifier': 61.78343949044586, 'validation_loss': 5.244562307993571, 'n_experts': 2, 'expert_0': 90.56586685685498, 'expert_1': 86.27417147383736}\n",
      "Epoch: [1][0/9]\tTime 1.347 (1.347)\tLoss 5.2420 (5.2420)\tPrec@1 1.562 (1.562)\n",
      "{'coverage': '53 out of157', 'system_accuracy': 85.35031847133757, 'expert_accuracy': 88.46136834352241, 'classifier_accuracy': 79.2451334997481, 'alone_classifier': 68.15286624203821, 'validation_loss': 5.208581606547038, 'n_experts': 2, 'expert_0': 89.39366850403482, 'expert_1': 86.84164820185157}\n",
      "Epoch: [2][0/9]\tTime 1.300 (1.300)\tLoss 4.7008 (4.7008)\tPrec@1 53.125 (53.125)\n",
      "{'coverage': '7 out of157', 'system_accuracy': 86.62420382165605, 'expert_accuracy': 87.33321688904414, 'classifier_accuracy': 71.42755103498521, 'alone_classifier': 71.3375796178344, 'validation_loss': 5.177621046702067, 'n_experts': 2, 'expert_0': 88.99982200035599, 'expert_1': 83.999664001344}\n",
      "Epoch: [3][0/9]\tTime 1.298 (1.298)\tLoss 4.2897 (4.2897)\tPrec@1 21.875 (21.875)\n",
      "{'coverage': '32 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 91.19985408023346, 'classifier_accuracy': 81.24974609454344, 'alone_classifier': 68.78980891719745, 'validation_loss': 5.6719099680582685, 'n_experts': 2, 'expert_0': 91.86025148778722, 'expert_1': 89.7431295224127}\n",
      "Epoch: [4][0/9]\tTime 1.300 (1.300)\tLoss 4.0470 (4.0470)\tPrec@1 43.750 (43.750)\n",
      "{'coverage': '55 out of157', 'system_accuracy': 85.35031847133757, 'expert_accuracy': 91.17629181119253, 'classifier_accuracy': 74.54531900851089, 'alone_classifier': 71.3375796178344, 'validation_loss': 5.649436314900716, 'n_experts': 2, 'expert_0': 90.19572472264815, 'expert_1': 92.15650134705353}\n",
      "Epoch: [5][0/9]\tTime 1.323 (1.323)\tLoss 4.6095 (4.6095)\tPrec@1 53.125 (53.125)\n",
      "{'coverage': '50 out of157', 'system_accuracy': 82.1656050955414, 'expert_accuracy': 82.24283692927676, 'classifier_accuracy': 81.99983600032799, 'alone_classifier': 73.88535031847134, 'validation_loss': 5.401212692260742, 'n_experts': 2, 'expert_0': 85.41631076537182, 'expert_1': 79.66074691272233}\n",
      "Epoch: [6][0/9]\tTime 1.313 (1.313)\tLoss 4.3351 (4.3351)\tPrec@1 59.375 (59.375)\n",
      "{'coverage': '19 out of157', 'system_accuracy': 86.62420382165605, 'expert_accuracy': 88.40566897729133, 'classifier_accuracy': 73.68382271672255, 'alone_classifier': 72.61146496815287, 'validation_loss': 5.7277506192525225, 'n_experts': 2, 'expert_0': 91.66636111212962, 'expert_1': 85.897215648165}\n",
      "Epoch: [7][0/9]\tTime 1.306 (1.306)\tLoss 4.3702 (4.3702)\tPrec@1 25.000 (25.000)\n",
      "{'coverage': '19 out of157', 'system_accuracy': 87.26114649681529, 'expert_accuracy': 89.85494223921414, 'classifier_accuracy': 68.42069252267093, 'alone_classifier': 75.1592356687898, 'validation_loss': 5.51370112101237, 'n_experts': 2, 'expert_0': 91.66644841321806, 'expert_1': 87.03671467883453}\n",
      "Epoch: [8][0/9]\tTime 1.306 (1.306)\tLoss 4.3674 (4.3674)\tPrec@1 21.875 (21.875)\n",
      "{'coverage': '43 out of157', 'system_accuracy': 85.98726114649682, 'expert_accuracy': 88.5963357959021, 'classifier_accuracy': 79.069583559108, 'alone_classifier': 78.34394904458598, 'validation_loss': 5.614002227783203, 'n_experts': 2, 'expert_0': 91.02540762715992, 'expert_1': 83.33287037294237}\n",
      "Epoch: [9][0/9]\tTime 1.312 (1.312)\tLoss 3.9980 (3.9980)\tPrec@1 40.625 (40.625)\n",
      "{'coverage': '60 out of157', 'system_accuracy': 82.80254777070064, 'expert_accuracy': 86.59775959224825, 'classifier_accuracy': 76.66653888910184, 'alone_classifier': 73.88535031847134, 'validation_loss': 6.04213015238444, 'n_experts': 2, 'expert_0': 90.76895148014928, 'expert_1': 78.12451172180174}\n",
      "Epoch: [10][0/9]\tTime 1.328 (1.328)\tLoss 4.1841 (4.1841)\tPrec@1 65.625 (65.625)\n",
      "{'coverage': '41 out of157', 'system_accuracy': 85.98726114649682, 'expert_accuracy': 89.65501783617614, 'classifier_accuracy': 75.6095716839715, 'alone_classifier': 78.98089171974522, 'validation_loss': 5.611671129862468, 'n_experts': 2, 'expert_0': 90.7404046651679, 'expert_1': 88.7093912600282}\n",
      "Epoch: [11][0/9]\tTime 1.311 (1.311)\tLoss 4.0881 (4.0881)\tPrec@1 34.375 (34.375)\n",
      "{'coverage': '47 out of157', 'system_accuracy': 86.62420382165605, 'expert_accuracy': 90.90892562013524, 'classifier_accuracy': 76.59558171152827, 'alone_classifier': 78.34394904458598, 'validation_loss': 5.645088354746501, 'n_experts': 2, 'expert_0': 93.05529706861924, 'expert_1': 86.84164820185157}\n",
      "Epoch: [12][0/9]\tTime 1.328 (1.328)\tLoss 3.6083 (3.6083)\tPrec@1 28.125 (28.125)\n",
      "{'coverage': '41 out of157', 'system_accuracy': 86.62420382165605, 'expert_accuracy': 88.79295035698213, 'classifier_accuracy': 80.48760856680836, 'alone_classifier': 81.52866242038216, 'validation_loss': 5.687703927357991, 'n_experts': 2, 'expert_0': 90.24346222701352, 'expert_1': 87.9997653339591}\n",
      "Epoch: [13][0/9]\tTime 1.328 (1.328)\tLoss 4.3345 (4.3345)\tPrec@1 18.750 (18.750)\n",
      "{'coverage': '35 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 90.16378661674325, 'classifier_accuracy': 85.71404081702623, 'alone_classifier': 80.2547770700637, 'validation_loss': 6.100432713826497, 'n_experts': 2, 'expert_0': 92.85692176923388, 'expert_1': 84.21008310482577}\n",
      "Epoch: [14][0/9]\tTime 1.318 (1.318)\tLoss 4.0389 (4.0389)\tPrec@1 40.625 (40.625)\n",
      "{'coverage': '71 out of157', 'system_accuracy': 87.26114649681529, 'expert_accuracy': 90.69746349427093, 'classifier_accuracy': 83.09847450919082, 'alone_classifier': 79.61783439490446, 'validation_loss': 6.027812321980794, 'n_experts': 2, 'expert_0': 89.85481201503762, 'expert_1': 94.11653980541405}\n",
      "Epoch: [15][0/9]\tTime 1.322 (1.322)\tLoss 3.9392 (3.9392)\tPrec@1 76.562 (76.562)\n",
      "{'coverage': '77 out of157', 'system_accuracy': 85.35031847133757, 'expert_accuracy': 87.49978125054686, 'classifier_accuracy': 83.11677517301925, 'alone_classifier': 79.61783439490446, 'validation_loss': 6.088010311126709, 'n_experts': 2, 'expert_0': 87.93073127334044, 'expert_1': 86.36285124680685}\n",
      "Epoch: [16][0/9]\tTime 1.313 (1.313)\tLoss 3.9943 (3.9943)\tPrec@1 57.812 (57.812)\n",
      "{'coverage': '52 out of157', 'system_accuracy': 85.35031847133757, 'expert_accuracy': 87.61888072594147, 'classifier_accuracy': 80.76907544408569, 'alone_classifier': 78.98089171974522, 'validation_loss': 6.089176495869954, 'n_experts': 2, 'expert_0': 90.3222892829378, 'expert_1': 83.7205408346938}\n",
      "Epoch: [17][0/9]\tTime 1.313 (1.313)\tLoss 4.0455 (4.0455)\tPrec@1 59.375 (59.375)\n",
      "{'coverage': '52 out of157', 'system_accuracy': 85.35031847133757, 'expert_accuracy': 86.66650158761601, 'classifier_accuracy': 82.69214866894487, 'alone_classifier': 78.98089171974522, 'validation_loss': 6.064467589060466, 'n_experts': 2, 'expert_0': 88.13529445662896, 'expert_1': 84.78224007721705}\n",
      "Epoch: [18][0/9]\tTime 1.293 (1.293)\tLoss 4.0817 (4.0817)\tPrec@1 62.500 (62.500)\n",
      "{'coverage': '30 out of157', 'system_accuracy': 85.98726114649682, 'expert_accuracy': 87.40143716309107, 'classifier_accuracy': 79.99973333422221, 'alone_classifier': 78.98089171974522, 'validation_loss': 6.191680749257405, 'n_experts': 2, 'expert_0': 91.04450434476314, 'expert_1': 83.33305555648148}\n",
      "Epoch: [19][0/9]\tTime 1.306 (1.306)\tLoss 3.7564 (3.7564)\tPrec@1 23.438 (23.438)\n",
      "{'coverage': '41 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 90.51708531537014, 'classifier_accuracy': 80.48760856680836, 'alone_classifier': 77.70700636942675, 'validation_loss': 6.40867265065511, 'n_experts': 2, 'expert_0': 95.1609833516666, 'expert_1': 85.18486968566783}\n",
      "Epoch: [20][0/9]\tTime 1.320 (1.320)\tLoss 4.2977 (4.2977)\tPrec@1 32.812 (32.812)\n",
      "{'coverage': '41 out of157', 'system_accuracy': 85.98726114649682, 'expert_accuracy': 89.65501783617614, 'classifier_accuracy': 75.6095716839715, 'alone_classifier': 78.98089171974522, 'validation_loss': 6.28483517964681, 'n_experts': 2, 'expert_0': 91.30414933880577, 'expert_1': 83.33263889467588}\n",
      "Epoch: [21][0/9]\tTime 1.302 (1.302)\tLoss 4.0097 (4.0097)\tPrec@1 20.312 (20.312)\n",
      "{'coverage': '44 out of157', 'system_accuracy': 87.26114649681529, 'expert_accuracy': 89.38037277810128, 'classifier_accuracy': 81.8179958681912, 'alone_classifier': 79.61783439490446, 'validation_loss': 6.298171679178874, 'n_experts': 2, 'expert_0': 92.85687755177841, 'expert_1': 83.7205408346938}\n",
      "Epoch: [22][0/9]\tTime 1.324 (1.324)\tLoss 4.0746 (4.0746)\tPrec@1 26.562 (26.562)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 86.62420382165605, 'expert_accuracy': 87.28798764747856, 'classifier_accuracy': 84.61516765341626, 'alone_classifier': 78.98089171974522, 'validation_loss': 6.229832490285237, 'n_experts': 2, 'expert_0': 89.47344875408221, 'expert_1': 83.33293650982614}\n",
      "Epoch: [23][0/9]\tTime 1.308 (1.308)\tLoss 4.1281 (4.1281)\tPrec@1 15.625 (15.625)\n",
      "{'coverage': '65 out of157', 'system_accuracy': 84.07643312101911, 'expert_accuracy': 84.78242438603394, 'classifier_accuracy': 83.07679526646882, 'alone_classifier': 76.43312101910828, 'validation_loss': 6.251845995585124, 'n_experts': 2, 'expert_0': 87.87825528330131, 'expert_1': 83.05056593028499}\n",
      "Epoch: [24][0/9]\tTime 1.291 (1.291)\tLoss 4.2112 (4.2112)\tPrec@1 45.312 (45.312)\n",
      "{'coverage': '52 out of157', 'system_accuracy': 85.35031847133757, 'expert_accuracy': 85.71412244929057, 'classifier_accuracy': 84.61522189380405, 'alone_classifier': 76.43312101910828, 'validation_loss': 6.789331277211507, 'n_experts': 2, 'expert_0': 93.02282314965977, 'expert_1': 80.64490114548018}\n",
      "Epoch: [25][0/9]\tTime 1.308 (1.308)\tLoss 3.7953 (3.7953)\tPrec@1 23.438 (23.438)\n",
      "{'coverage': '47 out of157', 'system_accuracy': 86.62420382165605, 'expert_accuracy': 87.27256859532982, 'classifier_accuracy': 85.10620190169807, 'alone_classifier': 73.88535031847134, 'validation_loss': 6.607820192972819, 'n_experts': 2, 'expert_0': 91.11070617463922, 'expert_1': 84.61512426115611}\n",
      "Epoch: [26][0/9]\tTime 1.323 (1.323)\tLoss 4.1601 (4.1601)\tPrec@1 31.250 (31.250)\n",
      "{'coverage': '47 out of157', 'system_accuracy': 83.43949044585987, 'expert_accuracy': 87.27256859532982, 'classifier_accuracy': 74.46792666398582, 'alone_classifier': 77.70700636942675, 'validation_loss': 6.598510265350342, 'n_experts': 2, 'expert_0': 86.84187673190333, 'expert_1': 88.2347750895583}\n",
      "Epoch: [27][0/9]\tTime 1.308 (1.308)\tLoss 3.8642 (3.8642)\tPrec@1 21.875 (21.875)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 84.07643312101911, 'expert_accuracy': 87.28798764747856, 'classifier_accuracy': 74.35878369542641, 'alone_classifier': 73.88535031847134, 'validation_loss': 6.108819802602132, 'n_experts': 2, 'expert_0': 90.62471679776, 'expert_1': 83.33302469250114}\n",
      "Epoch: [28][0/9]\tTime 1.315 (1.315)\tLoss 4.0081 (4.0081)\tPrec@1 35.938 (35.938)\n",
      "{'coverage': '69 out of157', 'system_accuracy': 84.71337579617834, 'expert_accuracy': 89.77252324426534, 'classifier_accuracy': 78.26075614383167, 'alone_classifier': 75.79617834394904, 'validation_loss': 5.528624852498372, 'n_experts': 2, 'expert_0': 91.52511347419161, 'expert_1': 86.20630202550328}\n",
      "Epoch: [29][0/9]\tTime 1.314 (1.314)\tLoss 4.3263 (4.3263)\tPrec@1 60.938 (60.938)\n",
      "{'coverage': '65 out of157', 'system_accuracy': 84.07643312101911, 'expert_accuracy': 86.95633270362455, 'classifier_accuracy': 79.99987692326627, 'alone_classifier': 78.34394904458598, 'validation_loss': 5.644631385803223, 'n_experts': 2, 'expert_0': 93.18139463002441, 'expert_1': 81.24966145974392}\n",
      "Epoch: [30][0/9]\tTime 1.304 (1.304)\tLoss 4.2547 (4.2547)\tPrec@1 42.188 (42.188)\n",
      "{'coverage': '35 out of157', 'system_accuracy': 83.43949044585987, 'expert_accuracy': 86.88510346704349, 'classifier_accuracy': 71.42836734752186, 'alone_classifier': 78.98089171974522, 'validation_loss': 5.630849202473958, 'n_experts': 2, 'expert_0': 90.19572472264815, 'expert_1': 84.50680420618532}\n",
      "Epoch: [31][0/9]\tTime 1.308 (1.308)\tLoss 4.4050 (4.4050)\tPrec@1 35.938 (35.938)\n",
      "{'coverage': '35 out of157', 'system_accuracy': 86.62420382165605, 'expert_accuracy': 88.52444504189337, 'classifier_accuracy': 79.99977142922448, 'alone_classifier': 81.52866242038216, 'validation_loss': 5.602839310963948, 'n_experts': 2, 'expert_0': 91.26195871464327, 'expert_1': 73.68343491121146}\n",
      "Epoch: [32][0/9]\tTime 1.293 (1.293)\tLoss 4.0891 (4.0891)\tPrec@1 32.812 (32.812)\n",
      "{'coverage': '46 out of157', 'system_accuracy': 82.80254777070064, 'expert_accuracy': 85.58543137760111, 'classifier_accuracy': 76.08679111567149, 'alone_classifier': 76.43312101910828, 'validation_loss': 6.034346739451091, 'n_experts': 2, 'expert_0': 89.53467550075464, 'expert_1': 71.99942400460796}\n",
      "Epoch: [33][0/9]\tTime 1.324 (1.324)\tLoss 4.0283 (4.0283)\tPrec@1 31.250 (31.250)\n",
      "{'coverage': '48 out of157', 'system_accuracy': 87.26114649681529, 'expert_accuracy': 91.74295093036525, 'classifier_accuracy': 77.08317274339011, 'alone_classifier': 78.98089171974522, 'validation_loss': 5.691327253977458, 'n_experts': 2, 'expert_0': 93.10323424543851, 'expert_1': 86.36285124680685}\n",
      "Epoch: [34][0/9]\tTime 1.304 (1.304)\tLoss 4.1325 (4.1325)\tPrec@1 48.438 (48.438)\n",
      "{'coverage': '52 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 90.47601814091782, 'classifier_accuracy': 82.69214866894487, 'alone_classifier': 78.98089171974522, 'validation_loss': 6.029176553090413, 'n_experts': 2, 'expert_0': 91.7805704641905, 'expert_1': 87.49945312841795}\n",
      "Epoch: [35][0/9]\tTime 1.313 (1.313)\tLoss 4.0434 (4.0434)\tPrec@1 50.000 (50.000)\n",
      "{'coverage': '37 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 89.16651805580324, 'classifier_accuracy': 83.78355734173691, 'alone_classifier': 80.2547770700637, 'validation_loss': 6.306353251139323, 'n_experts': 2, 'expert_0': 94.82725921634753, 'expert_1': 83.87069719129939}\n",
      "Epoch: [36][0/9]\tTime 1.321 (1.321)\tLoss 3.6282 (3.6282)\tPrec@1 23.438 (23.438)\n",
      "{'coverage': '46 out of157', 'system_accuracy': 85.35031847133757, 'expert_accuracy': 87.38722993291904, 'classifier_accuracy': 80.4346077508527, 'alone_classifier': 78.98089171974522, 'validation_loss': 6.090056737263997, 'n_experts': 2, 'expert_0': 89.9997750005625, 'expert_1': 80.64464100231612}\n",
      "Epoch: [37][0/9]\tTime 1.324 (1.324)\tLoss 3.9708 (3.9708)\tPrec@1 32.812 (32.812)\n",
      "{'coverage': '55 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 91.17629181119253, 'classifier_accuracy': 85.45439008292712, 'alone_classifier': 80.89171974522293, 'validation_loss': 6.4542544682820635, 'n_experts': 2, 'expert_0': 93.65049634763065, 'expert_1': 87.17904010748663}\n",
      "Epoch: [38][0/9]\tTime 1.310 (1.310)\tLoss 4.2176 (4.2176)\tPrec@1 65.625 (65.625)\n",
      "{'coverage': '60 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.65961101111131, 'classifier_accuracy': 89.99985000024999, 'alone_classifier': 80.2547770700637, 'validation_loss': 6.638064702351888, 'n_experts': 2, 'expert_0': 94.64251913386023, 'expert_1': 80.48741225652557}\n",
      "Epoch: [39][0/9]\tTime 1.304 (1.304)\tLoss 4.0158 (4.0158)\tPrec@1 60.938 (60.938)\n",
      "{'coverage': '51 out of157', 'system_accuracy': 87.26114649681529, 'expert_accuracy': 87.73568351757827, 'classifier_accuracy': 86.27434063854776, 'alone_classifier': 81.52866242038216, 'validation_loss': 6.5760698318481445, 'n_experts': 2, 'expert_0': 95.08165546998207, 'expert_1': 77.77743210030178}\n",
      "Epoch: [40][0/9]\tTime 1.311 (1.311)\tLoss 4.0421 (4.0421)\tPrec@1 48.438 (48.438)\n",
      "{'coverage': '52 out of157', 'system_accuracy': 85.98726114649682, 'expert_accuracy': 85.71412244929057, 'classifier_accuracy': 86.53829511866323, 'alone_classifier': 81.52866242038216, 'validation_loss': 6.792406400044759, 'n_experts': 2, 'expert_0': 94.82725921634753, 'expert_1': 74.46776822226289}\n",
      "Epoch: [41][0/9]\tTime 1.328 (1.328)\tLoss 4.0733 (4.0733)\tPrec@1 39.062 (39.062)\n",
      "{'coverage': '58 out of157', 'system_accuracy': 84.71337579617834, 'expert_accuracy': 85.85841240724766, 'classifier_accuracy': 82.75847800262413, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.004855155944824, 'n_experts': 2, 'expert_0': 92.72693553841623, 'expert_1': 77.27237603465439}\n",
      "Epoch: [42][0/9]\tTime 1.309 (1.309)\tLoss 3.9987 (3.9987)\tPrec@1 48.438 (48.438)\n",
      "{'coverage': '38 out of157', 'system_accuracy': 85.98726114649682, 'expert_accuracy': 85.71414165690477, 'classifier_accuracy': 86.84187673190333, 'alone_classifier': 79.61783439490446, 'validation_loss': 6.961697101593018, 'n_experts': 2, 'expert_0': 91.56604441917007, 'expert_1': 72.22182098988338}\n",
      "Epoch: [43][0/9]\tTime 1.299 (1.299)\tLoss 4.0938 (4.0938)\tPrec@1 23.438 (23.438)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 88.13544383823078, 'classifier_accuracy': 87.17926364291372, 'alone_classifier': 80.2547770700637, 'validation_loss': 6.487254937489827, 'n_experts': 2, 'expert_0': 93.84586508964587, 'expert_1': 81.13176931407806}\n",
      "Epoch: [44][0/9]\tTime 1.320 (1.320)\tLoss 3.9643 (3.9643)\tPrec@1 34.375 (34.375)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 90.08249573141201, 'classifier_accuracy': 86.11087191424467, 'alone_classifier': 80.2547770700637, 'validation_loss': 6.608714739481608, 'n_experts': 2, 'expert_0': 93.74970703216552, 'expert_1': 85.96461065048895}\n",
      "Epoch: [45][0/9]\tTime 1.297 (1.297)\tLoss 4.1774 (4.1774)\tPrec@1 20.312 (20.312)\n",
      "{'coverage': '51 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 87.73568351757827, 'classifier_accuracy': 92.15668204572147, 'alone_classifier': 80.89171974522293, 'validation_loss': 6.577591260274251, 'n_experts': 2, 'expert_0': 93.47785444411112, 'expert_1': 83.33305555648148}\n",
      "Epoch: [46][0/9]\tTime 1.289 (1.289)\tLoss 3.9747 (3.9747)\tPrec@1 50.000 (50.000)\n",
      "{'coverage': '57 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 85.999828000344, 'classifier_accuracy': 92.98229301352103, 'alone_classifier': 81.52866242038216, 'validation_loss': 6.582396507263184, 'n_experts': 2, 'expert_0': 92.45248131139128, 'expert_1': 78.72306926353505}\n",
      "Epoch: [47][0/9]\tTime 1.314 (1.314)\tLoss 4.2092 (4.2092)\tPrec@1 57.812 (57.812)\n",
      "{'coverage': '49 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.88872428014021, 'classifier_accuracy': 89.79573511074467, 'alone_classifier': 82.1656050955414, 'validation_loss': 6.57440185546875, 'n_experts': 2, 'expert_0': 93.33302222325926, 'expert_1': 83.33298611255786}\n",
      "Epoch: [48][0/9]\tTime 1.321 (1.321)\tLoss 4.0680 (4.0680)\tPrec@1 79.688 (79.688)\n",
      "{'coverage': '46 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.28812921057799, 'classifier_accuracy': 89.13024102121517, 'alone_classifier': 79.61783439490446, 'validation_loss': 6.7830155690511065, 'n_experts': 2, 'expert_0': 93.15042972485006, 'expert_1': 78.94695291077416}\n",
      "Epoch: [49][0/9]\tTime 1.319 (1.319)\tLoss 4.3060 (4.3060)\tPrec@1 42.188 (42.188)\n",
      "{'coverage': '54 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 87.37847110976483, 'classifier_accuracy': 90.74057270264314, 'alone_classifier': 81.52866242038216, 'validation_loss': 6.776798248291016, 'n_experts': 2, 'expert_0': 94.44409465150129, 'expert_1': 79.59151187138012}\n",
      "Epoch: [50][0/9]\tTime 1.295 (1.295)\tLoss 3.9501 (3.9501)\tPrec@1 75.000 (75.000)\n",
      "{'coverage': '38 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 89.07548054541084, 'classifier_accuracy': 89.47344875408221, 'alone_classifier': 80.2547770700637, 'validation_loss': 6.998815695444743, 'n_experts': 2, 'expert_0': 94.44418209949416, 'expert_1': 80.85071978417113}\n",
      "Epoch: [51][0/9]\tTime 1.331 (1.331)\tLoss 3.9424 (3.9424)\tPrec@1 14.062 (14.062)\n",
      "{'coverage': '42 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 88.69549792087318, 'classifier_accuracy': 92.85692176923388, 'alone_classifier': 81.52866242038216, 'validation_loss': 6.918528397878011, 'n_experts': 2, 'expert_0': 95.08165546998207, 'expert_1': 81.48117969933445}\n",
      "Epoch: [52][0/9]\tTime 1.303 (1.303)\tLoss 3.7467 (3.7467)\tPrec@1 32.812 (32.812)\n",
      "{'coverage': '30 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.97623783269633, 'classifier_accuracy': 86.66637777874074, 'alone_classifier': 79.61783439490446, 'validation_loss': 6.853778680165608, 'n_experts': 2, 'expert_0': 95.58795415307601, 'expert_1': 81.35565642150365}\n",
      "Epoch: [53][0/9]\tTime 1.316 (1.316)\tLoss 4.2394 (4.2394)\tPrec@1 17.188 (17.188)\n",
      "{'coverage': '38 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 89.07548054541084, 'classifier_accuracy': 92.10502077626111, 'alone_classifier': 81.52866242038216, 'validation_loss': 7.248452822367351, 'n_experts': 2, 'expert_0': 94.44409465150129, 'expert_1': 84.61512426115611}\n",
      "Epoch: [54][0/9]\tTime 1.312 (1.312)\tLoss 4.0045 (4.0045)\tPrec@1 12.500 (12.500)\n",
      "{'coverage': '49 out of157', 'system_accuracy': 87.26114649681529, 'expert_accuracy': 86.11095164638583, 'classifier_accuracy': 89.79573511074467, 'alone_classifier': 82.1656050955414, 'validation_loss': 6.858395576477051, 'n_experts': 2, 'expert_0': 94.73634349292898, 'expert_1': 81.42833877617491}\n",
      "Epoch: [55][0/9]\tTime 1.306 (1.306)\tLoss 4.1660 (4.1660)\tPrec@1 48.438 (48.438)\n",
      "{'coverage': '37 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.33318611135648, 'classifier_accuracy': 89.188948137978, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.2270401318868, 'n_experts': 2, 'expert_0': 94.82725921634753, 'expert_1': 82.25779916838978}\n",
      "Epoch: [56][0/9]\tTime 1.313 (1.313)\tLoss 3.7350 (3.7350)\tPrec@1 29.688 (29.688)\n",
      "{'coverage': '51 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 89.62247241042941, 'classifier_accuracy': 86.27434063854776, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.14655605951945, 'n_experts': 2, 'expert_0': 91.9351873058474, 'expert_1': 86.36324380343726}\n",
      "Epoch: [57][0/9]\tTime 1.301 (1.301)\tLoss 4.0672 (4.0672)\tPrec@1 37.500 (37.500)\n",
      "{'coverage': '69 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 87.49980113681559, 'classifier_accuracy': 89.85494223921414, 'alone_classifier': 80.89171974522293, 'validation_loss': 6.912500381469727, 'n_experts': 2, 'expert_0': 93.47785444411112, 'expert_1': 80.95199546668826}\n",
      "Epoch: [58][0/9]\tTime 1.311 (1.311)\tLoss 4.0795 (4.0795)\tPrec@1 62.500 (62.500)\n",
      "{'coverage': '44 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.49541859217948, 'classifier_accuracy': 88.63616219054047, 'alone_classifier': 81.52866242038216, 'validation_loss': 6.886933326721191, 'n_experts': 2, 'expert_0': 94.33926664427682, 'expert_1': 83.33305555648148}\n",
      "Epoch: [59][0/9]\tTime 1.314 (1.314)\tLoss 3.7469 (3.7469)\tPrec@1 34.375 (34.375)\n",
      "{'coverage': '44 out of157', 'system_accuracy': 87.26114649681529, 'expert_accuracy': 87.61046440625768, 'classifier_accuracy': 86.36344008309071, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.377473036448161, 'n_experts': 2, 'expert_0': 91.66636111212962, 'expert_1': 83.0185546469636}\n",
      "Epoch: [60][0/9]\tTime 1.303 (1.303)\tLoss 3.7195 (3.7195)\tPrec@1 48.438 (48.438)\n",
      "{'coverage': '42 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.69549792087318, 'classifier_accuracy': 88.0950283451706, 'alone_classifier': 80.2547770700637, 'validation_loss': 6.990249315897624, 'n_experts': 2, 'expert_0': 91.46319155319132, 'expert_1': 81.81768595341846}\n",
      "Epoch: [61][0/9]\tTime 1.317 (1.317)\tLoss 3.5904 (3.5904)\tPrec@1 43.750 (43.750)\n",
      "{'coverage': '37 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 90.83318194469675, 'classifier_accuracy': 86.48625273985745, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.559183438618978, 'n_experts': 2, 'expert_0': 93.54818591787974, 'expert_1': 81.48087791942282}\n",
      "Epoch: [62][0/9]\tTime 1.294 (1.294)\tLoss 3.9929 (3.9929)\tPrec@1 9.375 (9.375)\n",
      "{'coverage': '46 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 89.18902848823696, 'classifier_accuracy': 86.95633270362455, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.255829652150472, 'n_experts': 2, 'expert_0': 92.49976875057811, 'expert_1': 80.64464100231612}\n",
      "Epoch: [63][0/9]\tTime 1.312 (1.312)\tLoss 3.9417 (3.9417)\tPrec@1 28.125 (28.125)\n",
      "{'coverage': '38 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 89.91581526753735, 'classifier_accuracy': 92.10502077626111, 'alone_classifier': 81.52866242038216, 'validation_loss': 6.944529851277669, 'n_experts': 2, 'expert_0': 94.52028898550962, 'expert_1': 82.60833648549354}\n",
      "Epoch: [64][0/9]\tTime 1.294 (1.294)\tLoss 4.1651 (4.1651)\tPrec@1 9.375 (9.375)\n",
      "{'coverage': '47 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 89.09074710773253, 'classifier_accuracy': 91.48916704432543, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.179346084594727, 'n_experts': 2, 'expert_0': 94.11727797145893, 'expert_1': 84.74547543906631}\n",
      "Epoch: [65][0/9]\tTime 1.292 (1.292)\tLoss 4.0909 (4.0909)\tPrec@1 42.188 (42.188)\n",
      "{'coverage': '42 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 89.56506162597978, 'classifier_accuracy': 92.85692176923388, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.030297756195068, 'n_experts': 2, 'expert_0': 95.71401224567929, 'expert_1': 79.99964444602469}\n",
      "Epoch: [66][0/9]\tTime 1.305 (1.305)\tLoss 3.9924 (3.9924)\tPrec@1 50.000 (50.000)\n",
      "{'coverage': '43 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 89.47352723942589, 'classifier_accuracy': 88.37188750723836, 'alone_classifier': 81.52866242038216, 'validation_loss': 6.981441656748454, 'n_experts': 2, 'expert_0': 93.42080678735056, 'expert_1': 81.57851800779996}\n",
      "Epoch: [67][0/9]\tTime 1.298 (1.298)\tLoss 4.2199 (4.2199)\tPrec@1 28.125 (28.125)\n",
      "{'coverage': '45 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 90.17841039569572, 'classifier_accuracy': 91.11090864242523, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.464474519093831, 'n_experts': 2, 'expert_0': 93.44231658256858, 'expert_1': 86.27417147383736}\n",
      "Epoch: [68][0/9]\tTime 1.309 (1.309)\tLoss 4.1771 (4.1771)\tPrec@1 48.438 (48.438)\n",
      "{'coverage': '34 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 88.61774208497222, 'classifier_accuracy': 94.11737024302869, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.159559408823649, 'n_experts': 2, 'expert_0': 90.78923476517166, 'expert_1': 85.1060208254433}\n",
      "Epoch: [69][0/9]\tTime 1.318 (1.318)\tLoss 4.2516 (4.2516)\tPrec@1 4.688 (4.688)\n",
      "{'coverage': '40 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 89.74343633600625, 'classifier_accuracy': 92.49976875057811, 'alone_classifier': 80.2547770700637, 'validation_loss': 6.731244881947835, 'n_experts': 2, 'expert_0': 94.36593136357361, 'expert_1': 82.60833648549354}\n",
      "Epoch: [70][0/9]\tTime 1.299 (1.299)\tLoss 4.2943 (4.2943)\tPrec@1 60.938 (60.938)\n",
      "{'coverage': '54 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 86.40759920854522, 'classifier_accuracy': 94.44426954764899, 'alone_classifier': 80.2547770700637, 'validation_loss': 6.963499704996745, 'n_experts': 2, 'expert_0': 90.76895148014928, 'expert_1': 78.94695291077416}\n",
      "Epoch: [71][0/9]\tTime 1.311 (1.311)\tLoss 4.2940 (4.2940)\tPrec@1 56.250 (56.250)\n",
      "{'coverage': '66 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 89.01079338287168, 'classifier_accuracy': 89.3938039487819, 'alone_classifier': 79.61783439490446, 'validation_loss': 6.953831513722737, 'n_experts': 2, 'expert_0': 93.7496093766276, 'expert_1': 83.7205408346938}\n",
      "Epoch: [72][0/9]\tTime 1.313 (1.313)\tLoss 4.2946 (4.2946)\tPrec@1 84.375 (84.375)\n",
      "{'coverage': '49 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 89.81464849139168, 'classifier_accuracy': 91.8365472723525, 'alone_classifier': 82.80254777070064, 'validation_loss': 7.070546785990397, 'n_experts': 2, 'expert_0': 94.7365096964572, 'expert_1': 84.31339484943196}\n",
      "Epoch: [73][0/9]\tTime 1.312 (1.312)\tLoss 3.8251 (3.8251)\tPrec@1 54.688 (54.688)\n",
      "{'coverage': '41 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 89.65501783617614, 'classifier_accuracy': 90.24368233248211, 'alone_classifier': 81.52866242038216, 'validation_loss': 7.021201769510905, 'n_experts': 2, 'expert_0': 94.02957006098488, 'expert_1': 83.67312786478422}\n",
      "Epoch: [74][0/9]\tTime 1.301 (1.301)\tLoss 4.2197 (4.2197)\tPrec@1 45.312 (45.312)\n",
      "{'coverage': '34 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 90.24375570121023, 'classifier_accuracy': 91.17620242293404, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.330201307932536, 'n_experts': 2, 'expert_0': 91.46319155319132, 'expert_1': 87.80444973439154}\n",
      "Epoch: [75][0/9]\tTime 1.324 (1.324)\tLoss 4.0043 (4.0043)\tPrec@1 10.938 (10.938)\n",
      "{'coverage': '44 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 91.15028114994486, 'classifier_accuracy': 88.63616219054047, 'alone_classifier': 81.52866242038216, 'validation_loss': 6.944360891977946, 'n_experts': 2, 'expert_0': 94.80494855857516, 'expert_1': 83.33287037294237}\n",
      "Epoch: [76][0/9]\tTime 1.304 (1.304)\tLoss 3.9612 (3.9612)\tPrec@1 45.312 (45.312)\n",
      "{'coverage': '48 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 89.90809191175795, 'classifier_accuracy': 87.4998177087131, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.214261531829834, 'n_experts': 2, 'expert_0': 94.11727797145893, 'expert_1': 86.20659928758866}\n",
      "Epoch: [77][0/9]\tTime 1.286 (1.286)\tLoss 3.8750 (3.8750)\tPrec@1 46.875 (46.875)\n",
      "{'coverage': '42 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 89.56506162597978, 'classifier_accuracy': 92.85692176923388, 'alone_classifier': 82.1656050955414, 'validation_loss': 7.006102720896403, 'n_experts': 2, 'expert_0': 93.93910927542643, 'expert_1': 83.67312786478422}\n",
      "Epoch: [78][0/9]\tTime 1.306 (1.306)\tLoss 3.8438 (3.8438)\tPrec@1 51.562 (51.562)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.982900028983, 'classifier_accuracy': 89.74335963241118, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.0396192868550616, 'n_experts': 2, 'expert_0': 91.99975466732089, 'expert_1': 83.7205408346938}\n",
      "Epoch: [79][0/9]\tTime 1.295 (1.295)\tLoss 4.0040 (4.0040)\tPrec@1 37.500 (37.500)\n",
      "{'coverage': '51 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 91.50926130328055, 'classifier_accuracy': 84.31356016948986, 'alone_classifier': 79.61783439490446, 'validation_loss': 6.904605865478516, 'n_experts': 2, 'expert_0': 94.28544489872885, 'expert_1': 86.11063271870712}\n",
      "Epoch: [80][0/9]\tTime 1.294 (1.294)\tLoss 4.2523 (4.2523)\tPrec@1 62.500 (62.500)\n",
      "{'coverage': '51 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 87.73568351757827, 'classifier_accuracy': 88.23512110760566, 'alone_classifier': 82.1656050955414, 'validation_loss': 6.836203575134277, 'n_experts': 2, 'expert_0': 94.82725921634753, 'expert_1': 79.16633680692998}\n",
      "Epoch: [81][0/9]\tTime 1.325 (1.325)\tLoss 4.0475 (4.0475)\tPrec@1 85.938 (85.938)\n",
      "{'coverage': '38 out of157', 'system_accuracy': 87.26114649681529, 'expert_accuracy': 87.39481110115781, 'classifier_accuracy': 86.84187673190333, 'alone_classifier': 81.52866242038216, 'validation_loss': 6.831102689107259, 'n_experts': 2, 'expert_0': 93.74976562558592, 'expert_1': 74.35859303285625}\n",
      "Epoch: [82][0/9]\tTime 1.308 (1.308)\tLoss 3.9929 (3.9929)\tPrec@1 46.875 (46.875)\n",
      "{'coverage': '34 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 90.24375570121023, 'classifier_accuracy': 85.29386678274474, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.259801387786865, 'n_experts': 2, 'expert_0': 96.96940312302083, 'expert_1': 82.45585103210165}\n",
      "Epoch: [83][0/9]\tTime 1.311 (1.311)\tLoss 3.5236 (3.5236)\tPrec@1 31.250 (31.250)\n",
      "{'coverage': '33 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 87.90308402728382, 'classifier_accuracy': 87.87852158023763, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.396444320678711, 'n_experts': 2, 'expert_0': 91.86025148778722, 'expert_1': 78.94695291077416}\n",
      "Epoch: [84][0/9]\tTime 1.310 (1.310)\tLoss 4.2506 (4.2506)\tPrec@1 23.438 (23.438)\n",
      "{'coverage': '38 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 87.39481110115781, 'classifier_accuracy': 89.47344875408221, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.086613655090332, 'n_experts': 2, 'expert_0': 90.90885478219536, 'expert_1': 80.95199546668826}\n",
      "Epoch: [85][0/9]\tTime 1.292 (1.292)\tLoss 3.8752 (3.8752)\tPrec@1 34.375 (34.375)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 89.25605081644493, 'classifier_accuracy': 86.11087191424467, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.54310417175293, 'n_experts': 2, 'expert_0': 94.25265689044392, 'expert_1': 76.47013841095053}\n",
      "Epoch: [86][0/9]\tTime 1.333 (1.333)\tLoss 3.7892 (3.7892)\tPrec@1 40.625 (40.625)\n",
      "{'coverage': '35 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 90.16378661674325, 'classifier_accuracy': 91.42831020482798, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.397389570871989, 'n_experts': 2, 'expert_0': 93.42080678735056, 'expert_1': 84.78224007721705}\n",
      "Epoch: [87][0/9]\tTime 1.305 (1.305)\tLoss 4.0042 (4.0042)\tPrec@1 25.000 (25.000)\n",
      "{'coverage': '38 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.23514582328433, 'classifier_accuracy': 89.47344875408221, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.442322413126628, 'n_experts': 2, 'expert_0': 93.74970703216552, 'expert_1': 81.81788429860255}\n",
      "Epoch: [88][0/9]\tTime 1.320 (1.320)\tLoss 4.0044 (4.0044)\tPrec@1 28.125 (28.125)\n",
      "{'coverage': '33 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 89.51598465163765, 'classifier_accuracy': 90.90881542783202, 'alone_classifier': 81.52866242038216, 'validation_loss': 7.231200536092122, 'n_experts': 2, 'expert_0': 95.31220214936828, 'expert_1': 83.33305555648148}\n",
      "Epoch: [89][0/9]\tTime 1.333 (1.333)\tLoss 3.6653 (3.6653)\tPrec@1 25.000 (25.000)\n",
      "{'coverage': '46 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.28812921057799, 'classifier_accuracy': 89.13024102121517, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.187151273091634, 'n_experts': 2, 'expert_0': 91.89164353609854, 'expert_1': 81.08064280733618}\n",
      "Epoch: [90][0/9]\tTime 1.302 (1.302)\tLoss 3.9420 (3.9420)\tPrec@1 75.000 (75.000)\n",
      "{'coverage': '48 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 87.155803383847, 'classifier_accuracy': 89.5831467017777, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.414357662200928, 'n_experts': 2, 'expert_0': 93.05529706861924, 'expert_1': 75.67526662018044}\n",
      "Epoch: [91][0/9]\tTime 1.318 (1.318)\tLoss 3.9925 (3.9925)\tPrec@1 57.812 (57.812)\n",
      "{'coverage': '40 out of157', 'system_accuracy': 85.35031847133757, 'expert_accuracy': 88.03403754865376, 'classifier_accuracy': 77.49980625048437, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.826381683349609, 'n_experts': 2, 'expert_0': 92.2075527076553, 'expert_1': 79.999600002}\n",
      "Epoch: [92][0/9]\tTime 1.321 (1.321)\tLoss 3.8672 (3.8672)\tPrec@1 53.125 (53.125)\n",
      "{'coverage': '34 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 90.24375570121023, 'classifier_accuracy': 85.29386678274474, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.59119971593221, 'n_experts': 2, 'expert_0': 92.13462441657434, 'expert_1': 85.29361591990636}\n",
      "Epoch: [93][0/9]\tTime 1.286 (1.286)\tLoss 4.0590 (4.0590)\tPrec@1 21.875 (21.875)\n",
      "{'coverage': '44 out of157', 'system_accuracy': 87.26114649681529, 'expert_accuracy': 87.61046440625768, 'classifier_accuracy': 86.36344008309071, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.565378824869792, 'n_experts': 2, 'expert_0': 91.89164353609854, 'expert_1': 79.4867718627084}\n",
      "Epoch: [94][0/9]\tTime 1.332 (1.332)\tLoss 3.9726 (3.9726)\tPrec@1 65.625 (65.625)\n",
      "{'coverage': '40 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 89.74343633600625, 'classifier_accuracy': 82.49979375051562, 'alone_classifier': 80.2547770700637, 'validation_loss': 8.114896933237711, 'n_experts': 2, 'expert_0': 92.95748462680386, 'expert_1': 84.78224007721705}\n",
      "Epoch: [95][0/9]\tTime 1.312 (1.312)\tLoss 4.0469 (4.0469)\tPrec@1 35.938 (35.938)\n",
      "{'coverage': '40 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.03403754865376, 'classifier_accuracy': 92.49976875057811, 'alone_classifier': 81.52866242038216, 'validation_loss': 7.5575486818949384, 'n_experts': 2, 'expert_0': 93.74970703216552, 'expert_1': 81.13176931407806}\n",
      "Epoch: [96][0/9]\tTime 1.318 (1.318)\tLoss 4.2388 (4.2388)\tPrec@1 23.438 (23.438)\n",
      "{'coverage': '42 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 87.82593421576658, 'classifier_accuracy': 92.85692176923388, 'alone_classifier': 80.89171974522293, 'validation_loss': 6.986068566640218, 'n_experts': 2, 'expert_0': 93.10312723059576, 'expert_1': 82.45585103210165}\n",
      "Epoch: [97][0/9]\tTime 1.312 (1.312)\tLoss 3.9494 (3.9494)\tPrec@1 57.812 (57.812)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 87.28798764747856, 'classifier_accuracy': 92.30745562190866, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.414806048075358, 'n_experts': 2, 'expert_0': 90.76895148014928, 'expert_1': 83.0185546469636}\n",
      "Epoch: [98][0/9]\tTime 1.301 (1.301)\tLoss 4.0158 (4.0158)\tPrec@1 34.375 (34.375)\n",
      "{'coverage': '41 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 88.79295035698213, 'classifier_accuracy': 92.68270077390055, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.483116785685222, 'n_experts': 2, 'expert_0': 92.85681122567419, 'expert_1': 84.99971666761111}\n",
      "Epoch: [99][0/9]\tTime 1.303 (1.303)\tLoss 4.0353 (4.0353)\tPrec@1 29.688 (29.688)\n",
      "{'coverage': '37 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.33318611135648, 'classifier_accuracy': 91.89164353609854, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.462156613667806, 'n_experts': 2, 'expert_0': 91.3040831765705, 'expert_1': 84.31339484943196}\n",
      "Epoch: [100][0/9]\tTime 1.302 (1.302)\tLoss 4.0782 (4.0782)\tPrec@1 15.625 (15.625)\n",
      "{'coverage': '31 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 89.68239732952804, 'classifier_accuracy': 87.0964932371186, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.369260311126709, 'n_experts': 2, 'expert_0': 92.30745562190866, 'expert_1': 85.41631076537182}\n",
      "Epoch: [101][0/9]\tTime 1.297 (1.297)\tLoss 4.2934 (4.2934)\tPrec@1 12.500 (12.500)\n",
      "{'coverage': '37 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 89.16651805580324, 'classifier_accuracy': 91.89164353609854, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.566615581512451, 'n_experts': 2, 'expert_0': 93.50625063311523, 'expert_1': 81.3949702559523}\n",
      "Epoch: [102][0/9]\tTime 1.310 (1.310)\tLoss 4.2191 (4.2191)\tPrec@1 31.250 (31.250)\n",
      "{'coverage': '38 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.23514582328433, 'classifier_accuracy': 89.47344875408221, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.310309886932373, 'n_experts': 2, 'expert_0': 91.5490378900341, 'expert_1': 83.33298611255786}\n",
      "Epoch: [103][0/9]\tTime 1.289 (1.289)\tLoss 4.0587 (4.0587)\tPrec@1 21.875 (21.875)\n",
      "{'coverage': '54 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 88.34934301098444, 'classifier_accuracy': 87.0368758576373, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.453237851460774, 'n_experts': 2, 'expert_0': 92.72693553841623, 'expert_1': 83.33298611255786}\n",
      "Epoch: [104][0/9]\tTime 1.307 (1.307)\tLoss 4.0663 (4.0663)\tPrec@1 67.188 (67.188)\n",
      "{'coverage': '45 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 87.49984375027901, 'classifier_accuracy': 88.88869135846365, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.444778124491374, 'n_experts': 2, 'expert_0': 91.04450434476314, 'expert_1': 82.2218567917476}\n",
      "Epoch: [105][0/9]\tTime 1.301 (1.301)\tLoss 3.8790 (3.8790)\tPrec@1 46.875 (46.875)\n",
      "{'coverage': '42 out of157', 'system_accuracy': 87.26114649681529, 'expert_accuracy': 88.69549792087318, 'classifier_accuracy': 83.33313492110733, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.625319004058838, 'n_experts': 2, 'expert_0': 92.95748462680386, 'expert_1': 81.81780991904583}\n",
      "Epoch: [106][0/9]\tTime 1.322 (1.322)\tLoss 3.8317 (3.8317)\tPrec@1 64.062 (64.062)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 87.28798764747856, 'classifier_accuracy': 92.30745562190866, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.465210437774658, 'n_experts': 2, 'expert_0': 90.54029583703827, 'expert_1': 81.81780991904583}\n",
      "Epoch: [107][0/9]\tTime 1.305 (1.305)\tLoss 4.2503 (4.2503)\tPrec@1 34.375 (34.375)\n",
      "{'coverage': '34 out of157', 'system_accuracy': 86.62420382165605, 'expert_accuracy': 87.80473527685321, 'classifier_accuracy': 82.3526989626501, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.421685536702474, 'n_experts': 2, 'expert_0': 92.49976875057811, 'expert_1': 79.06939967721081}\n",
      "Epoch: [108][0/9]\tTime 1.318 (1.318)\tLoss 3.9490 (3.9490)\tPrec@1 40.625 (40.625)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.982900028983, 'classifier_accuracy': 89.74335963241118, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.906800270080566, 'n_experts': 2, 'expert_0': 91.7805704641905, 'expert_1': 84.4440691374705}\n",
      "Epoch: [109][0/9]\tTime 1.303 (1.303)\tLoss 4.2072 (4.2072)\tPrec@1 23.438 (23.438)\n",
      "{'coverage': '40 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.88873694233001, 'classifier_accuracy': 89.9997750005625, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.45048173268636, 'n_experts': 2, 'expert_0': 91.99975466732089, 'expert_1': 83.33293650982614}\n",
      "Epoch: [110][0/9]\tTime 1.315 (1.315)\tLoss 4.1525 (4.1525)\tPrec@1 53.125 (53.125)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.982900028983, 'classifier_accuracy': 89.74335963241118, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.888015906016032, 'n_experts': 2, 'expert_0': 91.7805704641905, 'expert_1': 84.4440691374705}\n",
      "Epoch: [111][0/9]\tTime 1.308 (1.308)\tLoss 4.1329 (4.1329)\tPrec@1 31.250 (31.250)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 86.62420382165605, 'expert_accuracy': 86.77671607154367, 'classifier_accuracy': 86.11087191424467, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.588090101877849, 'n_experts': 2, 'expert_0': 91.17620242293404, 'expert_1': 81.13176931407806}\n",
      "Epoch: [112][0/9]\tTime 1.313 (1.313)\tLoss 4.2309 (4.2309)\tPrec@1 17.188 (17.188)\n",
      "{'coverage': '34 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.61774208497222, 'classifier_accuracy': 91.17620242293404, 'alone_classifier': 81.52866242038216, 'validation_loss': 7.606618404388428, 'n_experts': 2, 'expert_0': 93.24299123515881, 'expert_1': 81.63231986808218}\n",
      "Epoch: [113][0/9]\tTime 1.312 (1.312)\tLoss 4.1956 (4.1956)\tPrec@1 12.500 (12.500)\n",
      "{'coverage': '34 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.61774208497222, 'classifier_accuracy': 88.23503460283939, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.3074337641398115, 'n_experts': 2, 'expert_0': 91.46319155319132, 'expert_1': 82.92642474914757}\n",
      "Epoch: [114][0/9]\tTime 1.313 (1.313)\tLoss 3.9920 (3.9920)\tPrec@1 7.812 (7.812)\n",
      "{'coverage': '44 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.49541859217948, 'classifier_accuracy': 90.90888429799023, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.778746604919434, 'n_experts': 2, 'expert_0': 92.18721191496276, 'expert_1': 83.67312786478422}\n",
      "Epoch: [115][0/9]\tTime 1.311 (1.311)\tLoss 3.6403 (3.6403)\tPrec@1 57.812 (57.812)\n",
      "{'coverage': '43 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 90.35071868294968, 'classifier_accuracy': 86.04631152020576, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.747739473978679, 'n_experts': 2, 'expert_0': 93.84586508964587, 'expert_1': 85.71393586148628}\n",
      "Epoch: [116][0/9]\tTime 1.322 (1.322)\tLoss 3.8864 (3.8864)\tPrec@1 60.938 (60.938)\n",
      "{'coverage': '45 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 88.39269929875125, 'classifier_accuracy': 86.66647407450205, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.394811153411865, 'n_experts': 2, 'expert_0': 92.98212988726355, 'expert_1': 83.63605950523817}\n",
      "Epoch: [117][0/9]\tTime 1.335 (1.335)\tLoss 4.1956 (4.1956)\tPrec@1 46.875 (46.875)\n",
      "{'coverage': '44 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 89.38037277810128, 'classifier_accuracy': 88.63616219054047, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.532193183898926, 'n_experts': 2, 'expert_0': 92.42396235162923, 'expert_1': 85.1060208254433}\n",
      "Epoch: [118][0/9]\tTime 1.323 (1.323)\tLoss 4.1213 (4.1213)\tPrec@1 42.188 (42.188)\n",
      "{'coverage': '41 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 89.65501783617614, 'classifier_accuracy': 90.24368233248211, 'alone_classifier': 81.52866242038216, 'validation_loss': 7.3829348882039385, 'n_experts': 2, 'expert_0': 92.06319979936572, 'expert_1': 86.79212531273467}\n",
      "Epoch: [119][0/9]\tTime 1.318 (1.318)\tLoss 3.9372 (3.9372)\tPrec@1 15.625 (15.625)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 90.67781241048743, 'classifier_accuracy': 89.74335963241118, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.602370738983154, 'n_experts': 2, 'expert_0': 95.31220214936828, 'expert_1': 85.18486968566783}\n",
      "Epoch: [120][0/9]\tTime 1.310 (1.310)\tLoss 4.2072 (4.2072)\tPrec@1 46.875 (46.875)\n",
      "{'coverage': '44 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 88.49541859217948, 'classifier_accuracy': 86.36344008309071, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.652159849802653, 'n_experts': 2, 'expert_0': 92.30740828489758, 'expert_1': 83.33298611255786}\n",
      "Epoch: [121][0/9]\tTime 1.315 (1.315)\tLoss 4.1330 (4.1330)\tPrec@1 21.875 (21.875)\n",
      "{'coverage': '42 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.69549792087318, 'classifier_accuracy': 90.47597505720223, 'alone_classifier': 82.1656050955414, 'validation_loss': 7.659021218617757, 'n_experts': 2, 'expert_0': 91.7805704641905, 'expert_1': 83.33293650982614}\n",
      "Epoch: [122][0/9]\tTime 1.313 (1.313)\tLoss 3.8434 (3.8434)\tPrec@1 68.750 (68.750)\n",
      "{'coverage': '42 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 87.82593421576658, 'classifier_accuracy': 88.0950283451706, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.315013726552327, 'n_experts': 2, 'expert_0': 93.74970703216552, 'expert_1': 80.39184160062118}\n",
      "Epoch: [123][0/9]\tTime 1.311 (1.311)\tLoss 4.0468 (4.0468)\tPrec@1 64.062 (64.062)\n",
      "{'coverage': '40 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.88873694233001, 'classifier_accuracy': 87.49978125054686, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.885812918345134, 'n_experts': 2, 'expert_0': 92.95748462680386, 'expert_1': 82.60833648549354}\n",
      "Epoch: [124][0/9]\tTime 1.296 (1.296)\tLoss 4.0274 (4.0274)\tPrec@1 42.188 (42.188)\n",
      "{'coverage': '37 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 90.83318194469675, 'classifier_accuracy': 89.188948137978, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.1059346199035645, 'n_experts': 2, 'expert_0': 92.85692176923388, 'expert_1': 86.11063271870712}\n",
      "Epoch: [125][0/9]\tTime 1.297 (1.297)\tLoss 4.2937 (4.2937)\tPrec@1 10.938 (10.938)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 90.9089406463791, 'classifier_accuracy': 86.11087191424467, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.209925651550293, 'n_experts': 2, 'expert_0': 92.85692176923388, 'expert_1': 86.48601899449193}\n",
      "Epoch: [126][0/9]\tTime 1.316 (1.316)\tLoss 3.8244 (3.8244)\tPrec@1 25.000 (25.000)\n",
      "{'coverage': '37 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 89.99985000024999, 'classifier_accuracy': 83.78355734173691, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.286951382954915, 'n_experts': 2, 'expert_0': 92.85687755177841, 'expert_1': 85.999656001376}\n",
      "Epoch: [127][0/9]\tTime 1.317 (1.317)\tLoss 4.0352 (4.0352)\tPrec@1 26.562 (26.562)\n",
      "{'coverage': '40 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 90.59813572968251, 'classifier_accuracy': 87.49978125054686, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.394827842712402, 'n_experts': 2, 'expert_0': 92.64678633298136, 'expert_1': 87.75474385818833}\n",
      "Epoch: [128][0/9]\tTime 1.316 (1.316)\tLoss 3.9491 (3.9491)\tPrec@1 39.062 (39.062)\n",
      "{'coverage': '37 out of157', 'system_accuracy': 91.0828025477707, 'expert_accuracy': 90.83318194469675, 'classifier_accuracy': 91.89164353609854, 'alone_classifier': 79.61783439490446, 'validation_loss': 8.009128252665201, 'n_experts': 2, 'expert_0': 92.85687755177841, 'expert_1': 87.99964800140799}\n",
      "Epoch: [129][0/9]\tTime 1.307 (1.307)\tLoss 3.7263 (3.7263)\tPrec@1 34.375 (34.375)\n",
      "{'coverage': '38 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 88.23514582328433, 'classifier_accuracy': 89.47344875408221, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.496558507283528, 'n_experts': 2, 'expert_0': 91.42831020482798, 'expert_1': 83.67312786478422}\n",
      "Epoch: [130][0/9]\tTime 1.317 (1.317)\tLoss 4.0781 (4.0781)\tPrec@1 35.938 (35.938)\n",
      "{'coverage': '34 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 87.80473527685321, 'classifier_accuracy': 88.23503460283939, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.590834935506185, 'n_experts': 2, 'expert_0': 92.59236396947168, 'expert_1': 78.57105442355036}\n",
      "Epoch: [131][0/9]\tTime 1.302 (1.302)\tLoss 4.1642 (4.1642)\tPrec@1 14.062 (14.062)\n",
      "{'coverage': '41 out of157', 'system_accuracy': 87.89808917197452, 'expert_accuracy': 88.79295035698213, 'classifier_accuracy': 85.36564544964524, 'alone_classifier': 80.89171974522293, 'validation_loss': 7.782083511352539, 'n_experts': 2, 'expert_0': 92.85687755177841, 'expert_1': 82.60833648549354}\n",
      "Epoch: [132][0/9]\tTime 1.310 (1.310)\tLoss 4.1211 (4.1211)\tPrec@1 64.062 (64.062)\n",
      "{'coverage': '35 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 89.34411582931831, 'classifier_accuracy': 88.5711755109271, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.6619979540507, 'n_experts': 2, 'expert_0': 92.95748462680386, 'expert_1': 84.31339484943196}\n",
      "Epoch: [133][0/9]\tTime 1.299 (1.299)\tLoss 3.8316 (3.8316)\tPrec@1 40.625 (40.625)\n",
      "{'coverage': '34 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 89.43074889309122, 'classifier_accuracy': 85.29386678274474, 'alone_classifier': 78.34394904458598, 'validation_loss': 7.466024557749431, 'n_experts': 2, 'expert_0': 93.42080678735056, 'expert_1': 82.97837030480721}\n",
      "Epoch: [134][0/9]\tTime 1.303 (1.303)\tLoss 4.0469 (4.0469)\tPrec@1 43.750 (43.750)\n",
      "{'coverage': '40 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.88873694233001, 'classifier_accuracy': 89.9997750005625, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.41074275970459, 'n_experts': 2, 'expert_0': 92.42396235162923, 'expert_1': 84.31339484943196}\n",
      "Epoch: [135][0/9]\tTime 1.319 (1.319)\tLoss 3.9802 (3.9802)\tPrec@1 40.625 (40.625)\n",
      "{'coverage': '41 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 90.51708531537014, 'classifier_accuracy': 87.80466389106367, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.457489808400472, 'n_experts': 2, 'expert_0': 93.15042972485006, 'expert_1': 86.04611141343528}\n",
      "Epoch: [136][0/9]\tTime 1.299 (1.299)\tLoss 4.1329 (4.1329)\tPrec@1 29.688 (29.688)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.42960590147784, 'classifier_accuracy': 91.66641203774434, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.404936790466309, 'n_experts': 2, 'expert_0': 90.27752700686942, 'expert_1': 85.71393586148628}\n",
      "Epoch: [137][0/9]\tTime 1.318 (1.318)\tLoss 4.0587 (4.0587)\tPrec@1 20.312 (20.312)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 89.25605081644493, 'classifier_accuracy': 86.11087191424467, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.739462534586589, 'n_experts': 2, 'expert_0': 93.05529706861924, 'expert_1': 83.67312786478422}\n",
      "Epoch: [138][0/9]\tTime 1.326 (1.326)\tLoss 4.0663 (4.0663)\tPrec@1 42.188 (42.188)\n",
      "{'coverage': '35 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 89.34411582931831, 'classifier_accuracy': 85.71404081702623, 'alone_classifier': 81.52866242038216, 'validation_loss': 7.65720780690511, 'n_experts': 2, 'expert_0': 93.33308444510814, 'expert_1': 82.97837030480721}\n",
      "Epoch: [139][0/9]\tTime 1.325 (1.325)\tLoss 3.8552 (3.8552)\tPrec@1 48.438 (48.438)\n",
      "{'coverage': '40 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 88.88873694233001, 'classifier_accuracy': 89.9997750005625, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.529595851898193, 'n_experts': 2, 'expert_0': 92.64678633298136, 'expert_1': 83.67312786478422}\n",
      "Epoch: [140][0/9]\tTime 1.324 (1.324)\tLoss 3.9295 (3.9295)\tPrec@1 35.938 (35.938)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 88.53503184713375, 'expert_accuracy': 89.25605081644493, 'classifier_accuracy': 86.11087191424467, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.077761809031169, 'n_experts': 2, 'expert_0': 93.33308444510814, 'expert_1': 82.60833648549354}\n",
      "Epoch: [141][0/9]\tTime 1.301 (1.301)\tLoss 3.7457 (3.7457)\tPrec@1 39.062 (39.062)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 90.08249573141201, 'classifier_accuracy': 88.8886419759945, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.655790646870931, 'n_experts': 2, 'expert_0': 92.95748462680386, 'expert_1': 85.999656001376}\n",
      "Epoch: [142][0/9]\tTime 1.325 (1.325)\tLoss 4.0664 (4.0664)\tPrec@1 29.688 (29.688)\n",
      "{'coverage': '38 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 89.07548054541084, 'classifier_accuracy': 92.10502077626111, 'alone_classifier': 78.34394904458598, 'validation_loss': 7.800726254781087, 'n_experts': 2, 'expert_0': 93.15042972485006, 'expert_1': 82.60833648549354}\n",
      "Epoch: [143][0/9]\tTime 1.284 (1.284)\tLoss 3.7455 (3.7455)\tPrec@1 21.875 (21.875)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 89.83035621973522, 'classifier_accuracy': 89.74335963241118, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.445225556691487, 'n_experts': 2, 'expert_0': 92.95748462680386, 'expert_1': 85.1060208254433}\n",
      "Epoch: [144][0/9]\tTime 1.311 (1.311)\tLoss 3.9294 (3.9294)\tPrec@1 40.625 (40.625)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 90.08249573141201, 'classifier_accuracy': 88.8886419759945, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.845175584157308, 'n_experts': 2, 'expert_0': 93.24299123515881, 'expert_1': 85.1060208254433}\n",
      "Epoch: [145][0/9]\tTime 1.326 (1.326)\tLoss 4.0156 (4.0156)\tPrec@1 23.438 (23.438)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 90.44585987261146, 'expert_accuracy': 90.08249573141201, 'classifier_accuracy': 91.66641203774434, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.489883899688721, 'n_experts': 2, 'expert_0': 92.64678633298136, 'expert_1': 86.79212531273467}\n",
      "Epoch: [146][0/9]\tTime 1.296 (1.296)\tLoss 4.0156 (4.0156)\tPrec@1 46.875 (46.875)\n",
      "{'coverage': '36 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 90.08249573141201, 'classifier_accuracy': 86.11087191424467, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.561837355295817, 'n_experts': 2, 'expert_0': 93.15042972485006, 'expert_1': 85.41631076537182}\n",
      "Epoch: [147][0/9]\tTime 1.306 (1.306)\tLoss 4.1642 (4.1642)\tPrec@1 21.875 (21.875)\n",
      "{'coverage': '39 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 89.83035621973522, 'classifier_accuracy': 87.17926364291372, 'alone_classifier': 80.2547770700637, 'validation_loss': 7.273924668629964, 'n_experts': 2, 'expert_0': 93.24299123515881, 'expert_1': 84.09052686124154}\n",
      "Epoch: [148][0/9]\tTime 1.311 (1.311)\tLoss 4.2503 (4.2503)\tPrec@1 37.500 (37.500)\n",
      "{'coverage': '35 out of157', 'system_accuracy': 89.80891719745223, 'expert_accuracy': 89.34411582931831, 'classifier_accuracy': 91.42831020482798, 'alone_classifier': 78.98089171974522, 'validation_loss': 7.710959434509277, 'n_experts': 2, 'expert_0': 92.95748462680386, 'expert_1': 84.31339484943196}\n",
      "Epoch: [149][0/9]\tTime 1.321 (1.321)\tLoss 3.7691 (3.7691)\tPrec@1 17.188 (17.188)\n",
      "{'coverage': '34 out of157', 'system_accuracy': 89.171974522293, 'expert_accuracy': 89.43074889309122, 'classifier_accuracy': 88.23503460283939, 'alone_classifier': 79.61783439490446, 'validation_loss': 7.552573998769124, 'n_experts': 2, 'expert_0': 93.58950361665738, 'expert_1': 82.2218567917476}\n",
      "Evaluate on Test Data\n",
      "{'coverage': '24 out of87', 'system_accuracy': 94.25287356321839, 'expert_accuracy': 98.41238599242543, 'classifier_accuracy': 83.33298611255786, 'alone_classifier': 72.41379310344827, 'validation_loss': 7.604172229766846, 'n_experts': 2, 'expert_0': 97.3679085899548, 'expert_1': 99.99920000639995}\n",
      "Running fold 2 out of 10\n",
      "Complete first data generation\n",
      "Complete dataloader generation\n",
      "model size: 323.716MB\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/4]\tTime 0.150 (0.150)\tLoss 2.7649 (2.7649)\tPrec@1 37.500 (37.500)\n",
      "Accuracy of the network on the 32 test images: 12.500 %\n",
      "Confusion Matrix:\n",
      "[[ 4  0]\n",
      " [28  0]]\n",
      "Epoch: [1][0/4]\tTime 0.154 (0.154)\tLoss 1.7964 (1.7964)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [2][0/4]\tTime 0.154 (0.154)\tLoss 1.7795 (1.7795)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [3][0/4]\tTime 0.155 (0.155)\tLoss 1.1118 (1.1118)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [4][0/4]\tTime 0.161 (0.161)\tLoss 1.5723 (1.5723)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [5][0/4]\tTime 0.152 (0.152)\tLoss 1.4581 (1.4581)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [6][0/4]\tTime 0.157 (0.157)\tLoss 1.0869 (1.0869)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [7][0/4]\tTime 0.165 (0.165)\tLoss 0.9213 (0.9213)\tPrec@1 75.000 (75.000)\n",
      "Accuracy of the network on the 32 test images: 59.375 %\n",
      "Confusion Matrix:\n",
      "[[ 4  0]\n",
      " [13 15]]\n",
      "Expert trained\n",
      "Starting with AL\n",
      "\n",
      " \n",
      " Round 0 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/5]\tTime 0.160 (0.160)\tLoss 0.9629 (0.9629)\tPrec@1 62.500 (62.500)\n",
      "Accuracy of the network on the 40 test images: 30.000 %\n",
      "Confusion Matrix:\n",
      "[[ 4  0]\n",
      " [28  8]]\n",
      "Epoch: [1][0/5]\tTime 0.159 (0.159)\tLoss 1.1600 (1.1600)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [2][0/5]\tTime 0.158 (0.158)\tLoss 0.6758 (0.6758)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [3][0/5]\tTime 0.158 (0.158)\tLoss 1.0707 (1.0707)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [4][0/5]\tTime 0.155 (0.155)\tLoss 0.5814 (0.5814)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/5]\tTime 0.161 (0.161)\tLoss 0.2731 (0.2731)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/5]\tTime 0.154 (0.154)\tLoss 0.2921 (0.2921)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [7][0/5]\tTime 0.160 (0.160)\tLoss 0.3516 (0.3516)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 40 test images: 97.500 %\n",
      "Confusion Matrix:\n",
      "[[ 4  0]\n",
      " [ 1 35]]\n",
      "\n",
      " \n",
      " Round 1 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/6]\tTime 0.155 (0.155)\tLoss 0.4395 (0.4395)\tPrec@1 87.500 (87.500)\n",
      "Accuracy of the network on the 48 test images: 27.083 %\n",
      "Confusion Matrix:\n",
      "[[ 4  0]\n",
      " [35  9]]\n",
      "Epoch: [1][0/6]\tTime 0.161 (0.161)\tLoss 2.3361 (2.3361)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [2][0/6]\tTime 0.158 (0.158)\tLoss 1.5036 (1.5036)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [3][0/6]\tTime 0.154 (0.154)\tLoss 0.3753 (0.3753)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/6]\tTime 0.160 (0.160)\tLoss 0.8681 (0.8681)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [5][0/6]\tTime 0.157 (0.157)\tLoss 0.7062 (0.7062)\tPrec@1 62.500 (62.500)\n",
      "Epoch: [6][0/6]\tTime 0.157 (0.157)\tLoss 0.4306 (0.4306)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/6]\tTime 0.155 (0.155)\tLoss 0.2982 (0.2982)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 48 test images: 100.000 %\n",
      "Confusion Matrix:\n",
      "[[ 4  0]\n",
      " [ 0 44]]\n",
      "\n",
      " \n",
      " Round 2 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/7]\tTime 0.163 (0.163)\tLoss 1.5390 (1.5390)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 56 test images: 96.429 %\n",
      "Confusion Matrix:\n",
      "[[ 4  2]\n",
      " [ 0 50]]\n",
      "Epoch: [1][0/7]\tTime 0.162 (0.162)\tLoss 1.4324 (1.4324)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [2][0/7]\tTime 0.156 (0.156)\tLoss 0.5771 (0.5771)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [3][0/7]\tTime 0.160 (0.160)\tLoss 0.1728 (0.1728)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/7]\tTime 0.159 (0.159)\tLoss 0.0432 (0.0432)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/7]\tTime 0.160 (0.160)\tLoss 0.0251 (0.0251)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/7]\tTime 0.150 (0.150)\tLoss 0.0642 (0.0642)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/7]\tTime 0.162 (0.162)\tLoss 0.0027 (0.0027)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 56 test images: 100.000 %\n",
      "Confusion Matrix:\n",
      "[[ 6  0]\n",
      " [ 0 50]]\n",
      "\n",
      " \n",
      " Round 3 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/8]\tTime 0.161 (0.161)\tLoss 0.0669 (0.0669)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 64 test images: 81.250 %\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [12 45]]\n",
      "Epoch: [1][0/8]\tTime 0.158 (0.158)\tLoss 0.6836 (0.6836)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [2][0/8]\tTime 0.156 (0.156)\tLoss 0.5635 (0.5635)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [3][0/8]\tTime 0.159 (0.159)\tLoss 0.2683 (0.2683)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/8]\tTime 0.158 (0.158)\tLoss 0.1773 (0.1773)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [5][0/8]\tTime 0.161 (0.161)\tLoss 0.3500 (0.3500)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [6][0/8]\tTime 0.161 (0.161)\tLoss 0.5320 (0.5320)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [7][0/8]\tTime 0.162 (0.162)\tLoss 0.3484 (0.3484)\tPrec@1 87.500 (87.500)\n",
      "Accuracy of the network on the 64 test images: 98.438 %\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [ 1 56]]\n",
      "AL finished\n",
      "Complete first data generation\n",
      "Complete dataloader generation\n",
      "model size: 323.716MB\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/4]\tTime 0.167 (0.167)\tLoss 1.8777 (1.8777)\tPrec@1 12.500 (12.500)\n",
      "Accuracy of the network on the 32 test images: 21.875 %\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [25  0]]\n",
      "Epoch: [1][0/4]\tTime 0.172 (0.172)\tLoss 2.5607 (2.5607)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [2][0/4]\tTime 0.163 (0.163)\tLoss 2.9297 (2.9297)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [3][0/4]\tTime 0.157 (0.157)\tLoss 1.9644 (1.9644)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [4][0/4]\tTime 0.159 (0.159)\tLoss 1.9429 (1.9429)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [5][0/4]\tTime 0.161 (0.161)\tLoss 2.2347 (2.2347)\tPrec@1 50.000 (50.000)\n",
      "Epoch: [6][0/4]\tTime 0.164 (0.164)\tLoss 1.9303 (1.9303)\tPrec@1 12.500 (12.500)\n",
      "Epoch: [7][0/4]\tTime 0.153 (0.153)\tLoss 2.3717 (2.3717)\tPrec@1 50.000 (50.000)\n",
      "Accuracy of the network on the 32 test images: 34.375 %\n",
      "Confusion Matrix:\n",
      "[[ 7  0]\n",
      " [21  4]]\n",
      "Expert trained\n",
      "Starting with AL\n",
      "\n",
      " \n",
      " Round 0 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/5]\tTime 0.166 (0.166)\tLoss 2.4383 (2.4383)\tPrec@1 50.000 (50.000)\n",
      "Accuracy of the network on the 40 test images: 30.000 %\n",
      "Confusion Matrix:\n",
      "[[ 9  0]\n",
      " [28  3]]\n",
      "Epoch: [1][0/5]\tTime 0.161 (0.161)\tLoss 2.4012 (2.4012)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [2][0/5]\tTime 0.167 (0.167)\tLoss 1.9961 (1.9961)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [3][0/5]\tTime 0.157 (0.157)\tLoss 1.8641 (1.8641)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [4][0/5]\tTime 0.166 (0.166)\tLoss 1.4520 (1.4520)\tPrec@1 62.500 (62.500)\n",
      "Epoch: [5][0/5]\tTime 0.164 (0.164)\tLoss 2.4851 (2.4851)\tPrec@1 50.000 (50.000)\n",
      "Epoch: [6][0/5]\tTime 0.166 (0.166)\tLoss 2.0675 (2.0675)\tPrec@1 62.500 (62.500)\n",
      "Epoch: [7][0/5]\tTime 0.167 (0.167)\tLoss 2.4085 (2.4085)\tPrec@1 87.500 (87.500)\n",
      "Accuracy of the network on the 40 test images: 55.000 %\n",
      "Confusion Matrix:\n",
      "[[ 9  0]\n",
      " [18 13]]\n",
      "\n",
      " \n",
      " Round 1 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/6]\tTime 0.162 (0.162)\tLoss 2.0162 (2.0162)\tPrec@1 62.500 (62.500)\n",
      "Accuracy of the network on the 48 test images: 47.917 %\n",
      "Confusion Matrix:\n",
      "[[10  0]\n",
      " [25 13]]\n",
      "Epoch: [1][0/6]\tTime 0.161 (0.161)\tLoss 1.6093 (1.6093)\tPrec@1 50.000 (50.000)\n",
      "Epoch: [2][0/6]\tTime 0.163 (0.163)\tLoss 1.1610 (1.1610)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [3][0/6]\tTime 0.163 (0.163)\tLoss 0.3975 (0.3975)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [4][0/6]\tTime 0.167 (0.167)\tLoss 1.0919 (1.0919)\tPrec@1 62.500 (62.500)\n",
      "Epoch: [5][0/6]\tTime 0.162 (0.162)\tLoss 0.6320 (0.6320)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [6][0/6]\tTime 0.165 (0.165)\tLoss 0.7602 (0.7602)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [7][0/6]\tTime 0.164 (0.164)\tLoss 0.8850 (0.8850)\tPrec@1 87.500 (87.500)\n",
      "Accuracy of the network on the 48 test images: 85.417 %\n",
      "Confusion Matrix:\n",
      "[[10  0]\n",
      " [ 7 31]]\n",
      "\n",
      " \n",
      " Round 2 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/7]\tTime 0.169 (0.169)\tLoss 1.6111 (1.6111)\tPrec@1 62.500 (62.500)\n",
      "Accuracy of the network on the 56 test images: 80.357 %\n",
      "Confusion Matrix:\n",
      "[[12  1]\n",
      " [10 33]]\n",
      "Epoch: [1][0/7]\tTime 0.165 (0.165)\tLoss 1.2723 (1.2723)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [2][0/7]\tTime 0.169 (0.169)\tLoss 1.7081 (1.7081)\tPrec@1 25.000 (25.000)\n",
      "Epoch: [3][0/7]\tTime 0.158 (0.158)\tLoss 0.6235 (0.6235)\tPrec@1 87.500 (87.500)\n",
      "Epoch: [4][0/7]\tTime 0.169 (0.169)\tLoss 0.7972 (0.7972)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [5][0/7]\tTime 0.170 (0.170)\tLoss 0.2959 (0.2959)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [6][0/7]\tTime 0.165 (0.165)\tLoss 0.0646 (0.0646)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/7]\tTime 0.157 (0.157)\tLoss 0.3702 (0.3702)\tPrec@1 87.500 (87.500)\n",
      "Accuracy of the network on the 56 test images: 94.643 %\n",
      "Confusion Matrix:\n",
      "[[13  0]\n",
      " [ 3 40]]\n",
      "\n",
      " \n",
      " Round 3 \n",
      " \n",
      "\n",
      "Number of model parameters: 84860202\n",
      "Epoch: [0][0/8]\tTime 0.160 (0.160)\tLoss 0.2051 (0.2051)\tPrec@1 100.000 (100.000)\n",
      "Accuracy of the network on the 64 test images: 85.938 %\n",
      "Confusion Matrix:\n",
      "[[ 7  7]\n",
      " [ 2 48]]\n",
      "Epoch: [1][0/8]\tTime 0.159 (0.159)\tLoss 0.6780 (0.6780)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [2][0/8]\tTime 0.166 (0.166)\tLoss 1.7461 (1.7461)\tPrec@1 50.000 (50.000)\n",
      "Epoch: [3][0/8]\tTime 0.165 (0.165)\tLoss 1.8945 (1.8945)\tPrec@1 37.500 (37.500)\n",
      "Epoch: [4][0/8]\tTime 0.158 (0.158)\tLoss 1.0146 (1.0146)\tPrec@1 62.500 (62.500)\n",
      "Epoch: [5][0/8]\tTime 0.164 (0.164)\tLoss 1.0422 (1.0422)\tPrec@1 75.000 (75.000)\n",
      "Epoch: [6][0/8]\tTime 0.158 (0.158)\tLoss 0.6820 (0.6820)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [7][0/8]\tTime 0.167 (0.167)\tLoss 1.4386 (1.4386)\tPrec@1 87.500 (87.500)\n",
      "Accuracy of the network on the 64 test images: 90.625 %\n",
      "Confusion Matrix:\n",
      "[[14  0]\n",
      " [ 6 44]]\n",
      "AL finished\n",
      "Start L2D Training\n",
      "Epoch: [0][0/9]\tTime 1.326 (1.326)\tLoss 4.9280 (4.9280)\tPrec@1 28.125 (28.125)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mincrease_experts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 66\u001b[0m, in \u001b[0;36mincrease_experts\u001b[0;34m(param)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# print(model)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#trainD = GalaxyZooDataset()\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#valD = GalaxyZooDataset(split=\"val\")\u001b[39;00m\n\u001b[1;32m     64\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m nih_dataloader\u001b[38;5;241m.\u001b[39mget_data_loader_for_fold(fold_idx)\n\u001b[0;32m---> 66\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpert_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, valid_loader, test_loader, expert_fns, config, seed, experts)\u001b[0m\n\u001b[1;32m     24\u001b[0m lrate \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m---> 27\u001b[0m     iters, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpert_fns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     experts_fns_eval \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m expert \u001b[38;5;129;01min\u001b[39;00m experts:\n",
      "Cell \u001b[0;32mIn[19], line 29\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(iters, warmup_iters, lrate, train_loader, model, optimizer, scheduler, epoch, expert_fns, loss_fn, n_classes, alpha, config)\u001b[0m\n\u001b[1;32m     25\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     27\u001b[0m epoch_train_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (\u001b[38;5;28minput\u001b[39m, target, hpred) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iters \u001b[38;5;241m<\u001b[39m warmup_iters:\n\u001b[1;32m     31\u001b[0m         lr \u001b[38;5;241m=\u001b[39m lrate \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m(iters) \u001b[38;5;241m/\u001b[39m warmup_iters\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/NIH/Dataset.py:127\u001b[0m, in \u001b[0;36mNIHDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    126\u001b[0m     filename, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_ids[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index]\n\u001b[0;32m--> 127\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess:\n\u001b[1;32m    129\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformImage(img)\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/NIH/Dataset.py:102\u001b[0m, in \u001b[0;36mNIHDataset.getImage\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages[idx]\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/NIH/Dataset.py:93\u001b[0m, in \u001b[0;36mNIHDataset.loadImage\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadImage\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    Load one single image\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m244\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m244\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/PIL/Image.py:2192\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2184\u001b[0m             \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2185\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2186\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2187\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2188\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2189\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2190\u001b[0m         )\n\u001b[0;32m-> 2192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "increase_experts(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082619ff-e24a-44f9-beb2-3c01fd1c94c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joli-env_kernel",
   "language": "python",
   "name": "joli-env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
