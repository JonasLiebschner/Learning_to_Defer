{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce4ea949-0385-4214-846f-26600a12ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tarfile\n",
    "import shutil\n",
    "import urllib\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import hashlib\n",
    "\n",
    "import random\n",
    "from itertools import chain\n",
    "from typing import Any, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.v2 as transforms2\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "641e5263-f741-428a-ab66-5132efb70134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDatasetCIFAR100():\n",
    "    \"\"\"\n",
    "    Contains the main Dataset with GT Label and Expert Label for every Image, sorted by file name\n",
    "    \"\"\"\n",
    "    def __init__(self, path_labels, path_data):\n",
    "\n",
    "        self.path_labels = path_labels\n",
    "        self.cifar_dataset = self.load_cifar_100(path_data)\n",
    "        self.gt_df = pd.DataFrame({\"GT\": self.cifar_dataset.targets})\n",
    "        self.gt_df = self.gt_df.rename_axis(\"Image ID\").reset_index()\n",
    "\n",
    "        print(\"Number of images of the whole dataset: \" + str(len(self.gt_df[\"Image ID\"].values)))\n",
    "        \n",
    "    def load_cifar_100(self, path):\n",
    "        \"\"\"\n",
    "        Loads the CIFAR100 dataset from pytorch\n",
    "        \"\"\"\n",
    "        transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        return torchvision.datasets.CIFAR100(root=f'{path}/CIFAR100', train=True, download=True, transform=transform)\n",
    "        \n",
    "\n",
    "    def get_synthetic_labels(self, path, experts_args, seed):\n",
    "        expert_labels = {}\n",
    "        for name, expert_arg in experts_args.items():\n",
    "            path_name = self. expert_to_path(name, expert_arg.copy(), seed)\n",
    "            if self.check_if_expert_exists(path, path_name, expert_arg[\"strength\"]):\n",
    "                expert_labels[seed][name] == self.load_expert_from_path(pat, path_name, expert_arg[\"strength\"])\n",
    "            else:\n",
    "                expert_labels[seed][name] == self.create_synthetic_labels(expert_args, name, seed)[\"train\"]\n",
    "             \n",
    "        return self.synthetic_labels\n",
    "\n",
    "    def create_synthetic_labels(self, expert_args, name, seed):\n",
    "        expert_labels = synex.generate_synthetic_expert(strength=expert_arg[\"strength\"], binary=expert_arg[\"binary\"], num_classes=expert_arg[\"num_classes\"], per_s=expert_arg[\"per_s\"], per_w=expert_arg[\"per_w\"], seed=seed, path=self.path_labels, name=name)\n",
    "        return expert_labels\n",
    "\n",
    "    def check_if_expert_exists(self, path, name_path, strength):\n",
    "        my_file = Path(f'{path}/synthetic_experts/{path_name}/cifar100_expert_{strength}_labels.json')\n",
    "        return my_file.is_file()\n",
    "\n",
    "    def load_expert_from_path(self, path, path_name, strength):\n",
    "        with open(f'{path}/synthetic_experts/{path_name}/cifar100_expert_{strength}_labels.json', 'r') as f:\n",
    "            labels = json.load(f)\n",
    "        return labels[\"train\"]\n",
    "\n",
    "    def expert_to_path(self, name, args, seed):\n",
    "        args = args.copy()\n",
    "        args[\"name\"] = name\n",
    "        args[\"seed\"] = seed\n",
    "        return self.param_to_path(args)\n",
    "\n",
    "    def param_to_path(self, args):\n",
    "        s = \"\"\n",
    "        for key, value in args.items():\n",
    "            s += f\"{key}_{value}_\"\n",
    "        s = s[:-1]\n",
    "        return int(hashlib.sha256(s.encode('utf-8')).hexdigest(), 16) % 10**8\n",
    "    \n",
    "\n",
    "    def getExpert(self, id):\n",
    "        \"\"\"\n",
    "        Returns the data for the given expert\n",
    "        \"\"\"\n",
    "        return self.data[[\"Image ID\", \"GT\", str(id)]].copy()\n",
    "\n",
    "    def getData(self):\n",
    "        \"\"\"\n",
    "        Returns all data\n",
    "        \"\"\"\n",
    "        return self.data.copy()\n",
    "    \n",
    "    def getDataForLabelers(self, labelerIds):\n",
    "        \"\"\"\n",
    "        Returns the data with [\"Image ID\", \"GT\", [labelerIds]]\n",
    "        \"\"\"\n",
    "        temp = self.data[[\"Image ID\", \"GT\"]].copy()\n",
    "        for labelerId in labelerIds:\n",
    "            temp[str(labelerId)] = self.data[str(labelerId)]\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fd2fca2-f79d-47ec-a1fc-f7278552b3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ../../../Datasets/CIFAR100/CIFAR100/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 169001437/169001437 [00:07<00:00, 24062902.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../Datasets/CIFAR100/CIFAR100/cifar-100-python.tar.gz to ../../../Datasets/CIFAR100/CIFAR100\n",
      "Number of images of the whole dataset: 50000\n"
     ]
    }
   ],
   "source": [
    "bd = BasicDatasetCIFAR100(path_labels=\"../../../Datasets/CIFAR100\", path_data=\"../../../Datasets/CIFAR100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ce9b8d-35ad-45d0-adf7-89ce58f44f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrueEx_cifar100_60_labels.json\n"
     ]
    }
   ],
   "source": [
    "bd.get_synthetic_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b89bb-418b-43e5-ba5e-5ce58ad0d40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joli-env_kernel",
   "language": "python",
   "name": "joli-env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
