{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fea6ec85-0e5f-41a6-b440-89d19e4a596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Verma.main_increase_experts_hard_coded as verm\n",
    "import Verma.experts as vexp\n",
    "import Verma.losses as vlos\n",
    "from Verma.utils import AverageMeter, accuracy\n",
    "import Verma.resnet50 as vres\n",
    "\n",
    "import NIH.Dataset as ds\n",
    "import expert as ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2733e4a6-282d-49c8-b221-5ebba2acf25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c66724-6e7c-4f63-8ad5-de7de616db1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e081bf9-3d61-4c7e-a526-0f999cbec5bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"batch_size\": 64,\n",
    "    \"alpha\": 1.0, #scaling parameter for the loss function, default=1.0\n",
    "    \"epochs\": 150,\n",
    "    \"patience\": 50, #number of patience steps for early stopping the training\n",
    "    \"expert_type\": \"MLPMixer\", #specify the expert type. For the type of experts available, see-> models -> experts. defualt=predict\n",
    "    \"n_classes\": 2, #K for K class classification\n",
    "    \"k\": 0, #\n",
    "    \"n_experts\": 2, #\n",
    "    \"lr\": 0.001, #learning rate\n",
    "    \"weight_decay\": 5e-4, #\n",
    "    \"warmup_epochs\": 5, #\n",
    "    \"loss_type\": \"softmax\", #surrogate loss type for learning to defer\n",
    "    \"ckp_dir\": \"./Models\", #directory name to save the checkpoints\n",
    "    \"experiment_name\": \"multiple_experts\", #specify the experiment name. Checkpoints will be saved with this name\n",
    "    #\n",
    "    \"TRAIN_BATCH_SIZE\": 64,\n",
    "    \"TEST_BATCH_SIZE\": 64,\n",
    "    \"NUM_EXPERTS\": 2,\n",
    "    \"K\": 10,\n",
    "    \"TARGET\": \"Airspace_Opacity\",\n",
    "    \"LABELER_IDS\": [4323195249, 4295232296],\n",
    "    #\n",
    "    \"maxLabels\": 16,\n",
    "    \"PATH\": \"../Datasets/NIH/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75ffd9-2631-4281-b014-f9d42667bcc1",
   "metadata": {},
   "source": [
    "Expert, adjustable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b11bd4b-9239-4d3c-a015-8060cc9875bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class synth_expert:\n",
    "    '''\n",
    "\n",
    "    ----\n",
    "    k: number of classes expert can predict\n",
    "    n_classes: number of classes\n",
    "    '''\n",
    "    def __init__(self, flip_prob=0.30, p_in=0.75):\n",
    "        self.n_classes = 2\n",
    "        self.flip_prob = flip_prob\n",
    "        self.p_in = p_in\n",
    "        \n",
    "\n",
    "    def HumanExpert(self, X, labels, hpred):\n",
    "        return hpred.cpu().tolist()\n",
    "\n",
    "    # flips human label with prob. flip_prob\n",
    "    def FlipHuman(self, X, labels, hpred):\n",
    "        batch_size = labels.size()[0]  # batch_size\n",
    "        outs = [0] * batch_size\n",
    "        for i in range(0, batch_size):\n",
    "            coin_flip = np.random.binomial(1, self.flip_prob)\n",
    "            if coin_flip == 1:\n",
    "                outs[i] = ((1 - hpred[i]) > 0)*1\n",
    "            else:\n",
    "                outs[i] = hpred[i].item()\n",
    "        return outs\n",
    "\n",
    "    # takes human prediction with prob. p_in, otherwise predicts randomly\n",
    "    def predict_prob(self, input, labels, hpred):\n",
    "        batch_size = labels.size()[0]\n",
    "        outs = [0] * batch_size\n",
    "        for i in range(0, batch_size):\n",
    "            coin_flip = np.random.binomial(1, self.p_in)\n",
    "            if coin_flip == 1:\n",
    "                outs[i] = hpred[i].item()\n",
    "            if coin_flip == 0:\n",
    "                outs[i] = random.randint(0, self.n_classes - 1)\n",
    "        return outs\n",
    "        \n",
    "    # Experts predict correctly for some class, not perfectly other class\n",
    "    # def predict_prob(self, input, labels, hpred, k=0, p_in=0.75, p_out=1/2):\n",
    "    #     batch_size = labels.size()[0]\n",
    "    #     outs = [0] * batch_size\n",
    "    #     for i in range(0, batch_size):\n",
    "    #         if labels[i].item() <= k:\n",
    "    #             coin_flip = np.random.binomial(1, p_in)\n",
    "    #             if coin_flip == 1:\n",
    "    #                 outs[i] = labels[i].item()\n",
    "    #             if coin_flip == 0:\n",
    "    #                 outs[i] = random.randint(0, self.n_classes - 1)\n",
    "    #         else:\n",
    "    #             coin_flip = np.random.binomial(1, p_out)\n",
    "    #             if coin_flip == 1:\n",
    "    #                 outs[i] = labels[i].item()\n",
    "    #             if coin_flip == 0:\n",
    "    #                 outs[i] = random.randint(0, self.n_classes - 1)\n",
    "    #     return outs\n",
    "\n",
    "\n",
    "    # completely random\n",
    "    def predict_random(self, input, labels, hpred):\n",
    "        batch_size = labels.size()[0]  # batch_size\n",
    "        outs = [0] * batch_size\n",
    "        for i in range(0, batch_size):\n",
    "            prediction_rand = random.randint(0, self.n_classes - 1)\n",
    "            outs[i] = prediction_rand\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061b1d3d-9f2b-4377-8052-f42d72cbc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NihExpert:\n",
    "    \"\"\"A class used to represent an Expert on NIH ChestX-ray data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labeler_id : int\n",
    "        the Reader ID to specify which radiologist the expert object represents\n",
    "    target : str\n",
    "        the target to make predictions for\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    labeler_id : int\n",
    "        the Reader ID to specify which radiologist the expert object represents\n",
    "    target : str\n",
    "        the target to make predictions for\n",
    "    image_id_to_prediction : dict of {int : str}\n",
    "        a dictionary that maps the image id to the prediction the radiologist made for the specified target\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    predict(image_ids)\n",
    "        makes a prediction for the given image ids\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labeler_id: int, target: str, PATH, numLabels=800, prob=0.5):\n",
    "        self.labelerId = labeler_id\n",
    "        self.target = target\n",
    "        self.maxLabels = numLabels\n",
    "        self.prob = prob\n",
    "        \n",
    "        self.resetPredictionCount()\n",
    "\n",
    "        individual_labels = pd.read_csv(PATH + \"labels.csv\")\n",
    "\n",
    "        expert_labels = individual_labels[individual_labels[\"Reader ID\"] == self.labelerId][\n",
    "            [\"Image ID\", self.target + \"_Expert_Label\", self.target + \"_GT_Label\"]]\n",
    "        expert_labels = expert_labels.fillna(0)\n",
    "\n",
    "        self.image_id_to_prediction = pd.Series(expert_labels[self.target + \"_Expert_Label\"].values,\n",
    "                                                index=expert_labels[\"Image ID\"]).to_dict()\n",
    "\n",
    "    def predict(self, image_ids):\n",
    "        \"\"\"Returns the experts predictions for the given image ids. Works only for image ids that are labeled by the expert\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_ids : list of int\n",
    "            the image ids to get the radiologists predictions for\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of int\n",
    "            returns a list of 0 or 1 that represent the radiologists prediction for the specified target\n",
    "        \"\"\"\n",
    "        return [self.image_id_to_prediction[image_id] for image_id in image_ids]\n",
    "\n",
    "    def predict_unlabeled_data(self, image_ids):\n",
    "        \"\"\"Returns the experts predictions for the given image ids. Works for all image ids, returns -1 if not labeled by expert\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_ids : list of int\n",
    "            the image ids to get the radiologists predictions for\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of int\n",
    "            returns a list of 0 or 1 that represent the radiologists prediction for the specified target, or -1 if no prediction\n",
    "        \"\"\"\n",
    "        return [self.image_id_to_prediction[image_id] if image_id in self.image_id_to_prediction else -1 for image_id in image_ids]\n",
    "    \n",
    "    def predictN(self, img, target, image_ids):\n",
    "        \"\"\"Returns the experts predictions for the given image ids. Works only for image ids that are labeled by the expert\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_ids : list of int\n",
    "            the image ids to get the radiologists predictions for\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of int\n",
    "            returns a list of 0 or 1 that represent the radiologists prediction for the specified target\n",
    "        \"\"\"\n",
    "        return [self.image_id_to_prediction[image_id] for image_id in image_ids]\n",
    "    \n",
    "    def predictNew(self, image_ids):\n",
    "        \"\"\"\n",
    "        Returns the expert prediction for the first n predictions\n",
    "        For every other prediction is predicts with the probability (random guessing)\n",
    "        \"\"\"\n",
    "        length = len(image_ids)\n",
    "        if (self.predictions + length) <= self.maxLabels:\n",
    "            self.predictions += length\n",
    "            return [self.image_id_to_prediction[image_id] for image_id in image_ids]\n",
    "        else:\n",
    "            temp_predictions = [self.image_id_to_prediction[image_id] for image_id in image_ids[:(self.maxLabels - self.predictions)]]\n",
    "            self.predictions = self.maxLabels\n",
    "            for image_id in image_ids[(self.maxLabels - self.predictions):]:\n",
    "                if np.random.uniform(0,1) > self.prob:\n",
    "                    temp_predictions.append(self.image_id_to_prediction[image_id])\n",
    "                else:\n",
    "                    temp_predictions.append(np.random.randint(2, size=1))\n",
    "    \n",
    "    def resetPredictionCount(self):\n",
    "        self.predictions = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7ac056e-1fde-4991-a4ce-eb3e61c68085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25352563-9f08-4c63-ac2e-54ca40fd60bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "837f19ed-5aa2-46be-b470-0d87812cecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_experts(param):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    experiment_experts = [7, 9, 10]\n",
    "    # for seed in ['', 948,  625,  436,  791]:\n",
    "    for seed in [948, 625, 436]:\n",
    "        print(\"run for seed {}\".format(seed))\n",
    "        if seed != \"\":\n",
    "            set_seed(seed)\n",
    "        log = {\"selected_experts\": [], \"selected_expert_fns\": []} \n",
    "    \n",
    "        \n",
    "        \n",
    "        #Use new Dataset\n",
    "        nih_dataloader = ds.NIH_K_Fold_Dataloader(\n",
    "            dataset = basic_Dataset,\n",
    "            k = params[\"K\"],\n",
    "            labelerIds = params[\"LABELER_IDS\"],\n",
    "            train_batch_size = params[\"TRAIN_BATCH_SIZE\"],\n",
    "            test_batch_size = params[\"TEST_BATCH_SIZE\"],\n",
    "            seed = seed,\n",
    "            maxLabels = maxL,\n",
    "            preload = True,\n",
    "            prebuild = True,\n",
    "            param = params\n",
    "        )\n",
    "            \n",
    "        expert_fns = []\n",
    "        for labelerId in list(params[\"LABELER_IDS\"]):\n",
    "            nih_expert = ex.Expert(dataset = basic_Dataset, labeler_id=labelerId)\n",
    "            expert_fns.append(nih_expert.predict)\n",
    "            \n",
    "        for fold_idx in range(param[\"K\"]):\n",
    "            print(f'Running fold {fold_idx+1} out of {param[\"K\"]}')\n",
    "        #for i, n in enumerate(experiment_experts):\n",
    "            #print(\"n is {}\".format(n))\n",
    "            #num_experts = n\n",
    "            \n",
    "            num_experts = len(expert_fns)\n",
    "\n",
    "            #Use new Expert\n",
    "            #expert_fns = [experts[j] for j in range(n)]\n",
    "            \n",
    "            model = model = vres.ResNet50_defer(int(param[\"n_classes\"]) + num_experts)\n",
    "            # print(model)\n",
    "            #trainD = GalaxyZooDataset()\n",
    "            #valD = GalaxyZooDataset(split=\"val\")\n",
    "            \n",
    "            train_loader, val_loader, test_loader = nih_dataloader.get_data_loader_for_fold(fold_idx)\n",
    "            \n",
    "            train(model, train_loader, val_loader, test_loader, expert_fns, param, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e56945e-a5ce-4c3b-84f7-53dc46569ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, test_loader, expert_fns, config, seed=\"\"):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    n_classes = config[\"n_classes\"] + len(expert_fns)\n",
    "    kwargs = {\"num_workers\": 0, \"pin_memory\": True}\n",
    "\n",
    "    model = model.to(device)\n",
    "    cudnn.benchmark = True\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), config[\"lr\"], weight_decay=config[\"weight_decay\"]\n",
    "    )\n",
    "    criterion = vlos.Criterion()\n",
    "    loss_fn = getattr(criterion, config[\"loss_type\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, len(train_loader) * config[\"epochs\"]\n",
    "    )\n",
    "    best_validation_loss = np.inf\n",
    "    patience = 0\n",
    "    iters = 0\n",
    "    warmup_iters = config[\"warmup_epochs\"] * len(train_loader)\n",
    "    lrate = config[\"lr\"]\n",
    "\n",
    "    for epoch in range(0, config[\"epochs\"]):\n",
    "        iters, train_loss = train_epoch(\n",
    "            iters,\n",
    "            warmup_iters,\n",
    "            lrate,\n",
    "            train_loader,\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            epoch,\n",
    "            expert_fns,\n",
    "            loss_fn,\n",
    "            n_classes,\n",
    "            config[\"alpha\"],\n",
    "            config,\n",
    "        )\n",
    "        metrics = evaluate(model, expert_fns, loss_fn, n_classes, valid_loader, config)\n",
    "\n",
    "        validation_loss = metrics[\"validation_loss\"]\n",
    "\n",
    "        if validation_loss < best_validation_loss:\n",
    "            \"\"\"best_validation_loss = validation_loss\n",
    "            print(\n",
    "                \"Saving the model with classifier accuracy {}\".format(\n",
    "                    metrics[\"classifier_accuracy\"]\n",
    "                ),\n",
    "                flush=True,\n",
    "            )\n",
    "            save_path = os.path.join(\n",
    "                config[\"ckp_dir\"],\n",
    "                config[\"experiment_name\"]\n",
    "                + \"_\"\n",
    "                + str(len(expert_fns))\n",
    "                + \"_experts\"\n",
    "                + \"_seed_\"\n",
    "                + str(seed),\n",
    "            )\"\"\"\n",
    "            #torch.save(model.state_dict(), save_path + \".pt\")\n",
    "            # Additionally save the whole config dict\n",
    "            #with open(save_path + \".json\", \"w\") as f:\n",
    "            #    json.dump(config, f)\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        if patience >= config[\"patience\"]:\n",
    "            print(\"Early Exiting Training.\", flush=True)\n",
    "            break\n",
    "            \n",
    "    print(\"Evaluate on Test Data\")\n",
    "    metrics = evaluate(model, expert_fns, loss_fn, n_classes, test_loader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd8a5255-aac7-4048-bcbd-0a00fe8ef6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    iters,\n",
    "    warmup_iters,\n",
    "    lrate,\n",
    "    train_loader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    epoch,\n",
    "    expert_fns,\n",
    "    loss_fn,\n",
    "    n_classes,\n",
    "    alpha,\n",
    "    config,\n",
    "):\n",
    "    \"\"\" Train for one epoch \"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    epoch_train_loss = []\n",
    "\n",
    "    for i, (input, target, hpred) in enumerate(train_loader):\n",
    "        if iters < warmup_iters:\n",
    "            lr = lrate * float(iters) / warmup_iters\n",
    "            print(iters, lr)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "\n",
    "        target = target.to(device)\n",
    "        input = input.to(device)\n",
    "        hpred = hpred\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "\n",
    "        if config[\"loss_type\"] == \"softmax\":\n",
    "            output = F.softmax(output, dim=1)\n",
    "\n",
    "        # get expert  predictions and costs\n",
    "        batch_size = output.size()[0]  # batch_size\n",
    "        collection_Ms = []\n",
    "        # We only support \\alpha=1\n",
    "        for _, fn in enumerate(expert_fns):\n",
    "            # We assume each expert function has access to the extra metadata, even if they don't use it.\n",
    "            m = fn(input, target, hpred)\n",
    "            #m = fn(hpred)\n",
    "            m2 = [0] * batch_size\n",
    "            for j in range(0, batch_size):\n",
    "                if m[j] == target[j].item():\n",
    "                    m[j] = 1\n",
    "                    m2[j] = alpha\n",
    "                else:\n",
    "                    m[j] = 0\n",
    "                    m2[j] = 1\n",
    "            m = torch.tensor(m)\n",
    "            m2 = torch.tensor(m2)\n",
    "            m = m.to(device)\n",
    "            m2 = m2.to(device)\n",
    "            collection_Ms.append((m, m2))\n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_fn(output, target, collection_Ms, n_classes)\n",
    "        epoch_train_loss.append(loss.item())\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if not iters < warmup_iters:\n",
    "            scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        iters += 1\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}]\\t\"\n",
    "                \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
    "                \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
    "                \"Prec@1 {top1.val:.3f} ({top1.avg:.3f})\".format(\n",
    "                    epoch,\n",
    "                    i,\n",
    "                    len(train_loader),\n",
    "                    batch_time=batch_time,\n",
    "                    loss=losses,\n",
    "                    top1=top1,\n",
    "                ),\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    return iters, np.average(epoch_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18375f87-e050-4b01-a66d-d0519c461050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, expert_fns, loss_fn, n_classes, data_loader, config):\n",
    "    \"\"\"\n",
    "    Computes metrics for deferal\n",
    "    -----\n",
    "    Arguments:\n",
    "    net: model\n",
    "    expert_fn: expert model\n",
    "    n_classes: number of classes\n",
    "    loader: data loader\n",
    "    \"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    #  === Individual Expert Accuracies === #\n",
    "    expert_correct_dic = {k: 0 for k in range(len(expert_fns))}\n",
    "    expert_total_dic = {k: 0 for k in range(len(expert_fns))}\n",
    "    #  === Individual  Expert Accuracies === #\n",
    "    alpha = config[\"alpha\"]\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels, hpred = data\n",
    "            images, labels, hpred = images.to(device), labels.to(device), hpred\n",
    "            outputs = model(images)\n",
    "            if config[\"loss_type\"] == \"softmax\":\n",
    "                outputs = F.softmax(outputs, dim=1)\n",
    "            if config[\"loss_type\"] == \"ova\":\n",
    "                ouputs = F.sigmoid(outputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_size = outputs.size()[0]  # batch_size\n",
    "\n",
    "            expert_predictions = []\n",
    "            collection_Ms = []  # a collection of 3-tuple\n",
    "            for i, fn in enumerate(expert_fns, 0):\n",
    "                exp_prediction1 = fn(images, labels, hpred)\n",
    "                #exp_prediction1 = fn(hpred)\n",
    "                m = [0] * batch_size\n",
    "                m2 = [0] * batch_size\n",
    "                for j in range(0, batch_size):\n",
    "                    if exp_prediction1[j] == labels[j].item():\n",
    "                        m[j] = 1\n",
    "                        m2[j] = alpha\n",
    "                    else:\n",
    "                        m[j] = 0\n",
    "                        m2[j] = 1\n",
    "\n",
    "                m = torch.tensor(m)\n",
    "                m2 = torch.tensor(m2)\n",
    "                m = m.to(device)\n",
    "                m2 = m2.to(device)\n",
    "                collection_Ms.append((m, m2))\n",
    "                expert_predictions.append(exp_prediction1)\n",
    "\n",
    "            loss = loss_fn(outputs, labels, collection_Ms, n_classes)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            for i in range(0, batch_size):\n",
    "                r = predicted[i].item() >= n_classes - len(expert_fns)\n",
    "                prediction = predicted[i]\n",
    "                if predicted[i] >= n_classes - len(expert_fns):\n",
    "                    max_idx = 0\n",
    "                    # get second max\n",
    "                    for j in range(0, n_classes - len(expert_fns)):\n",
    "                        if outputs.data[i][j] >= outputs.data[i][max_idx]:\n",
    "                            max_idx = j\n",
    "                    prediction = max_idx\n",
    "                else:\n",
    "                    prediction = predicted[i]\n",
    "                alone_correct += (prediction == labels[i]).item()\n",
    "                if r == 0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == labels[i]).item()\n",
    "                    correct_sys += (predicted[i] == labels[i]).item()\n",
    "                if r == 1:\n",
    "                    deferred_exp = (predicted[i] - (n_classes - len(expert_fns))).item()\n",
    "                    # cdeferred_exp = ((n_classes - 1) - predicted[i]).item()  # reverse order, as in loss function\n",
    "                    exp_prediction = expert_predictions[deferred_exp][i]\n",
    "                    #\n",
    "                    # Deferral accuracy: No matter expert ===\n",
    "                    exp += exp_prediction == labels[i].item()\n",
    "                    exp_total += 1\n",
    "                    # Individual Expert Accuracy ===\n",
    "                    expert_correct_dic[deferred_exp] += (\n",
    "                        exp_prediction == labels[i].item()\n",
    "                    )\n",
    "                    expert_total_dic[deferred_exp] += 1\n",
    "                    #\n",
    "                    correct_sys += exp_prediction == labels[i].item()\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "\n",
    "    #  === Individual Expert Accuracies === #\n",
    "    expert_accuracies = {\n",
    "        \"expert_{}\".format(str(k)): 100\n",
    "        * expert_correct_dic[k]\n",
    "        / (expert_total_dic[k] + 0.0002)\n",
    "        for k in range(len(expert_fns))\n",
    "    }\n",
    "    # Add expert accuracies dict\n",
    "    to_print = {\n",
    "        \"coverage\": cov,\n",
    "        \"system_accuracy\": 100 * correct_sys / real_total,\n",
    "        \"expert_accuracy\": 100 * exp / (exp_total + 0.0002),\n",
    "        \"classifier_accuracy\": 100 * correct / (total + 0.0001),\n",
    "        \"alone_classifier\": 100 * alone_correct / real_total,\n",
    "        \"validation_loss\": np.average(losses),\n",
    "        \"n_experts\": len(expert_fns),\n",
    "        **expert_accuracies,\n",
    "    }\n",
    "    print(to_print, flush=True)\n",
    "    return to_print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd8e0ca0-518e-4bab-ad22-5d588aa3b6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run for seed 948\n",
      "Running fold 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/home/joli/joli-env/lib/python3.9/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/joli/joli-env/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '6 out of157', 'system_accuracy': 81.52866242038216, 'expert_accuracy': 83.44359808794955, 'classifier_accuracy': 33.33277778703688, 'alone_classifier': 51.59235668789809, 'validation_loss': 5.318822701772054, 'n_experts': 2, 'expert_0': 87.09658688906045, 'expert_1': 77.5859393588298}\n",
      "Saving the model with classifier accuracy 33.33277778703688\n",
      "{'coverage': '9 out of157', 'system_accuracy': 81.52866242038216, 'expert_accuracy': 83.78367056260734, 'classifier_accuracy': 44.443950622770856, 'alone_classifier': 49.681528662420384, 'validation_loss': 5.343492190043132, 'n_experts': 2, 'expert_0': 84.70568304545165, 'expert_1': 82.53942050977616}\n",
      "{'coverage': '10 out of157', 'system_accuracy': 80.2547770700637, 'expert_accuracy': 83.67335554645504, 'classifier_accuracy': 29.99970000299997, 'alone_classifier': 52.22929936305732, 'validation_loss': 5.318757851918538, 'n_experts': 2, 'expert_0': 86.04631152020576, 'expert_1': 80.32760548326071}\n",
      "Saving the model with classifier accuracy 29.99970000299997\n",
      "{'coverage': '7 out of157', 'system_accuracy': 83.43949044585987, 'expert_accuracy': 84.66655377792829, 'classifier_accuracy': 57.142040827988176, 'alone_classifier': 50.955414012738856, 'validation_loss': 5.323877811431885, 'n_experts': 2, 'expert_0': 85.55536543252126, 'expert_1': 83.33305555648148}\n",
      "{'coverage': '9 out of157', 'system_accuracy': 84.07643312101911, 'expert_accuracy': 86.48636961301403, 'classifier_accuracy': 44.443950622770856, 'alone_classifier': 48.40764331210191, 'validation_loss': 5.398746808369954, 'n_experts': 2, 'expert_0': 87.35612102041144, 'expert_1': 85.24562214550116}\n",
      "{'coverage': '7 out of157', 'system_accuracy': 80.89171974522293, 'expert_accuracy': 83.33322222237037, 'classifier_accuracy': 28.571020413994088, 'alone_classifier': 50.318471337579616, 'validation_loss': 5.3596828778584795, 'n_experts': 2, 'expert_0': 85.71409733165422, 'expert_1': 79.66074691272233}\n",
      "{'coverage': '9 out of157', 'system_accuracy': 82.80254777070064, 'expert_accuracy': 85.13502008781069, 'classifier_accuracy': 44.443950622770856, 'alone_classifier': 51.59235668789809, 'validation_loss': 5.336196104685466, 'n_experts': 2, 'expert_0': 86.66647407450205, 'expert_1': 82.75833531608512}\n",
      "{'coverage': '9 out of157', 'system_accuracy': 83.43949044585987, 'expert_accuracy': 85.81069485041236, 'classifier_accuracy': 44.443950622770856, 'alone_classifier': 52.22929936305732, 'validation_loss': 5.36204465230306, 'n_experts': 2, 'expert_0': 86.51665951312468, 'expert_1': 84.74547543906631}\n",
      "{'coverage': '7 out of157', 'system_accuracy': 83.43949044585987, 'expert_accuracy': 85.33321955570726, 'classifier_accuracy': 42.85653062099113, 'alone_classifier': 50.318471337579616, 'validation_loss': 5.348549048105876, 'n_experts': 2, 'expert_0': 87.77758271648284, 'expert_1': 81.66639444535186}\n",
      "{'coverage': '10 out of157', 'system_accuracy': 81.52866242038216, 'expert_accuracy': 84.35362672975955, 'classifier_accuracy': 39.99960000399996, 'alone_classifier': 51.59235668789809, 'validation_loss': 5.320173422495524, 'n_experts': 2, 'expert_0': 87.05861868560308, 'expert_1': 80.64490114548018}\n",
      "{'coverage': '6 out of157', 'system_accuracy': 81.52866242038216, 'expert_accuracy': 83.44359808794955, 'classifier_accuracy': 33.33277778703688, 'alone_classifier': 53.503184713375795, 'validation_loss': 5.362987200419108, 'n_experts': 2, 'expert_0': 87.20909951372205, 'expert_1': 78.46129704216294}\n",
      "{'coverage': '6 out of157', 'system_accuracy': 82.80254777070064, 'expert_accuracy': 84.10584886642533, 'classifier_accuracy': 49.99916668055533, 'alone_classifier': 52.86624203821656, 'validation_loss': 5.317469755808513, 'n_experts': 2, 'expert_0': 86.51665951312468, 'expert_1': 80.64490114548018}\n",
      "Saving the model with classifier accuracy 49.99916668055533\n",
      "{'coverage': '6 out of157', 'system_accuracy': 82.80254777070064, 'expert_accuracy': 84.10584886642533, 'classifier_accuracy': 49.99916668055533, 'alone_classifier': 52.22929936305732, 'validation_loss': 5.405354976654053, 'n_experts': 2, 'expert_0': 86.51665951312468, 'expert_1': 80.64490114548018}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mincrease_experts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 49\u001b[0m, in \u001b[0;36mincrease_experts\u001b[0;34m(param)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# print(model)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#trainD = GalaxyZooDataset()\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#valD = GalaxyZooDataset(split=\"val\")\u001b[39;00m\n\u001b[1;32m     47\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m nih_dataloader\u001b[38;5;241m.\u001b[39mget_data_loader_for_fold(fold_idx)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpert_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 40\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, valid_loader, test_loader, expert_fns, config, seed)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     25\u001b[0m     iters, train_loss \u001b[38;5;241m=\u001b[39m train_epoch(\n\u001b[1;32m     26\u001b[0m         iters,\n\u001b[1;32m     27\u001b[0m         warmup_iters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m         config,\n\u001b[1;32m     39\u001b[0m     )\n\u001b[0;32m---> 40\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpert_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     validation_loss \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validation_loss \u001b[38;5;241m<\u001b[39m best_validation_loss:\n",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, expert_fns, loss_fn, n_classes, data_loader, config)\u001b[0m\n\u001b[1;32m     26\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     29\u001b[0m         images, labels, hpred \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     30\u001b[0m         images, labels, hpred \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device), hpred\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/NIH/Dataset.py:81\u001b[0m, in \u001b[0;36mNIH_Dataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m     80\u001b[0m     filename, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_ids[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index]\n\u001b[0;32m---> 81\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess:\n\u001b[1;32m     83\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformImage(img)\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/NIH/Dataset.py:56\u001b[0m, in \u001b[0;36mNIH_Dataset.getImage\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages[idx]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/joli/Masterarbeit/NIH/Dataset.py:47\u001b[0m, in \u001b[0;36mNIH_Dataset.loadImage\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadImage\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    Load one single image\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m244\u001b[39m,\u001b[38;5;241m244\u001b[39m))\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/PIL/Image.py:937\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m    891\u001b[0m ):\n\u001b[1;32m    892\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    939\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "increase_experts(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89cf324-ea02-48e4-8851-e76919699c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34267196-d7a2-4acb-9841-c8a22bb61167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joli-env_kernel",
   "language": "python",
   "name": "joli-env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
