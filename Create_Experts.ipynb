{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3832b2af-b416-47e1-b54a-31bbd04e66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from absl import flags\n",
    "from absl import app\n",
    "\n",
    "from SSL.feature_extractor.utils import save_to_logs, get_train_dir\n",
    "from SSL.feature_extractor.emb_model_lib import EmbeddingModel\n",
    "\n",
    "import Dataset.Dataset as ds\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5640ed14-688e-45a6-8f23-b90bc22e0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2126a759-08e6-4457-a6c8-e8abaa9dc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"PATH\": \"../Datasets/NIH/\",\n",
    "    \"TARGET\": \"Airspace_Opacity\",\n",
    "    \"LABELER_IDS\": [4323195249, 4295232296],\n",
    "    \"K\": 10, #Number of folds\n",
    "    \"SEEDS\": [1, 2, 3, 4, 42], #Seeds for the experiments\n",
    "    \"GT\": True, # Determines if the classifier gets all data with GT Label or only the labeld data\n",
    "    \"MOD\": [\"confidence\", \"disagreement\", \"disagreement_diff\", \"ssl\"], #Determines the experiment modus\n",
    "\n",
    "    \"OVERLAP\": 100,\n",
    "    \"INITAL_SIZE\": [8, 16, 32],\n",
    "    \"ROUNDS\": [2, 4, 8],\n",
    "    \"LABELS_PER_ROUND\": [4, 8, 16],\n",
    "    \"LABELED\": 32,\n",
    "\n",
    "    \"SETTING\": [\"AL\", \"SSL\", \"SSL_AL\"],\n",
    "\n",
    "    \"AL\": { #Parameter for Active Learning\n",
    "        \"INITIAL_SIZE\": [8, 16, 32], #\n",
    "        \"EPOCH_TRAIN\": 10, #\n",
    "        \"n_dataset\": 2, #Number Classes\n",
    "        \"BATCH_SIZE\": 4,\n",
    "        \"MAX_ROUNDS\": [2, 4, 8],\n",
    "        \"BATCH_SIZE_AL\": [4, 8, 16],\n",
    "        #\"EPOCHS_DEFER\": 5,\n",
    "        \"COST\": [(10, 0)], #Cost for Cost sensitiv learning\n",
    "        #\"TRAIN REJECTOR\": False,\n",
    "        \"PRELOAD\": True,\n",
    "        \"PREPROCESS\": True,\n",
    "        \n",
    "    },\n",
    "    \"SSL\": {\n",
    "        \"PREBUILD\": False,\n",
    "        \"TRAIN_BATCH_SIZE\": 64,\n",
    "        \"TEST_BATCH_SIZE\": 64,\n",
    "    },\n",
    "    \"L2D\": { # Parameter for Learning to defer\n",
    "        \"TRAIN_BATCH_SIZE\": 64,\n",
    "        \"TEST_BATCH_SIZE\": 64,\n",
    "        \"PRELOAD\": True,\n",
    "        \"PREBUILD\": True,\n",
    "        \"VERMA\": {},\n",
    "        \"HEMMER\": {}\n",
    "        \n",
    "    },\n",
    "    \"NEPTUNE\": {\n",
    "        \"NEPTUNE\": False,\n",
    "    },\n",
    "    \"EMBEDDED\": {\n",
    "        \"ARGS\": {\n",
    "            'dataset': \"nih\",\n",
    "            'model': \"resnet18\",\n",
    "            'num_classes': 2,\n",
    "            'batch': 64,\n",
    "            'lr': 0.001,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f49ec584-903f-4860-836a-52057b10ab0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images of the whole dataset: 4381\n",
      "Loaded image number: 0\n",
      "Loaded image number: 200\n",
      "Loaded image number: 400\n",
      "Loaded image number: 600\n",
      "Loaded image number: 800\n",
      "Loaded image number: 1000\n",
      "Loaded image number: 1200\n",
      "Loaded image number: 1400\n",
      "Loaded image number: 1600\n",
      "Loaded image number: 1800\n",
      "Loaded image number: 2000\n",
      "Loaded image number: 2200\n",
      "Loaded image number: 2400\n",
      "Loaded image number: 2600\n",
      "Loaded image number: 2800\n",
      "Loaded image number: 3000\n",
      "Loaded image number: 3200\n",
      "Loaded image number: 3400\n",
      "Loaded image number: 3600\n",
      "Loaded image number: 3800\n",
      "Loaded image number: 4000\n",
      "Loaded image number: 4200\n",
      "Full length: 4381\n",
      "Loaded image number: 0\n",
      "Loaded image number: 200\n",
      "Loaded image number: 400\n",
      "Loaded image number: 600\n",
      "Loaded image number: 800\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Length of train + test + val: 852\n",
      "Loaded set number 0\n",
      "Loaded set number 1\n",
      "Loaded set number 2\n",
      "Loaded set number 3\n",
      "Loaded set number 4\n",
      "Loaded set number 5\n",
      "Loaded set number 6\n",
      "Loaded set number 7\n",
      "Loaded set number 8\n",
      "Loaded set number 9\n",
      "Added\n",
      "Added\n",
      "Added\n",
      "Added\n",
      "Added\n",
      "Added\n",
      "Added\n",
      "Added\n",
      "Added\n",
      "Added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataManager = ds.DataManager(path = param[\"PATH\"], target = param[\"TARGET\"], param=param, seeds=[0])\n",
    "dataManager.createData()\n",
    "sslDataset = dataManager.getSSLDataset(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf009fa9-9a16-47c0-8775-f88c26f09a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(param[\"LABELED\"]*param[\"OVERLAP\"]/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f607065-0517-43dd-8a7b-745a85e211c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sslDataset.createLabeledIndices(labelerIds=param[\"LABELER_IDS\"], n_L=param[\"LABELED\"], k=round(param[\"LABELED\"]*param[\"OVERLAP\"]/100), seed=0)\n",
    "train_dataloader, val_dataloader, test_dataloader = sslDataset.get_data_loader_for_fold(0)\n",
    "#train_dataloader, val_dataloader, test_dataloader = nih_dataloader.get_data_loader_for_fold(1)\n",
    "dataloaders = (train_dataloader, val_dataloader, test_dataloader)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523d2d78-d882-479f-a9b8-b6aed61e70cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'dataset': \"nih\",\n",
    "    'model': \"resnet18\",\n",
    "    'num_classes': 2,\n",
    "    'batch': 64,\n",
    "    'lr': 0.001,\n",
    "}\n",
    "\n",
    "path = \"../../../Datasets/NIH/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c05b71-0fc7-4acb-b304-eec705522872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def cleanTrainDir(path):\n",
    "    shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41ddaf29-f7c2-4372-85f9-2c64ea6cbfd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SSL_Working'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcleanTrainDir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSSL_Working\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mcleanTrainDir\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanTrainDir\u001b[39m(path):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/shutil.py:724\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    722\u001b[0m     orig_st \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlstat(path)\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 724\u001b[0m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/home/joli/joli-env/lib/python3.9/shutil.py:722\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;66;03m# Note: To guard against symlink races, we use the standard\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# lstat()/open()/fstat() trick.\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 722\u001b[0m     orig_st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m     onerror(os\u001b[38;5;241m.\u001b[39mlstat, path, sys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SSL_Working'"
     ]
    }
   ],
   "source": [
    "cleanTrainDir(\"SSL_Working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc2af491-95c3-482f-b5a6-e2138b86c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedded(dataloaders, param, neptune_param):\n",
    "    args = param[\"EMBEDDED\"][\"ARGS\"]\n",
    "    path = param[\"PATH\"]\n",
    "    neptune_param = neptune_param\n",
    "\n",
    "    wkdir = os.getcwd() + \"/SSL_Working\"\n",
    "    sys.path.append(wkdir)\n",
    "\n",
    "    SAVE = True\n",
    "\n",
    "    # get training directory\n",
    "    train_dir = get_train_dir(wkdir, args, 'emb_net')\n",
    "\n",
    "    print(\"Train dir: \" + train_dir)\n",
    "\n",
    "    NEPTUNE = neptune_param[\"NEPTUNE\"]\n",
    "\n",
    "    writer = None\n",
    "\n",
    "    if SAVE:\n",
    "        # initialize summary writer for tensorboard\n",
    "        writer = SummaryWriter(train_dir + 'logs/')\n",
    "\n",
    "    # initialize base model\n",
    "    emb_model = EmbeddingModel(args, wkdir, writer, dataloaders, param, neptune_param)\n",
    "    # try to load previous training runs\n",
    "    start_epoch = emb_model.load_from_checkpoint(mode='latest')\n",
    "    # train model\n",
    "    for epoch in range(start_epoch, 100):\n",
    "        # train one epoch\n",
    "        loss = emb_model.train_one_epoch(epoch)\n",
    "        # get validation accuracy\n",
    "        valid_acc = emb_model.get_test_accuracy(return_acc=True)\n",
    "        print(f'loss: {loss}')\n",
    "\n",
    "        if NEPTUNE:\n",
    "            run[f'embedded/seed{neptune_param[\"seed\"]}_fold{neptune_param[\"fold\"]}/loss/accuracy'].append(loss)\n",
    "            run[f'embedded/seed{neptune_param[\"seed\"]}_fold{neptune_param[\"fold\"]}/val/accuracy'].append(valid_acc)\n",
    "        # save logs to json\n",
    "        if SAVE:\n",
    "            save_to_logs(train_dir, valid_acc, loss.item())\n",
    "            # save model to checkpoint\n",
    "            emb_model.save_to_checkpoint(epoch, loss, valid_acc)\n",
    "    # get test accuracy\n",
    "    acc = emb_model.get_test_accuracy()\n",
    "\n",
    "    if NEPTUNE:\n",
    "        run[\"embedded/test/accuracy\"].append(acc)\n",
    "\n",
    "    return emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4860635f-bffc-4541-96f8-3b5a80ef7f3b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dir: /home/joli/Masterarbeit/SSL_Working/NIH/emb_net@dataset-nih-model-resnet18-num_classes-2/\n",
      "load Resnet-18 checkpoint\n",
      "load Resnet-18 pretrained on ImageNet\n",
      "Loaded Model resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/joli/joli-env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Checkpoint found\n",
      "Starting new from epoch 1\n",
      "Train Epoch 1: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.7809307604994324 \n",
      "Test-Acc-Class [0.82735426 0.73333333]\n",
      "loss: 0.6101260781288147\n",
      "Train Epoch 2: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8024971623155505 \n",
      "Test-Acc-Class [0.80493274 0.8       ]\n",
      "loss: 0.5630812048912048\n",
      "Train Epoch 3: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8036322360953462 \n",
      "Test-Acc-Class [0.80717489 0.8       ]\n",
      "loss: 0.4447552561759949\n",
      "Train Epoch 4: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8047673098751419 \n",
      "Test-Acc-Class [0.80717489 0.80229885]\n",
      "loss: 0.47221580147743225\n",
      "Train Epoch 5: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8047673098751419 \n",
      "Test-Acc-Class [0.81390135 0.7954023 ]\n",
      "loss: 0.46554216742515564\n",
      "Train Epoch 6: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8059023836549376 \n",
      "Test-Acc-Class [0.8206278 0.7908046]\n",
      "loss: 0.46865206956863403\n",
      "Train Epoch 7: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8059023836549376 \n",
      "Test-Acc-Class [0.81390135 0.79770115]\n",
      "loss: 0.44122210144996643\n",
      "Train Epoch 8: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8047673098751419 \n",
      "Test-Acc-Class [0.80717489 0.80229885]\n",
      "loss: 0.5236914157867432\n",
      "Train Epoch 9: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8059023836549376 \n",
      "Test-Acc-Class [0.80941704 0.80229885]\n",
      "loss: 0.5595349669456482\n",
      "Train Epoch 10: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8024971623155505 \n",
      "Test-Acc-Class [0.8161435  0.78850575]\n",
      "loss: 0.4306733012199402\n",
      "Train Epoch 11: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8047673098751419 \n",
      "Test-Acc-Class [0.8206278  0.78850575]\n",
      "loss: 0.5184729695320129\n",
      "Train Epoch 12: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8047673098751419 \n",
      "Test-Acc-Class [0.81390135 0.7954023 ]\n",
      "loss: 0.4695785641670227\n",
      "Train Epoch 13: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8036322360953462 \n",
      "Test-Acc-Class [0.8161435 0.7908046]\n",
      "loss: 0.5075873732566833\n",
      "Train Epoch 14: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8070374574347332 \n",
      "Test-Acc-Class [0.81165919 0.80229885]\n",
      "loss: 0.4694374203681946\n",
      "Train Epoch 15: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8059023836549376 \n",
      "Test-Acc-Class [0.82286996 0.78850575]\n",
      "loss: 0.6326395273208618\n",
      "Train Epoch 16: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8047673098751419 \n",
      "Test-Acc-Class [0.80493274 0.8045977 ]\n",
      "loss: 0.4960649311542511\n",
      "Train Epoch 17: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8036322360953462 \n",
      "Test-Acc-Class [0.81838565 0.78850575]\n",
      "loss: 0.5256441235542297\n",
      "Train Epoch 18: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8047673098751419 \n",
      "Test-Acc-Class [0.80493274 0.8045977 ]\n",
      "loss: 0.6047822833061218\n",
      "Train Epoch 19: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8070374574347332 \n",
      "Test-Acc-Class [0.80941704 0.8045977 ]\n",
      "loss: 0.49288925528526306\n",
      "Train Epoch 20: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8059023836549376 \n",
      "Test-Acc-Class [0.80269058 0.8091954 ]\n",
      "loss: 0.508998692035675\n",
      "Train Epoch 21: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8024971623155505 \n",
      "Test-Acc-Class [0.80941704 0.7954023 ]\n",
      "loss: 0.49634435772895813\n",
      "Train Epoch 22: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.80044843 0.8183908 ]\n",
      "loss: 0.49418890476226807\n",
      "Train Epoch 23: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8047673098751419 \n",
      "Test-Acc-Class [0.80941704 0.8       ]\n",
      "loss: 0.4830152094364166\n",
      "Train Epoch 24: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8138479001135074 \n",
      "Test-Acc-Class [0.80717489 0.82068966]\n",
      "loss: 0.49962836503982544\n",
      "Train Epoch 25: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.80044843 0.82528736]\n",
      "loss: 0.47636106610298157\n",
      "Train Epoch 26: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8081725312145289 \n",
      "Test-Acc-Class [0.80044843 0.81609195]\n",
      "loss: 0.519833505153656\n",
      "Train Epoch 27: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8104426787741204 \n",
      "Test-Acc-Class [0.80717489 0.8137931 ]\n",
      "loss: 0.5152038931846619\n",
      "Train Epoch 28: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8081725312145289 \n",
      "Test-Acc-Class [0.80044843 0.81609195]\n",
      "loss: 0.47697558999061584\n",
      "Train Epoch 29: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8059023836549376 \n",
      "Test-Acc-Class [0.8161435 0.7954023]\n",
      "loss: 0.4933779835700989\n",
      "Train Epoch 30: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8059023836549376 \n",
      "Test-Acc-Class [0.81838565 0.79310345]\n",
      "loss: 0.4622255563735962\n",
      "Train Epoch 31: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.81165919 0.80689655]\n",
      "loss: 0.4417575001716614\n",
      "Train Epoch 32: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8047673098751419 \n",
      "Test-Acc-Class [0.82511211 0.78390805]\n",
      "loss: 0.47835543751716614\n",
      "Train Epoch 33: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.79372197 0.82528736]\n",
      "loss: 0.5010311603546143\n",
      "Train Epoch 34: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.80941704 0.8091954 ]\n",
      "loss: 0.5499435663223267\n",
      "Train Epoch 35: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8081725312145289 \n",
      "Test-Acc-Class [0.80717489 0.8091954 ]\n",
      "loss: 0.4712691307067871\n",
      "Train Epoch 36: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8024971623155505 \n",
      "Test-Acc-Class [0.81390135 0.7908046 ]\n",
      "loss: 0.48435088992118835\n",
      "Train Epoch 37: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.80044843 0.82528736]\n",
      "loss: 0.506963312625885\n",
      "Train Epoch 38: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.81165919 0.80689655]\n",
      "loss: 0.4813631772994995\n",
      "Train Epoch 39: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8047673098751419 \n",
      "Test-Acc-Class [0.8206278  0.78850575]\n",
      "loss: 0.590700089931488\n",
      "Train Epoch 40: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8070374574347332 \n",
      "Test-Acc-Class [0.81838565 0.7954023 ]\n",
      "loss: 0.5068839192390442\n",
      "Train Epoch 41: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8081725312145289 \n",
      "Test-Acc-Class [0.80941704 0.80689655]\n",
      "loss: 0.508647620677948\n",
      "Train Epoch 42: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8138479001135074 \n",
      "Test-Acc-Class [0.80941704 0.8183908 ]\n",
      "loss: 0.5004795789718628\n",
      "Train Epoch 43: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.81165919 0.81149425]\n",
      "loss: 0.4298698306083679\n",
      "Train Epoch 44: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8104426787741204 \n",
      "Test-Acc-Class [0.80493274 0.81609195]\n",
      "loss: 0.4324857294559479\n",
      "Train Epoch 45: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8138479001135074 \n",
      "Test-Acc-Class [0.80493274 0.82298851]\n",
      "loss: 0.4422436058521271\n",
      "Train Epoch 46: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8104426787741204 \n",
      "Test-Acc-Class [0.8161435 0.8045977]\n",
      "loss: 0.5432084202766418\n",
      "Train Epoch 47: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.80717489 0.81609195]\n",
      "loss: 0.4828428328037262\n",
      "Train Epoch 48: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8138479001135074 \n",
      "Test-Acc-Class [0.80269058 0.82528736]\n",
      "loss: 0.5035951733589172\n",
      "Train Epoch 49: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8138479001135074 \n",
      "Test-Acc-Class [0.80717489 0.82068966]\n",
      "loss: 0.4971637725830078\n",
      "Train Epoch 50: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.8161435  0.80229885]\n",
      "loss: 0.46208688616752625\n",
      "Train Epoch 51: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.81390135 0.8045977 ]\n",
      "loss: 0.42260125279426575\n",
      "Train Epoch 52: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8081725312145289 \n",
      "Test-Acc-Class [0.8161435 0.8      ]\n",
      "loss: 0.46016278862953186\n",
      "Train Epoch 53: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.8161435  0.80229885]\n",
      "loss: 0.522055983543396\n",
      "Train Epoch 54: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.80941704 0.8137931 ]\n",
      "loss: 0.5128769278526306\n",
      "Train Epoch 55: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.80717489 0.8183908 ]\n",
      "loss: 0.4617924690246582\n",
      "Train Epoch 56: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.80493274 0.8137931 ]\n",
      "loss: 0.4306730031967163\n",
      "Train Epoch 57: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.80941704 0.8137931 ]\n",
      "loss: 0.4874686002731323\n",
      "Train Epoch 58: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8104426787741204 \n",
      "Test-Acc-Class [0.80941704 0.81149425]\n",
      "loss: 0.5340538620948792\n",
      "Train Epoch 59: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.81390135 0.81149425]\n",
      "loss: 0.493518590927124\n",
      "Train Epoch 60: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.81165919 0.81149425]\n",
      "loss: 0.5145331621170044\n",
      "Train Epoch 61: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.80717489 0.81149425]\n",
      "loss: 0.4232642352581024\n",
      "Train Epoch 62: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.80941704 0.8091954 ]\n",
      "loss: 0.4746151268482208\n",
      "Train Epoch 63: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8093076049943246 \n",
      "Test-Acc-Class [0.80493274 0.8137931 ]\n",
      "loss: 0.4263782799243927\n",
      "Train Epoch 64: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.80717489 0.8183908 ]\n",
      "loss: 0.4875480532646179\n",
      "Train Epoch 65: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.82735426 0.79770115]\n",
      "loss: 0.45096555352211\n",
      "Train Epoch 66: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8104426787741204 \n",
      "Test-Acc-Class [0.80717489 0.8137931 ]\n",
      "loss: 0.45377200841903687\n",
      "Train Epoch 67: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8104426787741204 \n",
      "Test-Acc-Class [0.80493274 0.81609195]\n",
      "loss: 0.48069268465042114\n",
      "Train Epoch 68: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8138479001135074 \n",
      "Test-Acc-Class [0.81390135 0.8137931 ]\n",
      "loss: 0.4238682985305786\n",
      "Train Epoch 69: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.80941704 0.8137931 ]\n",
      "loss: 0.4422989785671234\n",
      "Train Epoch 70: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.81838565 0.80689655]\n",
      "loss: 0.44887563586235046\n",
      "Train Epoch 71: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.81838565 0.80689655]\n",
      "loss: 0.49188995361328125\n",
      "Train Epoch 72: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8104426787741204 \n",
      "Test-Acc-Class [0.80717489 0.8137931 ]\n",
      "loss: 0.3961116671562195\n",
      "Train Epoch 73: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8104426787741204 \n",
      "Test-Acc-Class [0.8206278 0.8      ]\n",
      "loss: 0.4884900450706482\n",
      "Train Epoch 74: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.80941704 0.8137931 ]\n",
      "loss: 0.5175780057907104\n",
      "Train Epoch 75: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.81165919 0.81149425]\n",
      "loss: 0.46200132369995117\n",
      "Train Epoch 76: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.81165919 0.81149425]\n",
      "loss: 0.5293262600898743\n",
      "Train Epoch 77: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.81165919 0.8137931 ]\n",
      "loss: 0.46972107887268066\n",
      "Train Epoch 78: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.81838565 0.80689655]\n",
      "loss: 0.4493144154548645\n",
      "Train Epoch 79: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8161180476730987 \n",
      "Test-Acc-Class [0.80493274 0.82758621]\n",
      "loss: 0.5146828889846802\n",
      "Train Epoch 80: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8104426787741204 \n",
      "Test-Acc-Class [0.81165919 0.8091954 ]\n",
      "loss: 0.42460477352142334\n",
      "Train Epoch 81: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.8161435  0.80689655]\n",
      "loss: 0.5028241872787476\n",
      "Train Epoch 82: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.8161435 0.8091954]\n",
      "loss: 0.39894843101501465\n",
      "Train Epoch 83: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.81838565 0.80689655]\n",
      "loss: 0.49672049283981323\n",
      "Train Epoch 84: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.80941704 0.81609195]\n",
      "loss: 0.443538635969162\n",
      "Train Epoch 85: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.81390135 0.8091954 ]\n",
      "loss: 0.5270788073539734\n",
      "Train Epoch 86: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8149829738933031 \n",
      "Test-Acc-Class [0.81838565 0.81149425]\n",
      "loss: 0.554313063621521\n",
      "Train Epoch 87: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.81390135 0.8091954 ]\n",
      "loss: 0.506924033164978\n",
      "Train Epoch 88: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8149829738933031 \n",
      "Test-Acc-Class [0.81390135 0.81609195]\n",
      "loss: 0.4754719138145447\n",
      "Train Epoch 89: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8138479001135074 \n",
      "Test-Acc-Class [0.81390135 0.8137931 ]\n",
      "loss: 0.43726158142089844\n",
      "Train Epoch 90: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8149829738933031 \n",
      "Test-Acc-Class [0.82286996 0.80689655]\n",
      "loss: 0.4673493206501007\n",
      "Train Epoch 91: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8161180476730987 \n",
      "Test-Acc-Class [0.81390135 0.8183908 ]\n",
      "loss: 0.43323221802711487\n",
      "Train Epoch 92: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8172531214528944 \n",
      "Test-Acc-Class [0.81165919 0.82298851]\n",
      "loss: 0.46105438470840454\n",
      "Train Epoch 93: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8172531214528944 \n",
      "Test-Acc-Class [0.80941704 0.82528736]\n",
      "loss: 0.46527960896492004\n",
      "Train Epoch 94: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8149829738933031 \n",
      "Test-Acc-Class [0.81838565 0.81149425]\n",
      "loss: 0.46978601813316345\n",
      "Train Epoch 95: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8127128263337117 \n",
      "Test-Acc-Class [0.81165919 0.8137931 ]\n",
      "loss: 0.43044841289520264\n",
      "Train Epoch 96: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8138479001135074 \n",
      "Test-Acc-Class [0.81390135 0.8137931 ]\n",
      "loss: 0.43497228622436523\n",
      "Train Epoch 97: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8149829738933031 \n",
      "Test-Acc-Class [0.8206278 0.8091954]\n",
      "loss: 0.43674907088279724\n",
      "Train Epoch 98: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.811577752553916 \n",
      "Test-Acc-Class [0.81390135 0.8091954 ]\n",
      "loss: 0.5115869641304016\n",
      "Train Epoch 99: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8195232690124858 \n",
      "Test-Acc-Class [0.80717489 0.83218391]\n",
      "loss: 0.4709450304508209\n",
      "Train Epoch 100: |███████████████████████████████████████-| 100.0% Complete\n",
      "Test-Accuracy: 0.8206583427922814 \n",
      "Test-Acc-Class [0.80493274 0.83678161]\n",
      "loss: 0.4891860783100128\n",
      "Test-Accuracy: 0.8206583427922814 \n",
      "Test-Acc-Class [0.80493274 0.83678161]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SSL.feature_extractor.emb_model_lib.EmbeddingModel at 0x7f08a96f5c10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_embedded(dataloaders, param, param[\"NEPTUNE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e57541a-d899-4385-9286-b4c3ffeb4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from SSL.LinearModel import LinearNN\n",
    "from SSL.utils import accuracy, setup_default_logging, AverageMeter, WarmupCosineLrScheduler\n",
    "from SSL.utils import load_from_checkpoint\n",
    "from SSL.Expert import CIFAR100Expert, NIHExpert\n",
    "from SSL.feature_extractor.embedding_model import EmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70337611-12e5-41b9-9401-4077ebf5a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model(args):\n",
    "    \"\"\"Initialize models\n",
    "\n",
    "    Lineare Modelle, welche später die extrahierten Features übergeben bekommen\n",
    "\n",
    "    :param args: training arguments\n",
    "    :return: tuple\n",
    "        - model: Initialized model\n",
    "        - criteria_x: Supervised loss function\n",
    "        - ema_model: Initialized ema model\n",
    "    \"\"\"\n",
    "    if args[\"dataset\"].lower() == 'cifar100':\n",
    "        feature_dim = 1280\n",
    "    elif args[\"dataset\"].lower() == 'nih':\n",
    "        feature_dim = 512\n",
    "    else:\n",
    "        print(f'Dataset {args[\"dataset\"]} not defined')\n",
    "        sys.exit()\n",
    "    model = LinearNN(num_classes=args[\"n_classes\"], feature_dim=feature_dim, proj=True)\n",
    "\n",
    "    model.train()\n",
    "    model.cuda()  \n",
    "    \n",
    "    if args[\"eval_ema\"]:\n",
    "        ema_model = LinearNN(num_classes=args[\"n_classes\"], feature_dim=feature_dim, proj=True)\n",
    "        for param_q, param_k in zip(model.parameters(), ema_model.parameters()):\n",
    "            param_k.data.copy_(param_q.detach().data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient for eval_net\n",
    "        ema_model.cuda()  \n",
    "        ema_model.eval()\n",
    "    else:\n",
    "        ema_model = None\n",
    "        \n",
    "    criteria_x = nn.CrossEntropyLoss().cuda()\n",
    "    return model, criteria_x, ema_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e26164-17e1-4fce-9c0f-0ade550720b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch,\n",
    "                    model,\n",
    "                    ema_model,\n",
    "                    emb_model,\n",
    "                    prob_list,\n",
    "                    criteria_x,\n",
    "                    optim,\n",
    "                    lr_schdlr,\n",
    "                    dltrain_x,\n",
    "                    dltrain_u,\n",
    "                    args,\n",
    "                    n_iters,\n",
    "                    logger,\n",
    "                    queue_feats,\n",
    "                    queue_probs,\n",
    "                    queue_ptr,\n",
    "                    ):\n",
    "    \"\"\"Train one epoch on the train set\n",
    "\n",
    "    :param epoch: Current epoch\n",
    "    :param model: Model\n",
    "    :param ema_model: EMA-Model\n",
    "    :param emb_model: Embedding model\n",
    "    :param prob_list: List of probabilities\n",
    "    :param criteria_x: Supervised loss function\n",
    "    :param optim: Optimizer\n",
    "    :param lr_schdlr: Learning rate scheduler\n",
    "    :param dltrain_x: Data loader for the labeled training instances\n",
    "    :param dltrain_u: Data loader for the unlabeled training instances\n",
    "    :param args: Training arguments\n",
    "    :param n_iters: Number of iterations per epoch\n",
    "    :param logger: Logger\n",
    "    :param queue_feats: Memory bank feature vectors\n",
    "    :param queue_probs: Memory bank probabilities\n",
    "    :param queue_ptr: Memory bank ptr\n",
    "    :return: tuple\n",
    "        - Average supervised loss\n",
    "        - Average unsupervised loss\n",
    "        - Average contrastive loss\n",
    "        - Average mask\n",
    "        - Average number of edges in the pseudo label graph\n",
    "        - Percentage of correct pseudo labels\n",
    "        - Memory bank feature vectors\n",
    "        - Memory bank probabilities\n",
    "        - Memory bank ptr\n",
    "        - List of probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    loss_x_meter = AverageMeter()\n",
    "    loss_u_meter = AverageMeter()\n",
    "    loss_contrast_meter = AverageMeter()\n",
    "    # the number of correct pseudo-labels\n",
    "    n_correct_u_lbs_meter = AverageMeter()\n",
    "    # the number of confident unlabeled data\n",
    "    n_strong_aug_meter = AverageMeter()\n",
    "    mask_meter = AverageMeter()\n",
    "    # the number of edges in the pseudo-label graph\n",
    "    pos_meter = AverageMeter()\n",
    "\n",
    "    \n",
    "    epoch_start = time.time()  # start time\n",
    "    dl_x, dl_u = iter(dltrain_x), iter(dltrain_u)\n",
    "    for it in range(n_iters):\n",
    "        ims_x_weak, lbs_x, im_id = next(dl_x)\n",
    "        (ims_u_weak, ims_u_strong0, ims_u_strong1), lbs_u_real, im_id = next(dl_u)\n",
    "\n",
    "        lbs_x = lbs_x.type(torch.LongTensor) \n",
    "        lbs_x = lbs_x.cuda()\n",
    "        lbs_u_real = lbs_u_real.cuda()\n",
    "\n",
    "        # --------------------------------------\n",
    "        bt = ims_x_weak.size(0)\n",
    "        btu = ims_u_weak.size(0)\n",
    "\n",
    "        imgs = torch.cat([ims_x_weak, ims_u_weak, ims_u_strong0, ims_u_strong1], dim=0).cuda()\n",
    "        embedding = emb_model.get_embedding(batch=imgs)\n",
    "        logits, features = model(embedding)\n",
    "\n",
    "        logits_x = logits[:bt]\n",
    "        logits_u_w, logits_u_s0, logits_u_s1 = torch.split(logits[bt:], btu)\n",
    "        \n",
    "        feats_x = features[:bt]\n",
    "        feats_u_w, feats_u_s0, feats_u_s1 = torch.split(features[bt:], btu)\n",
    "\n",
    "        \n",
    "        loss_x = criteria_x(logits_x, lbs_x)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_u_w = logits_u_w.detach()\n",
    "            feats_x = feats_x.detach()\n",
    "            feats_u_w = feats_u_w.detach()\n",
    "            \n",
    "            probs = torch.softmax(logits_u_w, dim=1)            \n",
    "            # DA\n",
    "            prob_list.append(probs.mean(0))\n",
    "            if len(prob_list)>32:\n",
    "                prob_list.pop(0)\n",
    "            prob_avg = torch.stack(prob_list, dim=0).mean(0)\n",
    "            probs = probs / prob_avg\n",
    "            probs = probs / probs.sum(dim=1, keepdim=True)   \n",
    "\n",
    "            probs_orig = probs.clone()\n",
    "            \n",
    "            if epoch>0 or it>args[\"queue_batch\"]: # memory-smoothing \n",
    "                A = torch.exp(torch.mm(feats_u_w, queue_feats.t())/args[\"temperature\"])       \n",
    "                A = A/A.sum(1,keepdim=True)                    \n",
    "                probs = args[\"alpha\"]*probs + (1-args[\"alpha\"])*torch.mm(A, queue_probs)               \n",
    "            \n",
    "            scores, lbs_u_guess = torch.max(probs, dim=1)\n",
    "            mask = scores.ge(args[\"thr\"]).float() \n",
    "                   \n",
    "            feats_w = torch.cat([feats_u_w,feats_x],dim=0)   \n",
    "            onehot = torch.zeros(bt,args[\"n_classes\"]).cuda().scatter(1,lbs_x.view(-1,1),1)\n",
    "            probs_w = torch.cat([probs_orig,onehot],dim=0)\n",
    "            \n",
    "            # update memory bank\n",
    "            n = bt+btu   \n",
    "            queue_feats[queue_ptr:queue_ptr + n,:] = feats_w\n",
    "            queue_probs[queue_ptr:queue_ptr + n,:] = probs_w      \n",
    "            queue_ptr = (queue_ptr+n)%args[\"queue_size\"]\n",
    "\n",
    "            \n",
    "        # embedding similarity\n",
    "        sim = torch.exp(torch.mm(feats_u_s0, feats_u_s1.t())/args[\"temperature\"]) \n",
    "        sim_probs = sim / sim.sum(1, keepdim=True)\n",
    "        \n",
    "        # pseudo-label graph with self-loop\n",
    "        Q = torch.mm(probs, probs.t())       \n",
    "        Q.fill_diagonal_(1)    \n",
    "        pos_mask = (Q>=args[\"contrast_th\"]).float()\n",
    "            \n",
    "        Q = Q * pos_mask\n",
    "        Q = Q / Q.sum(1, keepdim=True)\n",
    "        \n",
    "        # contrastive loss\n",
    "        loss_contrast = - (torch.log(sim_probs + 1e-7) * Q).sum(1)\n",
    "        loss_contrast = loss_contrast.mean()  \n",
    "        \n",
    "        # unsupervised classification loss\n",
    "        loss_u = - torch.sum((F.log_softmax(logits_u_s0,dim=1) * probs),dim=1) * mask                \n",
    "        loss_u = loss_u.mean()\n",
    "        \n",
    "        loss = loss_x + args[\"lam_u\"] * loss_u + args[\"lam_c\"] * loss_contrast\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        lr_schdlr.step()\n",
    "\n",
    "        if args[\"eval_ema\"]:\n",
    "            with torch.no_grad():\n",
    "                ema_model_update(model, ema_model, args[\"ema_m\"])\n",
    "                \n",
    "        loss_x_meter.update(loss_x.item())\n",
    "        loss_u_meter.update(loss_u.item())\n",
    "        loss_contrast_meter.update(loss_contrast.item())\n",
    "        mask_meter.update(mask.mean().item())       \n",
    "        pos_meter.update(pos_mask.sum(1).float().mean().item())\n",
    "        \n",
    "        corr_u_lb = (lbs_u_guess == lbs_u_real).float() * mask\n",
    "        n_correct_u_lbs_meter.update(corr_u_lb.sum().item())\n",
    "        n_strong_aug_meter.update(mask.sum().item())\n",
    "\n",
    "        if (it + 1) % 64 == 0:\n",
    "            t = time.time() - epoch_start\n",
    "\n",
    "            lr_log = [pg['lr'] for pg in optim.param_groups]\n",
    "            lr_log = sum(lr_log) / len(lr_log)\n",
    "\n",
    "            logger.info(\"{}-x{}-s{}, {} | epoch:{}, iter: {}. loss_u: {:.3f}. loss_x: {:.3f}. loss_c: {:.3f}. \"\n",
    "                        \"n_correct_u: {:.2f}/{:.2f}. Mask:{:.3f}. num_pos: {:.1f}. LR: {:.3f}. Time: {:.2f}\".format(\n",
    "                args[\"dataset\"], args[\"n_labeled\"], args[\"seed\"], args[\"exp_dir\"], epoch, it + 1, loss_u_meter.avg, loss_x_meter.avg, loss_contrast_meter.avg, n_correct_u_lbs_meter.avg, n_strong_aug_meter.avg, mask_meter.avg, pos_meter.avg, lr_log, t))\n",
    "            epoch_start = time.time()\n",
    "\n",
    "    return loss_x_meter.avg, loss_u_meter.avg, loss_contrast_meter.avg, mask_meter.avg, pos_meter.avg, n_correct_u_lbs_meter.avg/n_strong_aug_meter.avg, queue_feats, queue_probs, queue_ptr, prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ce2d18-8558-403d-97b1-0ca1ff4315f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, ema_model, emb_model, dataloader):\n",
    "    \"\"\"Evaluate model on train or validation set\n",
    "\n",
    "    :param model: Model\n",
    "    :param ema_model: EMA-Model\n",
    "    :param emb_model: Embedding model\n",
    "    :param dataloader: Data loader for the evaluation set\n",
    "    :return: tuple\n",
    "        - Accuracy of the model\n",
    "        - Accuracy of the ema_model\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    top1_meter = AverageMeter()\n",
    "    ema_top1_meter = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ims, lbs, im_id in dataloader:\n",
    "            ims = ims.cuda()\n",
    "            lbs = lbs.cuda()\n",
    "\n",
    "            embedding = emb_model.get_embedding(batch=ims)\n",
    "            logits, _ = model(embedding)\n",
    "            scores = torch.softmax(logits, dim=1)\n",
    "            preds += torch.argmax(scores, dim=1).cpu().tolist()\n",
    "            targets += lbs.cpu().tolist()\n",
    "            top1 = accuracy(scores, lbs, (1, ))\n",
    "            top1_meter.update(top1.item())\n",
    "            \n",
    "            if ema_model is not None:\n",
    "                embedding = emb_model.get_embedding(batch=ims)\n",
    "                logits, _ = ema_model(embedding)\n",
    "                scores = torch.softmax(logits, dim=1)\n",
    "                top1 = accuracy(scores, lbs, (1, ))\n",
    "                ema_top1_meter.update(top1.item())\n",
    "    return top1_meter.avg, ema_top1_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d14a958-817e-4845-ba13-2e97455f150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def ema_model_update(model, ema_model, ema_m):\n",
    "    \"\"\"Momentum update of evaluation model (exponential moving average)\n",
    "\n",
    "    :param model: Model\n",
    "    :param ema_model: EMA-Model\n",
    "    :param ema_m: Ema parameter\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for param_train, param_eval in zip(model.parameters(), ema_model.parameters()):\n",
    "        param_eval.copy_(param_eval * ema_m + param_train.detach() * (1-ema_m))\n",
    "\n",
    "    for buffer_train, buffer_eval in zip(model.buffers(), ema_model.buffers()):\n",
    "        buffer_eval.copy_(buffer_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d968e619-796b-4d69-abfa-91f1f60aacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class exper:\n",
    "    def __init__(self, id):\n",
    "        self.labeler_id = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43f9bbe9-ab56-433a-8210-b11ffbd2bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpertModelSSL(labelerId, sslDataset, seed, fold_idx, n_labeled, embedded_model=None, param=None, neptune_param=None):\n",
    "    args = {\n",
    "        \"dataset\": \"NIH\", #\n",
    "        \"wresnet_k\": 2, #width factor of wide resnet\n",
    "        \"wresnet_n\": 28, #depth of wide resnet\n",
    "        \"n_classes\": 2, #number of classes in dataset\n",
    "        \"n_epoches\": 10, #number of training epoches\n",
    "        \"batchsize\": 16, #train batch size of labeled samples\n",
    "        \"mu\": 7, #factor of train batch size of unlabeled samples\n",
    "        \"n_imgs_per_epoch\": 32768, #number of training images for each epoch\n",
    "        #\"n_imgs_per_epoch\": 4381,\n",
    "        \"eval_ema\": True, #whether to use ema model for evaluation\n",
    "        \"ema_m\": 0.999, #\n",
    "        \"lam_u\": 1., #coefficient of unlabeled loss\n",
    "        \"lr\": 0.03, #learning rate for training\n",
    "        \"weight_decay\": 5e-4, #weight decay\n",
    "        \"momentum\": 0.9, #momentum for optimizer\n",
    "        \"temperature\": 0.2, #softmax temperature\n",
    "        \"low_dim\": 64, #\n",
    "        \"lam_c\": 1, #coefficient of contrastive loss\n",
    "        \"contrast_th\": 0.8, #pseudo label graph threshold\n",
    "        \"thr\": 0.95, #pseudo label threshold\n",
    "        \"alpha\": 0.9, #\n",
    "        \"queue_batch\": 5, #number of batches stored in memory bank\n",
    "        \"exp_dir\": \"EmbeddingCM_bin\", #experiment id\n",
    "        #\"ex_strength\": 4323195249, #Strength of the expert \n",
    "        #\"ex_strength\": 4295232296\n",
    "    }\n",
    "\n",
    "    arg[\"labelerId\"] = labelerId\n",
    "    arg[\"n_labeled\"] = n_labeled\n",
    "    path = param[\"PATH\"]\n",
    "\n",
    "    #Setzt Logger fest\n",
    "    logger, output_dir = setup_default_logging(\"SSL_Working/\", args)\n",
    "    logger.info(dict(args))\n",
    "    \n",
    "    tb_logger = SummaryWriter(output_dir)\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    #Calculates number of iterations\n",
    "    n_iters_per_epoch = args[\"n_imgs_per_epoch\"] // args[\"batchsize\"]  # 1024\n",
    "    n_iters_all = n_iters_per_epoch * args[\"n_epoches\"]  # 1024 * 200\n",
    "\n",
    "    #Erstellt das Modell\n",
    "    model, criteria_x, ema_model = set_model(args)\n",
    "    #Lädt das trainierte eingebettete Modell\n",
    "    emb_model = EmbeddingModel(os.getcwd() + \"/SSL_Working\", args[\"dataset\"])\n",
    "    logger.info(\"Total params: {:.2f}M\".format(\n",
    "        sum(p.numel() for p in model.parameters()) / 1e6))\n",
    "\n",
    "\n",
    "    if 'nih' in args[\"dataset\"].lower(): #Erstellt den Experten mit seiner ID\n",
    "        exp = exper(int(args[\"labelerId\"]))\n",
    "        \n",
    "        dltrain_x, dltrain_u = sslDataset.get_train_loader_interface( \n",
    "            exp, args[\"batchsize\"], args[\"mu\"], n_iters_per_epoch, L=args[\"n_labeled\"], method='comatch')\n",
    "        dlval = sslDataset.get_val_loader_interface(exp, batch_size=64, num_workers=4, fold_idx=fold_idx)\n",
    "        dlval = sslDataset.get_test_loader_interface(exp, batch_size=64, num_workers=4, fold_idx=fold_idx)\n",
    "\n",
    "    wd_params, non_wd_params = [], []\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'bn' in name:\n",
    "            non_wd_params.append(param)  \n",
    "        else:\n",
    "            wd_params.append(param)\n",
    "    param_list = [\n",
    "        {'params': wd_params}, {'params': non_wd_params, 'weight_decay': 0}]\n",
    "    optim = torch.optim.SGD(param_list, lr=args[\"lr\"], weight_decay=args[\"weight_decay\"],\n",
    "                            momentum=args[\"momentum\"], nesterov=True)\n",
    "\n",
    "    lr_schdlr = WarmupCosineLrScheduler(optim, n_iters_all, warmup_iter=0)\n",
    "    \n",
    "    model, ema_model, optim, lr_schdlr, start_epoch, metrics, prob_list, queue = \\\n",
    "        load_from_checkpoint(output_dir, model, ema_model, optim, lr_schdlr)\n",
    "\n",
    "    # memory bank\n",
    "    args[\"queue_size\"] = args[\"queue_batch\"]*(args[\"mu\"]+1)*args[\"batchsize\"]\n",
    "    if queue is not None:\n",
    "        queue_feats = queue['queue_feats']\n",
    "        queue_probs = queue['queue_probs']\n",
    "        queue_ptr = queue['queue_ptr']\n",
    "    else:\n",
    "        queue_feats = torch.zeros(args[\"queue_size\"], args[\"low_dim\"]).cuda()\n",
    "        queue_probs = torch.zeros(args[\"queue_size\"], args[\"n_classes\"]).cuda()\n",
    "        queue_ptr = 0\n",
    "\n",
    "    train_args = dict(\n",
    "        model=model,\n",
    "        ema_model=ema_model,\n",
    "        emb_model=emb_model,\n",
    "        prob_list=prob_list,\n",
    "        criteria_x=criteria_x,\n",
    "        optim=optim,\n",
    "        lr_schdlr=lr_schdlr,\n",
    "        dltrain_x=dltrain_x,\n",
    "        dltrain_u=dltrain_u,\n",
    "        args=args,\n",
    "        n_iters=n_iters_per_epoch,\n",
    "        logger=logger\n",
    "    )\n",
    "    \n",
    "    best_acc = -1\n",
    "    best_epoch = 0\n",
    "\n",
    "    if metrics is not None:\n",
    "        best_acc = metrics['best_acc']\n",
    "        best_epoch = metrics['best_epoch']\n",
    "    logger.info('-----------start training--------------')\n",
    "    for epoch in range(start_epoch, args[\"n_epoches\"]):\n",
    "        \n",
    "        loss_x, loss_u, loss_c, mask_mean, num_pos, guess_label_acc, queue_feats, queue_probs, queue_ptr, prob_list = \\\n",
    "        train_one_epoch(epoch, **train_args, queue_feats=queue_feats,queue_probs=queue_probs,queue_ptr=queue_ptr)\n",
    "\n",
    "        top1, ema_top1 = evaluate(model, ema_model, emb_model, dlval)\n",
    "\n",
    "\n",
    "        tb_logger.add_scalar('loss_x', loss_x, epoch)\n",
    "        tb_logger.add_scalar('loss_u', loss_u, epoch)\n",
    "        tb_logger.add_scalar('loss_c', loss_c, epoch)\n",
    "        tb_logger.add_scalar('guess_label_acc', guess_label_acc, epoch)\n",
    "        tb_logger.add_scalar('test_acc', top1, epoch)\n",
    "        tb_logger.add_scalar('test_ema_acc', ema_top1, epoch)\n",
    "        tb_logger.add_scalar('mask', mask_mean, epoch)\n",
    "        tb_logger.add_scalar('num_pos', num_pos, epoch)\n",
    "\n",
    "        if best_acc < top1:\n",
    "            best_acc = top1\n",
    "            best_epoch = epoch\n",
    "\n",
    "        logger.info(\"Epoch {}. Acc: {:.4f}. Ema-Acc: {:.4f}. best_acc: {:.4f} in epoch{}\".\n",
    "                    format(epoch, top1, ema_top1, best_acc, best_epoch))\n",
    "        \n",
    "        save_obj = {\n",
    "            'model': model.state_dict(),\n",
    "            'ema_model': ema_model.state_dict(),\n",
    "            'optimizer': optim.state_dict(),\n",
    "            'lr_scheduler': lr_schdlr.state_dict(),\n",
    "            'prob_list': prob_list,\n",
    "            'queue': {'queue_feats':queue_feats, 'queue_probs':queue_probs, 'queue_ptr':queue_ptr},\n",
    "            'metrics': {'best_acc': best_acc, 'best_epoch': best_epoch},\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        #torch.save(save_obj, os.path.join(output_dir, 'ckp.latest'))\n",
    "    _, _ = evaluate(model, ema_model, emb_model, dlval)\n",
    "\n",
    "    return emb_model, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d0d96b9-1e74-4445-9696-99f0c024c4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIH\n",
      "2023-07-03 12:06:02,666 - INFO - train -   {'root': '', 'dataset': 'NIH', 'wresnet_k': 2, 'wresnet_n': 28, 'n_classes': 2, 'n_labeled': 12, 'n_epoches': 10, 'batchsize': 16, 'mu': 7, 'n_imgs_per_epoch': 32768, 'eval_ema': True, 'ema_m': 0.999, 'lam_u': 1.0, 'lr': 0.03, 'weight_decay': 0.0005, 'momentum': 0.9, 'seed': 2, 'temperature': 0.2, 'low_dim': 64, 'lam_c': 1, 'contrast_th': 0.8, 'thr': 0.95, 'alpha': 0.9, 'queue_batch': 5, 'exp_dir': 'EmbeddingCM_bin', 'ex_strength': 4295232296}\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joli/joli-env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/joli/joli-env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load Resnet-18 checkpoint\n",
      "None\n",
      "Loaded Model resnet18\n",
      "2023-07-03 12:06:02,973 - INFO - train -   Total params: 0.30M\n",
      "Index: 0\n",
      "Labels: 32\n",
      "Index: 0\n",
      "Index: 0\n",
      "No Checkpoint found at SSL_Working/NIH/EmbeddingCM_bin/ex4295232296_x12_seed2/ckp.latest\n",
      "Starting new from epoch 1\n",
      "2023-07-03 12:06:03,449 - INFO - train -   -----------start training--------------\n",
      "2023-07-03 12:06:26,918 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 64. loss_u: 0.558. loss_x: 1.951. loss_c: 4.719. n_correct_u: 11.75/98.02. Mask:0.875. num_pos: 93.5. LR: 0.030. Time: 23.47\n",
      "2023-07-03 12:06:48,416 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 128. loss_u: 0.428. loss_x: 0.976. loss_c: 4.718. n_correct_u: 11.84/100.08. Mask:0.894. num_pos: 95.1. LR: 0.030. Time: 21.49\n",
      "2023-07-03 12:07:09,779 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 192. loss_u: 0.372. loss_x: 0.652. loss_c: 4.718. n_correct_u: 11.73/98.90. Mask:0.883. num_pos: 93.4. LR: 0.030. Time: 21.36\n",
      "2023-07-03 12:07:31,270 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 256. loss_u: 0.338. loss_x: 0.490. loss_c: 4.716. n_correct_u: 11.43/96.41. Mask:0.861. num_pos: 90.3. LR: 0.030. Time: 21.48\n",
      "2023-07-03 12:07:52,766 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 320. loss_u: 0.301. loss_x: 0.392. loss_c: 4.712. n_correct_u: 11.27/94.65. Mask:0.845. num_pos: 88.5. LR: 0.030. Time: 21.49\n",
      "2023-07-03 12:08:14,200 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 384. loss_u: 0.270. loss_x: 0.327. loss_c: 4.701. n_correct_u: 10.83/90.88. Mask:0.811. num_pos: 85.0. LR: 0.030. Time: 21.43\n",
      "2023-07-03 12:08:35,684 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 448. loss_u: 0.246. loss_x: 0.281. loss_c: 4.684. n_correct_u: 10.42/86.39. Mask:0.771. num_pos: 80.8. LR: 0.030. Time: 21.48\n",
      "2023-07-03 12:08:57,197 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 512. loss_u: 0.224. loss_x: 0.246. loss_c: 4.659. n_correct_u: 9.95/81.61. Mask:0.729. num_pos: 76.4. LR: 0.030. Time: 21.51\n",
      "2023-07-03 12:09:18,795 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 576. loss_u: 0.207. loss_x: 0.219. loss_c: 4.635. n_correct_u: 9.53/77.16. Mask:0.689. num_pos: 72.4. LR: 0.030. Time: 21.59\n",
      "2023-07-03 12:09:40,459 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 640. loss_u: 0.211. loss_x: 0.259. loss_c: 4.621. n_correct_u: 9.41/75.33. Mask:0.673. num_pos: 70.9. LR: 0.030. Time: 21.66\n",
      "2023-07-03 12:10:02,104 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 704. loss_u: 0.214. loss_x: 0.236. loss_c: 4.629. n_correct_u: 9.59/77.09. Mask:0.688. num_pos: 72.4. LR: 0.030. Time: 21.64\n",
      "2023-07-03 12:10:23,737 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 768. loss_u: 0.208. loss_x: 0.216. loss_c: 4.630. n_correct_u: 9.64/77.28. Mask:0.690. num_pos: 72.4. LR: 0.030. Time: 21.63\n",
      "2023-07-03 12:10:45,293 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 832. loss_u: 0.202. loss_x: 0.200. loss_c: 4.630. n_correct_u: 9.63/77.07. Mask:0.688. num_pos: 72.2. LR: 0.030. Time: 21.56\n",
      "2023-07-03 12:11:06,790 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 896. loss_u: 0.209. loss_x: 0.316. loss_c: 4.629. n_correct_u: 9.61/76.70. Mask:0.685. num_pos: 72.1. LR: 0.030. Time: 21.50\n",
      "2023-07-03 12:11:28,296 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 960. loss_u: 0.222. loss_x: 0.298. loss_c: 4.635. n_correct_u: 9.77/78.21. Mask:0.698. num_pos: 73.5. LR: 0.030. Time: 21.50\n",
      "2023-07-03 12:11:49,850 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1024. loss_u: 0.220. loss_x: 0.279. loss_c: 4.640. n_correct_u: 9.92/79.89. Mask:0.713. num_pos: 75.3. LR: 0.030. Time: 21.55\n",
      "2023-07-03 12:12:11,369 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1088. loss_u: 0.217. loss_x: 0.263. loss_c: 4.644. n_correct_u: 10.03/81.05. Mask:0.724. num_pos: 76.4. LR: 0.030. Time: 21.52\n",
      "2023-07-03 12:12:32,933 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1152. loss_u: 0.213. loss_x: 0.249. loss_c: 4.646. n_correct_u: 10.09/81.62. Mask:0.729. num_pos: 77.0. LR: 0.030. Time: 21.56\n",
      "2023-07-03 12:12:54,417 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1216. loss_u: 0.207. loss_x: 0.236. loss_c: 4.648. n_correct_u: 10.17/82.34. Mask:0.735. num_pos: 77.7. LR: 0.030. Time: 21.48\n",
      "2023-07-03 12:13:15,828 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1280. loss_u: 0.203. loss_x: 0.224. loss_c: 4.647. n_correct_u: 10.18/82.34. Mask:0.735. num_pos: 77.6. LR: 0.030. Time: 21.41\n",
      "2023-07-03 12:13:37,221 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1344. loss_u: 0.198. loss_x: 0.213. loss_c: 4.644. n_correct_u: 10.14/81.89. Mask:0.731. num_pos: 77.2. LR: 0.030. Time: 21.39\n",
      "2023-07-03 12:13:58,721 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1408. loss_u: 0.195. loss_x: 0.204. loss_c: 4.644. n_correct_u: 10.11/81.66. Mask:0.729. num_pos: 76.9. LR: 0.030. Time: 21.50\n",
      "2023-07-03 12:14:20,205 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1472. loss_u: 0.191. loss_x: 0.195. loss_c: 4.640. n_correct_u: 10.06/80.88. Mask:0.722. num_pos: 76.1. LR: 0.030. Time: 21.48\n",
      "2023-07-03 12:14:41,643 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1536. loss_u: 0.189. loss_x: 0.189. loss_c: 4.640. n_correct_u: 10.00/80.38. Mask:0.718. num_pos: 75.7. LR: 0.030. Time: 21.44\n",
      "2023-07-03 12:15:03,019 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1600. loss_u: 0.187. loss_x: 0.182. loss_c: 4.640. n_correct_u: 10.01/80.27. Mask:0.717. num_pos: 75.5. LR: 0.030. Time: 21.37\n",
      "2023-07-03 12:15:24,436 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1664. loss_u: 0.184. loss_x: 0.175. loss_c: 4.638. n_correct_u: 10.00/80.06. Mask:0.715. num_pos: 75.3. LR: 0.030. Time: 21.42\n",
      "2023-07-03 12:15:45,882 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1728. loss_u: 0.182. loss_x: 0.169. loss_c: 4.637. n_correct_u: 10.01/79.92. Mask:0.714. num_pos: 75.1. LR: 0.030. Time: 21.45\n",
      "2023-07-03 12:16:07,296 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1792. loss_u: 0.179. loss_x: 0.163. loss_c: 4.636. n_correct_u: 9.99/79.72. Mask:0.712. num_pos: 74.9. LR: 0.030. Time: 21.41\n",
      "2023-07-03 12:16:28,761 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1856. loss_u: 0.183. loss_x: 0.186. loss_c: 4.634. n_correct_u: 9.99/79.42. Mask:0.709. num_pos: 74.6. LR: 0.030. Time: 21.46\n",
      "2023-07-03 12:16:50,277 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1920. loss_u: 0.186. loss_x: 0.180. loss_c: 4.637. n_correct_u: 10.04/79.99. Mask:0.714. num_pos: 75.1. LR: 0.030. Time: 21.51\n",
      "2023-07-03 12:17:11,755 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 1984. loss_u: 0.187. loss_x: 0.175. loss_c: 4.639. n_correct_u: 10.08/80.33. Mask:0.717. num_pos: 75.3. LR: 0.030. Time: 21.48\n",
      "2023-07-03 12:17:32,324 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:0, iter: 2048. loss_u: 0.185. loss_x: 0.169. loss_c: 4.640. n_correct_u: 10.09/80.59. Mask:0.720. num_pos: 75.6. LR: 0.030. Time: 20.57\n",
      "2023-07-03 12:17:33,108 - INFO - train -   Epoch 0. Acc: 12.4681. Ema-Acc: 12.2130. best_acc: 12.4681 in epoch0\n",
      "2023-07-03 12:17:55,935 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 64. loss_u: 0.117. loss_x: 0.003. loss_c: 4.584. n_correct_u: 9.31/71.72. Mask:0.640. num_pos: 65.9. LR: 0.030. Time: 22.82\n",
      "2023-07-03 12:18:17,575 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 128. loss_u: 0.110. loss_x: 0.003. loss_c: 4.614. n_correct_u: 9.64/76.16. Mask:0.680. num_pos: 71.7. LR: 0.030. Time: 21.63\n",
      "2023-07-03 12:18:39,186 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 192. loss_u: 0.110. loss_x: 0.003. loss_c: 4.603. n_correct_u: 9.51/73.72. Mask:0.658. num_pos: 69.4. LR: 0.030. Time: 21.61\n",
      "2023-07-03 12:19:00,926 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 256. loss_u: 0.112. loss_x: 0.008. loss_c: 4.608. n_correct_u: 9.61/74.02. Mask:0.661. num_pos: 70.1. LR: 0.030. Time: 21.74\n",
      "2023-07-03 12:19:22,545 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 320. loss_u: 0.162. loss_x: 0.180. loss_c: 4.626. n_correct_u: 9.82/77.08. Mask:0.688. num_pos: 73.6. LR: 0.030. Time: 21.62\n",
      "2023-07-03 12:19:44,046 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 384. loss_u: 0.168. loss_x: 0.150. loss_c: 4.639. n_correct_u: 10.06/79.96. Mask:0.714. num_pos: 75.9. LR: 0.030. Time: 21.50\n",
      "2023-07-03 12:20:05,714 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 448. loss_u: 0.161. loss_x: 0.129. loss_c: 4.647. n_correct_u: 10.23/82.50. Mask:0.737. num_pos: 78.5. LR: 0.030. Time: 21.66\n",
      "2023-07-03 12:20:27,274 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 512. loss_u: 0.154. loss_x: 0.113. loss_c: 4.648. n_correct_u: 10.29/82.77. Mask:0.739. num_pos: 78.7. LR: 0.030. Time: 21.56\n",
      "2023-07-03 12:20:48,953 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 576. loss_u: 0.151. loss_x: 0.101. loss_c: 4.647. n_correct_u: 10.22/81.98. Mask:0.732. num_pos: 77.9. LR: 0.030. Time: 21.67\n",
      "2023-07-03 12:21:10,568 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 640. loss_u: 0.146. loss_x: 0.091. loss_c: 4.644. n_correct_u: 10.20/81.50. Mask:0.728. num_pos: 77.5. LR: 0.030. Time: 21.61\n",
      "2023-07-03 12:21:32,256 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 704. loss_u: 0.154. loss_x: 0.112. loss_c: 4.648. n_correct_u: 10.20/81.72. Mask:0.730. num_pos: 77.7. LR: 0.029. Time: 21.69\n",
      "2023-07-03 12:21:53,860 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 768. loss_u: 0.152. loss_x: 0.102. loss_c: 4.651. n_correct_u: 10.28/82.41. Mask:0.736. num_pos: 78.3. LR: 0.029. Time: 21.60\n",
      "2023-07-03 12:22:15,432 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 832. loss_u: 0.148. loss_x: 0.095. loss_c: 4.649. n_correct_u: 10.29/82.49. Mask:0.737. num_pos: 78.4. LR: 0.029. Time: 21.57\n",
      "2023-07-03 12:22:37,016 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 896. loss_u: 0.145. loss_x: 0.088. loss_c: 4.649. n_correct_u: 10.26/82.07. Mask:0.733. num_pos: 77.9. LR: 0.029. Time: 21.58\n",
      "2023-07-03 12:22:58,783 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 960. loss_u: 0.141. loss_x: 0.082. loss_c: 4.642. n_correct_u: 10.17/81.24. Mask:0.725. num_pos: 77.0. LR: 0.029. Time: 21.77\n",
      "2023-07-03 12:23:20,450 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1024. loss_u: 0.138. loss_x: 0.077. loss_c: 4.637. n_correct_u: 10.12/80.40. Mask:0.718. num_pos: 76.1. LR: 0.029. Time: 21.66\n",
      "2023-07-03 12:23:42,151 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1088. loss_u: 0.138. loss_x: 0.078. loss_c: 4.636. n_correct_u: 10.09/80.09. Mask:0.715. num_pos: 75.8. LR: 0.029. Time: 21.70\n",
      "2023-07-03 12:24:03,836 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1152. loss_u: 0.138. loss_x: 0.074. loss_c: 4.634. n_correct_u: 10.11/79.94. Mask:0.714. num_pos: 75.4. LR: 0.029. Time: 21.68\n",
      "2023-07-03 12:24:25,400 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1216. loss_u: 0.136. loss_x: 0.073. loss_c: 4.631. n_correct_u: 10.05/79.30. Mask:0.708. num_pos: 74.7. LR: 0.029. Time: 21.56\n",
      "2023-07-03 12:24:47,155 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1280. loss_u: 0.136. loss_x: 0.070. loss_c: 4.632. n_correct_u: 10.07/79.43. Mask:0.709. num_pos: 74.8. LR: 0.029. Time: 21.75\n",
      "2023-07-03 12:25:08,957 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1344. loss_u: 0.136. loss_x: 0.067. loss_c: 4.633. n_correct_u: 10.10/79.53. Mask:0.710. num_pos: 74.9. LR: 0.029. Time: 21.80\n",
      "2023-07-03 12:25:30,625 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1408. loss_u: 0.134. loss_x: 0.064. loss_c: 4.628. n_correct_u: 10.02/78.84. Mask:0.704. num_pos: 74.2. LR: 0.029. Time: 21.67\n",
      "2023-07-03 12:25:52,323 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1472. loss_u: 0.133. loss_x: 0.061. loss_c: 4.626. n_correct_u: 9.97/78.38. Mask:0.700. num_pos: 73.7. LR: 0.029. Time: 21.70\n",
      "2023-07-03 12:26:14,101 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1536. loss_u: 0.140. loss_x: 0.109. loss_c: 4.626. n_correct_u: 9.98/78.33. Mask:0.699. num_pos: 73.8. LR: 0.029. Time: 21.77\n",
      "2023-07-03 12:26:35,828 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1600. loss_u: 0.145. loss_x: 0.105. loss_c: 4.630. n_correct_u: 10.05/79.18. Mask:0.707. num_pos: 74.6. LR: 0.029. Time: 21.73\n",
      "2023-07-03 12:26:57,536 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1664. loss_u: 0.145. loss_x: 0.101. loss_c: 4.632. n_correct_u: 10.10/79.89. Mask:0.713. num_pos: 75.3. LR: 0.029. Time: 21.71\n",
      "2023-07-03 12:27:19,207 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1728. loss_u: 0.144. loss_x: 0.098. loss_c: 4.633. n_correct_u: 10.12/80.13. Mask:0.715. num_pos: 75.5. LR: 0.029. Time: 21.66\n",
      "2023-07-03 12:27:40,942 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1792. loss_u: 0.143. loss_x: 0.094. loss_c: 4.633. n_correct_u: 10.13/80.19. Mask:0.716. num_pos: 75.5. LR: 0.029. Time: 21.73\n",
      "2023-07-03 12:28:02,590 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1856. loss_u: 0.143. loss_x: 0.094. loss_c: 4.633. n_correct_u: 10.08/79.91. Mask:0.713. num_pos: 75.2. LR: 0.029. Time: 21.65\n",
      "2023-07-03 12:28:24,248 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1920. loss_u: 0.144. loss_x: 0.093. loss_c: 4.635. n_correct_u: 10.11/80.23. Mask:0.716. num_pos: 75.7. LR: 0.029. Time: 21.66\n",
      "2023-07-03 12:28:45,945 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 1984. loss_u: 0.143. loss_x: 0.090. loss_c: 4.636. n_correct_u: 10.11/80.32. Mask:0.717. num_pos: 75.8. LR: 0.029. Time: 21.69\n",
      "2023-07-03 12:29:06,701 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:1, iter: 2048. loss_u: 0.142. loss_x: 0.088. loss_c: 4.635. n_correct_u: 10.10/80.25. Mask:0.717. num_pos: 75.7. LR: 0.029. Time: 20.76\n",
      "2023-07-03 12:29:07,541 - INFO - train -   Epoch 1. Acc: 12.2130. Ema-Acc: 12.6913. best_acc: 12.4681 in epoch0\n",
      "2023-07-03 12:29:30,412 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 64. loss_u: 0.096. loss_x: 0.001. loss_c: 4.566. n_correct_u: 8.03/65.97. Mask:0.589. num_pos: 62.5. LR: 0.029. Time: 22.85\n",
      "2023-07-03 12:29:52,228 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 128. loss_u: 0.115. loss_x: 0.041. loss_c: 4.567. n_correct_u: 8.10/64.78. Mask:0.578. num_pos: 62.0. LR: 0.029. Time: 21.81\n",
      "2023-07-03 12:30:13,915 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 192. loss_u: 0.112. loss_x: 0.028. loss_c: 4.589. n_correct_u: 8.79/70.04. Mask:0.625. num_pos: 66.7. LR: 0.029. Time: 21.68\n",
      "2023-07-03 12:30:35,585 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 256. loss_u: 0.109. loss_x: 0.022. loss_c: 4.582. n_correct_u: 8.79/68.90. Mask:0.615. num_pos: 65.7. LR: 0.029. Time: 21.67\n",
      "2023-07-03 12:30:57,527 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 320. loss_u: 0.108. loss_x: 0.019. loss_c: 4.572. n_correct_u: 8.67/67.89. Mask:0.606. num_pos: 64.8. LR: 0.029. Time: 21.94\n",
      "2023-07-03 12:31:19,362 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 384. loss_u: 0.108. loss_x: 0.017. loss_c: 4.583. n_correct_u: 8.93/69.81. Mask:0.623. num_pos: 66.8. LR: 0.029. Time: 21.83\n",
      "2023-07-03 12:31:41,082 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 448. loss_u: 0.106. loss_x: 0.015. loss_c: 4.581. n_correct_u: 8.99/70.09. Mask:0.626. num_pos: 66.8. LR: 0.029. Time: 21.72\n",
      "2023-07-03 12:32:02,885 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 512. loss_u: 0.108. loss_x: 0.029. loss_c: 4.585. n_correct_u: 9.09/70.89. Mask:0.633. num_pos: 67.5. LR: 0.029. Time: 21.80\n",
      "2023-07-03 12:32:24,439 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 576. loss_u: 0.106. loss_x: 0.026. loss_c: 4.587. n_correct_u: 9.22/71.87. Mask:0.642. num_pos: 68.3. LR: 0.029. Time: 21.55\n",
      "2023-07-03 12:32:46,062 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 640. loss_u: 0.141. loss_x: 0.110. loss_c: 4.596. n_correct_u: 9.31/73.09. Mask:0.653. num_pos: 69.7. LR: 0.028. Time: 21.62\n",
      "2023-07-03 12:33:07,677 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 704. loss_u: 0.158. loss_x: 0.100. loss_c: 4.606. n_correct_u: 9.50/75.34. Mask:0.673. num_pos: 71.6. LR: 0.028. Time: 21.61\n",
      "2023-07-03 12:33:29,348 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 768. loss_u: 0.163. loss_x: 0.092. loss_c: 4.615. n_correct_u: 9.72/77.50. Mask:0.692. num_pos: 73.7. LR: 0.028. Time: 21.66\n",
      "2023-07-03 12:33:50,892 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 832. loss_u: 0.164. loss_x: 0.085. loss_c: 4.622. n_correct_u: 9.82/78.68. Mask:0.702. num_pos: 74.7. LR: 0.028. Time: 21.54\n",
      "2023-07-03 12:34:12,566 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 896. loss_u: 0.162. loss_x: 0.079. loss_c: 4.626. n_correct_u: 9.91/79.64. Mask:0.711. num_pos: 75.5. LR: 0.028. Time: 21.67\n",
      "2023-07-03 12:34:34,195 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 960. loss_u: 0.159. loss_x: 0.074. loss_c: 4.629. n_correct_u: 9.94/80.21. Mask:0.716. num_pos: 76.1. LR: 0.028. Time: 21.63\n",
      "2023-07-03 12:34:55,809 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1024. loss_u: 0.156. loss_x: 0.069. loss_c: 4.628. n_correct_u: 9.93/80.13. Mask:0.715. num_pos: 75.8. LR: 0.028. Time: 21.61\n",
      "2023-07-03 12:35:17,473 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1088. loss_u: 0.154. loss_x: 0.066. loss_c: 4.628. n_correct_u: 9.97/80.37. Mask:0.718. num_pos: 75.8. LR: 0.028. Time: 21.66\n",
      "2023-07-03 12:35:39,154 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1152. loss_u: 0.153. loss_x: 0.062. loss_c: 4.627. n_correct_u: 9.97/80.20. Mask:0.716. num_pos: 75.5. LR: 0.028. Time: 21.68\n",
      "2023-07-03 12:36:00,724 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1216. loss_u: 0.151. loss_x: 0.059. loss_c: 4.628. n_correct_u: 9.99/80.37. Mask:0.718. num_pos: 75.7. LR: 0.028. Time: 21.57\n",
      "2023-07-03 12:36:22,414 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1280. loss_u: 0.148. loss_x: 0.056. loss_c: 4.624. n_correct_u: 9.95/79.72. Mask:0.712. num_pos: 75.1. LR: 0.028. Time: 21.69\n",
      "2023-07-03 12:36:44,157 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1344. loss_u: 0.145. loss_x: 0.054. loss_c: 4.616. n_correct_u: 9.84/78.67. Mask:0.702. num_pos: 74.0. LR: 0.028. Time: 21.74\n",
      "2023-07-03 12:37:05,772 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1408. loss_u: 0.156. loss_x: 0.087. loss_c: 4.621. n_correct_u: 9.91/79.51. Mask:0.710. num_pos: 74.9. LR: 0.028. Time: 21.61\n",
      "2023-07-03 12:37:27,382 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1472. loss_u: 0.160. loss_x: 0.083. loss_c: 4.625. n_correct_u: 9.95/79.99. Mask:0.714. num_pos: 75.2. LR: 0.028. Time: 21.61\n",
      "2023-07-03 12:37:49,094 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1536. loss_u: 0.159. loss_x: 0.080. loss_c: 4.628. n_correct_u: 9.99/80.55. Mask:0.719. num_pos: 75.8. LR: 0.028. Time: 21.71\n",
      "2023-07-03 12:38:10,811 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1600. loss_u: 0.158. loss_x: 0.077. loss_c: 4.629. n_correct_u: 9.98/80.50. Mask:0.719. num_pos: 75.7. LR: 0.028. Time: 21.71\n",
      "2023-07-03 12:38:32,498 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1664. loss_u: 0.155. loss_x: 0.074. loss_c: 4.628. n_correct_u: 9.97/80.39. Mask:0.718. num_pos: 75.6. LR: 0.028. Time: 21.69\n",
      "2023-07-03 12:38:54,176 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1728. loss_u: 0.153. loss_x: 0.071. loss_c: 4.625. n_correct_u: 9.91/79.86. Mask:0.713. num_pos: 75.1. LR: 0.028. Time: 21.68\n",
      "2023-07-03 12:39:15,857 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1792. loss_u: 0.152. loss_x: 0.069. loss_c: 4.623. n_correct_u: 9.89/79.58. Mask:0.711. num_pos: 74.8. LR: 0.028. Time: 21.68\n",
      "2023-07-03 12:39:37,437 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1856. loss_u: 0.149. loss_x: 0.066. loss_c: 4.621. n_correct_u: 9.88/79.35. Mask:0.708. num_pos: 74.6. LR: 0.028. Time: 21.58\n",
      "2023-07-03 12:39:59,231 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1920. loss_u: 0.148. loss_x: 0.064. loss_c: 4.618. n_correct_u: 9.85/79.04. Mask:0.706. num_pos: 74.3. LR: 0.028. Time: 21.79\n",
      "2023-07-03 12:40:20,929 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 1984. loss_u: 0.146. loss_x: 0.062. loss_c: 4.618. n_correct_u: 9.83/78.74. Mask:0.703. num_pos: 74.0. LR: 0.028. Time: 21.70\n",
      "2023-07-03 12:40:42,055 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:2, iter: 2048. loss_u: 0.145. loss_x: 0.061. loss_c: 4.616. n_correct_u: 9.82/78.57. Mask:0.702. num_pos: 73.8. LR: 0.027. Time: 21.13\n",
      "2023-07-03 12:40:42,900 - INFO - train -   Epoch 2. Acc: 12.4043. Ema-Acc: 12.6913. best_acc: 12.4681 in epoch0\n",
      "2023-07-03 12:41:05,894 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 64. loss_u: 0.109. loss_x: 0.006. loss_c: 4.542. n_correct_u: 8.50/62.44. Mask:0.557. num_pos: 55.7. LR: 0.027. Time: 22.97\n",
      "2023-07-03 12:41:27,853 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 128. loss_u: 0.182. loss_x: 0.156. loss_c: 4.586. n_correct_u: 9.12/69.00. Mask:0.616. num_pos: 63.3. LR: 0.027. Time: 21.96\n",
      "2023-07-03 12:41:49,680 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 192. loss_u: 0.179. loss_x: 0.105. loss_c: 4.618. n_correct_u: 9.70/75.17. Mask:0.671. num_pos: 68.9. LR: 0.027. Time: 21.83\n",
      "2023-07-03 12:42:11,607 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 256. loss_u: 0.163. loss_x: 0.080. loss_c: 4.623. n_correct_u: 10.09/78.16. Mask:0.698. num_pos: 72.1. LR: 0.027. Time: 21.93\n",
      "2023-07-03 12:42:33,401 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 320. loss_u: 0.150. loss_x: 0.064. loss_c: 4.620. n_correct_u: 10.08/78.37. Mask:0.700. num_pos: 72.3. LR: 0.027. Time: 21.79\n",
      "2023-07-03 12:42:55,244 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 384. loss_u: 0.148. loss_x: 0.056. loss_c: 4.610. n_correct_u: 10.08/77.68. Mask:0.694. num_pos: 70.9. LR: 0.027. Time: 21.84\n",
      "2023-07-03 12:43:17,019 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 448. loss_u: 0.145. loss_x: 0.050. loss_c: 4.608. n_correct_u: 10.15/77.93. Mask:0.696. num_pos: 70.6. LR: 0.027. Time: 21.77\n",
      "2023-07-03 12:43:38,710 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 512. loss_u: 0.142. loss_x: 0.044. loss_c: 4.602. n_correct_u: 10.09/77.42. Mask:0.691. num_pos: 70.0. LR: 0.027. Time: 21.69\n",
      "2023-07-03 12:44:00,501 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 576. loss_u: 0.138. loss_x: 0.040. loss_c: 4.599. n_correct_u: 10.11/77.41. Mask:0.691. num_pos: 69.9. LR: 0.027. Time: 21.78\n",
      "2023-07-03 12:44:22,277 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 640. loss_u: 0.163. loss_x: 0.108. loss_c: 4.605. n_correct_u: 10.08/77.83. Mask:0.695. num_pos: 71.1. LR: 0.027. Time: 21.77\n",
      "2023-07-03 12:44:44,072 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 704. loss_u: 0.171. loss_x: 0.098. loss_c: 4.613. n_correct_u: 10.23/79.50. Mask:0.710. num_pos: 72.7. LR: 0.027. Time: 21.79\n",
      "2023-07-03 12:45:05,785 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 768. loss_u: 0.170. loss_x: 0.090. loss_c: 4.620. n_correct_u: 10.35/80.99. Mask:0.723. num_pos: 74.3. LR: 0.027. Time: 21.71\n",
      "2023-07-03 12:45:27,472 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 832. loss_u: 0.167. loss_x: 0.083. loss_c: 4.624. n_correct_u: 10.44/81.80. Mask:0.730. num_pos: 75.1. LR: 0.027. Time: 21.68\n",
      "2023-07-03 12:45:49,310 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 896. loss_u: 0.167. loss_x: 0.078. loss_c: 4.621. n_correct_u: 10.43/81.75. Mask:0.730. num_pos: 74.7. LR: 0.027. Time: 21.84\n",
      "2023-07-03 12:46:11,125 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 960. loss_u: 0.165. loss_x: 0.073. loss_c: 4.624. n_correct_u: 10.48/82.19. Mask:0.734. num_pos: 75.3. LR: 0.027. Time: 21.81\n",
      "2023-07-03 12:46:32,777 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1024. loss_u: 0.160. loss_x: 0.069. loss_c: 4.625. n_correct_u: 10.49/82.53. Mask:0.737. num_pos: 75.7. LR: 0.027. Time: 21.65\n",
      "2023-07-03 12:46:54,550 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1088. loss_u: 0.158. loss_x: 0.065. loss_c: 4.624. n_correct_u: 10.48/82.46. Mask:0.736. num_pos: 75.6. LR: 0.027. Time: 21.77\n",
      "2023-07-03 12:47:16,354 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1152. loss_u: 0.156. loss_x: 0.062. loss_c: 4.622. n_correct_u: 10.48/82.23. Mask:0.734. num_pos: 75.2. LR: 0.026. Time: 21.80\n",
      "2023-07-03 12:47:38,120 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1216. loss_u: 0.155. loss_x: 0.059. loss_c: 4.620. n_correct_u: 10.47/82.12. Mask:0.733. num_pos: 74.9. LR: 0.026. Time: 21.76\n",
      "2023-07-03 12:47:59,819 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1280. loss_u: 0.153. loss_x: 0.056. loss_c: 4.619. n_correct_u: 10.47/82.20. Mask:0.734. num_pos: 75.0. LR: 0.026. Time: 21.70\n",
      "2023-07-03 12:48:21,536 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1344. loss_u: 0.158. loss_x: 0.072. loss_c: 4.620. n_correct_u: 10.48/82.20. Mask:0.734. num_pos: 75.0. LR: 0.026. Time: 21.72\n",
      "2023-07-03 12:48:43,546 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1408. loss_u: 0.158. loss_x: 0.069. loss_c: 4.622. n_correct_u: 10.51/82.54. Mask:0.737. num_pos: 75.4. LR: 0.026. Time: 22.01\n",
      "2023-07-03 12:49:05,728 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1472. loss_u: 0.156. loss_x: 0.066. loss_c: 4.623. n_correct_u: 10.53/82.82. Mask:0.739. num_pos: 75.7. LR: 0.026. Time: 22.18\n",
      "2023-07-03 12:49:27,801 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1536. loss_u: 0.155. loss_x: 0.064. loss_c: 4.624. n_correct_u: 10.54/82.99. Mask:0.741. num_pos: 75.9. LR: 0.026. Time: 22.07\n",
      "2023-07-03 12:49:49,768 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1600. loss_u: 0.153. loss_x: 0.061. loss_c: 4.622. n_correct_u: 10.53/82.72. Mask:0.739. num_pos: 75.7. LR: 0.026. Time: 21.97\n",
      "2023-07-03 12:50:11,886 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1664. loss_u: 0.152. loss_x: 0.059. loss_c: 4.622. n_correct_u: 10.54/82.79. Mask:0.739. num_pos: 75.8. LR: 0.026. Time: 22.12\n",
      "2023-07-03 12:50:33,734 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1728. loss_u: 0.150. loss_x: 0.057. loss_c: 4.621. n_correct_u: 10.50/82.45. Mask:0.736. num_pos: 75.5. LR: 0.026. Time: 21.85\n",
      "2023-07-03 12:50:55,476 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1792. loss_u: 0.148. loss_x: 0.055. loss_c: 4.618. n_correct_u: 10.48/82.16. Mask:0.734. num_pos: 75.1. LR: 0.026. Time: 21.74\n",
      "2023-07-03 12:51:17,333 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1856. loss_u: 0.147. loss_x: 0.053. loss_c: 4.618. n_correct_u: 10.47/82.01. Mask:0.732. num_pos: 75.1. LR: 0.026. Time: 21.84\n",
      "2023-07-03 12:51:39,187 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1920. loss_u: 0.146. loss_x: 0.052. loss_c: 4.618. n_correct_u: 10.44/81.64. Mask:0.729. num_pos: 74.8. LR: 0.026. Time: 21.85\n",
      "2023-07-03 12:52:01,184 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 1984. loss_u: 0.145. loss_x: 0.051. loss_c: 4.618. n_correct_u: 10.44/81.55. Mask:0.728. num_pos: 74.8. LR: 0.026. Time: 22.00\n",
      "2023-07-03 12:52:22,567 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:3, iter: 2048. loss_u: 0.144. loss_x: 0.050. loss_c: 4.618. n_correct_u: 10.43/81.46. Mask:0.727. num_pos: 74.8. LR: 0.026. Time: 21.38\n",
      "2023-07-03 12:52:23,408 - INFO - train -   Epoch 3. Acc: 12.4681. Ema-Acc: 12.6913. best_acc: 12.4681 in epoch0\n",
      "2023-07-03 12:52:46,376 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 64. loss_u: 0.097. loss_x: 0.002. loss_c: 4.592. n_correct_u: 10.03/76.28. Mask:0.681. num_pos: 71.5. LR: 0.026. Time: 22.96\n",
      "2023-07-03 12:53:08,303 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 128. loss_u: 0.216. loss_x: 0.338. loss_c: 4.628. n_correct_u: 9.91/77.44. Mask:0.691. num_pos: 74.9. LR: 0.025. Time: 21.92\n",
      "2023-07-03 12:53:30,242 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 192. loss_u: 0.206. loss_x: 0.225. loss_c: 4.653. n_correct_u: 10.34/83.25. Mask:0.743. num_pos: 79.6. LR: 0.025. Time: 21.93\n",
      "2023-07-03 12:53:52,018 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 256. loss_u: 0.188. loss_x: 0.169. loss_c: 4.661. n_correct_u: 10.57/85.41. Mask:0.763. num_pos: 81.5. LR: 0.025. Time: 21.78\n",
      "2023-07-03 12:54:13,971 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 320. loss_u: 0.172. loss_x: 0.135. loss_c: 4.652. n_correct_u: 10.48/84.36. Mask:0.753. num_pos: 80.0. LR: 0.025. Time: 21.95\n",
      "2023-07-03 12:54:35,848 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 384. loss_u: 0.164. loss_x: 0.115. loss_c: 4.652. n_correct_u: 10.41/83.95. Mask:0.750. num_pos: 79.6. LR: 0.025. Time: 21.88\n",
      "2023-07-03 12:54:57,838 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 448. loss_u: 0.160. loss_x: 0.100. loss_c: 4.645. n_correct_u: 10.42/83.37. Mask:0.744. num_pos: 78.4. LR: 0.025. Time: 21.99\n",
      "2023-07-03 12:55:19,764 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 512. loss_u: 0.151. loss_x: 0.087. loss_c: 4.638. n_correct_u: 10.41/83.05. Mask:0.742. num_pos: 77.9. LR: 0.025. Time: 21.92\n",
      "2023-07-03 12:55:41,594 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 576. loss_u: 0.144. loss_x: 0.078. loss_c: 4.632. n_correct_u: 10.36/82.43. Mask:0.736. num_pos: 77.1. LR: 0.025. Time: 21.83\n",
      "2023-07-03 12:56:03,516 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 640. loss_u: 0.140. loss_x: 0.071. loss_c: 4.622. n_correct_u: 10.32/81.60. Mask:0.729. num_pos: 75.9. LR: 0.025. Time: 21.92\n",
      "2023-07-03 12:56:25,421 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 704. loss_u: 0.137. loss_x: 0.065. loss_c: 4.622. n_correct_u: 10.30/81.49. Mask:0.728. num_pos: 76.0. LR: 0.025. Time: 21.90\n",
      "2023-07-03 12:56:47,181 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 768. loss_u: 0.135. loss_x: 0.060. loss_c: 4.625. n_correct_u: 10.32/81.86. Mask:0.731. num_pos: 76.4. LR: 0.025. Time: 21.76\n",
      "2023-07-03 12:57:09,070 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 832. loss_u: 0.132. loss_x: 0.056. loss_c: 4.621. n_correct_u: 10.27/81.17. Mask:0.725. num_pos: 75.9. LR: 0.025. Time: 21.89\n",
      "2023-07-03 12:57:31,195 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 896. loss_u: 0.129. loss_x: 0.052. loss_c: 4.618. n_correct_u: 10.17/80.27. Mask:0.717. num_pos: 75.2. LR: 0.025. Time: 22.12\n",
      "2023-07-03 12:57:53,139 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 960. loss_u: 0.128. loss_x: 0.049. loss_c: 4.617. n_correct_u: 10.10/79.50. Mask:0.710. num_pos: 74.5. LR: 0.025. Time: 21.94\n",
      "2023-07-03 12:58:15,091 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1024. loss_u: 0.126. loss_x: 0.047. loss_c: 4.613. n_correct_u: 10.02/78.64. Mask:0.702. num_pos: 73.8. LR: 0.024. Time: 21.94\n",
      "2023-07-03 12:58:37,045 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1088. loss_u: 0.124. loss_x: 0.044. loss_c: 4.610. n_correct_u: 9.98/78.15. Mask:0.698. num_pos: 73.3. LR: 0.024. Time: 21.95\n",
      "2023-07-03 12:58:58,888 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1152. loss_u: 0.122. loss_x: 0.042. loss_c: 4.607. n_correct_u: 9.93/77.72. Mask:0.694. num_pos: 72.9. LR: 0.024. Time: 21.84\n",
      "2023-07-03 12:59:20,876 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1216. loss_u: 0.121. loss_x: 0.040. loss_c: 4.602. n_correct_u: 9.88/77.06. Mask:0.688. num_pos: 72.0. LR: 0.024. Time: 21.99\n",
      "2023-07-03 12:59:42,793 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1280. loss_u: 0.121. loss_x: 0.043. loss_c: 4.598. n_correct_u: 9.85/76.60. Mask:0.684. num_pos: 71.4. LR: 0.024. Time: 21.91\n",
      "2023-07-03 13:00:04,932 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1344. loss_u: 0.120. loss_x: 0.041. loss_c: 4.599. n_correct_u: 9.84/76.77. Mask:0.685. num_pos: 71.7. LR: 0.024. Time: 22.14\n",
      "2023-07-03 13:00:26,951 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1408. loss_u: 0.120. loss_x: 0.040. loss_c: 4.598. n_correct_u: 9.83/76.64. Mask:0.684. num_pos: 71.4. LR: 0.024. Time: 22.01\n",
      "2023-07-03 13:00:48,866 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1472. loss_u: 0.120. loss_x: 0.039. loss_c: 4.597. n_correct_u: 9.84/76.54. Mask:0.683. num_pos: 71.3. LR: 0.024. Time: 21.91\n",
      "2023-07-03 13:01:10,815 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1536. loss_u: 0.120. loss_x: 0.038. loss_c: 4.597. n_correct_u: 9.85/76.57. Mask:0.684. num_pos: 71.4. LR: 0.024. Time: 21.95\n",
      "2023-07-03 13:01:32,652 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1600. loss_u: 0.119. loss_x: 0.036. loss_c: 4.597. n_correct_u: 9.88/76.72. Mask:0.685. num_pos: 71.5. LR: 0.024. Time: 21.84\n",
      "2023-07-03 13:01:54,443 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1664. loss_u: 0.123. loss_x: 0.050. loss_c: 4.600. n_correct_u: 9.90/76.99. Mask:0.687. num_pos: 71.8. LR: 0.024. Time: 21.79\n",
      "2023-07-03 13:02:16,375 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1728. loss_u: 0.123. loss_x: 0.048. loss_c: 4.602. n_correct_u: 9.96/77.64. Mask:0.693. num_pos: 72.4. LR: 0.024. Time: 21.92\n",
      "2023-07-03 13:02:38,340 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1792. loss_u: 0.123. loss_x: 0.046. loss_c: 4.603. n_correct_u: 9.98/77.86. Mask:0.695. num_pos: 72.5. LR: 0.024. Time: 21.96\n",
      "2023-07-03 13:03:00,308 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1856. loss_u: 0.123. loss_x: 0.045. loss_c: 4.604. n_correct_u: 9.98/77.89. Mask:0.695. num_pos: 72.5. LR: 0.023. Time: 21.96\n",
      "2023-07-03 13:03:22,179 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1920. loss_u: 0.123. loss_x: 0.044. loss_c: 4.603. n_correct_u: 9.99/77.87. Mask:0.695. num_pos: 72.4. LR: 0.023. Time: 21.87\n",
      "2023-07-03 13:03:44,100 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 1984. loss_u: 0.122. loss_x: 0.043. loss_c: 4.604. n_correct_u: 10.00/77.95. Mask:0.696. num_pos: 72.5. LR: 0.023. Time: 21.92\n",
      "2023-07-03 13:04:05,538 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:4, iter: 2048. loss_u: 0.121. loss_x: 0.041. loss_c: 4.603. n_correct_u: 10.00/77.84. Mask:0.695. num_pos: 72.3. LR: 0.023. Time: 21.44\n",
      "2023-07-03 13:04:06,387 - INFO - train -   Epoch 4. Acc: 12.2449. Ema-Acc: 12.6913. best_acc: 12.4681 in epoch0\n",
      "2023-07-03 13:04:29,536 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 64. loss_u: 0.100. loss_x: 0.005. loss_c: 4.609. n_correct_u: 10.36/78.86. Mask:0.704. num_pos: 75.8. LR: 0.023. Time: 23.13\n",
      "2023-07-03 13:04:51,558 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 128. loss_u: 0.205. loss_x: 0.142. loss_c: 4.636. n_correct_u: 10.23/77.38. Mask:0.691. num_pos: 74.4. LR: 0.023. Time: 22.02\n",
      "2023-07-03 13:05:13,527 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 192. loss_u: 0.188. loss_x: 0.095. loss_c: 4.650. n_correct_u: 10.50/82.31. Mask:0.735. num_pos: 78.3. LR: 0.023. Time: 21.97\n",
      "2023-07-03 13:05:35,387 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 256. loss_u: 0.170. loss_x: 0.071. loss_c: 4.657. n_correct_u: 10.55/83.59. Mask:0.746. num_pos: 79.4. LR: 0.023. Time: 21.86\n",
      "2023-07-03 13:05:57,243 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 320. loss_u: 0.160. loss_x: 0.057. loss_c: 4.645. n_correct_u: 10.43/82.24. Mask:0.734. num_pos: 77.7. LR: 0.023. Time: 21.86\n",
      "2023-07-03 13:06:19,148 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 384. loss_u: 0.153. loss_x: 0.053. loss_c: 4.645. n_correct_u: 10.41/82.30. Mask:0.735. num_pos: 77.9. LR: 0.023. Time: 21.90\n",
      "2023-07-03 13:06:41,028 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 448. loss_u: 0.145. loss_x: 0.045. loss_c: 4.645. n_correct_u: 10.39/82.22. Mask:0.734. num_pos: 77.6. LR: 0.023. Time: 21.88\n",
      "2023-07-03 13:07:02,881 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 512. loss_u: 0.143. loss_x: 0.041. loss_c: 4.630. n_correct_u: 10.16/80.02. Mask:0.714. num_pos: 75.1. LR: 0.023. Time: 21.85\n",
      "2023-07-03 13:07:24,823 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 576. loss_u: 0.139. loss_x: 0.038. loss_c: 4.627. n_correct_u: 10.21/79.96. Mask:0.714. num_pos: 74.8. LR: 0.022. Time: 21.94\n",
      "2023-07-03 13:07:46,731 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 640. loss_u: 0.140. loss_x: 0.045. loss_c: 4.623. n_correct_u: 10.17/79.23. Mask:0.707. num_pos: 74.1. LR: 0.022. Time: 21.91\n",
      "2023-07-03 13:08:08,523 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 704. loss_u: 0.137. loss_x: 0.041. loss_c: 4.624. n_correct_u: 10.23/79.93. Mask:0.714. num_pos: 74.6. LR: 0.022. Time: 21.78\n",
      "2023-07-03 13:08:30,297 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 768. loss_u: 0.137. loss_x: 0.038. loss_c: 4.622. n_correct_u: 10.24/79.69. Mask:0.712. num_pos: 74.1. LR: 0.022. Time: 21.77\n",
      "2023-07-03 13:08:52,281 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 832. loss_u: 0.135. loss_x: 0.036. loss_c: 4.621. n_correct_u: 10.26/79.64. Mask:0.711. num_pos: 74.2. LR: 0.022. Time: 21.98\n",
      "2023-07-03 13:09:14,217 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 896. loss_u: 0.131. loss_x: 0.034. loss_c: 4.619. n_correct_u: 10.27/79.68. Mask:0.711. num_pos: 74.2. LR: 0.022. Time: 21.94\n",
      "2023-07-03 13:09:36,011 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 960. loss_u: 0.130. loss_x: 0.032. loss_c: 4.619. n_correct_u: 10.23/79.41. Mask:0.709. num_pos: 74.0. LR: 0.022. Time: 21.79\n",
      "2023-07-03 13:09:57,959 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1024. loss_u: 0.128. loss_x: 0.030. loss_c: 4.609. n_correct_u: 10.11/78.04. Mask:0.697. num_pos: 72.6. LR: 0.022. Time: 21.95\n",
      "2023-07-03 13:10:19,859 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1088. loss_u: 0.126. loss_x: 0.029. loss_c: 4.610. n_correct_u: 10.09/77.92. Mask:0.696. num_pos: 72.7. LR: 0.022. Time: 21.89\n",
      "2023-07-03 13:10:41,743 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1152. loss_u: 0.124. loss_x: 0.028. loss_c: 4.606. n_correct_u: 9.99/76.98. Mask:0.687. num_pos: 71.8. LR: 0.022. Time: 21.88\n",
      "2023-07-03 13:11:03,618 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1216. loss_u: 0.128. loss_x: 0.038. loss_c: 4.609. n_correct_u: 10.01/77.51. Mask:0.692. num_pos: 72.3. LR: 0.022. Time: 21.87\n",
      "2023-07-03 13:11:25,496 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1280. loss_u: 0.127. loss_x: 0.036. loss_c: 4.608. n_correct_u: 10.02/77.50. Mask:0.692. num_pos: 72.1. LR: 0.021. Time: 21.88\n",
      "2023-07-03 13:11:47,468 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1344. loss_u: 0.127. loss_x: 0.035. loss_c: 4.608. n_correct_u: 10.05/77.64. Mask:0.693. num_pos: 72.1. LR: 0.021. Time: 21.97\n",
      "2023-07-03 13:12:09,317 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1408. loss_u: 0.125. loss_x: 0.033. loss_c: 4.606. n_correct_u: 10.04/77.55. Mask:0.692. num_pos: 72.0. LR: 0.021. Time: 21.84\n",
      "2023-07-03 13:12:31,126 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1472. loss_u: 0.124. loss_x: 0.032. loss_c: 4.607. n_correct_u: 10.08/77.91. Mask:0.696. num_pos: 72.3. LR: 0.021. Time: 21.81\n",
      "2023-07-03 13:12:52,933 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1536. loss_u: 0.123. loss_x: 0.031. loss_c: 4.606. n_correct_u: 10.05/77.64. Mask:0.693. num_pos: 72.1. LR: 0.021. Time: 21.80\n",
      "2023-07-03 13:13:14,909 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1600. loss_u: 0.122. loss_x: 0.030. loss_c: 4.605. n_correct_u: 10.02/77.29. Mask:0.690. num_pos: 71.8. LR: 0.021. Time: 21.97\n",
      "2023-07-03 13:13:36,735 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1664. loss_u: 0.121. loss_x: 0.029. loss_c: 4.605. n_correct_u: 10.03/77.28. Mask:0.690. num_pos: 71.7. LR: 0.021. Time: 21.82\n",
      "2023-07-03 13:13:58,658 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1728. loss_u: 0.121. loss_x: 0.032. loss_c: 4.602. n_correct_u: 10.00/76.88. Mask:0.686. num_pos: 71.3. LR: 0.021. Time: 21.92\n",
      "2023-07-03 13:14:20,463 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1792. loss_u: 0.127. loss_x: 0.036. loss_c: 4.605. n_correct_u: 10.05/77.42. Mask:0.691. num_pos: 71.8. LR: 0.021. Time: 21.80\n",
      "2023-07-03 13:14:42,264 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1856. loss_u: 0.126. loss_x: 0.035. loss_c: 4.607. n_correct_u: 10.09/77.98. Mask:0.696. num_pos: 72.4. LR: 0.021. Time: 21.79\n",
      "2023-07-03 13:15:04,124 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1920. loss_u: 0.126. loss_x: 0.034. loss_c: 4.609. n_correct_u: 10.13/78.30. Mask:0.699. num_pos: 72.7. LR: 0.021. Time: 21.86\n",
      "2023-07-03 13:15:25,935 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 1984. loss_u: 0.126. loss_x: 0.033. loss_c: 4.610. n_correct_u: 10.15/78.50. Mask:0.701. num_pos: 72.9. LR: 0.020. Time: 21.81\n",
      "2023-07-03 13:15:47,125 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:5, iter: 2048. loss_u: 0.125. loss_x: 0.032. loss_c: 4.609. n_correct_u: 10.12/78.22. Mask:0.698. num_pos: 72.6. LR: 0.020. Time: 21.19\n",
      "2023-07-03 13:15:47,973 - INFO - train -   Epoch 5. Acc: 11.9898. Ema-Acc: 12.9145. best_acc: 12.4681 in epoch0\n",
      "2023-07-03 13:16:11,025 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 64. loss_u: 0.092. loss_x: 0.001. loss_c: 4.503. n_correct_u: 9.73/72.00. Mask:0.643. num_pos: 63.4. LR: 0.020. Time: 23.03\n",
      "2023-07-03 13:16:32,867 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 128. loss_u: 0.092. loss_x: 0.004. loss_c: 4.522. n_correct_u: 9.56/72.23. Mask:0.645. num_pos: 63.8. LR: 0.020. Time: 21.84\n",
      "2023-07-03 13:16:54,813 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 192. loss_u: 0.096. loss_x: 0.004. loss_c: 4.535. n_correct_u: 9.73/72.57. Mask:0.648. num_pos: 64.5. LR: 0.020. Time: 21.94\n",
      "2023-07-03 13:17:16,707 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 256. loss_u: 0.092. loss_x: 0.005. loss_c: 4.553. n_correct_u: 9.88/74.71. Mask:0.667. num_pos: 67.7. LR: 0.020. Time: 21.89\n",
      "2023-07-03 13:17:38,552 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 320. loss_u: 0.093. loss_x: 0.005. loss_c: 4.562. n_correct_u: 9.97/75.74. Mask:0.676. num_pos: 69.2. LR: 0.020. Time: 21.84\n",
      "2023-07-03 13:18:00,424 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 384. loss_u: 0.095. loss_x: 0.006. loss_c: 4.557. n_correct_u: 9.86/74.81. Mask:0.668. num_pos: 68.0. LR: 0.020. Time: 21.87\n",
      "2023-07-03 13:18:22,215 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 448. loss_u: 0.095. loss_x: 0.006. loss_c: 4.565. n_correct_u: 9.94/75.59. Mask:0.675. num_pos: 69.3. LR: 0.020. Time: 21.79\n",
      "2023-07-03 13:18:44,133 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 512. loss_u: 0.096. loss_x: 0.006. loss_c: 4.570. n_correct_u: 10.00/75.95. Mask:0.678. num_pos: 69.8. LR: 0.020. Time: 21.92\n",
      "2023-07-03 13:19:05,881 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 576. loss_u: 0.098. loss_x: 0.008. loss_c: 4.569. n_correct_u: 9.86/74.81. Mask:0.668. num_pos: 68.8. LR: 0.019. Time: 21.75\n",
      "2023-07-03 13:19:27,794 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 640. loss_u: 0.101. loss_x: 0.008. loss_c: 4.572. n_correct_u: 9.88/75.01. Mask:0.670. num_pos: 69.1. LR: 0.019. Time: 21.91\n",
      "2023-07-03 13:19:49,580 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 704. loss_u: 0.114. loss_x: 0.046. loss_c: 4.582. n_correct_u: 10.01/76.36. Mask:0.682. num_pos: 70.5. LR: 0.019. Time: 21.79\n",
      "2023-07-03 13:20:11,363 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 768. loss_u: 0.112. loss_x: 0.042. loss_c: 4.590. n_correct_u: 10.16/78.30. Mask:0.699. num_pos: 72.5. LR: 0.019. Time: 21.77\n",
      "2023-07-03 13:20:33,257 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 832. loss_u: 0.116. loss_x: 0.039. loss_c: 4.592. n_correct_u: 10.22/78.62. Mask:0.702. num_pos: 72.4. LR: 0.019. Time: 21.89\n",
      "2023-07-03 13:20:55,015 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 896. loss_u: 0.116. loss_x: 0.037. loss_c: 4.590. n_correct_u: 10.19/78.65. Mask:0.702. num_pos: 72.2. LR: 0.019. Time: 21.75\n",
      "2023-07-03 13:21:16,987 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 960. loss_u: 0.117. loss_x: 0.035. loss_c: 4.592. n_correct_u: 10.24/79.03. Mask:0.706. num_pos: 72.5. LR: 0.019. Time: 21.97\n",
      "2023-07-03 13:21:38,876 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1024. loss_u: 0.116. loss_x: 0.033. loss_c: 4.592. n_correct_u: 10.25/79.33. Mask:0.708. num_pos: 72.6. LR: 0.019. Time: 21.89\n",
      "2023-07-03 13:22:00,842 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1088. loss_u: 0.115. loss_x: 0.031. loss_c: 4.592. n_correct_u: 10.25/79.39. Mask:0.709. num_pos: 72.6. LR: 0.019. Time: 21.96\n",
      "2023-07-03 13:22:22,981 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1152. loss_u: 0.114. loss_x: 0.030. loss_c: 4.591. n_correct_u: 10.22/79.13. Mask:0.707. num_pos: 72.4. LR: 0.019. Time: 22.13\n",
      "2023-07-03 13:22:44,892 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1216. loss_u: 0.114. loss_x: 0.028. loss_c: 4.591. n_correct_u: 10.20/78.79. Mask:0.703. num_pos: 72.0. LR: 0.019. Time: 21.91\n",
      "2023-07-03 13:23:06,694 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1280. loss_u: 0.114. loss_x: 0.027. loss_c: 4.589. n_correct_u: 10.15/78.38. Mask:0.700. num_pos: 71.5. LR: 0.018. Time: 21.80\n",
      "2023-07-03 13:23:28,629 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1344. loss_u: 0.114. loss_x: 0.026. loss_c: 4.588. n_correct_u: 10.12/78.01. Mask:0.696. num_pos: 71.2. LR: 0.018. Time: 21.93\n",
      "2023-07-03 13:23:50,420 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1408. loss_u: 0.113. loss_x: 0.025. loss_c: 4.586. n_correct_u: 10.13/77.85. Mask:0.695. num_pos: 71.0. LR: 0.018. Time: 21.78\n",
      "2023-07-03 13:24:12,254 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1472. loss_u: 0.112. loss_x: 0.025. loss_c: 4.584. n_correct_u: 10.13/77.83. Mask:0.695. num_pos: 70.9. LR: 0.018. Time: 21.83\n",
      "2023-07-03 13:24:34,166 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1536. loss_u: 0.112. loss_x: 0.024. loss_c: 4.582. n_correct_u: 10.10/77.55. Mask:0.692. num_pos: 70.6. LR: 0.018. Time: 21.91\n",
      "2023-07-03 13:24:55,953 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1600. loss_u: 0.111. loss_x: 0.023. loss_c: 4.580. n_correct_u: 10.09/77.38. Mask:0.691. num_pos: 70.4. LR: 0.018. Time: 21.78\n",
      "2023-07-03 13:25:17,828 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1664. loss_u: 0.112. loss_x: 0.024. loss_c: 4.580. n_correct_u: 10.05/77.00. Mask:0.688. num_pos: 70.1. LR: 0.018. Time: 21.87\n",
      "2023-07-03 13:25:39,650 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1728. loss_u: 0.111. loss_x: 0.023. loss_c: 4.581. n_correct_u: 10.05/77.05. Mask:0.688. num_pos: 70.2. LR: 0.018. Time: 21.82\n",
      "2023-07-03 13:26:01,553 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1792. loss_u: 0.110. loss_x: 0.022. loss_c: 4.579. n_correct_u: 10.06/76.91. Mask:0.687. num_pos: 70.0. LR: 0.018. Time: 21.90\n",
      "2023-07-03 13:26:23,644 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1856. loss_u: 0.111. loss_x: 0.022. loss_c: 4.578. n_correct_u: 10.03/76.69. Mask:0.685. num_pos: 69.7. LR: 0.017. Time: 22.09\n",
      "2023-07-03 13:26:45,575 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1920. loss_u: 0.111. loss_x: 0.021. loss_c: 4.578. n_correct_u: 10.04/76.78. Mask:0.686. num_pos: 69.8. LR: 0.017. Time: 21.93\n",
      "2023-07-03 13:27:07,424 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 1984. loss_u: 0.111. loss_x: 0.021. loss_c: 4.577. n_correct_u: 10.03/76.67. Mask:0.685. num_pos: 69.6. LR: 0.017. Time: 21.84\n",
      "2023-07-03 13:27:29,148 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:6, iter: 2048. loss_u: 0.110. loss_x: 0.021. loss_c: 4.575. n_correct_u: 10.03/76.68. Mask:0.685. num_pos: 69.5. LR: 0.017. Time: 21.72\n",
      "2023-07-03 13:27:30,004 - INFO - train -   Epoch 6. Acc: 12.6913. Ema-Acc: 12.2449. best_acc: 12.6913 in epoch6\n",
      "2023-07-03 13:27:53,063 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 64. loss_u: 0.119. loss_x: 0.013. loss_c: 4.542. n_correct_u: 9.06/66.75. Mask:0.596. num_pos: 57.8. LR: 0.017. Time: 23.04\n",
      "2023-07-03 13:28:15,056 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 128. loss_u: 0.109. loss_x: 0.009. loss_c: 4.574. n_correct_u: 9.66/72.99. Mask:0.652. num_pos: 65.1. LR: 0.017. Time: 21.99\n",
      "2023-07-03 13:28:37,002 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 192. loss_u: 0.104. loss_x: 0.008. loss_c: 4.577. n_correct_u: 9.76/72.79. Mask:0.650. num_pos: 65.3. LR: 0.017. Time: 21.95\n",
      "2023-07-03 13:28:58,927 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 256. loss_u: 0.104. loss_x: 0.008. loss_c: 4.558. n_correct_u: 9.62/71.16. Mask:0.635. num_pos: 62.8. LR: 0.017. Time: 21.92\n",
      "2023-07-03 13:29:20,831 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 320. loss_u: 0.106. loss_x: 0.008. loss_c: 4.563. n_correct_u: 9.62/71.42. Mask:0.638. num_pos: 63.1. LR: 0.017. Time: 21.90\n",
      "2023-07-03 13:29:42,822 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 384. loss_u: 0.104. loss_x: 0.008. loss_c: 4.561. n_correct_u: 9.58/71.28. Mask:0.636. num_pos: 62.9. LR: 0.017. Time: 21.99\n",
      "2023-07-03 13:30:04,680 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 448. loss_u: 0.104. loss_x: 0.008. loss_c: 4.562. n_correct_u: 9.51/70.83. Mask:0.632. num_pos: 62.3. LR: 0.016. Time: 21.85\n",
      "2023-07-03 13:30:26,679 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 512. loss_u: 0.104. loss_x: 0.007. loss_c: 4.549. n_correct_u: 9.59/70.73. Mask:0.632. num_pos: 61.4. LR: 0.016. Time: 22.00\n",
      "2023-07-03 13:30:48,560 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 576. loss_u: 0.105. loss_x: 0.009. loss_c: 4.551. n_correct_u: 9.66/70.99. Mask:0.634. num_pos: 62.1. LR: 0.016. Time: 21.87\n",
      "2023-07-03 13:31:10,468 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 640. loss_u: 0.104. loss_x: 0.009. loss_c: 4.550. n_correct_u: 9.67/71.29. Mask:0.636. num_pos: 62.3. LR: 0.016. Time: 21.91\n",
      "2023-07-03 13:31:32,481 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 704. loss_u: 0.103. loss_x: 0.008. loss_c: 4.547. n_correct_u: 9.71/71.40. Mask:0.637. num_pos: 62.4. LR: 0.016. Time: 22.01\n",
      "2023-07-03 13:31:54,475 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 768. loss_u: 0.105. loss_x: 0.012. loss_c: 4.551. n_correct_u: 9.64/71.12. Mask:0.635. num_pos: 62.5. LR: 0.016. Time: 21.99\n",
      "2023-07-03 13:32:16,452 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 832. loss_u: 0.105. loss_x: 0.011. loss_c: 4.555. n_correct_u: 9.70/71.46. Mask:0.638. num_pos: 63.1. LR: 0.016. Time: 21.98\n",
      "2023-07-03 13:32:38,440 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 896. loss_u: 0.105. loss_x: 0.011. loss_c: 4.556. n_correct_u: 9.71/71.79. Mask:0.641. num_pos: 63.4. LR: 0.016. Time: 21.99\n",
      "2023-07-03 13:33:00,550 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 960. loss_u: 0.104. loss_x: 0.011. loss_c: 4.556. n_correct_u: 9.67/71.47. Mask:0.638. num_pos: 63.2. LR: 0.016. Time: 22.10\n",
      "2023-07-03 13:33:22,502 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1024. loss_u: 0.104. loss_x: 0.010. loss_c: 4.553. n_correct_u: 9.65/71.35. Mask:0.637. num_pos: 62.9. LR: 0.015. Time: 21.95\n",
      "2023-07-03 13:33:44,372 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1088. loss_u: 0.104. loss_x: 0.010. loss_c: 4.552. n_correct_u: 9.65/71.43. Mask:0.638. num_pos: 62.9. LR: 0.015. Time: 21.87\n",
      "2023-07-03 13:34:06,376 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1152. loss_u: 0.102. loss_x: 0.010. loss_c: 4.548. n_correct_u: 9.67/71.48. Mask:0.638. num_pos: 63.0. LR: 0.015. Time: 22.00\n",
      "2023-07-03 13:34:28,374 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1216. loss_u: 0.102. loss_x: 0.010. loss_c: 4.546. n_correct_u: 9.61/71.22. Mask:0.636. num_pos: 62.7. LR: 0.015. Time: 22.00\n",
      "2023-07-03 13:34:50,414 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1280. loss_u: 0.102. loss_x: 0.010. loss_c: 4.545. n_correct_u: 9.65/71.37. Mask:0.637. num_pos: 62.8. LR: 0.015. Time: 22.04\n",
      "2023-07-03 13:35:12,350 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1344. loss_u: 0.103. loss_x: 0.010. loss_c: 4.540. n_correct_u: 9.64/71.21. Mask:0.636. num_pos: 62.2. LR: 0.015. Time: 21.94\n",
      "2023-07-03 13:35:34,413 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1408. loss_u: 0.102. loss_x: 0.009. loss_c: 4.540. n_correct_u: 9.63/71.36. Mask:0.637. num_pos: 62.3. LR: 0.015. Time: 22.06\n",
      "2023-07-03 13:35:56,338 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1472. loss_u: 0.101. loss_x: 0.009. loss_c: 4.539. n_correct_u: 9.66/71.57. Mask:0.639. num_pos: 62.5. LR: 0.015. Time: 21.92\n",
      "2023-07-03 13:36:18,326 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1536. loss_u: 0.102. loss_x: 0.009. loss_c: 4.536. n_correct_u: 9.62/71.39. Mask:0.637. num_pos: 62.1. LR: 0.015. Time: 21.99\n",
      "2023-07-03 13:36:40,322 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1600. loss_u: 0.101. loss_x: 0.009. loss_c: 4.535. n_correct_u: 9.61/71.34. Mask:0.637. num_pos: 62.0. LR: 0.014. Time: 21.99\n",
      "2023-07-03 13:37:02,300 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1664. loss_u: 0.101. loss_x: 0.009. loss_c: 4.534. n_correct_u: 9.62/71.54. Mask:0.639. num_pos: 62.2. LR: 0.014. Time: 21.97\n",
      "2023-07-03 13:37:24,217 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1728. loss_u: 0.100. loss_x: 0.009. loss_c: 4.532. n_correct_u: 9.61/71.47. Mask:0.638. num_pos: 62.1. LR: 0.014. Time: 21.92\n",
      "2023-07-03 13:37:46,322 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1792. loss_u: 0.100. loss_x: 0.009. loss_c: 4.531. n_correct_u: 9.59/71.43. Mask:0.638. num_pos: 62.0. LR: 0.014. Time: 22.10\n",
      "2023-07-03 13:38:08,309 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1856. loss_u: 0.099. loss_x: 0.009. loss_c: 4.533. n_correct_u: 9.62/71.67. Mask:0.640. num_pos: 62.4. LR: 0.014. Time: 21.99\n",
      "2023-07-03 13:38:30,225 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1920. loss_u: 0.099. loss_x: 0.009. loss_c: 4.532. n_correct_u: 9.61/71.66. Mask:0.640. num_pos: 62.5. LR: 0.014. Time: 21.92\n",
      "2023-07-03 13:38:52,127 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 1984. loss_u: 0.099. loss_x: 0.008. loss_c: 4.531. n_correct_u: 9.58/71.44. Mask:0.638. num_pos: 62.2. LR: 0.014. Time: 21.90\n",
      "2023-07-03 13:39:13,302 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:7, iter: 2048. loss_u: 0.099. loss_x: 0.008. loss_c: 4.531. n_correct_u: 9.57/71.32. Mask:0.637. num_pos: 62.1. LR: 0.014. Time: 21.17\n",
      "2023-07-03 13:39:14,147 - INFO - train -   Epoch 7. Acc: 12.4362. Ema-Acc: 12.6594. best_acc: 12.6913 in epoch6\n",
      "2023-07-03 13:39:37,353 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 64. loss_u: 0.088. loss_x: 0.011. loss_c: 4.548. n_correct_u: 9.97/71.44. Mask:0.638. num_pos: 65.8. LR: 0.014. Time: 23.19\n",
      "2023-07-03 13:39:59,297 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 128. loss_u: 0.092. loss_x: 0.010. loss_c: 4.550. n_correct_u: 9.92/71.74. Mask:0.641. num_pos: 66.2. LR: 0.013. Time: 21.94\n",
      "2023-07-03 13:40:21,314 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 192. loss_u: 0.090. loss_x: 0.009. loss_c: 4.522. n_correct_u: 9.31/68.20. Mask:0.609. num_pos: 61.5. LR: 0.013. Time: 22.02\n",
      "2023-07-03 13:40:43,321 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 256. loss_u: 0.092. loss_x: 0.009. loss_c: 4.525. n_correct_u: 9.26/67.88. Mask:0.606. num_pos: 60.9. LR: 0.013. Time: 22.01\n",
      "2023-07-03 13:41:05,383 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 320. loss_u: 0.092. loss_x: 0.009. loss_c: 4.522. n_correct_u: 9.28/68.11. Mask:0.608. num_pos: 60.8. LR: 0.013. Time: 22.06\n",
      "2023-07-03 13:41:27,452 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 384. loss_u: 0.091. loss_x: 0.008. loss_c: 4.520. n_correct_u: 9.37/69.00. Mask:0.616. num_pos: 61.3. LR: 0.013. Time: 22.07\n",
      "2023-07-03 13:41:49,415 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 448. loss_u: 0.092. loss_x: 0.008. loss_c: 4.520. n_correct_u: 9.33/68.81. Mask:0.614. num_pos: 60.8. LR: 0.013. Time: 21.96\n",
      "2023-07-03 13:42:11,528 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 512. loss_u: 0.094. loss_x: 0.012. loss_c: 4.521. n_correct_u: 9.35/69.07. Mask:0.617. num_pos: 60.7. LR: 0.013. Time: 22.11\n",
      "2023-07-03 13:42:33,531 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 576. loss_u: 0.095. loss_x: 0.011. loss_c: 4.522. n_correct_u: 9.36/69.09. Mask:0.617. num_pos: 60.6. LR: 0.013. Time: 22.00\n",
      "2023-07-03 13:42:55,614 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 640. loss_u: 0.093. loss_x: 0.011. loss_c: 4.520. n_correct_u: 9.38/69.34. Mask:0.619. num_pos: 60.7. LR: 0.012. Time: 22.08\n",
      "2023-07-03 13:43:17,542 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 704. loss_u: 0.093. loss_x: 0.010. loss_c: 4.525. n_correct_u: 9.41/69.86. Mask:0.624. num_pos: 61.6. LR: 0.012. Time: 21.93\n",
      "2023-07-03 13:43:39,362 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 768. loss_u: 0.092. loss_x: 0.010. loss_c: 4.523. n_correct_u: 9.39/69.66. Mask:0.622. num_pos: 61.4. LR: 0.012. Time: 21.82\n",
      "2023-07-03 13:44:01,410 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 832. loss_u: 0.092. loss_x: 0.010. loss_c: 4.520. n_correct_u: 9.31/69.06. Mask:0.617. num_pos: 60.7. LR: 0.012. Time: 22.05\n",
      "2023-07-03 13:44:23,267 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 896. loss_u: 0.093. loss_x: 0.010. loss_c: 4.515. n_correct_u: 9.32/68.92. Mask:0.615. num_pos: 60.3. LR: 0.012. Time: 21.85\n",
      "2023-07-03 13:44:45,322 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 960. loss_u: 0.092. loss_x: 0.010. loss_c: 4.516. n_correct_u: 9.34/69.20. Mask:0.618. num_pos: 60.5. LR: 0.012. Time: 22.05\n",
      "2023-07-03 13:45:07,403 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1024. loss_u: 0.092. loss_x: 0.009. loss_c: 4.515. n_correct_u: 9.37/69.35. Mask:0.619. num_pos: 60.7. LR: 0.012. Time: 22.08\n",
      "2023-07-03 13:45:29,304 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1088. loss_u: 0.091. loss_x: 0.009. loss_c: 4.514. n_correct_u: 9.39/69.27. Mask:0.618. num_pos: 60.6. LR: 0.012. Time: 21.90\n",
      "2023-07-03 13:45:51,217 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1152. loss_u: 0.091. loss_x: 0.009. loss_c: 4.511. n_correct_u: 9.33/68.76. Mask:0.614. num_pos: 60.1. LR: 0.012. Time: 21.91\n",
      "2023-07-03 13:46:13,119 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1216. loss_u: 0.091. loss_x: 0.009. loss_c: 4.512. n_correct_u: 9.31/68.69. Mask:0.613. num_pos: 60.0. LR: 0.011. Time: 21.90\n",
      "2023-07-03 13:46:34,766 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1280. loss_u: 0.090. loss_x: 0.009. loss_c: 4.513. n_correct_u: 9.30/68.76. Mask:0.614. num_pos: 60.2. LR: 0.011. Time: 21.64\n",
      "2023-07-03 13:46:56,641 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1344. loss_u: 0.089. loss_x: 0.009. loss_c: 4.512. n_correct_u: 9.33/68.77. Mask:0.614. num_pos: 60.3. LR: 0.011. Time: 21.87\n",
      "2023-07-03 13:47:18,380 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1408. loss_u: 0.089. loss_x: 0.009. loss_c: 4.508. n_correct_u: 9.29/68.37. Mask:0.610. num_pos: 59.8. LR: 0.011. Time: 21.73\n",
      "2023-07-03 13:47:40,243 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1472. loss_u: 0.089. loss_x: 0.009. loss_c: 4.507. n_correct_u: 9.28/68.34. Mask:0.610. num_pos: 59.8. LR: 0.011. Time: 21.86\n",
      "2023-07-03 13:48:02,038 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1536. loss_u: 0.088. loss_x: 0.008. loss_c: 4.506. n_correct_u: 9.28/68.32. Mask:0.610. num_pos: 59.8. LR: 0.011. Time: 21.79\n",
      "2023-07-03 13:48:23,991 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1600. loss_u: 0.088. loss_x: 0.008. loss_c: 4.506. n_correct_u: 9.28/68.25. Mask:0.609. num_pos: 59.7. LR: 0.011. Time: 21.95\n",
      "2023-07-03 13:48:45,797 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1664. loss_u: 0.087. loss_x: 0.008. loss_c: 4.503. n_correct_u: 9.27/68.19. Mask:0.609. num_pos: 59.6. LR: 0.011. Time: 21.80\n",
      "2023-07-03 13:49:07,648 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1728. loss_u: 0.087. loss_x: 0.008. loss_c: 4.501. n_correct_u: 9.23/67.88. Mask:0.606. num_pos: 59.3. LR: 0.010. Time: 21.84\n",
      "2023-07-03 13:49:29,427 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1792. loss_u: 0.087. loss_x: 0.008. loss_c: 4.501. n_correct_u: 9.22/67.85. Mask:0.606. num_pos: 59.2. LR: 0.010. Time: 21.78\n",
      "2023-07-03 13:49:51,388 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1856. loss_u: 0.087. loss_x: 0.008. loss_c: 4.500. n_correct_u: 9.23/67.86. Mask:0.606. num_pos: 59.2. LR: 0.010. Time: 21.96\n",
      "2023-07-03 13:50:13,289 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1920. loss_u: 0.087. loss_x: 0.008. loss_c: 4.499. n_correct_u: 9.23/67.85. Mask:0.606. num_pos: 59.1. LR: 0.010. Time: 21.90\n",
      "2023-07-03 13:50:35,162 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 1984. loss_u: 0.086. loss_x: 0.008. loss_c: 4.498. n_correct_u: 9.23/67.92. Mask:0.606. num_pos: 59.1. LR: 0.010. Time: 21.87\n",
      "2023-07-03 13:50:56,647 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:8, iter: 2048. loss_u: 0.086. loss_x: 0.008. loss_c: 4.498. n_correct_u: 9.23/67.95. Mask:0.607. num_pos: 59.2. LR: 0.010. Time: 21.48\n",
      "2023-07-03 13:50:57,473 - INFO - train -   Epoch 8. Acc: 12.2130. Ema-Acc: 12.8827. best_acc: 12.6913 in epoch6\n",
      "2023-07-03 13:51:20,800 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 64. loss_u: 0.077. loss_x: 0.006. loss_c: 4.468. n_correct_u: 8.81/63.48. Mask:0.567. num_pos: 54.4. LR: 0.010. Time: 23.31\n",
      "2023-07-03 13:51:42,736 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 128. loss_u: 0.083. loss_x: 0.007. loss_c: 4.447. n_correct_u: 8.55/61.77. Mask:0.552. num_pos: 51.5. LR: 0.010. Time: 21.93\n",
      "2023-07-03 13:52:04,698 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 192. loss_u: 0.080. loss_x: 0.006. loss_c: 4.466. n_correct_u: 8.83/63.56. Mask:0.568. num_pos: 53.6. LR: 0.009. Time: 21.96\n",
      "2023-07-03 13:52:26,530 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 256. loss_u: 0.079. loss_x: 0.006. loss_c: 4.468. n_correct_u: 8.88/64.54. Mask:0.576. num_pos: 54.6. LR: 0.009. Time: 21.83\n",
      "2023-07-03 13:52:48,493 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 320. loss_u: 0.078. loss_x: 0.006. loss_c: 4.471. n_correct_u: 8.95/65.07. Mask:0.581. num_pos: 55.4. LR: 0.009. Time: 21.96\n",
      "2023-07-03 13:53:10,533 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 384. loss_u: 0.078. loss_x: 0.006. loss_c: 4.466. n_correct_u: 8.88/64.61. Mask:0.577. num_pos: 54.8. LR: 0.009. Time: 22.04\n",
      "2023-07-03 13:53:32,240 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 448. loss_u: 0.078. loss_x: 0.006. loss_c: 4.459. n_correct_u: 8.83/64.10. Mask:0.572. num_pos: 54.2. LR: 0.009. Time: 21.70\n",
      "2023-07-03 13:53:54,104 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 512. loss_u: 0.078. loss_x: 0.006. loss_c: 4.452. n_correct_u: 8.80/63.68. Mask:0.569. num_pos: 53.5. LR: 0.009. Time: 21.86\n",
      "2023-07-03 13:54:16,017 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 576. loss_u: 0.079. loss_x: 0.006. loss_c: 4.447. n_correct_u: 8.80/63.73. Mask:0.569. num_pos: 53.2. LR: 0.009. Time: 21.91\n",
      "2023-07-03 13:54:37,919 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 640. loss_u: 0.078. loss_x: 0.006. loss_c: 4.447. n_correct_u: 8.83/63.90. Mask:0.571. num_pos: 53.3. LR: 0.009. Time: 21.90\n",
      "2023-07-03 13:54:59,875 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 704. loss_u: 0.078. loss_x: 0.006. loss_c: 4.446. n_correct_u: 8.88/64.21. Mask:0.573. num_pos: 53.6. LR: 0.008. Time: 21.95\n",
      "2023-07-03 13:55:21,756 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 768. loss_u: 0.077. loss_x: 0.006. loss_c: 4.444. n_correct_u: 8.91/64.57. Mask:0.577. num_pos: 53.7. LR: 0.008. Time: 21.88\n",
      "2023-07-03 13:55:43,555 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 832. loss_u: 0.077. loss_x: 0.006. loss_c: 4.445. n_correct_u: 8.98/64.93. Mask:0.580. num_pos: 54.0. LR: 0.008. Time: 21.80\n",
      "2023-07-03 13:56:05,461 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 896. loss_u: 0.076. loss_x: 0.006. loss_c: 4.441. n_correct_u: 8.94/64.74. Mask:0.578. num_pos: 53.9. LR: 0.008. Time: 21.90\n",
      "2023-07-03 13:56:27,412 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 960. loss_u: 0.076. loss_x: 0.006. loss_c: 4.439. n_correct_u: 8.98/64.76. Mask:0.578. num_pos: 53.8. LR: 0.008. Time: 21.95\n",
      "2023-07-03 13:56:49,343 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1024. loss_u: 0.076. loss_x: 0.006. loss_c: 4.437. n_correct_u: 8.93/64.49. Mask:0.576. num_pos: 53.5. LR: 0.008. Time: 21.93\n",
      "2023-07-03 13:57:11,241 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1088. loss_u: 0.077. loss_x: 0.006. loss_c: 4.434. n_correct_u: 8.92/64.42. Mask:0.575. num_pos: 53.3. LR: 0.008. Time: 21.90\n",
      "2023-07-03 13:57:33,204 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1152. loss_u: 0.077. loss_x: 0.005. loss_c: 4.428. n_correct_u: 8.94/64.52. Mask:0.576. num_pos: 53.0. LR: 0.008. Time: 21.96\n",
      "2023-07-03 13:57:55,099 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1216. loss_u: 0.077. loss_x: 0.005. loss_c: 4.427. n_correct_u: 8.96/64.55. Mask:0.576. num_pos: 52.9. LR: 0.007. Time: 21.89\n",
      "2023-07-03 13:58:16,948 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1280. loss_u: 0.077. loss_x: 0.005. loss_c: 4.427. n_correct_u: 8.98/64.68. Mask:0.577. num_pos: 53.1. LR: 0.007. Time: 21.85\n",
      "2023-07-03 13:58:38,729 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1344. loss_u: 0.076. loss_x: 0.005. loss_c: 4.427. n_correct_u: 8.97/64.63. Mask:0.577. num_pos: 53.0. LR: 0.007. Time: 21.78\n",
      "2023-07-03 13:59:00,636 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1408. loss_u: 0.076. loss_x: 0.005. loss_c: 4.427. n_correct_u: 8.98/64.70. Mask:0.578. num_pos: 53.2. LR: 0.007. Time: 21.90\n",
      "2023-07-03 13:59:22,520 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1472. loss_u: 0.076. loss_x: 0.005. loss_c: 4.426. n_correct_u: 8.96/64.61. Mask:0.577. num_pos: 53.1. LR: 0.007. Time: 21.88\n",
      "2023-07-03 13:59:44,452 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1536. loss_u: 0.076. loss_x: 0.005. loss_c: 4.426. n_correct_u: 8.96/64.59. Mask:0.577. num_pos: 53.0. LR: 0.007. Time: 21.93\n",
      "2023-07-03 14:00:06,352 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1600. loss_u: 0.076. loss_x: 0.005. loss_c: 4.424. n_correct_u: 8.95/64.51. Mask:0.576. num_pos: 52.9. LR: 0.007. Time: 21.89\n",
      "2023-07-03 14:00:28,283 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1664. loss_u: 0.076. loss_x: 0.005. loss_c: 4.423. n_correct_u: 8.95/64.43. Mask:0.575. num_pos: 52.8. LR: 0.007. Time: 21.93\n",
      "2023-07-03 14:00:50,098 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1728. loss_u: 0.075. loss_x: 0.005. loss_c: 4.419. n_correct_u: 8.96/64.35. Mask:0.575. num_pos: 52.6. LR: 0.006. Time: 21.81\n",
      "2023-07-03 14:01:33,896 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1856. loss_u: 0.075. loss_x: 0.005. loss_c: 4.417. n_correct_u: 8.96/64.25. Mask:0.574. num_pos: 52.5. LR: 0.006. Time: 21.91\n",
      "2023-07-03 14:01:55,771 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1920. loss_u: 0.075. loss_x: 0.005. loss_c: 4.416. n_correct_u: 8.97/64.18. Mask:0.573. num_pos: 52.4. LR: 0.006. Time: 21.87\n",
      "2023-07-03 14:02:17,684 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 1984. loss_u: 0.075. loss_x: 0.005. loss_c: 4.415. n_correct_u: 8.95/64.11. Mask:0.572. num_pos: 52.3. LR: 0.006. Time: 21.91\n",
      "2023-07-03 14:02:39,389 - INFO - train -   NIH-x12-s2, EmbeddingCM_bin | epoch:9, iter: 2048. loss_u: 0.075. loss_x: 0.005. loss_c: 4.413. n_correct_u: 8.95/64.06. Mask:0.572. num_pos: 52.2. LR: 0.006. Time: 21.70\n",
      "2023-07-03 14:02:40,232 - INFO - train -   Epoch 9. Acc: 13.3291. Ema-Acc: 13.3291. best_acc: 13.3291 in epoch9\n"
     ]
    }
   ],
   "source": [
    "emb_model, model = getExpertModelSSL(sslDataset=sslDataset, fold_idx=0, embedded_model=None, param=None, neptune_param=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a3ea7-5cf4-4dfb-8af2-dc1ec3959c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joli-env_kernel",
   "language": "python",
   "name": "joli-env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
